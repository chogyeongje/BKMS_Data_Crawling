제목,저자,게시 날짜,저널,권,호,페이지,게시자,설명,전체 인용횟수,학술 문서,컨퍼런스,도서,출처,기관,발명자,특허청,출원번호,특허 번호
Dropout: a simple way to prevent neural networks from overfitting,"Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov",2014/1/1,The journal of machine learning research,15,1,1929-1958,JMLR. org,"Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different “thinned” networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.",28491회,"Dropout: a simple way to prevent neural networks from overfitting
N Srivastava, G Hinton, A Krizhevsky, I Sutskever… - The journal of machine learning research, 2014
28491회 인용 관련 학술자료 전체 44개의 버전",,,,,,,,
Reducing the dimensionality of data with neural networks,"Geoffrey E Hinton, Ruslan R Salakhutdinov",2006/7/28,science,313,5786,504-507,American Association for the Advancement of Science,"High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such “autoencoder” networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.",15251회,"Reducing the dimensionality of data with neural networks
GE Hinton, RR Salakhutdinov - science, 2006
15251회 인용 관련 학술자료 전체 23개의 버전",,,,,,,,
"Show, attend and tell: Neural image caption generation with visual attention","Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard S Zemel, Yoshua Bengio",2015/2/10,,2,3,5,,"Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.",7141회,"Show, attend and tell: Neural image caption generation with visual attention
K Xu, J Ba, R Kiros, K Cho, A Courville… - International conference on machine learning, 2015
7141회 인용 관련 학술자료 전체 28개의 버전",International Conference on Machine Learning (ICML),,,,,,,
Improving neural networks by preventing co-adaptation of feature detectors,"Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, Ruslan R Salakhutdinov",2012/7/3,arXiv preprint arXiv:1207.0580,,,,,"When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This"" overfitting"" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random"" dropout"" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.",6456회,"Improving neural networks by preventing co-adaptation of feature detectors
GE Hinton, N Srivastava, A Krizhevsky, I Sutskever… - arXiv preprint arXiv:1207.0580, 2012
6431회 인용 관련 학술자료 전체 26개의 버전
Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv: 12070580*
GE Hinton, N Srivastava, A Krizhevsky, I Sutskever… - 2012
39회 인용 관련 학술자료",,,,,,,,
Semi-supervised learning using gaussian fields and harmonic functions,"Xiaojin Zhu, Zoubin Ghahramani, John D Lafferty",2003,,,,912-919,,"An approach to semi-supervised learning is proposed that is based on a Gaussian random field model. Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances. The learning problem is then formulated in terms of a Gaussian random field on this graph, where the mean of the field is characterized in terms of harmonic functions, and is efficiently obtained using matrix methods or belief propagation. The resulting learning algorithms have intimate connections with random walks, electric networks, and spectral graph theory. We discuss methods to incorporate class priors and the predictions of classifiers obtained by supervised learning. We also propose a method of parameter learning by entropy minimization, and show the algorithm’s ability to perform feature selection. Promising experimental results are presented for synthetic data, digit classification, and text classification tasks.",4246회,"Semi-supervised learning using gaussian fields and harmonic functions
X Zhu, Z Ghahramani, JD Lafferty - Proceedings of the 20th International conference on …, 2003
4246회 인용 관련 학술자료 전체 38개의 버전",Proceedings of the 20th International conference on Machine learning (ICML-03),,,,,,,
Probabilistic matrix factorization,"Andriy Mnih, Ruslan R Salakhutdinov",2008,,,,1257-1264,,"Many existing approaches to collaborative filtering can neither handle very large datasets nor easily deal with users who have very few ratings. In this paper we present the Probabilistic Matrix Factorization (PMF) model which scales linearly with the number of observations and, more importantly, performs well on the large, sparse, and very imbalanced Netflix dataset. We further extend the PMF model to include an adaptive prior on the model parameters and show how the model capacity can be controlled automatically. Finally, we introduce a constrained version of the PMF model that is based on the assumption that users who have rated similar sets of movies are likely to have similar preferences. The resulting model is able to generalize considerably better for users with very few ratings. When the predictions of multiple PMF models are linearly combined with the predictions of Restricted Boltzmann Machines models, we achieve an error rate of 0.8861, that is nearly 7% better than the score of Netflix’s own system.",4124회,"Probabilistic matrix factorization
A Mnih, RR Salakhutdinov - Advances in neural information processing systems, 2007
4109회 인용 관련 학술자료 전체 22개의 버전
Probabilistic matrix factorization*
S Ruslan, M Andriy - Advances in Neural Information Processing Systems, 2008
20회 인용 관련 학술자료",Advances in neural information processing systems,,,,,,,
Probabilistic matrix factorization,"Ruslan Salakhutdinov, Andriy Mnih",2007,,21,,,,,4109회,"Probabilistic matrix factorization*
A Mnih, RR Salakhutdinov - Advances in neural information processing systems, 2007
4109회 인용 관련 학술자료 전체 22개의 버전",Neural Information Processing Systems,,,,,,,
Deep Boltzmann Machines.,"Ruslan Salakhutdinov, Geoffrey E Hinton",2009/4/2,,1,,8,,"We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent expectations are estimated using a variational approximation that tends to focus on a single mode, and data-independent expectations are approximated using persistent Markov chains. The use of two quite different techniques for estimating the two types of expectation that enter into the gradient of the log-likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer “pre-training” phase that allows variational inference to be initialized by a single bottom-up pass. We present results on the MNIST and NORB datasets showing that deep Boltzmann machines learn good generative models and perform well on handwritten digit and visual object recognition tasks.",2755회,"Deep boltzmann machines
R Salakhutdinov, G Hinton - Artificial intelligence and statistics, 2009
2496회 인용 관련 학술자료 전체 27개의 버전
Efficient learning of deep Boltzmann machines*
R Salakhutdinov, H Larochelle - Proceedings of the thirteenth international conference …, 2010
408회 인용 관련 학술자료 전체 19개의 버전",International Conference on Artificial Intelligence and Statistics (AISTATS),,,,,,,
Xlnet: Generalized autoregressive pretraining for language understanding,"Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V Le",2019/6/19,arXiv preprint arXiv:1906.08237,,,,,"With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.",2682회,"Xlnet: Generalized autoregressive pretraining for language understanding
Z Yang, Z Dai, Y Yang, J Carbonell, R Salakhutdinov… - arXiv preprint arXiv:1906.08237, 2019
2682회 인용 관련 학술자료 전체 14개의 버전",,,,,,,,
Skip-thought vectors,"Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S Zemel, Antonio Torralba, Raquel Urtasun, Sanja Fidler",2015/6/22,arXiv preprint arXiv:1506.06726,,,,,"We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice. We will make our encoder publicly available.",2182회,"Skip-thought vectors
R Kiros, Y Zhu, R Salakhutdinov, RS Zemel, A Torralba… - arXiv preprint arXiv:1506.06726, 2015
2182회 인용 관련 학술자료 전체 14개의 버전",,,,,,,,
Principal manifolds and nonlinear dimensionality reduction via tangent space alignment,"Zhenyue Zhang, Hongyuan Zha",2004,SIAM journal on scientific computing,26,1,313-338,Society for Industrial and Applied Mathematics,"We present a new algorithm for manifold learning and nonlinear dimensionality reduction. Based on a set of unorganized data points sampled with noise from a parameterized manifold, the local geometry of the manifold is learned by constructing an approximation for the tangent space at each data point, and those tangent spaces are then aligned to give the global coordinates of the data points with respect to the underlying manifold. We also present an error analysis of our algorithm showing that reconstruction errors can be quite small in some cases. We illustrate our algorithm using curves and surfaces both in two-dimensional/three-dimensional (2D/3D) Euclidean spaces and in higher-dimensional Euclidean spaces. We also address several theoretical and algorithmic issues for further research and improvements.",2168회,"Principal manifolds and nonlinear dimensionality reduction via tangent space alignment
Z Zhang, H Zha - SIAM journal on scientific computing, 2004
2168회 인용 관련 학술자료 전체 23개의 버전",,,,,,,,
Siamese neural networks for one-shot image recognition,"Gregory Koch, Richard Zemel, Ruslan Salakhutdinov",2015/7/10,ICML deep learning workshop,2,,,,"The process of learning good features for machine learning applications can be very computationally expensive and may prove difficult in cases where little data is available. A prototypical example of this is the one-shot learning setting, in which we must correctly make predictions given only a single example of each new class.",2126회,"Siamese neural networks for one-shot image recognition
G Koch, R Zemel, R Salakhutdinov - ICML deep learning workshop, 2015
2126회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Restricted Boltzmann machines for collaborative filtering,"Ruslan Salakhutdinov, Andriy Mnih, Geoffrey Hinton",2007/6/20,,,,791-798,,"Most of the existing approaches to collaborative filtering cannot handle very large data sets. In this paper we show how a class of two-layer undirected graphical models, called Restricted Boltzmann Machines (RBM's), can be used to model tabular data, such as user's ratings of movies. We present efficient learning and inference procedures for this class of models and demonstrate that RBM's can be successfully applied to the Netflix data set, containing over 100 million user/movie ratings. We also show that RBM's slightly outperform carefully-tuned SVD models. When the predictions of multiple RBM models and multiple SVD models are linearly combined, we achieve an error rate that is well over 6% better than the score of Netflix's own system.",2049회,"Restricted Boltzmann machines for collaborative filtering
R Salakhutdinov, A Mnih, G Hinton - Proceedings of the 24th international conference on …, 2007
2049회 인용 관련 학술자료 전체 32개의 버전",,Proceedings of the 24th international conference on Machine learning,,,,,,
Unsupervised learning of video representations using lstms,"Nitish Srivastava, Elman Mansimov, Ruslan Salakhutdinov",2015/2/16,,2,,,,"We use Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences–patches of image pixels and high-level representations (“percepts"") of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We further evaluate the representations by finetuning them for a supervised learning problem–human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance.",1982회,"Unsupervised learning of video representations using lstms
N Srivastava, E Mansimov, R Salakhudinov - International conference on machine learning, 2015
1982회 인용 관련 학술자료 전체 19개의 버전",International Conference on Machine Learning (ICML),,,,,,,
Neighbourhood components analysis,"Jacob Goldberger, Geoffrey E Hinton, Sam Roweis, Russ R Salakhutdinov",2004,Advances in neural information processing systems,17,,513-520,,"In this paper we propose a novel method for learning a Mahalanobis distance measure to be used in the KNN classification algorithm. The algorithm directly maximizes a stochastic variant of the leave-one-out KNN score on the training set. It can also learn a low-dimensional linear embedding of labeled data that can be used for data visualization and fast classification. Unlike other methods, our classification model is non-parametric, making no assumptions about the shape of the class distributions or the boundaries between them. The performance of the method is demonstrated on several data sets, both for metric learning and linear dimensionality reduction.",1970회,"Neighbourhood components analysis
J Goldberger, GE Hinton, S Roweis, RR Salakhutdinov - Advances in neural information processing systems, 2004
1970회 인용 관련 학술자료 전체 20개의 버전",,,,,,,,
Human-level concept learning through probabilistic program induction,"Brenden M Lake, Ruslan Salakhutdinov, Joshua B Tenenbaum",2015/12/11,Science,350,6266,1332-1338,American Association for the Advancement of Science,"People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms—for action, imagination, and explanation. We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world’s alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches. We also present several “visual Turing tests” probing the model’s creative generalization abilities, which in many cases are indistinguishable from human …",1902회,"Human-level concept learning through probabilistic program induction
BM Lake, R Salakhutdinov, JB Tenenbaum - Science, 2015
1902회 인용 관련 학술자료 전체 35개의 버전",,,,,,,,
Unifying visual-semantic embeddings with multimodal neural language models,"Ryan Kiros, Ruslan Salakhutdinov, Richard S Zemel",2014/11/10,Transactions of the Association for Computational Linguistics (TACL),,,,,"Inspired by recent advances in multimodal learning and machine translation, we introduce an encoder-decoder pipeline that learns (a): a multimodal joint embedding space with images and text and (b): a novel language model for decoding distributed representations from our space. Our pipeline effectively unifies joint image-text embedding models with multimodal neural language models. We introduce the structure-content neural language model that disentangles the structure of a sentence to its content, conditioned on representations produced by the encoder. The encoder allows one to rank images and sentences while the decoder can generate novel descriptions from scratch. Using LSTM to encode sentences, we match the state-of-the-art performance on Flickr8K and Flickr30K without using object detections. We also set new best results when using the 19-layer Oxford convolutional network. Furthermore we show that with linear encoders, the learned embedding space captures multimodal regularities in terms of vector space arithmetic eg* image of a blue car*-"" blue""+"" red"" is near images of red cars. Sample captions generated for 800 images are made available for comparison.",1522회,"Unifying visual-semantic embeddings with multimodal neural language models
R Kiros, R Salakhutdinov, RS Zemel - arXiv preprint arXiv:1411.2539, 2014
1055회 인용 관련 학술자료 전체 6개의 버전
Multimodal neural language models*
R Kiros, R Salakhutdinov, R Zemel - International conference on machine learning, 2014
640회 인용 관련 학술자료 전체 21개의 버전",,,,,,,,
Bayesian probabilistic matrix factorization using Markov chain Monte Carlo,"Ruslan Salakhutdinov, Andriy Mnih",2008/7/5,,,,880-887,ACM,"Low-rank matrix approximation methods provide one of the simplest and most effective approaches to collaborative filtering. Such models are usually fitted to data by finding a MAP estimate of the model parameters, a procedure that can be performed efficiently even on very large datasets. However, unless the regularization parameters are tuned carefully, this approach is prone to overfitting because it finds a single point estimate of the parameters. In this paper we present a fully Bayesian treatment of the Probabilistic Matrix Factorization (PMF) model in which model capacity is controlled automatically by integrating over all model parameters and hyperparameters. We show that Bayesian PMF models can be efficiently trained using Markov chain Monte Carlo methods by applying them to the Netflix dataset, which consists of over 100 million movie ratings. The resulting models achieve significantly higher prediction …",1513회,"Bayesian probabilistic matrix factorization using Markov chain Monte Carlo
R Salakhutdinov, A Mnih - Proceedings of the 25th international conference on …, 2008
1513회 인용 관련 학술자료 전체 27개의 버전",Proceedings of the 25th international conference on Machine learning,,,,,,,
Bayesian probabilistic matrix factorization using Markov chain Monte Carlo,"Ruslan Salakhutdinov, Andriy Mnih",2008/7/5,,,,880-887,ACM,"Low-rank matrix approximation methods provide one of the simplest and most effective approaches to collaborative filtering. Such models are usually fitted to data by finding a MAP estimate of the model parameters, a procedure that can be performed efficiently even on very large datasets. However, unless the regularization parameters are tuned carefully, this approach is prone to overfitting because it finds a single point estimate of the parameters. In this paper we present a fully Bayesian treatment of the Probabilistic Matrix Factorization (PMF) model in which model capacity is controlled automatically by integrating over all model parameters and hyperparameters. We show that Bayesian PMF models can be efficiently trained using Markov chain Monte Carlo methods by applying them to the Netflix dataset, which consists of over 100 million movie ratings. The resulting models achieve significantly higher prediction …",1513회,"Bayesian probabilistic matrix factorization using Markov chain Monte Carlo
R Salakhutdinov, A Mnih - Proceedings of the 25th international conference on …, 2008
1513회 인용 관련 학술자료 전체 27개의 버전",Proceedings of the 25th international conference on Machine learning,,,,,,,
Bayesian probabilistic matrix factorization using Markov chain Monte Carlo,"Ruslan Salakhutdinov, Andriy Mnih",2008/7/5,,,,880-887,ACM,"Low-rank matrix approximation methods provide one of the simplest and most effective approaches to collaborative filtering. Such models are usually fitted to data by finding a MAP estimate of the model parameters, a procedure that can be performed efficiently even on very large datasets. However, unless the regularization parameters are tuned carefully, this approach is prone to overfitting because it finds a single point estimate of the parameters. In this paper we present a fully Bayesian treatment of the Probabilistic Matrix Factorization (PMF) model in which model capacity is controlled automatically by integrating over all model parameters and hyperparameters. We show that Bayesian PMF models can be efficiently trained using Markov chain Monte Carlo methods by applying them to the Netflix dataset, which consists of over 100 million movie ratings. The resulting models achieve significantly higher prediction …",1513회,"Bayesian probabilistic matrix factorization using Markov chain Monte Carlo
R Salakhutdinov, A Mnih - Proceedings of the 25th international conference on …, 2008
1513회 인용 관련 학술자료 전체 27개의 버전",Proceedings of the 25th international conference on Machine learning,,,,,,,
Multimodal Learning with Deep Boltzmann Machines.,"Nitish Srivastava, Ruslan Salakhutdinov",2012/12/3,NIPS,1,,2,,"Data often consists of multiple diverse modalities. For example, images are tagged with textual information and videos are accompanied by audio. Each modality is characterized by having distinct statistical properties. We propose a Deep Boltzmann Machine for learning a generative model of such multimodal data. We show that the model can be used to create fused representations by combining features across modalities. These learned representations are useful for classification and information retrieval. By sampling from the conditional distributions over each data modality, it is possible to create these representations even when some data modalities are missing. We conduct experiments on bi-modal image-text and audio-video data. The fused representation achieves good classification results on the MIR-Flickr data set matching or outperforming other deep models as well as SVM based models that use Multiple Kernel Learning. We further demonstrate that this multimodal model helps classification and retrieval even when only unimodal data is available at test time.",1314회,"Multimodal Learning with Deep Boltzmann Machines.
N Srivastava, R Salakhutdinov - NIPS, 2012
1314회 인용 관련 학술자료 전체 25개의 버전",,,,,,,,
Semantic hashing,"Ruslan Salakhutdinov, Geoffrey Hinton",2009/7/1,International Journal of Approximate Reasoning,50,7,969-978,Elsevier,"We show how to learn a deep graphical model of the word-count vectors obtained from a large set of documents. The values of the latent variables in the deepest layer are easy to infer and give a much better representation of each document than Latent Semantic Analysis. When the deepest layer is forced to use a small number of binary variables (e.g. 32), the graphical model performs “semantic hashing”: Documents are mapped to memory addresses in such a way that semantically similar documents are located at nearby addresses. Documents similar to a query document can then be found by simply accessing all the addresses that differ by only a few bits from the address of the query document. This way of extending the efficiency of hash-coding to approximate matching is much faster than locality sensitive hashing, which is the fastest current method. By using semantic hashing to filter the documents given to …",1233회,"Semantic hashing
R Salakhutdinov, G Hinton - International Journal of Approximate Reasoning, 2009
1233회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
Transformer-xl: Attentive language models beyond a fixed-length context,"Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V Le, Ruslan Salakhutdinov",2019/1/9,arXiv preprint arXiv:1901.02860,,,,,"Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.",1118회,"Transformer-xl: Attentive language models beyond a fixed-length context
Z Dai, Z Yang, Y Yang, J Carbonell, QV Le… - arXiv preprint arXiv:1901.02860, 2019
1118회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Aligning books and movies: Towards story-like visual explanations by watching movies and reading books,"Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, Sanja Fidler",2015,,,,19-27,,"Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in the current datasets. To align movies and books we propose a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for.",1070회,"Aligning books and movies: Towards story-like visual explanations by watching movies and reading books
Y Zhu, R Kiros, R Zemel, R Salakhutdinov, R Urtasun… - Proceedings of the IEEE international conference on …, 2015
1070회 인용 관련 학술자료 전체 16개의 버전",Proceedings of the IEEE international conference on computer vision,,,,,,,
Deep sets,"Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan Salakhutdinov, Alexander Smola",2017/3/10,arXiv preprint arXiv:1703.06114,,,,,"We study the problem of designing models for machine learning tasks defined on\emph {sets}. In contrast to traditional approach of operating on fixed dimensional vectors, we consider objective functions defined on sets that are invariant to permutations. Such problems are widespread, ranging from estimation of population statistics\cite {poczos13aistats}, to anomaly detection in piezometer data of embankment dams\cite {Jung15Exploration}, to cosmology\cite {Ntampaka16Dynamical, Ravanbakhsh16ICML1}. Our main theorem characterizes the permutation invariant functions and provides a family of functions to which any permutation invariant objective function must belong. This family of functions has a special structure which enables us to design a deep network architecture that can operate on sets and which can be deployed on a variety of scenarios including both unsupervised and supervised learning tasks. We also derive the necessary and sufficient conditions for permutation equivariance in deep models. We demonstrate the applicability of our method on population statistic estimation, point cloud classification, set expansion, and outlier detection.",934회,"Deep sets
M Zaheer, S Kottur, S Ravanbakhsh, B Poczos… - arXiv preprint arXiv:1703.06114, 2017
934회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Evaluation methods for topic models,"Hanna M Wallach, Iain Murray, Ruslan Salakhutdinov, David Mimno",2009/6/14,,,,1105-1112,,"A natural evaluation metric for statistical topic models is the probability of held-out documents given a trained model. While exact computation of this probability is intractable, several estimators for this probability have been used in the topic modeling literature, including the harmonic mean method and empirical likelihood method. In this paper, we demonstrate experimentally that commonly-used methods are unlikely to accurately estimate the probability of held-out documents, and propose two alternative methods that are both accurate and efficient.",904회,"Evaluation methods for topic models
HM Wallach, I Murray, R Salakhutdinov, D Mimno - Proceedings of the 26th annual international …, 2009
904회 인용 관련 학술자료 전체 26개의 버전",,Proceedings of the 26th annual international conference on machine learning,,,,,,
Revisiting Semi-Supervised Learning with Graph Embeddings,"Zhilin Yang, William Cohen, Ruslan Salakhutdinov",2016/3/29,,,,,,"We present a semi-supervised learning framework based on graph embeddings. Given a graph between instances, we train an embedding for each instance to jointly predict the class label and the neighborhood context in the graph. We develop both transductive and inductive variants of our method. In the transductive variant of our method, the class labels are determined by both the learned embeddings and input feature vectors, while in the inductive variant, the embeddings are defined as a parametric function of the feature vectors, so predictions can be made on instances not seen during training. On a large and diverse set of benchmark tasks, including text classification, distantly supervised entity extraction, and entity classification, we show improved performance over many of the existing models.",847회,"Revisiting semi-supervised learning with graph embeddings
Z Yang, W Cohen, R Salakhudinov - International conference on machine learning, 2016
847회 인용 관련 학술자료 전체 13개의 버전",International Conference on Machine Learning (ICML),,,,,,,
Importance weighted autoencoders,"Yuri Burda, Roger Grosse, Ruslan Salakhutdinov",2015/9/1,,,,,,"The variational autoencoder (VAE; Kingma, Welling (2014)) is a recently proposed generative model pairing a top-down generative network with a bottom-up recognition network which approximates posterior inference. It typically makes strong assumptions about posterior inference, for instance that the posterior distribution is approximately factorial, and that its parameters can be approximated with nonlinear regression from the observations. As we show empirically, the VAE objective can lead to overly simplified representations which fail to use the network's entire modeling capacity. We present the importance weighted autoencoder (IWAE), a generative model with the same architecture as the VAE, but which uses a strictly tighter log-likelihood lower bound derived from importance weighting. In the IWAE, the recognition network uses multiple samples to approximate the posterior, giving it increased flexibility to model complex posteriors which do not fit the VAE modeling assumptions. We show empirically that IWAEs learn richer latent space representations than VAEs, leading to improved test log-likelihood on density estimation benchmarks.",772회,"Importance weighted autoencoders
Y Burda, R Grosse, R Salakhutdinov - arXiv preprint arXiv:1509.00519, 2015
772회 인용 관련 학술자료 전체 3개의 버전",International Conference on Learning Representations (ICLR),,,,,,,
Multimodal Neural Language Models.,"Ryan Kiros, Ruslan Salakhutdinov, Richard S Zemel",2014/6/21,,14,,595-603,,"We introduce two multimodal neural language models: models of natural language that can be conditioned on other modalities. An image-text multimodal neural language model can be used to retrieve images given complex sentence queries, retrieve phrase descriptions given image queries, as well as generate text conditioned on images. We show that in the case of image-text modelling we can jointly learn word representations and image features by training our models together with a convolutional network. Unlike many of the existing methods, our approach can generate sentence descriptions for images without the use of templates, structured prediction, and/or syntactic trees. While we focus on image-text modelling, our algorithms can be easily applied to other modalities such as audio.",640회,"Multimodal neural language models
R Kiros, R Salakhutdinov, R Zemel - International conference on machine learning, 2014
640회 인용 관련 학술자료 전체 21개의 버전",International Conference on Machine Learning (ICML),,,,,,,
Toward controlled generation of text,"Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, Eric P Xing",2017/7/17,,,,1587-1596,PMLR,"Generic generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain. This paper aims at generating plausible text sentences, whose attributes are controlled by learning disentangled latent representations with designated semantics. We propose a new neural generative model which combines variational auto-encoders (VAEs) and holistic attribute discriminators for effective imposition of semantic structures. The model can alternatively be seen as enhancing VAEs with the wake-sleep algorithm for leveraging fake samples as extra training data. With differentiable approximation to discrete text samples, explicit constraints on independent attribute controls, and efficient collaborative learning of generator and discriminators, our model learns interpretable representations from even only word annotations, and produces short sentences with desired attributes of sentiment and tenses. Quantitative experiments using trained classifiers as evaluators validate the accuracy of sentence and attribute generation.",586회,"Toward controlled generation of text
Z Hu, Z Yang, X Liang, R Salakhutdinov, EP Xing - International Conference on Machine Learning, 2017
586회 인용 관련 학술자료 전체 9개의 버전",International Conference on Machine Learning,,,,,,,
Replicated softmax: an undirected topic model,"Ruslan Salakhutdinov, Geoffrey Hinton",2009,,,,1607-1614,,"We introduce a two-layer undirected graphical model, called a “Replicated Softmax”, that can be used to model and automatically extract low-dimensional latent semantic representations from a large unstructured collection of documents. We present efficient learning and inference algorithms for this model, and show how a Monte-Carlo based method, Annealed Importance Sampling, can be used to produce an accurate estimate of the log-probability the model assigns to test data. This allows us to demonstrate that the proposed model is able to generalize much better compared to Latent Dirichlet Allocation in terms of both the log-probability of held-out documents and the retrieval accuracy.",580회,"Replicated softmax: an undirected topic model
GE Hinton, RR Salakhutdinov - Advances in neural information processing systems, 2009
580회 인용 관련 학술자료 전체 14개의 버전",Advances in neural information processing systems,,,,,,,
Action recognition using visual attention,"Shikhar Sharma, Ryan Kiros, Ruslan Salakhutdinov",2015/11/12,,,,,,"We propose a soft attention based model for the task of action recognition in videos. We use multi-layered Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units which are deep both spatially and temporally. Our model learns to focus selectively on parts of the video frames and classifies videos after taking a few glimpses. The model essentially learns which parts in the frames are relevant for the task at hand and attaches higher importance to them. We evaluate the model on UCF-11 (YouTube Action), HMDB-51 and Hollywood2 datasets and analyze how the model focuses its attention depending on the scene and the action being performed.",578회,"Action recognition using visual attention
S Sharma, R Kiros, R Salakhutdinov - arXiv preprint arXiv:1511.04119, 2015
578회 인용 관련 학술자료 전체 9개의 버전","International Conference on Learning Representations (ICLR) , workshop",,,,,,,
Hamming distance metric learning,"Mohammad Norouzi, David J Fleet, Russ R Salakhutdinov",2012,,,,1061-1069,,"Motivated by large-scale multimedia applications we propose to learn mappings from high-dimensional data to binary codes that preserve semantic similarity. Binary codes are well suited to large-scale applications as they are storage efficient and permit exact sub-linear kNN search. The framework is applicable to broad families of mappings, and uses a flexible form of triplet ranking loss. We overcome discontinuous optimization of the discrete mappings by minimizing a piecewise-smooth upper bound on empirical loss, inspired by latent structural SVMs. We develop a new loss-augmented inference algorithm that is quadratic in the code length. We show strong retrieval performance on CIFAR-10 and MNIST, with promising classification results using no more than kNN on the binary codes.",564회,"Hamming distance metric learning
M Norouzi, DJ Fleet, RR Salakhutdinov - Advances in neural information processing systems, 2012
564회 인용 관련 학술자료 전체 13개의 버전",Advances in neural information processing systems,,,,,,,
Deep learning for neuroimaging: a validation study,"Sergey M Plis, Devon R Hjelm, Ruslan Salakhutdinov, Elena A Allen, Henry J Bockholt, Jeffrey D Long, Hans J Johnson, Jane S Paulsen, Jessica A Turner, Vince D Calhoun",2014/8/20,Frontiers in neuroscience,8,,229,Frontiers,"Deep learning methods have recently made notable advances in the tasks of classification and representation learning. These tasks are important for brain imaging and neuroscience discovery, making the methods attractive for porting to a neuroimager's toolbox. Success of these methods is, in part, explained by the flexibility of deep learning models. However, this flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. These methods include deep belief networks and their building block the restricted Boltzmann machine. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.",563회,"Deep learning for neuroimaging: a validation study
SM Plis, DR Hjelm, R Salakhutdinov, EA Allen… - Frontiers in neuroscience, 2014
563회 인용 관련 학술자료 전체 29개의 버전",,,,,,,,
One shot learning of simple visual concepts,"Brenden Lake, Ruslan Salakhutdinov, Jason Gross, Joshua Tenenbaum",2011,Proceedings of the annual meeting of the cognitive science society,33,33,,,"People can learn visual concepts from just one example, but it remains a mystery how this is accomplished. Many authors have proposed that transferred knowledge from more familiar concepts is a route to one shot learning, but what is the form of this abstract knowledge? One hypothesis is that the sharing of parts is core to one shot learning, and we evaluate this idea in the domain of handwritten characters, using a massive new dataset. These simple visual concepts have a rich internal part structure, yet they are particularly tractable for computational models. We introduce a generative model of how characters are composed from strokes, where knowledge from previous characters helps to infer the latent strokes in novel characters. The stroke model outperforms a competing stateof-the-art character model on a challenging one shot learning task, and it provides a good fit to human perceptual data.",529회,"One shot learning of simple visual concepts
B Lake, R Salakhutdinov, J Gross, J Tenenbaum - Proceedings of the annual meeting of the cognitive …, 2011
529회 인용 관련 학술자료 전체 18개의 버전",,,,,,,,
Efficient Learning of Deep Boltzmann Machines.,"Ruslan Salakhutdinov, Hugo Larochelle",2010/5,,,,693-700,,"We present a new approximate inference algorithm for Deep Boltzmann Machines (DBM’s), a generative model with many layers of hidden variables. The algorithm learns a separate “recognition” model that is used to quickly initialize, in a single bottom-up pass, the values of the latent variables in all hidden layers. We show that using such a recognition model, followed by a combined top-down and bottom-up pass, it is possible to efficiently learn a good generative model of high-dimensional highly-structured sensory input. We show that the additional computations required by incorporating a top-down feedback plays a critical role in the performance of a DBM, both as a generative and discriminative model. Moreover, inference is only at most three times slower compared to the approximate inference in a Deep Belief Network (DBN), making large-scale learning of DBM’s practical. Finally, we demonstrate that the DBM’s trained using the proposed approximate inference algorithm perform well compared to DBN’s and SVM’s on the MNIST handwritten digit, OCR English letters, and NORB visual object recognition tasks.",528회,"Efficient learning of deep Boltzmann machines
R Salakhutdinov, H Larochelle - Proceedings of the thirteenth international conference …, 2010
408회 인용 관련 학술자료 전체 19개의 버전
Proceedings of the thirteenth international conference on artificial intelligence and statistics*
X Glorot, Y Bengio, YW Teh, M Titterington - PMLR, 2010
123회 인용 관련 학술자료",International Conference on Artificial Intelligence and Statistics (AISTATS),,,,,,,
Learning a Nonlinear Embedding by Preserving Class Neighbourhood Structure.,"Ruslan Salakhutdinov, Geoffrey E Hinton",2007/3/21,,,,412-419,,"We show how to pretrain and fine-tune a multilayer neural network to learn a nonlinear transformation from the input space to a lowdimensional feature space in which K-nearest neighbour classification performs well. We also show how the non-linear transformation can be improved using unlabeled data. Our method achieves a much lower error rate than Support Vector Machines or standard backpropagation on a widely used version of the MNIST handwritten digit recognition task. If some of the dimensions of the low-dimensional feature space are not used for nearest neighbor classification, our method uses these dimensions to explicitly represent transformations of the digits that do not affect their identity.",527회,"Learning a nonlinear embedding by preserving class neighbourhood structure
R Salakhutdinov, G Hinton - Artificial Intelligence and Statistics, 2007
527회 인용 관련 학술자료 전체 19개의 버전",International Conference on Artificial Intelligence and Statistics (AISTATS),,,,,,,
On the quantitative analysis of deep belief networks,"Ruslan Salakhutdinov, Iain Murray",2008/7/5,,,,872-879,,"Deep Belief Networks (DBN's) are generative models that contain many layers of hidden variables. Efficient greedy algorithms for learning and approximate inference have allowed these models to be applied successfully in many application domains. The main building block of a DBN is a bipartite undirected graphical model called a restricted Boltzmann machine (RBM). Due to the presence of the partition function, model selection, complexity control, and exact maximum likelihood learning in RBM's are intractable. We show that Annealed Importance Sampling (AIS) can be used to efficiently estimate the partition function of an RBM, and we present a novel AIS scheme for comparing RBM's with different architectures. We further show how an AIS estimator, along with approximate inference, can be used to estimate a lower bound on the log-probability that a DBN model with multiple hidden layers assigns to the test …",486회,"On the quantitative analysis of deep belief networks
R Salakhutdinov, I Murray - Proceedings of the 25th international conference on …, 2008
486회 인용 관련 학술자료 전체 21개의 버전",,Proceedings of the 25th international conference on Machine learning,,,,,,
An efficient learning procedure for deep Boltzmann machines,"Ruslan Salakhutdinov, Geoffrey Hinton",2012/8,Neural computation,24,8,1967-2006,MIT Press,"We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent statistics are estimated using a variational approximation that tends to focus on a single mode, and data-independent statistics are estimated using persistent Markov chains. The use of two quite different techniques for estimating the two types of statistic that enter into the gradient of the log likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer pretraining phase that initializes the weights sensibly. The pretraining also allows the variational inference to be initialized sensibly with a single bottom-up pass. We present results on the MNIST and NORB data sets showing that deep Boltzmann machines learn very good generative models of handwritten digits and 3D objects …",483회,"An efficient learning procedure for deep Boltzmann machines
R Salakhutdinov, G Hinton - Neural computation, 2012
483회 인용 관련 학술자료 전체 24개의 버전",,,,,,,,
"Hotpotqa: A dataset for diverse, explainable multi-hop question answering","Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, Christopher D Manning",2018/9/25,arXiv preprint arXiv:1809.09600,,,,,"Existing question answering (QA) datasets fail to train QA systems to perform complex reasoning and provide explanations for answers. We introduce HotpotQA, a new dataset with 113k Wikipedia-based question-answer pairs with four key features:(1) the questions require finding and reasoning over multiple supporting documents to answer;(2) the questions are diverse and not constrained to any pre-existing knowledge bases or knowledge schemas;(3) we provide sentence-level supporting facts required for reasoning, allowing QA systems to reason with strong supervision and explain the predictions;(4) we offer a new type of factoid comparison questions to test QA systems' ability to extract relevant facts and perform necessary comparison. We show that HotpotQA is challenging for the latest QA systems, and the supporting facts enable models to improve performance and make explainable predictions.",450회,"Hotpotqa: A dataset for diverse, explainable multi-hop question answering
Z Yang, P Qi, S Zhang, Y Bengio, WW Cohen… - arXiv preprint arXiv:1809.09600, 2018
450회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Deep kernel learning,"Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, Eric P Xing",2015/11/6,,,,,,"We introduce scalable deep kernels, which combine the structural properties of deep learning architectures with the non-parametric flexibility of kernel methods. Specifically, we transform the inputs of a spectral mixture base kernel with a deep architecture, using local kernel interpolation, inducing points, and structure exploiting (Kronecker and Toeplitz) algebra for a scalable kernel representation. These closed-form kernels can be used as drop-in replacements for standard kernels, with benefits in expressive power and scalability. We jointly learn the properties of these kernels through the marginal likelihood of a Gaussian process. Inference and learning cost O (n) for n training points, and predictions cost O (1) per test point. On a large and diverse collection of applications, including a dataset with 2 million examples, we show improved performance over scalable Gaussian processes with flexible kernel learning models, and stand-alone deep architectures.",400회,"Deep kernel learning
AG Wilson, Z Hu, R Salakhutdinov, EP Xing - Artificial intelligence and statistics, 2016
400회 인용 관련 학술자료 전체 12개의 버전",International Conference on Artificial Intelligence and Statistics (AISTATS),,,,,,,
Actor-mimic: Deep multitask and transfer reinforcement learning,"Emilio Parisotto, Jimmy Lei Ba, Ruslan Salakhutdinov",2015/11/19,,,,,,"The ability to act in multiple environments and transfer previous knowledge to new situations can be considered a critical aspect of any intelligent agent. Towards this goal, we define a novel method of multitask and transfer learning that enables an autonomous agent to learn how to behave in multiple tasks simultaneously, and then generalize its knowledge to new domains. This method, termed"" Actor-Mimic"", exploits the use of deep reinforcement learning and model compression techniques to train a single policy network that learns how to act in a set of distinct tasks by using the guidance of several expert teachers. We then show that the representations learnt by the deep policy network are capable of generalizing to new tasks with no prior expert guidance, speeding up learning in novel environments. Although our method can in general be applied to a wide range of problems, we use Atari games as a testing environment to demonstrate these methods.",372회,"Actor-mimic: Deep multitask and transfer reinforcement learning
E Parisotto, JL Ba, R Salakhutdinov - arXiv preprint arXiv:1511.06342, 2015
372회 인용 관련 학술자료 전체 3개의 버전",International Conference on Learning Representations (ICLR),,,,,,,
Learning deep generative models,Ruslan Salakhutdinov,2015/4/10,,2,,361-385,Annual Reviews,"Building intelligent systems that are capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many artificial intelligence–related tasks, including object recognition, speech perception, and language understanding. Theoretical and biological arguments strongly suggest that building such systems requires models with deep architectures that involve many layers of nonlinear processing. In this article, we review several popular deep learning models, including deep belief networks and deep Boltzmann machines. We show that (a) these deep generative models, which contain many layers of latent variables and millions of parameters, can be learned efficiently, and (b) the learned high-level feature representations can be successfully applied in many application domains, including visual object recognition, information retrieval, classification, and regression tasks.",348회,"Learning deep generative models
R Salakhutdinov - Annual Review of Statistics and Its Application, 2015
348회 인용 관련 학술자료 전체 24개의 버전",,,Annual Review of Statistics and Its Application,,,,,
Multimodal learning with deep Boltzmann machines.,"Nitish Srivastava, Ruslan Salakhutdinov",2014/10/1,J. Mach. Learn. Res.,15,1,2949-2980,,"Data often consists of multiple diverse modalities. For example, images are tagged with textual information and videos are accompanied by audio. Each modality is characterized by having distinct statistical properties. We propose a Deep Boltzmann Machine for learning a generative model of such multimodal data. We show that the model can be used to create fused representations by combining features across modalities. These learned representations are useful for classification and information retrieval. By sampling from the conditional distributions over each data modality, it is possible to create these representations even when some data modalities are missing. We conduct experiments on bi-modal image-text and audio-video data. The fused representation achieves good classification results on the MIR-Flickr data set matching or outperforming other deep models as well as SVM based models that use Multiple Kernel Learning. We further demonstrate that this multimodal model helps classification and retrieval even when only unimodal data is available at test time.",348회,"Multimodal learning with deep Boltzmann machines.
N Srivastava, R Salakhutdinov - J. Mach. Learn. Res., 2014
348회 인용 관련 학술자료 전체 15개의 버전",,,,,,,,
Predicting deep zero-shot convolutional neural networks using textual descriptions,"Jimmy Lei Ba, Kevin Swersky, Sanja Fidler",2015,,,,4247-4255,,"One of the main challenges in Zero-Shot Learning of visual categories is gathering semantic attributes to accompany images. Recent work has shown that learning from textual descriptions, such as Wikipedia articles, avoids the problem of having to explicitly define these attributes. We present a new model that can classify unseen categories from their textual description. Specifically, we use text features to predict the output weights of both the convolutional and the fully connected layers in a deep convolutional neural network (CNN). We take advantage of the architecture of CNNs and learn features at different layers, rather than just learning an embedding space for both modalities, as is common with existing approaches. The proposed model also allows us to automatically generate a list of pseudo-attributes for each visual category consisting of words from Wikipedia articles. We train our models end-to-end using the Caltech-UCSD bird and flower datasets and evaluate both ROC and Precision-Recall curves. Our empirical results show that the proposed model significantly outperforms previous methods.",347회,"Predicting deep zero-shot convolutional neural networks using textual descriptions
J Lei Ba, K Swersky, S Fidler - Proceedings of the IEEE International Conference on …, 2015
347회 인용 관련 학술자료 전체 12개의 버전",Proceedings of the IEEE International Conference on Computer Vision,,,,,,,
Gated-attention readers for text comprehension,"Bhuwan Dhingra, Hanxiao Liu, Zhilin Yang, William W Cohen, Ruslan Salakhutdinov",2016/6/5,arXiv preprint arXiv:1606.01549,,,,,"In this paper we study the problem of answering cloze-style questions over documents. Our model, the Gated-Attention (GA) Reader, integrates a multi-hop architecture with a novel attention mechanism, which is based on multiplicative interactions between the query embedding and the intermediate states of a recurrent neural network document reader. This enables the reader to build query-specific representations of tokens in the document for accurate answer selection. The GA Reader obtains state-of-the-art results on three benchmarks for this task--the CNN\& Daily Mail news stories and the Who Did What dataset. The effectiveness of multiplicative interaction is demonstrated by an ablation study, and by comparing to alternative compositional operators for implementing the gated-attention. The code is available at this https URL.",341회,"Gated-attention readers for text comprehension
B Dhingra, H Liu, Z Yang, WW Cohen, R Salakhutdinov - arXiv preprint arXiv:1606.01549, 2016
341회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Good semi-supervised learning that requires a bad gan,"Zihang Dai, Zhilin Yang, Fan Yang, William W Cohen, Ruslan Salakhutdinov",2017/5/27,arXiv preprint arXiv:1705.09783,,,,,"Semi-supervised learning methods based on generative adversarial networks (GANs) obtained strong empirical results, but it is not clear 1) how the discriminator benefits from joint training with a generator, and 2) why good semi-supervised classification performance and a good generator cannot be obtained at the same time. Theoretically, we show that given the discriminator objective, good semisupervised learning indeed requires a bad generator, and propose the definition of a preferred generator. Empirically, we derive a novel formulation based on our analysis that substantially improves over feature matching GANs, obtaining state-of-the-art results on multiple benchmark datasets.",307회,"Good semi-supervised learning that requires a bad gan
Z Dai, Z Yang, F Yang, WW Cohen, R Salakhutdinov - arXiv preprint arXiv:1705.09783, 2017
307회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Learning to share visual appearance for multiclass object detection,"Ruslan Salakhutdinov, Antonio Torralba, Josh Tenenbaum",2011/6/20,,,,1481-1488,IEEE,"We present a hierarchical classification model that allows rare objects to borrow statistical strength from related objects that have many training examples. Unlike many of the existing object detection and recognition systems that treat different classes as unrelated entities, our model learns both a hierarchy for sharing visual appearance across 200 object categories and hierarchical parameters. Our experimental results on the challenging object localization and detection task demonstrate that the proposed model substantially improves the accuracy of the standard single object detectors that ignore hierarchical structure altogether.",296회,"Learning to share visual appearance for multiclass object detection
R Salakhutdinov, A Torralba, J Tenenbaum - CVPR 2011, 2011
296회 인용 관련 학술자료 전체 11개의 버전",CVPR 2011,,,,,,,
On exact computation with an infinitely wide neural net,"Sanjeev Arora, Simon S Du, Wei Hu, Zhiyuan Li, Ruslan Salakhutdinov, Ruosong Wang",2019/4/26,arXiv preprint arXiv:1904.11955,,,,,"How well does a classic deep net architecture like AlexNet or VGG19 classify on a standard dataset such as CIFAR-10 when its width---namely, number of channels in convolutional layers, and number of nodes in fully-connected internal layers---is allowed to increase to infinity? Such questions have come to the forefront in the quest to theoretically understand deep learning and its mysteries about optimization and generalization. They also connect deep learning to notions such as Gaussian processes and kernels. A recent paper [Jacot et al., 2018] introduced the Neural Tangent Kernel (NTK) which captures the behavior of fully-connected deep nets in the infinite width limit trained by gradient descent; this object was implicit in some other recent papers. An attraction of such ideas is that a pure kernel-based method is used to capture the power of a fully-trained deep net of infinite width.
The current paper gives the first efficient exact algorithm for computing the extension of NTK to convolutional neural nets, which we call Convolutional NTK (CNTK), as well as an efficient GPU implementation of this algorithm. This results in a significant new benchmark for the performance of a pure kernel-based method on CIFAR-10, being higher than the methods reported in [Novak et al., 2019], and only lower than the performance of the corresponding finite deep net architecture (once batch normalization, etc. are turned off). Theoretically, we also give the first non-asymptotic proof showing that a fully-trained sufficiently wide net is indeed equivalent to the kernel regression predictor using NTK.",289회,"On exact computation with an infinitely wide neural net
S Arora, SS Du, W Hu, Z Li, R Salakhutdinov, R Wang - arXiv preprint arXiv:1904.11955, 2019
289회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
"Encode, Review, and Decode: Reviewer Module for Caption Generation","Zhilin Yang, Ye Yuan, Yuexin Wu, Ruslan Salakhutdinov, William W Cohen",2016/5/25,NIPS 2016,,,,,,280회,"Review networks for caption generation*
Z Yang, Y Yuan, Y Wu, R Salakhutdinov, WW Cohen - arXiv preprint arXiv:1605.07912, 2016
210회 인용 관련 학술자료 전체 7개의 버전
Encode, review, and decode: Reviewer module for caption generation*
Z Wu, R Cohen - arXiv preprint arXiv:1605.07912, 2016
72회 인용 관련 학술자료",,,,,,,,
Generating images from captions with attention,"Elman Mansimov, Emilio Parisotto, Jimmy Lei Ba, Ruslan Salakhutdinov",2015/11/9,,,,,,"Motivated by the recent progress in generative models, we introduce a model that generates images from natural language descriptions. The proposed model iteratively draws patches on a canvas, while attending to the relevant words in the description. After training on Microsoft COCO, we compare our model with several baseline generative models on image generation and retrieval tasks. We demonstrate that our model produces higher quality samples than other approaches and generates images with novel scene compositions corresponding to previously unseen captions in the dataset.",278회,"Generating images from captions with attention
E Mansimov, E Parisotto, JL Ba, R Salakhutdinov - arXiv preprint arXiv:1511.02793, 2015
278회 인용 관련 학술자료 전체 15개의 버전",International Conference on Learning Representations (ICLR),,,,,,,
Transfer learning for sequence tagging with hierarchical recurrent networks,"Zhilin Yang, Ruslan Salakhutdinov, William W Cohen",2017/3/18,arXiv preprint arXiv:1703.06345,,,,,"Recent papers have shown that neural networks obtain state-of-the-art performance on several different sequence tagging tasks. One appealing property of such systems is their generality, as excellent performance can be achieved with a unified architecture and without task-specific feature engineering. However, it is unclear if such systems can be used for tasks without large amounts of training data. In this paper we explore the problem of transfer learning for neural sequence taggers, where a source task with plentiful annotations (eg, POS tagging on Penn Treebank) is used to improve performance on a target task with fewer available annotations (eg, POS tagging for microblogs). We examine the effects of transfer learning for deep hierarchical recurrent networks across domains, applications, and languages, and show that significant improvement can often be obtained. These improvements lead to improvements over the current state-of-the-art on several well-studied tasks.",275회,"Transfer learning for sequence tagging with hierarchical recurrent networks
Z Yang, R Salakhutdinov, WW Cohen - arXiv preprint arXiv:1703.06345, 2017
275회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Modelling relational data using bayesian clustered tensor factorization,"Ilya Sutskever, Ruslan R Salakhutdinov, Joshua B Tenenbaum",2009,,,,,Neural Information Processing Systems Foundation,"We consider the problem of learning probabilistic models for complex relational structures between various types of objects. A model can help us ""understand"" a dataset of relational facts in at least two ways, by finding interpretable structure in the data, and by supporting predictions, or inferences about whether particular unobserved relations are likely to be true. Often there is a tradeoff between these two aims: cluster-based models yield more easily interpretable representations, while factorization-based approaches have given better predictive performance on large data sets. We introduce the Bayesian Clustered Tensor Factorization (BCTF) model, which embeds a factorized representation of relations in a nonparametric Bayesian clustering framework. Inference is fully Bayesian but scales well to large data sets. The model simultaneously discovers interpretable clusters and yields predictive performance that matches or beats previous probabilistic models for relational data.",275회,"Modelling relational data using bayesian clustered tensor factorization
I Sutskever, RR Salakhutdinov, JB Tenenbaum - 2009
275회 인용 관련 학술자료 전체 20개의 버전",,,,,,,,
Breaking the softmax bottleneck: A high-rank RNN language model,"Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, William W Cohen",2017/11/10,arXiv preprint arXiv:1711.03953,,,,,"We formulate language modeling as a matrix factorization problem, and show that the expressiveness of Softmax-based models (including the majority of neural language models) is limited by a Softmax bottleneck. Given that natural language is highly context-dependent, this further implies that in practice Softmax with distributed word embeddings does not have enough capacity to model natural language. We propose a simple and effective method to address this issue, and improve the state-of-the-art perplexities on Penn Treebank and WikiText-2 to 47.69 and 40.68 respectively. The proposed method also excels on the large-scale 1B Word dataset, outperforming the baseline by over 5.6 points in perplexity.",265회,"Breaking the softmax bottleneck: A high-rank RNN language model
Z Yang, Z Dai, R Salakhutdinov, WW Cohen - arXiv preprint arXiv:1711.03953, 2017
265회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Semantic hashing,"Ruslan Salakhutdinov, Geoffrey Hinton",2007/7,,1,1,8,,"We show how to learn a deep graphical model of the word-count vectors obtained from a large set of documents. The values of the latent variables in the deepest layer are easy to infer and give a much better representation of each document than Latent Semantic Analysis. When the deepest layer is forced to use a small number of binary variables (eg 32), the graphical model performs “semantic hashing”: Documents are mapped to memory addresses in such a way that semantically similar documents are located at nearby addresses. Documents similar to a query document can then be found by simply accessing all the addresses that differ by only a few bits from the address of the query document. This way of extending the efficiency of hash-coding to approximate matching is much faster than locality sensitive hashing, which is the fastest current method. By using semantic hashing to filter the documents given to TF-IDF, we achieve higher accuracy than applying TF-IDF to the entire document set.",257회,"Semantic hashing
R Salakhutdinov, G Hinton - RBM, 2007
257회 인용 관련 학술자료 전체 17개의 버전",SIGIR workshop on Information Retrieval and applications of Graphical Models,,,,,,,
Multi-task neural networks for QSAR predictions,"George E Dahl, Navdeep Jaitly, Ruslan Salakhutdinov",2014/6/4,arXiv preprint arXiv:1406.1231,,,,,"Although artificial neural networks have occasionally been used for Quantitative Structure-Activity/Property Relationship (QSAR/QSPR) studies in the past, the literature has of late been dominated by other machine learning techniques such as random forests. However, a variety of new neural net techniques along with successful applications in other domains have renewed interest in network approaches. In this work, inspired by the winning team's use of neural networks in a recent QSAR competition, we used an artificial neural network to learn a function that predicts activities of compounds for multiple assays at the same time. We conducted experiments leveraging recent methods for dealing with overfitting in neural networks as well as other tricks from the neural networks literature. We compared our methods to alternative methods reported to perform well on these tasks and found that our neural net methods provided superior performance.",253회,"Multi-task neural networks for QSAR predictions
GE Dahl, N Jaitly, R Salakhutdinov - arXiv preprint arXiv:1406.1231, 2014
253회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Learning with hierarchical-deep models,"Ruslan Salakhutdinov, Joshua B Tenenbaum, Antonio Torralba",2012/12/20,IEEE transactions on pattern analysis and machine intelligence,35,8,1958-1971,IEEE,"We introduce HD (or “Hierarchical-Deep”) models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian (HB) models. Specifically, we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a deep Boltzmann machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training example by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.",251회,"Learning with hierarchical-deep models
R Salakhutdinov, JB Tenenbaum, A Torralba - IEEE transactions on pattern analysis and machine …, 2012
251회 인용 관련 학술자료 전체 15개의 버전",,,,,,,,
Collaborative filtering in a non-uniform world: Learning with the weighted trace norm,"Ruslan Salakhutdinov, Nathan Srebro",2010/2/14,arXiv preprint arXiv:1002.2780,,,,,We show that matrix completion with trace-norm regularization can be significantly hurt when entries of the matrix are sampled non-uniformly. We introduce a weighted version of the trace-norm regularizer that works well also with non-uniform sampling. Our experimental results demonstrate that the weighted trace-norm regularization indeed yields significant gains on the (highly non-uniformly sampled) Netflix dataset.,243회,"Collaborative filtering in a non-uniform world: Learning with the weighted trace norm
R Salakhutdinov, N Srebro - arXiv preprint arXiv:1002.2780, 2010
243회 인용 관련 학술자료 전체 18개의 버전",,,,,,,,
Improved variational autoencoders for text modeling using dilated convolutions,"Zichao Yang, Zhiting Hu, Ruslan Salakhutdinov, Taylor Berg-Kirkpatrick",2017/7/17,,,,3881-3890,PMLR,"Recent work on generative text modeling has found that variational autoencoders (VAE) with LSTM decoders perform worse than simpler LSTM language models (Bowman et al., 2015). This negative result is so far poorly understood, but has been attributed to the propensity of LSTM decoders to ignore conditioning information from the encoder. In this paper, we experiment with a new type of decoder for VAE: a dilated CNN. By changing the decoder’s dilation architecture, we control the size of context from previously generated words. In experiments, we find that there is a trade-off between contextual capacity of the decoder and effective use of encoding information. We show that when carefully managed, VAEs can outperform LSTM language models. We demonstrate perplexity gains on two datasets, representing the first positive language modeling result with VAE. Further, we conduct an in-depth investigation of the use of VAE (with our new decoding architecture) for semi-supervised and unsupervised labeling tasks, demonstrating gains over several strong baselines.",241회,"Improved variational autoencoders for text modeling using dilated convolutions
Z Yang, Z Hu, R Salakhutdinov, T Berg-Kirkpatrick - International conference on machine learning, 2017
241회 인용 관련 학술자료 전체 6개의 버전",International conference on machine learning,,,,,,,
Style transfer through back-translation,"Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, Alan W Black",2018/4/24,arXiv preprint arXiv:1804.09000,,,,,"Style transfer is the task of rephrasing the text to contain specific stylistic properties without changing the intent or affect within the context. This paper introduces a new method for automatic style transfer. We first learn a latent representation of the input sentence which is grounded in a language translation model in order to better preserve the meaning of the sentence while reducing stylistic properties. Then adversarial generation techniques are used to make the output match the desired style. We evaluate this technique on three different style transformations: sentiment, gender and political slant. Compared to two state-of-the-art style transfer modeling techniques we show improvements both in automatic evaluation of style transfer and in manual evaluation of meaning preservation and fluency.",235회,"Style transfer through back-translation
S Prabhumoye, Y Tsvetkov, R Salakhutdinov, AW Black - arXiv preprint arXiv:1804.09000, 2018
235회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
Using deep belief nets to learn covariance kernels for Gaussian processes,"Ruslan Salakhutdinov, Geoffrey Hinton",2008,,,,1249-1256,,"We show how to use unlabeled data and a deep belief net (DBN) to learn a good covariance kernel for a Gaussian process. We first learn a deep generative model of the unlabeled data using the fast, greedy algorithm introduced by [7]. If the data is high-dimensional and highly-structured, a Gaussian kernel applied to the top layer of features in the DBN works much better than a similar kernel applied to the raw input. Performance at both regression and classification can then be further improved by using backpropagation through the DBN to discriminatively fine-tune the covariance kernel.",230회,"Using Deep Belief Nets to Learn Covariance Kernels for Gaussian Processes.
R Salakhutdinov, GE Hinton - NIPS, 2007
230회 인용 관련 학술자료 전체 19개의 버전",Advances in neural information processing systems,,,,,,,
Discriminative Transfer Learning with Tree-based Priors.,"Nitish Srivastava, Ruslan Salakhutdinov",2013/6/3,NIPS,3,4,8,,"This paper proposes a way of improving classification performance for classes which have very few training examples. The key idea is to discover classes which are similar and transfer knowledge among them. Our method organizes the classes into a tree hierarchy. The tree structure can be used to impose a prior over classification parameters. We show that these priors can be combined with discriminative models such as deep neural networks. Our method benefits from the power of discriminative training of deep neural networks, at the same time using treebased priors over classification parameters. We also propose an algorithm for learning the underlying tree structure. This gives the model some flexibility to tune the tree so that the tree is pertinent to task being solved. We show that the model can transfer knowledge across related classes using fixed trees. Moreover, it can learn new meaningful trees usually leading to improved performance. Our method achieves state-of-the-art classification results on the CIFAR-100 image dataset and the MIR Flickr multimodal dataset.",224회,"Discriminative Transfer Learning with Tree-based Priors.
N Srivastava, R Salakhutdinov - NIPS, 2013
224회 인용 관련 학술자료 전체 10개의 버전
Supplementary Material for Discriminative Transfer Learning with Tree-based Priors*
N Srivastava, R Salakhutdinov
관련 학술자료 전체 3개의 버전",,,,,,,,
Spatially adaptive computation time for residual networks,"Michael Figurnov, Maxwell D Collins, Yukun Zhu, Li Zhang, Jonathan Huang, Dmitry Vetrov, Ruslan Salakhutdinov",2017,,,,1039-1048,,"This paper proposes a deep learning architecture based on Residual Network that dynamically adjusts the number of executed layers for the regions of the image. This architecture is end-to-end trainable, deterministic and problem-agnostic. It is therefore applicable without any modifications to a wide range of computer vision problems such as image classification, object detection and image segmentation. We present experimental results showing that this model improves the computational efficiency of Residual Networks on the challenging ImageNet classification and COCO object detection datasets. Additionally, we evaluate the computation time maps on the visual saliency dataset cat2000 and find that they correlate surprisingly well with human eye fixation positions.",216회,"Spatially adaptive computation time for residual networks
M Figurnov, MD Collins, Y Zhu, L Zhang, J Huang… - Proceedings of the IEEE Conference on Computer …, 2017
216회 인용 관련 학술자료 전체 8개의 버전",Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,,,,,
Path-sgd: Path-normalized optimization in deep neural networks,"Behnam Neyshabur, Ruslan Salakhutdinov, Nathan Srebro",2015/6/8,arXiv preprint arXiv:1506.02617,,,,,"We revisit the choice of SGD for training deep neural networks by reconsidering the appropriate geometry in which to optimize the weights. We argue for a geometry invariant to rescaling of weights that does not affect the output of the network, and suggest Path-SGD, which is an approximate steepest descent method with respect to a path-wise regularizer related to max-norm regularization. Path-SGD is easy and efficient to implement and leads to empirical gains over SGD and AdaGrad.",211회,"Path-sgd: Path-normalized optimization in deep neural networks
B Neyshabur, R Salakhutdinov, N Srebro - arXiv preprint arXiv:1506.02617, 2015
211회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Exploiting image-trained cnn architectures for unconstrained video classification,"Shengxin Zha, Florian Luisier, Walter Andrews, Nitish Srivastava, Ruslan Salakhutdinov",2015/3/13,,,,,,"We conduct an in-depth exploration of different strategies for doing event detection in videos using convolutional neural networks (CNNs) trained for image classification. We study different ways of performing spatial and temporal pooling, feature normalization, choice of CNN layers as well as choice of classifiers. Making judicious choices along these dimensions led to a very significant increase in performance over more naive approaches that have been used till now. We evaluate our approach on the challenging TRECVID MED'14 dataset with two popular CNN architectures pretrained on ImageNet. On this MED'14 dataset, our methods, based entirely on image-trained CNN features, can outperform several state-of-the-art non-CNN models. Our proposed late fusion of CNN-and motion-based features can further increase the mean average precision (mAP) on MED'14 from 34.95% to 38.74%. The fusion approach achieves the state-of-the-art classification performance on the challenging UCF-101 dataset.",211회,"Exploiting image-trained CNN architectures for unconstrained video classification
S Zha, F Luisier, W Andrews, N Srivastava… - arXiv preprint arXiv:1503.04144, 2015
211회 인용 관련 학술자료 전체 7개의 버전",BMVC,,,,,,,
One-shot learning by inverting a compositional causal process,"Brenden M Lake, Ruslan Salakhutdinov, Joshua B Tenenbaum",2013,,,,,"Neural Information Processing Systems Foundation, Inc.","People can learn a new visual class from just one example, yet machine learning algorithms typically require hundreds or thousands of examples to tackle the same problems. Here we present a Hierarchical Bayesian model based on compositionality and causality that can learn a wide range of natural (although simple) visual concepts, generalizing in human-like ways from just one image. We evaluated performance on a challenging one-shot classification task, where our model achieved a human-level error rate while substantially outperforming two deep learning models. We also used a visual Turing test ""to show that our model produces human-like performance on other conceptual tasks, including generating new examples and parsing.""",207회,"One-shot learning by inverting a compositional causal process
BM Lake, R Salakhutdinov, JB Tenenbaum - 2013
207회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
The more you know: Using knowledge graphs for image classification,"Kenneth Marino, Ruslan Salakhutdinov, Abhinav Gupta",2016/12/14,arXiv preprint arXiv:1612.04844,,,,,"One characteristic that sets humans apart from modern learning-based computer vision algorithms is the ability to acquire knowledge about the world and use that knowledge to reason about the visual world. Humans can learn about the characteristics of objects and the relationships that occur between them to learn a large variety of visual concepts, often with few examples. This paper investigates the use of structured prior knowledge in the form of knowledge graphs and shows that using this knowledge improves performance on image classification. We build on recent work on end-to-end learning on graphs, introducing the Graph Search Neural Network as a way of efficiently incorporating large knowledge graphs into a vision classification pipeline. We show in a number of experiments that our method outperforms standard neural network baselines for multi-label classification.",203회,"The more you know: Using knowledge graphs for image classification
K Marino, R Salakhutdinov, A Gupta - arXiv preprint arXiv:1612.04844, 2016
203회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Modeling documents with deep boltzmann machines,"Nitish Srivastava, Ruslan R Salakhutdinov, Geoffrey E Hinton",2013/9/26,,,,,,"We introduce a Deep Boltzmann Machine model suitable for modeling and extracting latent semantic representations from a large unstructured collection of documents. We overcome the apparent difficulty of training a DBM with judicious parameter tying. This parameter tying enables an efficient pretraining algorithm and a state initialization scheme that aids inference. The model can be trained just as efficiently as a standard Restricted Boltzmann Machine. Our experiments show that the model assigns better log probability to unseen data than the Replicated Softmax model. Features extracted from our model outperform LDA, Replicated Softmax, and DocNADE models on document retrieval and document classification tasks.",198회,"Modeling documents with deep boltzmann machines
N Srivastava, RR Salakhutdinov, GE Hinton - arXiv preprint arXiv:1309.6865, 2013
198회 인용 관련 학술자료 전체 23개의 버전",Uncertainty in Artificial Intelligence (UAI),,,,,,,
On the quantitative analysis of decoder-based generative models,"Yuhuai Wu, Yuri Burda, Ruslan Salakhutdinov, Roger Grosse",2016/11/14,arXiv preprint arXiv:1611.04273,,,,,"The past several years have seen remarkable progress in generative models which produce convincing samples of images and other modalities. A shared component of many powerful generative models is a decoder network, a parametric deep neural net that defines a generative distribution. Examples include variational autoencoders, generative adversarial networks, and generative moment matching networks. Unfortunately, it can be difficult to quantify the performance of these models because of the intractability of log-likelihood estimation, and inspecting samples can be misleading. We propose to use Annealed Importance Sampling for evaluating log-likelihoods for decoder-based models and validate its accuracy using bidirectional Monte Carlo. The evaluation code is provided at this https URL. Using this technique, we analyze the performance of decoder-based models, the effectiveness of existing log-likelihood estimators, the degree of overfitting, and the degree to which these models miss important modes of the data distribution.",195회,"On the quantitative analysis of decoder-based generative models
Y Wu, Y Burda, R Salakhutdinov, R Grosse - arXiv preprint arXiv:1611.04273, 2016
195회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Learning representations for multimodal data with deep belief nets,"Nitish Srivastava, Ruslan Salakhutdinov",2012/7,International conference on machine learning workshop,79,,3,,We propose a Deep Belief Network architecture for learning a joint representation of multimodal data. The model defines a probability distribution over the space of multimodal inputs and allows sampling from the conditional distributions over each data modality. This makes it possible for the model to create a multimodal representation even when some data modalities are missing. Our experimental results on bi-modal data consisting of images and text show that the Multimodal DBN can learn a good generative model of the joint space of image and text inputs that is useful for filling in missing data so it can be used both for image annotation and image retrieval. We further demonstrate that using the representation discovered by the Multimodal DBN our model can significantly outperform SVMs and LDA on discriminative tasks.,194회,"Learning representations for multimodal data with deep belief nets
N Srivastava, R Salakhutdinov - International conference on machine learning …, 2012
194회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Optimization with EM and expectation-conjugate-gradient,"Ruslan Salakhutdinov, Sam Roweis, Zoubin Ghahramani",2003/8/21,,,,672-679,,"We show a close relationship between the Expectation-Maximization (EM) algorithm and direct optimization algorithms such as gradientbased methods for parameter learning. We identify analytic conditions under which EM exhibits Newton-like behavior, and conditions under which it possesses poor, first-order convergence. Based on this analysis, we propose two novel algorithms for maximum likelihood estimation of latent variable models, and report empirical results showing that, as predicted by theory, the proposed new algorithms can substantially outperform standard EM in terms of speed of convergence in certain cases.",190회,"Optimization with EM and expectation-conjugate-gradient
R Salakhutdinov, ST Roweis, Z Ghahramani - Proceedings of the 20th International Conference on …, 2003
190회 인용 관련 학술자료 전체 27개의 버전",International Conference on Machine Learning (ICML),,,,,,,
Robust boltzmann machines for recognition and denoising,"Yichuan Tang, Ruslan Salakhutdinov, Geoffrey Hinton",2012/6/16,,,,2264-2271,IEEE,"While Boltzmann Machines have been successful at unsupervised learning and density modeling of images and speech data, they can be very sensitive to noise in the data. In this paper, we introduce a novel model, the Robust Boltzmann Machine (RoBM), which allows Boltzmann Machines to be robust to corruptions. In the domain of visual recognition, the RoBM is able to accurately deal with occlusions and noise by using multiplicative gating to induce a scale mixture of Gaussians over pixels. Image denoising and in-painting correspond to posterior inference in the RoBM. Our model is trained in an unsupervised fashion with unlabeled noisy data and can learn the spatial structure of the occluders. Compared to standard algorithms, the RoBM is significantly better at recognition and denoising on several face databases.",187회,"Robust boltzmann machines for recognition and denoising
Y Tang, R Salakhutdinov, G Hinton - 2012 IEEE conference on computer vision and pattern …, 2012
187회 인용 관련 학술자료 전체 15개의 버전",2012 IEEE conference on computer vision and pattern recognition,,,,,,,
Multi-task cross-lingual sequence tagging from scratch,"Zhilin Yang, Ruslan Salakhutdinov, William Cohen",2016/3/20,arXiv preprint arXiv:1603.06270,,,,,"We present a deep hierarchical recurrent neural network for sequence tagging. Given a sequence of words, our model employs deep gated recurrent units on both character and word levels to encode morphology and context information, and applies a conditional random field layer to predict the tags. Our model is task independent, language independent, and feature engineering free. We further extend our model to multi-task and cross-lingual joint training by sharing the architecture and parameters. Our model achieves state-of-the-art results in multiple languages on several benchmark tasks including POS tagging, chunking, and NER. We also demonstrate that multi-task and cross-lingual joint training can improve the performance in various cases.",186회,"Multi-task cross-lingual sequence tagging from scratch
Z Yang, R Salakhutdinov, W Cohen - arXiv preprint arXiv:1603.06270, 2016
186회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Neural map: Structured memory for deep reinforcement learning,"Emilio Parisotto, Ruslan Salakhutdinov",2017/2/27,arXiv preprint arXiv:1702.08360,,,,,"A critical component to enabling intelligent reasoning in partially observable environments is memory. Despite this importance, Deep Reinforcement Learning (DRL) agents have so far used relatively simple memory architectures, with the main methods to overcome partial observability being either a temporal convolution over the past k frames or an LSTM layer. More recent work (Oh et al., 2016) has went beyond these architectures by using memory networks which can allow more sophisticated addressing schemes over the past k frames. But even these architectures are unsatisfactory due to the reason that they are limited to only remembering information from the last k frames. In this paper, we develop a memory system with an adaptable write operator that is customized to the sorts of 3D environments that DRL agents typically interact with. This architecture, called the Neural Map, uses a spatially structured 2D memory image to learn to store arbitrary information about the environment over long time lags. We demonstrate empirically that the Neural Map surpasses previous DRL memories on a set of challenging 2D and 3D maze environments and show that it is capable of generalizing to environments that were not seen during training.",176회,"Neural map: Structured memory for deep reinforcement learning
E Parisotto, R Salakhutdinov - arXiv preprint arXiv:1702.08360, 2017
176회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
segdeepm: Exploiting segmentation and context in deep neural networks for object detection,"Yukun Zhu, Raquel Urtasun, Ruslan Salakhutdinov, Sanja Fidler",2015,,,,4703-4711,,"In this paper, we propose an approach that exploits object segmentation in order to improve the accuracy of object detection. We frame the problem as inference in a Markov Random Field, in which each detection hypothesis scores object appearance as well as contextual information using Convolutional Neural Networks, and allows the hypothesis to choose and score a segment out of a large pool of accurate object segmentation proposals. This enables the detector to incorporate additional evidence when it is available and thus results in more accurate detections. Our experiments show an improvement of 4.1% in mAP over the R-CNN baseline on PASCAL VOC 2010, and 1.4% over the current state-of-the-art, demonstrating the power of our approach.",168회,"segdeepm: Exploiting segmentation and context in deep neural networks for object detection
Y Zhu, R Urtasun, R Salakhutdinov, S Fidler - Proceedings of the IEEE Conference on Computer …, 2015
168회 인용 관련 학술자료 전체 18개의 버전",Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,,,,,
Practical large-scale optimization for max-norm regularization,"Jason Lee, Benjamin Recht, Ruslan R Salakhutdinov, Nathan Srebro, Joel A Tropp",2010,,,23,,Neural Information Processing Systems,"The max-norm was proposed as a convex matrix regularizer in [1] and was shown to be empirically superior to the trace-norm for collaborative filtering problems. Although the max-norm can be computed in polynomial time, there are currently no practical algorithms for solving large-scale optimization problems that incorporate the max-norm. The present work uses a factorization technique of Burer and Monteiro [2] to devise scalable first-order algorithms for convex programs involving the max-norm. These algorithms are applied to solve huge collaborative filtering, graph cut, and clustering problems. Empirically, the new methods outperform mature techniques from all three areas.",166회,"Practical large-scale optimization for max-norm regularization
J Lee, B Recht, RR Salakhutdinov, N Srebro, JA Tropp - 2010
166회 인용 관련 학술자료 전체 23개의 버전",,,,,,,,
Transfer learning by borrowing examples for multiclass object detection,Joseph Jaewhan Lim,2012,,,,,,"Despite the recent trend of increasingly large datasets for object detection, there still exist many classes with few training examples. To overcome this lack of training data for certain classes, we propose a novel way of augmenting the training data for each class by borrowing and transforming examples from other classes. Our model learns which training instances from other classes to borrow and how to transform the borrowed examples so that they become more similar to instances from the target class. Our experimental results demonstrate that our new object detector, with borrowed and transformed examples, improves upon the current state-of-the-art detector on the challenging SUN09 object detection dataset.",152회,"Transfer learning by borrowing examples for multiclass object detection
JJ Lim - 2012
152회 인용 관련 학술자료 전체 16개의 버전",,,,Massachusetts Institute of Technology,,,,
Stochastic variational deep kernel learning,"Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, Eric P Xing",2016/11/1,arXiv preprint arXiv:1611.00336,,,,,"Deep kernel learning combines the non-parametric flexibility of kernel methods with the inductive biases of deep learning architectures. We propose a novel deep kernel learning model and stochastic variational inference procedure which generalizes deep kernel learning approaches to enable classification, multi-task learning, additive covariance structures, and stochastic gradient training. Specifically, we apply additive base kernels to subsets of output features from deep neural architectures, and jointly learn the parameters of the base kernels and deep network through a Gaussian process marginal likelihood objective. Within this framework, we derive an efficient form of stochastic variational inference which leverages local kernel interpolation, inducing points, and structure exploiting algebra. We show improved performance over stand alone deep networks, SVMs, and state of the art scalable Gaussian processes on several classification benchmarks, including an airline delay dataset containing 6 million training points, CIFAR, and ImageNet.",147회,"Stochastic variational deep kernel learning
AG Wilson, Z Hu, R Salakhutdinov, EP Xing - arXiv preprint arXiv:1611.00336, 2016
147회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
One-shot learning with a hierarchical nonparametric bayesian model,"Ruslan Salakhutdinov, Joshua Tenenbaum, Antonio Torralba",2012/6/27,,,,195-206,JMLR Workshop and Conference Proceedings,"We develop a hierarchical Bayesian model that learns categories from single training examples. The model transfers acquired knowledge from previously learned categories to a novel category, in the form of a prior over category means and variances. The model discovers how to group categories into meaningful super-categories that express different priors for new classes. Given a single example of a novel category, we can efficiently infer which super-category the novel category belongs to, and thereby estimate not only the new categories mean but also an appropriate similarity metric based on parameters inherited from the super-category. On MNIST and MSR Cambridge image datasets the model learns useful representations of novel categories based on just a single training example, and performs significantly better than simpler hierarchical Bayesian approaches. It can also discover new categories in a completely unsupervised fashion, given just one or a few examples.",145회,"One-shot learning with a hierarchical nonparametric bayesian model
R Salakhutdinov, J Tenenbaum, A Torralba - Proceedings of ICML Workshop on Unsupervised and …, 2012
145회 인용 관련 학술자료 전체 25개의 버전",Proceedings of ICML Workshop on Unsupervised and Transfer Learning,,,,,,,
On Multiplicative Integration with Recurrent Neural Networks,"Yuhuai Wu, Saizheng Zhang, Ying Zhang, Yoshua Bengio, Ruslan Salakhutdinov",2016/6/21,NIPS 2016,,,,,"We introduce a general and simple structural design called Multiplicative Integration (MI) to improve recurrent neural networks (RNNs). MI changes the way in which information from difference sources flows and is integrated in the computational building block of an RNN, while introducing almost no extra parameters. The new structure can be easily embedded into many popular RNN models, including LSTMs and GRUs. We empirically analyze its learning behaviour and conduct evaluations on several tasks using different RNN models. Our experimental results demonstrate that Multiplicative Integration can provide a substantial performance boost over many of the existing RNN models.",142회,"On multiplicative integration with recurrent neural networks
Y Wu, S Zhang, Y Zhang, Y Bengio, R Salakhutdinov - arXiv preprint arXiv:1606.06630, 2016
142회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Architectural Complexity Measures of Recurrent Neural Networks,"Saizheng Zhang, Yuhuai Wu, Tong Che, Zhouhan Lin, Roland Memisevic, Ruslan Salakhutdinov, Yoshua Bengio",2016/2/26,NIPS 2016,,,,,"In this paper, we systematically analyze the connecting architectures of recurrent neural networks (RNNs). Our main contribution is twofold: first, we present a rigorous graph-theoretic framework describing the connecting architectures of RNNs in general. Second, we propose three architecture complexity measures of RNNs:(a) the recurrent depth, which captures the RNN's over-time nonlinear complexity,(b) the feedforward depth, which captures the local input-output nonlinearity (similar to the"" depth"" in feedforward neural networks (FNNs)), and (c) the recurrent skip coefficient which captures how rapidly the information propagates over time. We rigorously prove each measure's existence and computability. Our experimental results show that RNNs might benefit from larger recurrent depth and feedforward depth. We further demonstrate that increasing recurrent skip coefficient offers performance boosts on long term dependency problems.",138회,"Architectural complexity measures of recurrent neural networks
S Zhang, Y Wu, T Che, Z Lin, R Memisevic… - arXiv preprint arXiv:1602.08210, 2016
138회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Improving neural networks by preventing co-adaptation of feature detectors. arXiv 2012,"Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, Ruslan R Salakhutdinov",,arXiv preprint arXiv:1207.0580,,,,,,133회,"Improving neural networks by preventing co-adaptation of feature detectors. arXiv 2012
GE Hinton, N Srivastava, A Krizhevsky, I Sutskever… - arXiv preprint arXiv:1207.0580
133회 인용 관련 학술자료",,,,,,,,
A better way to pretrain deep boltzmann machines,"Ruslan Salakhutdinov, Geoffrey Hinton",2012,,,,2447-2455,,"We describe how the pretraining algorithm for Deep Boltzmann Machines (DBMs) is related to the pretraining algorithm for Deep Belief Networks and we show that under certain conditions, the pretraining procedure improves the variational lower bound of a two-hidden-layer DBM. Based on this analysis, we develop a different method of pretraining DBMs that distributes the modelling work more evenly over the hidden layers. Our results on the MNIST and NORB datasets demonstrate that the new pretraining algorithm allows us to learn better generative models.",132회,"A better way to pretrain deep boltzmann machines
GE Hinton, RR Salakhutdinov - Advances in Neural Information Processing Systems, 2012
132회 인용 관련 학술자료 전체 14개의 버전",Advances in Neural Information Processing Systems,,,,,,,
Learning in Markov random fields using tempered transitions,Russ R Salakhutdinov,2009,Advances in neural information processing systems,22,,1598-1606,,"Markov random fields (MRF’s), or undirected graphical models, provide a powerful framework for modeling complex dependencies among random variables. Maximum likelihood learning in MRF’s is hard due to the presence of the global normalizing constant. In this paper we consider a class of stochastic approximation algorithms of the Robbins-Monro type that use Markov chain Monte Carlo to do approximate maximum likelihood learning. We show that using MCMC operators based on tempered transitions enables the stochastic approximation algorithm to better explore highly multimodal distributions, which considerably improves parameter estimates in large, densely-connected MRF’s. Our results on MNIST and NORB datasets demonstrate that we can successfully learn good generative models of high-dimensional, richly structured data that perform well on digit and object recognition tasks.",128회,"Learning in Markov random fields using tempered transitions
RR Salakhutdinov - Advances in neural information processing systems, 2009
128회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
Learning stochastic feedforward neural networks,"Charlie Tang, Russ R Salakhutdinov",2013,,,,530-538,,"Multilayer perceptrons (MLPs) or neural networks are popular models used for nonlinear regression and classification tasks. As regressors, MLPs model the conditional distribution of the predictor variables Y given the input variables X. However, this predictive distribution is assumed to be unimodal (eg Gaussian). For tasks involving structured prediction, the conditional distribution should be multi-modal, resulting in one-to-many mappings. By using stochastic hidden variables rather than deterministic ones, Sigmoid Belief Nets (SBNs) can induce a rich multimodal distribution in the output space. However, previously proposed learning algorithms for SBNs are not efficient and unsuitable for modeling real-valued data. In this paper, we propose a stochastic feedforward network with hidden layers composed of both deterministic and stochastic variables. A new Generalized EM training procedure using importance sampling allows us to efficiently learn complicated conditional distributions. Our model achieves superior performance on synthetic and facial expressions datasets compared to conditional Restricted Boltzmann Machines and Mixture Density Networks. In addition, the latent features of our model improves classification and can learn to generate colorful textures of objects.",127회,"Learning stochastic feedforward neural networks
C Tang, RR Salakhutdinov - Advances in Neural Information Processing Systems, 2013
127회 인용 관련 학술자료 전체 8개의 버전",Advances in Neural Information Processing Systems,,,,,,,
Open domain question answering using early fusion of knowledge bases and text,"Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan Salakhutdinov, William W Cohen",2018/9/4,arXiv preprint arXiv:1809.00782,,,,,"Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at this https URL.",124회,"Open domain question answering using early fusion of knowledge bases and text
H Sun, B Dhingra, M Zaheer, K Mazaitis… - arXiv preprint arXiv:1809.00782, 2018
124회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Controllable text generation,"Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, Eric P Xing",2017/3,arXiv preprint arXiv:1703.00955,4,,,,,124회,"Controllable text generation
Z Hu, Z Yang, X Liang, R Salakhutdinov, EP Xing - arXiv preprint arXiv:1703.00955, 2017
124회 인용 관련 학술자료",,,,,,,,
Restricted Boltzmann machines for neuroimaging: an application in identifying intrinsic networks,"R Devon Hjelm, Vince D Calhoun, Ruslan Salakhutdinov, Elena A Allen, Tulay Adali, Sergey M Plis",2014/8/1,NeuroImage,96,,245-260,Academic Press,"Matrix factorization models are the current dominant approach for resolving meaningful data-driven features in neuroimaging data. Among them, independent component analysis (ICA) is arguably the most widely used for identifying functional networks, and its success has led to a number of versatile extensions to group and multimodal data. However there are indications that ICA may have reached a limit in flexibility and representational capacity, as the majority of such extensions are case-driven, custom-made solutions that are still contained within the class of mixture models. In this work, we seek out a principled and naturally extensible approach and consider a probabilistic model known as a restricted Boltzmann machine (RBM). An RBM separates linear factors from functional brain imaging data by fitting a probability distribution model to the data. Importantly, the solution can be used as a building block for …",122회,"Restricted Boltzmann machines for neuroimaging: an application in identifying intrinsic networks
RD Hjelm, VD Calhoun, R Salakhutdinov, EA Allen… - NeuroImage, 2014
122회 인용 관련 학술자료 전체 14개의 버전",,,,,,,,
Discovering binary codes for documents by learning deep generative models,"Geoffrey Hinton, Ruslan Salakhutdinov",2011/1,Topics in Cognitive Science,3,1,74-91,Blackwell Publishing Ltd,"We describe a deep generative model in which the lowest layer represents the word‐count vector of a document and the top layer represents a learned binary code for that document. The top two layers of the generative model form an undirected associative memory and the remaining layers form a belief net with directed, top‐down connections. We present efficient learning and inference procedures for this type of generative model and show that it allows more accurate and much faster retrieval than latent semantic analysis. By using our method as a filter for a much slower method called TF‐IDF we achieve higher accuracy than TF‐IDF alone and save several orders of magnitude in retrieval time. By using short binary codes as addresses, we can perform retrieval on very large document sets in a time that is independent of the size of the document set using only one word of memory to describe each document.",119회,"Discovering binary codes for documents by learning deep generative models
G Hinton, R Salakhutdinov - Topics in Cognitive Science, 2011
119회 인용 관련 학술자료 전체 14개의 버전",,,,,,,,
A survey on graph kernels,"Nils M Kriege, Fredrik D Johansson, Christopher Morris",2020/12,,5,1,1-42,SpringerOpen,"Graph kernels have become an established and widely-used technique for solving classification tasks on graphs. This survey gives a comprehensive overview of techniques for kernel-based graph classification developed in the past 15 years. We describe and categorize graph kernels based on properties inherent to their design, such as the nature of their extracted graph features, their method of computation and their applicability to problems in practice. In an extensive experimental evaluation, we study the classification accuracy of a large suite of graph kernels on established benchmarks as well as new datasets. We compare the performance of popular kernels with several baseline methods and study the effect of applying a Gaussian RBF kernel to the metric induced by a graph kernel. In doing so, we find that simple baselines become competitive after this transformation on some datasets. Moreover, we study the extent to which existing graph kernels agree in their predictions (and prediction errors) and obtain a data-driven categorization of kernels as result. Finally, based on our experimental results, we derive a practitioner’s guide to kernel-based graph classification.",117회,"A survey on graph kernels
NM Kriege, FD Johansson, C Morris - Applied Network Science, 2020
117회 인용 관련 학술자료 전체 9개의 버전",,,Applied Network Science,,,,,
Semi-supervised qa with generative domain-adaptive nets,"Zhilin Yang, Junjie Hu, Ruslan Salakhutdinov, William W Cohen",2017/2/7,arXiv preprint arXiv:1702.02206,,,,,"We study the problem of semi-supervised question answering----utilizing unlabeled text to boost the performance of question answering models. We propose a novel training framework, the Generative Domain-Adaptive Nets. In this framework, we train a generative model to generate questions based on the unlabeled text, and combine model-generated questions with human-generated questions for training question answering models. We develop novel domain adaptation algorithms, based on reinforcement learning, to alleviate the discrepancy between the model-generated data distribution and the human-generated data distribution. Experiments show that our proposed framework obtains substantial improvement from unlabeled text.",116회,"Semi-supervised qa with generative domain-adaptive nets
Z Yang, J Hu, R Salakhutdinov, WW Cohen - arXiv preprint arXiv:1702.02206, 2017
116회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Adaptive overrelaxed bound optimization methods,"Ruslan Salakhutdinov, Sam Roweis",2003/8/21,,,,664-671,,"We study a class of overrelaxed bound optimization algorithms, and their relationship to standard bound optimizers, such as Expectation-Maximization, Iterative Scaling, CCCP and Non-Negative Matrix Factorization. We provide a theoretical analysis of the convergence properties of these optimizers and identify analytic conditions under which they are expected to outperform the standard versions. Based on this analysis, we propose a novel, simple adaptive overrelaxed scheme for practical optimization and report empirical results on several synthetic and real-world data sets showing that these new adaptive methods exhibit superior performance (in certain cases by several times speedup) compared to their traditional counterparts. Our extensions are simple to implement, apply to a wide variety of algorithms, almost always give a substantial speedup, and do not require any theoretical analysis of the underlying algorithm.",115회,"Adaptive overrelaxed bound optimization methods
R Salakhutdinov, ST Roweis - Proceedings of the 20th International Conference on …, 2003
115회 인용 관련 학술자료 전체 17개의 버전",International Conference on Machine Learning (ICML),,,,,,,
Multimodal transformer for unaligned multimodal language sequences,"Yao-Hung Hubert Tsai, Shaojie Bai, Paul Pu Liang, J Zico Kolter, Louis-Philippe Morency, Ruslan Salakhutdinov",2019/7,Proceedings of the conference. Association for Computational Linguistics. Meeting,2019,,6558,NIH Public Access,"Human language is often multimodal, which comprehends a mixture of natural language, facial gestures, and acoustic behaviors. However, two major challenges in modeling such multimodal human language time-series data exist: 1) inherent data non-alignment due to variable sampling rates for the sequences from each modality; and 2) long-range dependencies between elements across modalities. In this paper, we introduce the Multimodal Transformer (MulT) to generically address the above issues in an end-to-end manner without explicitly aligning the data. At the heart of our model is the directional pairwise cross-modal attention, which attends to interactions between multimodal sequences across distinct time steps and latently adapt streams from one modality to another. Comprehensive experiments on both aligned and non-aligned multimodal time-series show that our model outperforms state-of-the-art …",106회,"Multimodal transformer for unaligned multimodal language sequences
YHH Tsai, S Bai, PP Liang, JZ Kolter, LP Morency… - Proceedings of the conference. Association for …, 2019
106회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
Learning robust visual-semantic embeddings,"Yao-Hung Hubert Tsai, Liang-Kang Huang, Ruslan Salakhutdinov",2017,,,,3571-3580,,"Many of the existing methods for learning joint embedding of images and text use only supervised information from paired images and its textual attributes. Taking advantage of the recent success of unsupervised learning in deep neural networks, we propose an end-to-end learning framework that is able to extract more robust multi-modal representations across domains. The proposed method combines representation learning models (ie, auto-encoders) together with cross-domain learning criteria (ie, Maximum Mean Discrepancy loss) to learn joint embeddings for semantic and visual features. A novel technique of unsupervised-data adaptation inference is introduced to construct more comprehensive embeddings for both labeled and unlabeled data. We evaluate our method on Animals with Attributes and Caltech-UCSD Birds 200-2011 dataset with a wide range of applications, including zero and few-shot image recognition and retrieval, from inductive to transductive settings. Empirically, we show that our framework improves over the current state of the art on many of the considered tasks.",103회,"Learning robust visual-semantic embeddings
YH Hubert Tsai, LK Huang, R Salakhutdinov - Proceedings of the IEEE International Conference on …, 2017
103회 인용 관련 학술자료 전체 5개의 버전",Proceedings of the IEEE International Conference on Computer Vision,,,,,,,
Learning deep Boltzmann machines using adaptive MCMC,Ruslan Salakhutdinov,2010,,,,943-950,,"When modeling high-dimensional richly structured data, it is often the case that the distribution defined by the Deep Boltzmann Machine (DBM) has a rough energy landscape with many local minima separated by high energy barriers. The commonly used Gibbs sampler tends to get trapped in one local mode, which often results in unstable learning dynamics and leads to poor parameter estimates. In this paper, we concentrate on learning DBM’s using adaptive MCMC algorithms. We first show a close connection between Fast PCD and adaptive MCMC. We then develop a Coupled Adaptive Simulated Tempering algorithm that can be used to better explore a highly multimodal energy landscape. Finally, we demonstrate that the proposed algorithm considerably improves parameter estimates, particularly when learning large-scale DBM’s.",99회,"Learning deep Boltzmann machines using adaptive MCMC
R Salakhutdinov - Proceedings of the 27th International Conference on …, 2010
99회 인용 관련 학술자료 전체 12개의 버전",Proceedings of the 27th International Conference on Machine Learning (ICML-10),,,,,,,
Evaluating probabilities under high-dimensional latent variable models,"Iain Murray, Ruslan Salakhutdinov",2009,,,,,,"We present a simple new Monte Carlo algorithm for evaluating probabilities of observations in complex latent variable models, such as Deep Belief Networks. While the method is based on Markov chains, estimates based on short runs are formally unbiased. In expectation, the log probability of a test set will be underestimated, and this could form the basis of a probabilistic bound. The method is much cheaper than gold-standard annealing-based methods and only slightly more expensive than the cheapest Monte Carlo methods. We give examples of the new method substantially improving simple variational bounds at modest extra cost.",97회,"Evaluating probabilities under high-dimensional latent variable models
I Murray, R Salakhutdinov - 2009
97회 인용 관련 학술자료 전체 18개의 버전",,,,,,,,
Exploiting compositionality to explore a large space of model structures,"Roger Grosse, Ruslan R Salakhutdinov, William T Freeman, Joshua B Tenenbaum",2012/10/16,,,,,,"The recent proliferation of richly structured probabilistic models raises the question of how to automatically determine an appropriate model for a dataset. We investigate this question for a space of matrix decomposition models which can express a variety of widely used models from unsupervised learning. To enable model selection, we organize these models into a context-free grammar which generates a wide variety of structures through the compositional application of a few simple rules. We use our grammar to generically and efficiently infer latent components and estimate predictive likelihood for nearly 2500 structures using a small toolbox of reusable algorithms. Using a greedy search over our grammar, we automatically choose the decomposition structure from raw data by evaluating only a small fraction of all models. The proposed method typically finds the correct structure for synthetic data and backs off gracefully to simpler models under heavy noise. It learns sensible structures for datasets as diverse as image patches, motion capture, 20 Questions, and US Senate votes, all using exactly the same code.",96회,"Exploiting compositionality to explore a large space of model structures
R Grosse, RR Salakhutdinov, WT Freeman… - arXiv preprint arXiv:1210.4856, 2012
96회 인용 관련 학술자료 전체 25개의 버전",Uncertainty in Artificial Intelligence (UAI),,,,,,,
On unifying deep generative models,"Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, Eric P Xing",2017/6/2,arXiv preprint arXiv:1706.00550,,,,,"Deep generative models have achieved impressive success in recent years. Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), as emerging families for generative model learning, have largely been considered as two distinct paradigms and received extensive independent studies respectively. This paper aims to establish formal connections between GANs and VAEs through a new formulation of them. We interpret sample generation in GANs as performing posterior inference, and show that GANs and VAEs involve minimizing KL divergences of respective posterior and inference distributions with opposite directions, extending the two learning phases of classic wake-sleep algorithm, respectively. The unified view provides a powerful tool to analyze a diverse set of existing model variants, and enables to transfer techniques across research lines in a principled way. For example, we apply the importance weighting method in VAE literatures for improved GAN learning, and enhance VAEs with an adversarial mechanism that leverages generated samples. Experiments show generality and effectiveness of the transferred techniques.",95회,"On unifying deep generative models
Z Hu, Z Yang, R Salakhutdinov, EP Xing - arXiv preprint arXiv:1706.00550, 2017
95회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Geometry of optimization and implicit regularization in deep learning,"Behnam Neyshabur, Ryota Tomioka, Ruslan Salakhutdinov, Nathan Srebro",2017/5/8,arXiv preprint arXiv:1705.03071,,,,,"We argue that the optimization plays a crucial role in generalization of deep learning models through implicit regularization. We do this by demonstrating that generalization ability is not controlled by network size but rather by some other implicit control. We then demonstrate how changing the empirical optimization procedure can improve generalization, even if actual optimization quality is not affected. We do so by studying the geometry of the parameter space of deep networks, and devising an optimization algorithm attuned to this geometry.
Comments: This survey chapter was done as a part of Intel Collaborative Research institute for Computational Intelligence (ICRI-CI)"" Why & When Deep Learning works--looking inside Deep Learning"" compendium with the generous support of ICRI-CI. arXiv admin note: substantial text overlap with arXiv: 1506.02617",93회,"Geometry of optimization and implicit regularization in deep learning
B Neyshabur, R Tomioka, R Salakhutdinov, N Srebro - arXiv preprint arXiv:1705.03071, 2017
93회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Multiple futures prediction,"Yichuan Charlie Tang, Ruslan Salakhutdinov",2019/11/4,arXiv preprint arXiv:1911.00997,,,,,"Temporal prediction is critical for making intelligent and robust decisions in complex dynamic environments. Motion prediction needs to model the inherently uncertain future which often contains multiple potential outcomes, due to multi-agent interactions and the latent goals of others. Towards these goals, we introduce a probabilistic framework that efficiently learns latent variables to jointly model the multi-step future motions of agents in a scene. Our framework is data-driven and learns semantically meaningful latent variables to represent the multimodal future, without requiring explicit labels. Using a dynamic attention-based state encoder, we learn to encode the past as well as the future interactions among agents, efficiently scaling to any number of agents. Finally, our model can be used for planning via computing a conditional probability density over the trajectories of other agents given a hypothetical rollout of the'self'agent. We demonstrate our algorithms by predicting vehicle trajectories of both simulated and real data, demonstrating the state-of-the-art results on several vehicle trajectory datasets.",88회,"Multiple futures prediction
YC Tang, R Salakhutdinov - arXiv preprint arXiv:1911.00997, 2019
88회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Learning generative models with visual attention,"Yichuan Tang, Nitish Srivastava, Ruslan Salakhutdinov",2013/12/20,arXiv preprint arXiv:1312.6110,,,,,"Attention has long been proposed by psychologists as important for effectively dealing with the enormous sensory stimulus available in the neocortex. Inspired by the visual attention models in computational neuroscience and the need of object-centric data for generative models, we describe for generative learning framework using attentional mechanisms. Attentional mechanisms can propagate signals from region of interest in a scene to an aligned canonical representation, where generative modeling takes place. By ignoring background clutter, generative models can concentrate their resources on the object of interest. Our model is a proper graphical model where the 2D Similarity transformation is a part of the top-down process. A ConvNet is employed to provide good initializations during posterior inference which is based on Hamiltonian Monte Carlo. Upon learning images of faces, our model can robustly attend to face regions of novel test subjects. More importantly, our model can learn generative models of new faces from a novel dataset of large images where the face locations are not known.",88회,"Learning generative models with visual attention
Y Tang, N Srivastava, R Salakhutdinov - arXiv preprint arXiv:1312.6110, 2013
88회 인용 관련 학술자료 전체 13개의 버전",,,,,,,,
On the convergence of bound optimization algorithms,"Ruslan R Salakhutdinov, Sam T Roweis, Zoubin Ghahramani",2012/10/19,arXiv preprint arXiv:1212.2490,,,,,"Many practitioners who use the EM algorithm complain that it is sometimes slow. When does this happen, and what can be done about it? In this paper, we study the general class of bound optimization algorithms-including Expectation-Maximization, Iterative Scaling and CCCP-and their relationship to direct optimization algorithms such as gradient-based methods for parameter learning. We derive a general relationship between the updates performed by bound optimization methods and those of gradient and second-order methods and identify analytic conditions under which bound optimization algorithms exhibit quasi-Newton behavior, and conditions under which they possess poor, first-order convergence. Based on this analysis, we consider several specific algorithms, interpret and analyze their convergence properties and provide some recipes for preprocessing input to these algorithms to yield faster convergence behavior. We report empirical results supporting our analysis and showing that simple data preprocessing can result in dramatically improved performance of bound optimizers in practice.",87회,"On the convergence of bound optimization algorithms
RR Salakhutdinov, ST Roweis, Z Ghahramani - arXiv preprint arXiv:1212.2490, 2012
87회 인용 관련 학술자료 전체 20개의 버전",,,,,,,,
Learning factorized multimodal representations,"Yao-Hung Hubert Tsai, Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency, Ruslan Salakhutdinov",2018/6/16,arXiv preprint arXiv:1806.06176,,,,,"Learning multimodal representations is a fundamentally complex research problem due to the presence of multiple heterogeneous sources of information. Although the presence of multiple modalities provides additional valuable information, there are two key challenges to address when learning from multimodal data: 1) models must learn the complex intra-modal and cross-modal interactions for prediction and 2) models must be robust to unexpected missing or noisy modalities during testing. In this paper, we propose to optimize for a joint generative-discriminative objective across multimodal data and labels. We introduce a model that factorizes representations into two sets of independent factors: multimodal discriminative and modality-specific generative factors. Multimodal discriminative factors are shared across all modalities and contain joint multimodal features required for discriminative tasks such as sentiment prediction. Modality-specific generative factors are unique for each modality and contain the information required for generating data. Experimental results show that our model is able to learn meaningful multimodal representations that achieve state-of-the-art or competitive performance on six multimodal datasets. Our model demonstrates flexible generative capabilities by conditioning on independent factors and can reconstruct missing modalities without significantly impacting performance. Lastly, we interpret our factorized representations to understand the interactions that influence multimodal learning.",86회,"Learning factorized multimodal representations
YHH Tsai, PP Liang, A Zadeh, LP Morency… - arXiv preprint arXiv:1806.06176, 2018
86회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Deep lambertian networks,"Yichuan Tang, Ruslan Salakhutdinov, Geoffrey Hinton",2012/6/27,,,,,,"Visual perception is a challenging problem in part due to illumination variations. A possible solution is to first estimate an illumination invariant representation before using it for recognition. The object albedo and surface normals are examples of such representations. In this paper, we introduce a multilayer generative model where the latent variables include the albedo, surface normals, and the light source. Combining Deep Belief Nets with the Lambertian reflectance assumption, our model can learn good priors over the albedo from 2D images. Illumination variations can be explained by changing only the lighting latent variable in our model. By transferring learned knowledge from similar objects, albedo and surface normals estimation from a single image is possible in our model. Experiments demonstrate that our model is able to generalize as well as improve over standard baselines in one-shot face recognition.",86회,"Deep lambertian networks
Y Tang, R Salakhutdinov, G Hinton - arXiv preprint arXiv:1206.6445, 2012
86회 인용 관련 학술자료 전체 20개의 버전",29th International Conference on Machine Learning (ICML 2012),,,,,,,
Gated-attention architectures for task-oriented language grounding,"Devendra Singh Chaplot, Kanthashree Mysore Sathyendra, Rama Kumar Pasumarthi, Dheeraj Rajagopal, Ruslan Salakhutdinov",2018/4/29,Proceedings of the AAAI Conference on Artificial Intelligence,32,1,,,"To perform tasks specified by natural language instructions, autonomous agents need to extract semantically meaningful representations of language and map it to visual elements and actions in the environment. This problem is called task-oriented language grounding. We propose an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments which assumes no prior linguistic or perceptual knowledge and requires only raw pixels from the environment and the natural language instruction as input. The proposed model combines the image and text representations using a Gated-Attention mechanism and learns a policy to execute the natural language instruction using standard reinforcement and imitation learning methods. We show the effectiveness of the proposed model on unseen instructions as well as unseen maps, both quantitatively and qualitatively. We also introduce a novel environment based on a 3D game engine to simulate the challenges of task-oriented language grounding over a rich set of instructions and environment states.",83회,"Gated-attention architectures for task-oriented language grounding
DS Chaplot, KM Sathyendra, RK Pasumarthi… - Proceedings of the AAAI Conference on Artificial …, 2018
83회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Words or characters? fine-grained gating for reading comprehension,"Zhilin Yang, Bhuwan Dhingra, Ye Yuan, Junjie Hu, William W Cohen, Ruslan Salakhutdinov",2016/11/6,arXiv preprint arXiv:1611.01724,,,,,"Previous work combines word-level and character-level representations using concatenation or scalar weighting, which is suboptimal for high-level tasks like reading comprehension. We present a fine-grained gating mechanism to dynamically combine word-level and character-level representations based on properties of the words. We also extend the idea of fine-grained gating to modeling the interaction between questions and paragraphs for reading comprehension. Experiments show that our approach can improve the performance on reading comprehension tasks, achieving new state-of-the-art results on the Children's Book Test dataset. To demonstrate the generality of our gating mechanism, we also show improved results on a social media tag prediction task.",82회,"Words or characters? fine-grained gating for reading comprehension
Z Yang, B Dhingra, Y Yuan, J Hu, WW Cohen… - arXiv preprint arXiv:1611.01724, 2016
82회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Point cloud gan,"Chun-Liang Li, Manzil Zaheer, Yang Zhang, Barnabas Poczos, Ruslan Salakhutdinov",2018/10/13,arXiv preprint arXiv:1810.05795,,,,,"Generative Adversarial Networks (GAN) can achieve promising performance on learning complex data distributions on different types of data. In this paper, we first show a straightforward extension of existing GAN algorithm is not applicable to point clouds, because the constraint required for discriminators is undefined for set data. We propose a two fold modification to GAN algorithm for learning to generate point clouds (PC-GAN). First, we combine ideas from hierarchical Bayesian modeling and implicit generative models by learning a hierarchical and interpretable sampling process. A key component of our method is that we train a posterior inference network for the hidden variables. Second, instead of using only state-of-the-art Wasserstein GAN objective, we propose a sandwiching objective, which results in a tighter Wasserstein distance estimate than the commonly used dual form. Thereby, PC-GAN defines a generic framework that can incorporate many existing GAN algorithms. We validate our claims on ModelNet40 benchmark dataset. Using the distance between generated point clouds and true meshes as metric, we find that PC-GAN trained by the sandwiching objective achieves better results on test data than the existing methods. Moreover, as a byproduct, PC-GAN learns versatile latent representations of point clouds, which can achieve competitive performance with other unsupervised learning algorithms on object recognition task. Lastly, we also provide studies on generating unseen classes of objects and transforming image to point cloud, which demonstrates the compelling generalization capability and potentials of PC-GAN.",80회,"Point cloud gan
CL Li, M Zaheer, Y Zhang, B Poczos, R Salakhutdinov - arXiv preprint arXiv:1810.05795, 2018
80회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Deep mixtures of factor analysers,"Yichuan Tang, Ruslan Salakhutdinov, Geoffrey Hinton",2012/6/18,,,,,,"An efficient way to learn deep density models that have many layers of latent variables is to learn one layer at a time using a model that has only one layer of latent variables. After learning each layer, samples from the posterior distributions for that layer are used as training data for learning the next layer. This approach is commonly used with Restricted Boltzmann Machines, which are undirected graphical models with a single hidden layer, but it can also be used with Mixtures of Factor Analysers (MFAs) which are directed graphical models. In this paper, we present a greedy layer-wise learning algorithm for Deep Mixtures of Factor Analysers (DMFAs). Even though a DMFA can be converted to an equivalent shallow MFA by multiplying together the factor loading matrices at different levels, learning and inference are much more efficient in a DMFA and the sharing of each lower-level factor loading matrix by many different higher level MFAs prevents overfitting. We demonstrate empirically that DMFAs learn better density models than both MFAs and two types of Restricted Boltzmann Machine on a wide variety of datasets.",80회,"Deep mixtures of factor analysers
Y Tang, R Salakhutdinov, G Hinton - arXiv preprint arXiv:1206.4635, 2012
80회 인용 관련 학술자료 전체 24개의 버전",29th International Conference on Machine Learning (ICML 2012),,,,,,,
A multiplicative model for learning distributed text-based attribute representations,"Ryan Kiros, Richard S Zemel, Ruslan Salakhutdinov",2014/6/10,arXiv preprint arXiv:1406.2710,,,,,"In this paper we propose a general framework for learning distributed representations of attributes: characteristics of text whose representations can be jointly learned with word embeddings. Attributes can correspond to document indicators (to learn sentence vectors), language indicators (to learn distributed language representations), meta-data and side information (such as the age, gender and industry of a blogger) or representations of authors. We describe a third-order model where word context and attribute vectors interact multiplicatively to predict the next word in a sequence. This leads to the notion of conditional word similarity: how meanings of words change when conditioned on different attributes. We perform several experimental tasks including sentiment classification, cross-lingual document classification, and blog authorship attribution. We also qualitatively evaluate conditional word neighbours and attribute-conditioned text generation.",75회,"A multiplicative model for learning distributed text-based attribute representations
R Kiros, RS Zemel, R Salakhutdinov - arXiv preprint arXiv:1406.2710, 2014
75회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
Learning and evaluating Boltzmann machines,Ruslan Salakhutdinov,2008/6/26,Utml Tr,2,,21,,"We provide a brief overview of the variational framework for obtaining deterministic approximations or upper bounds for the log-partition function. We also review some of the Monte Carlo based methods for estimating partition functions of arbitrary Markov Random Fields. We then develop an annealed importance sampling (AIS) procedure for estimating partition functions of restricted Boltzmann machines (RBM’s), semi-restricted Boltzmann machines (SRBM’s), and Boltzmann machines (BM’s). Our empirical results indicate that the AIS procedure provides much better estimates of the partition function than some of the popular variational-based methods. Finally, we develop a new learning algorithm for training general Boltzmann machines and show that it can be successfully applied to learning good generative models.",72회,"Learning and evaluating Boltzmann machines
R Salakhutdinov - Utml Tr, 2008
72회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
Resource configurable spoken query detection using deep Boltzmann machines,"Yaodong Zhang, Ruslan Salakhutdinov, Hung-An Chang, James Glass",2012/3/25,,,,5161-5164,IEEE,"In this paper we present a spoken query detection method based on posteriorgrams generated from Deep Boltzmann Machines (DBMs). The proposed method can be deployed in both semi-supervised and unsupervised training scenarios. The DBM-based posteriorgrams were evaluated on a series of keyword spotting tasks using the TIMIT speech corpus. In unsupervised training conditions, the DBM-approach improved upon our previous best unsupervised keyword detection performance using Gaussian mixture model-based posteriorgrams by over 10%. When limited amounts of labeled data were incorporated into training, the DBM-approach required less than one third of the annotated data in order to achieve a comparable performance of a system that used all of the annotated data for training.",70회,"Resource configurable spoken query detection using deep Boltzmann machines
Y Zhang, R Salakhutdinov, HA Chang, J Glass - 2012 IEEE International Conference on Acoustics …, 2012
70회 인용 관련 학술자료 전체 18개의 버전","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",,,,,,,
Learning to explore using active neural slam,"Devendra Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta, Ruslan Salakhutdinov",2020/4/10,arXiv preprint arXiv:2004.05155,,,,,"This work presents a modular and hierarchical approach to learn policies for exploring 3D environments, calledActive Neural SLAM'. Our approach leverages the strengths of both classical and learning-based methods, by using analytical path planners with learned SLAM module, and global and local policies. The use of learning provides flexibility with respect to input modalities (in the SLAM module), leverages structural regularities of the world (in global policies), and provides robustness to errors in state estimation (in local policies). Such use of learning within each module retains its benefits, while at the same time, hierarchical decomposition and modular training allow us to sidestep the high sample complexities associated with training end-to-end policies. Our experiments in visually and physically realistic simulated 3D environments demonstrate the effectiveness of our approach over past learning and geometry-based approaches. The proposed model can also be easily transferred to the PointGoal task and was the winning entry of the CVPR 2019 Habitat PointGoal Navigation Challenge.",64회,"Learning to explore using active neural slam
DS Chaplot, D Gandhi, S Gupta, A Gupta… - arXiv preprint arXiv:2004.05155, 2020
64회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Neural models for reasoning over multiple mentions using coreference,"Bhuwan Dhingra, Qiao Jin, Zhilin Yang, William W Cohen, Ruslan Salakhutdinov",2018/4/16,arXiv preprint arXiv:1804.05922,,,,,"Many problems in NLP require aggregating information from multiple mentions of the same entity which may be far apart in the text. Existing Recurrent Neural Network (RNN) layers are biased towards short-term dependencies and hence not suited to such tasks. We present a recurrent layer which is instead biased towards coreferent dependencies. The layer uses coreference annotations extracted from an external system to connect entity mentions belonging to the same cluster. Incorporating this layer into a state-of-the-art reading comprehension model improves performance on three datasets--Wikihop, LAMBADA and the bAbi AI tasks--with large gains when training data is scarce.",64회,"Neural models for reasoning over multiple mentions using coreference
B Dhingra, Q Jin, Z Yang, WW Cohen, R Salakhutdinov - arXiv preprint arXiv:1804.05922, 2018
64회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Tensor Analyzers.,"Yichuan Tang, Ruslan Salakhutdinov, Geoffrey E Hinton",2013,,,,163-171,,"Factor Analysis is a statistical method that seeks to explain linear variations in data by using unobserved latent variables. Due to its additive nature, it is not suitable for modeling data that is generated by multiple groups of latent factors which interact multiplicatively. In this paper, we introduce Tensor Analyzers which are a multilinear generalization of Factor Analyzers. We describe an efficient way of sampling from the posterior distribution over factor values and we demonstrate that these samples can be used in the EM algorithm for learning interesting mixture models of natural image patches. Tensor Analyzers can also accurately recognize a face under significant pose and illumination variations when given only one previous image of that face. We also show that Tensor Analyzers can be trained in an unsupervised, semi-supervised, or fully supervised settings.",63회,"Tensor analyzers
Y Tang, R Salakhutdinov, G Hinton - International conference on machine learning, 2013
63회 인용 관련 학술자료 전체 16개의 버전",International Conference on Machine Learning (ICML),,,,,,,
Learning with the weighted trace-norm under arbitrary sampling distributions,"Rina Foygel, Ruslan Salakhutdinov, Ohad Shamir, Nathan Srebro",2011/6/21,arXiv preprint arXiv:1106.4251,,,,,"We provide rigorous guarantees on learning with the weighted trace-norm under arbitrary sampling distributions. We show that the standard weighted trace-norm might fail when the sampling distribution is not a product distribution (ie when row and column indexes are not selected independently), present a corrected variant for which we establish strong learning guarantees, and demonstrate that it works better in practice. We provide guarantees when weighting by either the true or empirical sampling distribution, and suggest that even if the true distribution is known (or is uniform), weighting by the empirical distribution may be beneficial.",62회,"Learning with the weighted trace-norm under arbitrary sampling distributions
R Foygel, R Salakhutdinov, O Shamir, N Srebro - arXiv preprint arXiv:1106.4251, 2011
62회 인용 관련 학술자료 전체 19개의 버전",,,,,,,,
Graph neural tangent kernel: Fusing graph neural networks with graph kernels,"Simon S Du, Kangcheng Hou, Barnabás Póczos, Ruslan Salakhutdinov, Ruosong Wang, Keyulu Xu",2019/5/30,arXiv preprint arXiv:1905.13192,,,,,"While graph kernels (GKs) are easy to train and enjoy provable theoretical guarantees, their practical performances are limited by their expressive power, as the kernel function often depends on hand-crafted combinatorial features of graphs. Compared to graph kernels, graph neural networks (GNNs) usually achieve better practical performance, as GNNs use multi-layer architectures and non-linear activation functions to extract high-order information of graphs as features. However, due to the large number of hyper-parameters and the non-convex nature of the training procedure, GNNs are harder to train. Theoretical guarantees of GNNs are also not well-understood. Furthermore, the expressive power of GNNs scales with the number of parameters, and thus it is hard to exploit the full power of GNNs when computing resources are limited. The current paper presents a new class of graph kernels, Graph Neural Tangent Kernels (GNTKs), which correspond to infinitely wide multi-layer GNNs trained by gradient descent. GNTKs enjoy the full expressive power of GNNs and inherit advantages of GKs. Theoretically, we show GNTKs provably learn a class of smooth functions on graphs. Empirically, we test GNTKs on graph classification datasets and show they achieve strong performance.",60회,"Graph neural tangent kernel: Fusing graph neural networks with graph kernels
SS Du, K Hou, B Póczos, R Salakhutdinov, R Wang… - arXiv preprint arXiv:1905.13192, 2019
60회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Active neural localization,"Devendra Singh Chaplot, Emilio Parisotto, Ruslan Salakhutdinov",2018/1/24,arXiv preprint arXiv:1801.08214,,,,,"Localization is the problem of estimating the location of an autonomous agent from an observation and a map of the environment. Traditional methods of localization, which filter the belief based on the observations, are sub-optimal in the number of steps required, as they do not decide the actions taken by the agent. We propose"" Active Neural Localizer"", a fully differentiable neural network that learns to localize accurately and efficiently. The proposed model incorporates ideas of traditional filtering-based localization methods, by using a structured belief of the state with multiplicative interactions to propagate belief, and combines it with a policy model to localize accurately while minimizing the number of steps required for localization. Active Neural Localizer is trained end-to-end with reinforcement learning. We use a variety of simulation environments for our experiments which include random 2D mazes, random mazes in the Doom game engine and a photo-realistic environment in the Unreal game engine. The results on the 2D environments show the effectiveness of the learned policy in an idealistic setting while results on the 3D environments demonstrate the model's capability of learning the policy and perceptual model jointly from raw-pixel based RGB observations. We also show that a model trained on random textures in the Doom environment generalizes well to a photo-realistic office space environment in the Unreal engine.",60회,"Active neural localization
DS Chaplot, E Parisotto, R Salakhutdinov - arXiv preprint arXiv:1801.08214, 2018
60회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Scaling up natural gradient by sparsely factorizing the inverse Fisher matrix,"Roger Grosse, Ruslan Salakhudinov",2015,,37,,2304-2313,,"Second-order optimization methods, such as natural gradient, are difficult to apply to high-dimensional problems, because they require approximately solving large linear systems. We present FActorized Natural Gradient (FANG), an approximation to natural gradient descent where the Fisher matrix is approximated with a Gaussian graphical model whose precision matrix can be computed efficiently. We analyze the Fisher matrix for a small RBM and derive an extremely sparse graphical model which is a good match to the covariance of the sufficient statistics. Our experiments indicate that FANG allows RBMs to be trained more efficiently compared with stochastic gradient descent. Additionally, our analysis yields insight into the surprisingly good performance of the “centering trick” for training RBMs.",60회,"Scaling up natural gradient by sparsely factorizing the inverse fisher matrix
R Grosse, R Salakhudinov - International Conference on Machine Learning, 2015
60회 인용 관련 학술자료 전체 15개의 버전",International Conference on Machine Learning (ICML),,,,,,,
Search on the replay buffer: Bridging planning and reinforcement learning,"Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine",2019/6/12,arXiv preprint arXiv:1906.05253,,,,,"The history of learning for control has been an exciting back and forth between two broad classes of algorithms: planning and reinforcement learning. Planning algorithms effectively reason over long horizons, but assume access to a local policy and distance metric over collision-free paths. Reinforcement learning excels at learning policies and the relative values of states, but fails to plan over long horizons. Despite the successes of each method in various domains, tasks that require reasoning over long horizons with limited feedback and high-dimensional observations remain exceedingly challenging for both planning and reinforcement learning algorithms. Frustratingly, these sorts of tasks are potentially the most useful, as they are simple to design (a human only need to provide an example goal state) and avoid reward shaping, which can bias the agent towards finding a sub-optimal solution. We introduce a general control algorithm that combines the strengths of planning and reinforcement learning to effectively solve these tasks. Our aim is to decompose the task of reaching a distant goal state into a sequence of easier tasks, each of which corresponds to reaching a subgoal. Planning algorithms can automatically find these waypoints, but only if provided with suitable abstractions of the environment--namely, a graph consisting of nodes and edges. Our main insight is that this graph can be constructed via reinforcement learning, where a goal-conditioned value function provides edge weights, and nodes are taken to be previously seen observations in a replay buffer. Using graph search over our replay buffer, we can automatically generate …",59회,"Search on the replay buffer: Bridging planning and reinforcement learning
B Eysenbach, R Salakhutdinov, S Levine - arXiv preprint arXiv:1906.05253, 2019
59회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
The power of asymmetry in binary hashing,"Behnam Neyshabur, Payman Yadollahpour, Yury Makarychev, Ruslan Salakhutdinov, Nathan Srebro",2013/11/29,arXiv preprint arXiv:1311.7662,,,,,"When approximating binary similarity using the hamming distance between short binary hashes, we show that even if the similarity is symmetric, we can have shorter and more accurate hashes by using two distinct code maps. Ie by approximating the similarity between and as the hamming distance between and , for two distinct binary codes , rather than as the hamming distance between and .",59회,"The power of asymmetry in binary hashing
B Neyshabur, P Yadollahpour, Y Makarychev… - arXiv preprint arXiv:1311.7662, 2013
59회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
The Omniglot challenge: a 3-year progress report,"Brenden M Lake, Ruslan Salakhutdinov, Joshua B Tenenbaum",2019/10/1,,29,,97-104,Elsevier,"Three years ago, we released the Omniglot dataset for one-shot learning, along with five challenge tasks and a computational model that addresses these tasks. The model was not meant to be the final word on Omniglot; we hoped that the community would build on our work and develop new approaches. In the time since, we have been pleased to see wide adoption of the dataset. There has been notable progress on one-shot classification, but researchers have adopted new splits and procedures that make the task easier. There has been less progress on the other four tasks. We conclude that recent approaches are still far from human-like concept learning on Omniglot, a challenge that requires performing many tasks with a single model.",57회,"The Omniglot challenge: a 3-year progress report
BM Lake, R Salakhutdinov, JB Tenenbaum - Current Opinion in Behavioral Sciences, 2019
57회 인용 관련 학술자료 전체 4개의 버전",,,Current Opinion in Behavioral Sciences,,,,,
Learning wake-sleep recurrent attention models,"Jimmy Ba, Roger Grosse, Ruslan Salakhutdinov, Brendan Frey",2015/9/22,arXiv preprint arXiv:1509.06812,,,,,"Despite their success, convolutional neural networks are computationally expensive because they must examine all image locations. Stochastic attention-based models have been shown to improve computational efficiency at test time, but they remain difficult to train because of intractable posterior inference and high variance in the stochastic gradient estimates. Borrowing techniques from the literature on training deep generative models, we present the Wake-Sleep Recurrent Attention Model, a method for training stochastic attention networks which improves posterior inference and which reduces the variability in the stochastic gradients. We show that our method can greatly speed up the training time for stochastic attention networks in the domains of image classification and caption generation.",57회,"Learning wake-sleep recurrent attention models
J Ba, R Grosse, R Salakhutdinov, B Frey - arXiv preprint arXiv:1509.06812, 2015
57회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Efficient exploration via state marginal matching,"Lisa Lee, Benjamin Eysenbach, Emilio Parisotto, Eric Xing, Sergey Levine, Ruslan Salakhutdinov",2019/6/12,arXiv preprint arXiv:1906.05274,,,,,"Exploration is critical to a reinforcement learning agent's performance in its given environment. Prior exploration methods are often based on using heuristic auxiliary predictions to guide policy behavior, lacking a mathematically-grounded objective with clear properties. In contrast, we recast exploration as a problem of State Marginal Matching (SMM), where we aim to learn a policy for which the state marginal distribution matches a given target state distribution. The target distribution is a uniform distribution in most cases, but can incorporate prior knowledge if available. In effect, SMM amortizes the cost of learning to explore in a given environment. The SMM objective can be viewed as a two-player, zero-sum game between a state density model and a parametric policy, an idea that we use to build an algorithm for optimizing the SMM objective. Using this formalism, we further demonstrate that prior work approximately maximizes the SMM objective, offering an explanation for the success of these methods. On both simulated and real-world tasks, we demonstrate that agents that directly optimize the SMM objective explore faster and adapt more quickly to new tasks as compared to prior exploration methods.",56회,"Efficient exploration via state marginal matching
L Lee, B Eysenbach, E Parisotto, E Xing, S Levine… - arXiv preprint arXiv:1906.05274, 2019
56회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Knowledge-based word sense disambiguation using topic models,"Devendra Singh Chaplot, Ruslan Salakhutdinov",2018/4/27,Proceedings of the AAAI Conference on Artificial Intelligence,32,1,,,"Word Sense Disambiguation is an open problem in Natural Language Processing which is particularly challenging and useful in the unsupervised setting where all the words in any given text need to be disambiguated without using any labeled data. Typically WSD systems use the sentence or a small window of words around the target word as the context for disambiguation because their computational complexity scales exponentially with the size of the context. In this paper, we leverage the formalism of topic model to design a WSD system that scales linearly with the number of words in the context. As a result, our system is able to utilize the whole document as the context for a word to be disambiguated. The proposed method is a variant of Latent Dirichlet Allocation in which the topic proportions for a document are replaced by synset proportions. We further utilize the information in the WordNet by assigning a non-uniform prior to synset distribution over words and a logistic-normal prior for document distribution over synsets. We evaluate the proposed method on Senseval-2, Senseval-3, SemEval-2007, SemEval-2013 and SemEval-2015 English All-Word WSD datasets and show that it outperforms the state-of-the-art unsupervised knowledge-based WSD system by a significant margin.",55회,"Knowledge-based word sense disambiguation using topic models
DS Chaplot, R Salakhutdinov - Proceedings of the AAAI Conference on Artificial …, 2018
55회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
A generic approach for escaping saddle points,"Sashank Reddi, Manzil Zaheer, Suvrit Sra, Barnabas Poczos, Francis Bach, Ruslan Salakhutdinov, Alex Smola",2018/3/31,,,,1233-1242,PMLR,"A central challenge to using first-order methods for optimizing nonconvex problems is the presence of saddle points. First-order methods often get stuck at saddle points, greatly deteriorating their performance. Typically, to escape from saddles one has to use second-order methods. However, most works on second-order methods rely extensively on expensive Hessian-based computations, making them impractical in large-scale settings. To tackle this challenge, we introduce a generic framework that minimizes Hessian-based computations while at the same time provably converging to second-order critical points. Our framework carefully alternates between a first-order and a second-order subroutine, using the latter only close to saddle points, and yields convergence results competitive to the state-of-the-art. Empirical results suggest that our strategy also enjoys a good practical performance.",55회,"A generic approach for escaping saddle points
S Reddi, M Zaheer, S Sra, B Poczos, F Bach… - International Conference on Artificial Intelligence and …, 2018
55회 인용 관련 학술자료 전체 4개의 버전",International Conference on Artificial Intelligence and Statistics,,,,,,,
Global pose estimation with an attention-based recurrent network,"Emilio Parisotto, Devendra Singh Chaplot, Jian Zhang, Ruslan Salakhutdinov",2018,,,,237-246,,"The ability for an agent to localize itself within an environment is crucial for many real-world applications. For unknown environments, Simultaneous Localization and Mapping (SLAM) enables incremental and concurrent building of and localizing within a map. We present a new, differentiable architecture, Neural Graph Optimizer, progressing towards a complete neural network solution for SLAM by designing a system composed of a local pose estimation model, a novel pose selection module, and a novel graph optimization process. The entire architecture is trained in an end-to-end fashion, enabling the network to automatically learn domain-specific features relevant to the visual odometry and avoid the involved process of feature engineering. We demonstrate the effectiveness of our system on a simulated 2D maze and the 3D ViZ-Doom environment.",53회,"Global pose estimation with an attention-based recurrent network
E Parisotto, D Singh Chaplot, J Zhang… - Proceedings of the IEEE Conference on Computer …, 2018
53회 인용 관련 학술자료 전체 8개의 버전",Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops,,,,,,,
Accurate and conservative estimates of MRF log-likelihood using reverse annealing.,"Yuri Burda, Roger B Grosse, Ruslan Salakhutdinov",2015,,,,,,"Markov random fields (MRFs) are difficult to evaluate as generative models because computing the test log-probabilities requires the intractable partition function. Annealed importance sampling (AIS) is widely used to estimate MRF partition functions, and often yields quite accurate results. However, AIS is prone to overestimate the log-likelihood with little indication that anything is wrong. We present the Reverse AIS Estimator (RAISE), a stochastic lower bound on the log-likelihood of an approximation to the original MRF model. RAISE requires only the same MCMC transition operators as standard AIS. Experimental results indicate that RAISE agrees closely with AIS log-probability estimates for RBMs, DBMs, and DBNs, but typically errs on the side of underestimating, rather than overestimating, the log-likelihood.",53회,"Accurate and conservative estimates of MRF log-likelihood using reverse annealing
Y Burda, R Grosse, R Salakhutdinov - Artificial Intelligence and Statistics, 2015
53회 인용 관련 학술자료 전체 14개의 버전",International Conference on Artificial Intelligence and Statistics (AISTATS),,,,,,,
Harnessing the power of infinitely wide deep nets on small-data tasks,"Sanjeev Arora, Simon S Du, Zhiyuan Li, Ruslan Salakhutdinov, Ruosong Wang, Dingli Yu",2019/10/3,arXiv preprint arXiv:1910.01663,,,,,"Recent research shows that the following two models are equivalent:(a) infinitely wide neural networks (NNs) trained under l2 loss by gradient descent with infinitesimally small learning rate (b) kernel regression with respect to so-called Neural Tangent Kernels (NTKs)(Jacot et al., 2018). An efficient algorithm to compute the NTK, as well as its convolutional counterparts, appears in Arora et al.(2019a), which allowed studying performance of infinitely wide nets on datasets like CIFAR-10. However, super-quadratic running time of kernel methods makes them best suited for small-data tasks. We report results suggesting neural tangent kernels perform strongly on low-data tasks.",52회,"Harnessing the power of infinitely wide deep nets on small-data tasks
S Arora, SS Du, Z Li, R Salakhutdinov, R Wang, D Yu - arXiv preprint arXiv:1910.01663, 2019
52회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Deep neural networks with massive learned knowledge,"Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, Eric Xing",2016/11,,,,1670-1679,,"Regulating deep neural networks (DNNs) with human structured knowledge has shown to be of great benefit for improved accuracy and interpretability. We develop a general framework that enables learning knowledge and its confidence jointly with the DNNs, so that the vast amount of fuzzy knowledge can be incorporated and automatically optimized with little manual efforts. We apply the framework to sentence sentiment analysis, augmenting a DNN with massive linguistic constraints on discourse and polarity structures. Our model substantially enhances the performance using less training data, and shows improved interpretability. The principled framework can also be applied to posterior regularization for regulating other statistical models.",52회,"Deep neural networks with massive learned knowledge
Z Hu, Z Yang, R Salakhutdinov, E Xing - Proceedings of the 2016 Conference on Empirical …, 2016
52회 인용 관련 학술자료 전체 8개의 버전",Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,,,,,,,
Revisiting LSTM networks for semi-supervised text classification via mixed objective function,"Devendra Singh Sachan, Manzil Zaheer, Ruslan Salakhutdinov",2019/7/17,Proceedings of the AAAI Conference on Artificial Intelligence,33,01,6940-6948,,"In this paper, we study bidirectional LSTM network for the task of text classification using both supervised and semisupervised approaches. Several prior works have suggested that either complex pretraining schemes using unsupervised methods such as language modeling (Dai and Le 2015; Miyato, Dai, and Goodfellow 2016) or complicated models (Johnson and Zhang 2017) are necessary to achieve a high classification accuracy. However, we develop a training strategy that allows even a simple BiLSTM model, when trained with cross-entropy loss, to achieve competitive results compared with more complex approaches. Furthermore, in addition to cross-entropy loss, by using a combination of entropy minimization, adversarial, and virtual adversarial losses for both labeled and unlabeled data, we report state-of-theart results for text classification task on several benchmark datasets. In particular, on the ACL-IMDB sentiment analysis and AG-News topic classification datasets, our method outperforms current approaches by a substantial margin. We also show the generality of the mixed objective function by improving the performance on relation extraction task. 1",50회,"Revisiting LSTM networks for semi-supervised text classification via mixed objective function
DS Sachan, M Zaheer, R Salakhutdinov - Proceedings of the AAAI Conference on Artificial …, 2019
50회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Deep generative models with learnable knowledge constraints,"Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, Xiaodan Liang, Lianhui Qin, Haoye Dong, Eric Xing",2018/6/26,arXiv preprint arXiv:1806.09764,,,,,"The broad set of deep generative models (DGMs) has achieved remarkable advances. However, it is often difficult to incorporate rich structured domain knowledge with the end-to-end DGMs. Posterior regularization (PR) offers a principled framework to impose structured constraints on probabilistic models, but has limited applicability to the diverse DGMs that can lack a Bayesian formulation or even explicit density evaluation. PR also requires constraints to be fully specified a priori, which is impractical or suboptimal for complex knowledge with learnable uncertain parts. In this paper, we establish mathematical correspondence between PR and reinforcement learning (RL), and, based on the connection, expand PR to learn constraints as the extrinsic reward in RL. The resulting algorithm is model-agnostic to apply to any DGMs, and is flexible to adapt arbitrary constraints with the model jointly. Experiments on human image generation and templated sentence generation show models with learned knowledge constraints by our algorithm greatly improve over base generative models.",49회,"Deep generative models with learnable knowledge constraints
Z Hu, Z Yang, R Salakhutdinov, X Liang, L Qin, H Dong… - arXiv preprint arXiv:1806.09764, 2018
49회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
On characterizing the capacity of neural networks using algebraic topology,"William H Guss, Ruslan Salakhutdinov",2018/2/13,arXiv preprint arXiv:1802.04443,,,,,"The learnability of different neural architectures can be characterized directly by computable measures of data complexity. In this paper, we reframe the problem of architecture selection as understanding how data determines the most expressive and generalizable architectures suited to that data, beyond inductive bias. After suggesting algebraic topology as a measure for data complexity, we show that the power of a network to express the topological complexity of a dataset in its decision region is a strictly limiting factor in its ability to generalize. We then provide the first empirical characterization of the topological capacity of neural networks. Our empirical analysis shows that at every level of dataset complexity, neural networks exhibit topological phase transitions. This observation allowed us to connect existing theory to empirically driven conjectures on the choice of architectures for fully-connected neural networks.",49회,"On characterizing the capacity of neural networks using algebraic topology
WH Guss, R Salakhutdinov - arXiv preprint arXiv:1802.04443, 2018
49회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Transformation autoregressive networks,"Junier Oliva, Avinava Dubey, Manzil Zaheer, Barnabas Poczos, Ruslan Salakhutdinov, Eric Xing, Jeff Schneider",2018/7/3,,,,3898-3907,PMLR,"The fundamental task of general density estimation has been of keen interest to machine learning. In this work, we attempt to systematically characterize methods for density estimation. Broadly speaking, most of the existing methods can be categorized into either using: a) autoregressive models to estimate the conditional factors of the chain rule, ; or b) non-linear transformations of variables of a simple base distribution. Based on the study of the characteristics of these categories, we propose multiple novel methods for each category. For example we propose RNN based transformations to model non-Markovian dependencies. Further, through a comprehensive study over both real world and synthetic data, we show that jointly leveraging transformations of variables and autoregressive conditional models, results in a considerable improvement in performance. We illustrate the use of our models in outlier detection and image modeling. Finally we introduce a novel data driven framework for learning a family of distributions.",46회,"Transformation autoregressive networks
J Oliva, A Dubey, M Zaheer, B Poczos… - International Conference on Machine Learning, 2018
46회 인용 관련 학술자료 전체 7개의 버전",International Conference on Machine Learning,,,,,,,
Enhanced convolutional neural tangent kernels,"Zhiyuan Li, Ruosong Wang, Dingli Yu, Simon S Du, Wei Hu, Ruslan Salakhutdinov, Sanjeev Arora",2019/11/3,arXiv preprint arXiv:1911.00809,,,,,"Recent research shows that for training with loss, convolutional neural networks (CNNs) whose width (number of channels in convolutional layers) goes to infinity correspond to regression with respect to the CNN Gaussian Process kernel (CNN-GP) if only the last layer is trained, and correspond to regression with respect to the Convolutional Neural Tangent Kernel (CNTK) if all layers are trained. An exact algorithm to compute CNTK (Arora et al., 2019) yielded the finding that classification accuracy of CNTK on CIFAR-10 is within 6-7% of that of that of the corresponding CNN architecture (best figure being around 78%) which is interesting performance for a fixed kernel. Here we show how to significantly enhance the performance of these kernels using two ideas.(1) Modifying the kernel using a new operation called Local Average Pooling (LAP) which preserves efficient computability of the kernel and inherits the spirit of standard data augmentation using pixel shifts. Earlier papers were unable to incorporate naive data augmentation because of the quadratic training cost of kernel regression. This idea is inspired by Global Average Pooling (GAP), which we show for CNN-GP and CNTK is equivalent to full translation data augmentation.(2) Representing the input image using a pre-processing technique proposed by Coates et al.(2011), which uses a single convolutional layer composed of random image patches. On CIFAR-10, the resulting kernel, CNN-GP with LAP and horizontal flip data augmentation, achieves 89% accuracy, matching the performance of AlexNet (Krizhevsky et al., 2012). Note that this is the best such result we know of for a …",44회,"Enhanced convolutional neural tangent kernels
Z Li, R Wang, D Yu, SS Du, W Hu, R Salakhutdinov… - arXiv preprint arXiv:1911.00809, 2019
44회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Learning nonlinear dynamic models,"John Langford, Ruslan Salakhutdinov, Tong Zhang",2009/6/14,,,,593-600,,"We present a novel approach for learning nonlinear dynamic models, which leads to a new set of tools capable of solving problems that are otherwise difficult. We provide theory showing this new approach is consistent for models with long range structure, and apply the approach to motion capture and high-dimensional video data, yielding results superior to standard alternatives.",42회,"Learning nonlinear dynamic models
J Langford, R Salakhutdinov, T Zhang - Proceedings of the 26th Annual International …, 2009
42회 인용 관련 학술자료 전체 24개의 버전",,Proceedings of the 26th Annual International Conference on Machine Learning,,,,,,
Annealing between distributions by averaging moments.,"Roger B Grosse, Chris J Maddison, Ruslan Salakhutdinov",2013/1/1,,,,2769-2777,,"Many powerful Monte Carlo techniques for estimating partition functions, such as annealed importance sampling (AIS), are based on sampling from a sequence of intermediate distributions which interpolate between a tractable initial distribution and an intractable target distribution. The nearuniversal practice is to use geometric averages of the initial and target distributions, but alternative paths can perform substantially better. We present a novel sequence of intermediate distributions for exponential families: averaging the moments of the initial and target distributions. We derive an asymptotically optimal piecewise linear schedule for the moments path and show that it performs at least as well as geometric averages with a linear schedule. Moment averaging performs well empirically at estimating partition functions of restricted Boltzmann machines (RBMs), which form the building blocks of many deep learning models.",40회,"Annealing between distributions by averaging moments.
RB Grosse, CJ Maddison, R Salakhutdinov - NIPS, 2013
40회 인용 관련 학술자료 전체 12개의 버전",NIPS,,,,,,,
Cardinality restricted boltzmann machines,"Kevin Swersky, Daniel Tarlow, Ilya Sutskever, Ruslan Salakhutdinov, Richard Zemel, Ryan Prescott Adams",2012,Advances in neural information processing systems,,,,Massachusetts Institute of Technology Press,"The Restricted Boltzmann Machine (RBM) is a popular density model that is also good for extracting features. A main source of tractability in RBM models is that, given an input, the posterior distribution over hidden variables is factorizable and can be easily computed and sampled from. Sparsity and competition in the hidden representation is beneficial, and while an RBM with competition among its hidden units would acquire some of the attractive properties of sparse coding, such constraints are typically not added, as the resulting posterior over the hidden units seemingly becomes intractable. In this paper we show that a dynamic programming algorithm can be used to implement exact sparsity in the RBM’s hidden units. We also show how to pass derivatives through the resulting posterior marginals, which makes it possible to fine-tune a pre-trained neural network with sparse hidden layers.",39회,"Cardinality restricted boltzmann machines
K Swersky, D Tarlow, I Sutskever, R Salakhutdinov… - Advances in neural information processing systems, 2012
39회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
"Think locally, act globally: Federated learning with local and global representations","Paul Pu Liang, Terrance Liu, Liu Ziyin, Nicholas B Allen, Randy P Auerbach, David Brent, Ruslan Salakhutdinov, Louis-Philippe Morency",2020/1/6,arXiv preprint arXiv:2001.01523,,,,,"Federated learning is a method of training models on private data distributed over multiple devices. To keep device data private, the global model is trained by only communicating parameters and updates which poses scalability challenges for large models. To this end, we propose a new federated learning algorithm that jointly learns compact local representations on each device and a global model across all devices. As a result, the global model can be smaller since it only operates on local representations, reducing the number of communicated parameters. Theoretically, we provide a generalization analysis which shows that a combination of local and global models reduces both variance in the data as well as variance across device distributions. Empirically, we demonstrate that local models enable communication-efficient training while retaining performance. We also evaluate on the task of personalized mood prediction from real-world mobile data where privacy is key. Finally, local models handle heterogeneous data from new devices, and learn fair representations that obfuscate protected attributes such as race, age, and gender.",38회,"Think locally, act globally: Federated learning with local and global representations
PP Liang, T Liu, L Ziyin, NB Allen, RP Auerbach… - arXiv preprint arXiv:2001.01523, 2020
38회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Episodic memory in lifelong language learning,"Cyprien de Masson d'Autume, Sebastian Ruder, Lingpeng Kong, Dani Yogatama",2019/6/3,arXiv preprint arXiv:1906.01076,,,,,We introduce a lifelong language learning setup where a model needs to learn from a stream of text examples without any dataset identifier. We propose an episodic memory model that performs sparse experience replay and local adaptation to mitigate catastrophic forgetting in this setup. Experiments on text classification and question answering demonstrate the complementary benefits of sparse experience replay and local adaptation to allow the model to continuously learn from new datasets. We also show that the space complexity of the episodic memory module can be reduced significantly (~ 50-90%) by randomly choosing which examples to store in memory with a minimal decrease in performance. We consider an episodic memory component as a crucial building block of general linguistic intelligence and see our model as a first step in that direction.,38회,"Episodic memory in lifelong language learning
CM d'Autume, S Ruder, L Kong, D Yogatama - arXiv preprint arXiv:1906.01076, 2019
38회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Gated path planning networks,"Lisa Lee, Emilio Parisotto, Devendra Singh Chaplot, Eric Xing, Ruslan Salakhutdinov",2018/7/3,,,,2947-2955,PMLR,"Value Iteration Networks (VINs) are effective differentiable path planning modules that can be used by agents to perform navigation while still maintaining end-to-end differentiability of the entire architecture. Despite their effectiveness, they suffer from several disadvantages including training instability, random seed sensitivity, and other optimization problems. In this work, we reframe VINs as recurrent-convolutional networks which demonstrates that VINs couple recurrent convolutions with an unconventional max-pooling activation. From this perspective, we argue that standard gated recurrent update equations could potentially alleviate the optimization issues plaguing VIN. The resulting architecture, which we call the Gated Path Planning Network, is shown to empirically outperform VIN on a variety of metrics such as learning speed, hyperparameter sensitivity, iteration count, and even generalization. Furthermore, we show that this performance gap is consistent across different maze transition types, maze sizes and even show success on a challenging 3D environment, where the planner is only provided with first-person RGB images.",38회,"Gated path planning networks
L Lee, E Parisotto, DS Chaplot, E Xing… - International Conference on Machine Learning, 2018
38회 인용 관련 학술자료 전체 8개의 버전",International Conference on Machine Learning,,,,,,,
Initialization strategies of spatio-temporal convolutional neural networks,"Elman Mansimov, Nitish Srivastava, Ruslan Salakhutdinov",2015/3/25,arXiv preprint arXiv:1503.07274,,,,,"We propose a new way of incorporating temporal information present in videos into Spatial Convolutional Neural Networks (ConvNets) trained on images, that avoids training Spatio-Temporal ConvNets from scratch. We describe several initializations of weights in 3D Convolutional Layers of Spatio-Temporal ConvNet using 2D Convolutional Weights learned from ImageNet. We show that it is important to initialize 3D Convolutional Weights judiciously in order to learn temporal representations of videos. We evaluate our methods on the UCF-101 dataset and demonstrate improvement over Spatial ConvNets.",37회,"Initialization strategies of spatio-temporal convolutional neural networks
E Mansimov, N Srivastava, R Salakhutdinov - arXiv preprint arXiv:1503.07274, 2015
37회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Neighbourhood component analysis,"Sam Roweis, Geoffrey Hinton, Ruslan Salakhutdinov",2004,Adv. Neural Inf. Process. Syst.(NIPS),17,,513-520,,"Say I give you a dataset of N points {x_n} in D dimensions. Can you find for me (up to rotation and isotropic scaling) a projection matrix A (of size d by D) such that when you apply nearest neighbour classification to the point set {y_n= A x_n} you get the best possible performance? Nearest neighbour classification is a very simple nonparametric method for supervised learning, and has several appealing properties: the decision surfaces are nonlinear, the quality of the predictions automatically improve as the amount of training data increases, and there is only a single hyperparameter to be tuned.
However, there are two significant problems. First, we must define what we mean by"" nearest"", in other words we must specify a metric on the input space. Second, the computational load of the classifier is quite high at test time since we must store and search through the entire training set to find the neighbours of a query …",37회,"Neighbourhood component analysis
S Roweis, G Hinton, R Salakhutdinov - Adv. Neural Inf. Process. Syst.(NIPS), 2004
37회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Video relationship reasoning using gated spatio-temporal energy graph,"Yao-Hung Hubert Tsai, Santosh Divvala, Louis-Philippe Morency, Ruslan Salakhutdinov, Ali Farhadi",2019,,,,10424-10433,,"Visual relationship reasoning is a crucial yet challenging task for understanding rich interactions across visual concepts. For example, a relationship\man, open, door\involves a complex relation\open\between concrete entities\man, door\. While much of the existing work has studied this problem in the context of still images, understanding visual relationships in videos has received limited attention. Due to their temporal nature, videos enable us to model and reason about a more comprehensive set of visual relationships, such as those requiring multiple (temporal) observations (eg,\man, lift up, box\vs.\man, put down, box\), as well as relationships that are often correlated through time (eg,\woman, pay, money\followed by\woman, buy, coffee\). In this paper, we construct a Conditional Random Field on a fully-connected spatio-temporal graph that exploits the statistical dependency between relational entities spatially and temporally. We introduce a novel gated energy function parametrization that learns adaptive relations conditioned on visual observations. Our model optimization is computationally efficient, and its space computation complexity is significantly amortized through our proposed parameterization. Experimental results on benchmark video datasets (ImageNet Video and Charades) demonstrate state-of-the-art performance across three standard relationship reasoning tasks: Detection, Tagging, and Recognition.",35회,"Video relationship reasoning using gated spatio-temporal energy graph
YHH Tsai, S Divvala, LP Morency, R Salakhutdinov… - Proceedings of the IEEE/CVF Conference on Computer …, 2019
35회 인용 관련 학술자료 전체 7개의 버전",Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,,,,,,,
Differentiable reasoning over a virtual knowledge base,"Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig, Ruslan Salakhutdinov, William W Cohen",2020/2/25,arXiv preprint arXiv:2002.10640,,,,,"We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems.",32회,"Differentiable reasoning over a virtual knowledge base
B Dhingra, M Zaheer, V Balachandran, G Neubig… - arXiv preprint arXiv:2002.10640, 2020
32회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Learning data manipulation for augmentation and weighting,"Zhiting Hu, Bowen Tan, Ruslan Salakhutdinov, Tom Mitchell, Eric P Xing",2019/10/28,arXiv preprint arXiv:1910.12795,,,,,"Manipulating data, such as weighting data examples or augmenting with new instances, has been increasingly used to improve model training. Previous work has studied various rule-or learning-based approaches designed for specific types of data manipulation. In this work, we propose a new method that supports learning different manipulation schemes with the same gradient-based algorithm. Our approach builds upon a recent connection of supervised learning and reinforcement learning (RL), and adapts an off-the-shelf reward learning algorithm from RL for joint data manipulation learning and model training. Different parameterization of the"" data reward"" function instantiates different manipulation schemes. We showcase data augmentation that learns a text transformation network, and data weighting that dynamically adapts the data sample importance. Experiments show the resulting algorithms significantly improve the image and text classification performance in low data regime and class-imbalance problems.",32회,"Learning data manipulation for augmentation and weighting
Z Hu, B Tan, R Salakhutdinov, T Mitchell, EP Xing - arXiv preprint arXiv:1910.12795, 2019
32회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
The MineRL 2019 Competition on Sample Efficient Reinforcement Learning using Human Priors,"William H Guss, Cayden Codel, Katja Hofmann, Brandon Houghton, Noboru Kuno, Stephanie Milani, Sharada Mohanty, Diego Perez Liebana, Ruslan Salakhutdinov, Nicholay Topin, Manuela Veloso, Phillip Wang",2019/4/22,arXiv preprint arXiv:1904.10079,,,,,"Though deep reinforcement learning has led to breakthroughs in many difficult domains, these successes have required an ever-increasing number of samples. As state-ofthe-art reinforcement learning (RL) systems require an exponentially increasing number of samples, their development is restricted to a continually shrinking segment of the AI community. Likewise, many of these systemss cannot be applied to real-world problems, where environment samples are expensive. Resolution of these limitations requires new, sample-efficient methods. To facilitate research in this direction, we propose the MineRL Competition on Sample Efficient Reinforcement Learning using Human Priors.
The primary goal of the competition is to foster the development of algorithms which can efficiently leverage human demonstrations to drastically reduce the number of samples needed to solve complex, hierarchical, and sparse environments. To that end, we introduce:(1) the Minecraft ObtainDiamond task, a sequential decision making environment requiring long-term planning, hierarchical control, and efficient exploration methods; and (2) the MineRL-v0 dataset, a large-scale collection of over 60 million state-action pairs of human demonstrations that can be resimulated into embodied agent trajectories with arbitrary modifications to game state and visuals.",32회,"The MineRL 2019 Competition on Sample Efficient Reinforcement Learning using Human Priors
WH Guss, C Codel, K Hofmann, B Houghton, N Kuno… - arXiv preprint arXiv:1904.10079, 2019
32회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Learning to learn with compound hd models,"Ruslan Salakhutdinov, Joshua B Tenenbaum, Antonio Torralba",2011/12/12,,,,2061-2069,,"We introduce HD (or"" Hierarchical-Deep"") models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian models. Specifically we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a Deep Boltzmann Machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training examples, by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.",31회,"Learning to learn with compound hd models
R Salakhutdinov, JB Tenenbaum, A Torralba - Proceedings of the 24th International Conference on …, 2011
31회 인용 관련 학술자료 전체 4개의 버전",,Proceedings of the 24th International Conference on Neural Information Processing Systems,,,,,,
A comparative study of word embeddings for reading comprehension,"Bhuwan Dhingra, Hanxiao Liu, Ruslan Salakhutdinov, William W Cohen",2017/3/2,arXiv preprint arXiv:1703.00993,,,,,"The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on (1) the use of pre-trained word embeddings, and (2) the representation of out-of-vocabulary tokens at test time, can turn out to have a larger impact than architectural choices on the final performance. We systematically explore several options for these choices, and provide recommendations to researchers working in this area.",29회,"A comparative study of word embeddings for reading comprehension
B Dhingra, H Liu, R Salakhutdinov, WW Cohen - arXiv preprint arXiv:1703.00993, 2017
29회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Iterative refinement of the approximate posterior for directed belief networks,"Devon Hjelm, Russ R Salakhutdinov, Kyunghyun Cho, Nebojsa Jojic, Vince Calhoun, Junyoung Chung",2016,,,,4691-4699,,"Variational methods that rely on a recognition network to approximate the posterior of directed graphical models offer better inference and learning than previous methods. Recent advances that exploit the capacity and flexibility in this approach have expanded what kinds of models can be trained. However, as a proposal for the posterior, the capacity of the recognition network is limited, which can constrain the representational power of the generative model and increase the variance of Monte Carlo estimates. To address these issues, we introduce an iterative refinement procedure for improving the approximate posterior of the recognition network and show that training with the refined posterior is competitive with state-of-the-art methods. The advantages of refinement are further evident in an increased effective sample size, which implies a lower variance of gradient estimates.",28회,"Iterative refinement of the approximate posterior for directed belief networks
D Hjelm, RR Salakhutdinov, K Cho, N Jojic, V Calhoun… - Advances in Neural Information Processing Systems, 2016
28회 인용 관련 학술자료 전체 6개의 버전",Advances in Neural Information Processing Systems,,,,,,,
Transformer Dissection: A Unified Understanding of Transformer's Attention via the Lens of Kernel,"Yao-Hung Hubert Tsai, Shaojie Bai, Makoto Yamada, Louis-Philippe Morency, Ruslan Salakhutdinov",2019/8/30,arXiv preprint arXiv:1908.11775,,,,,"Transformer is a powerful architecture that achieves superior performance on various sequence learning tasks, including neural machine translation, language understanding, and sequence prediction. At the core of the Transformer is the attention mechanism, which concurrently processes all inputs in the streams. In this paper, we present a new formulation of attention via the lens of the kernel. To be more precise, we realize that the attention can be seen as applying kernel smoother over the inputs with the kernel scores being the similarities between inputs. This new formulation gives us a better way to understand individual components of the Transformer's attention, such as the better way to integrate the positional embedding. Another important advantage of our kernel-based formulation is that it paves the way to a larger space of composing Transformer's attention. As an example, we propose a new variant of Transformer's attention which models the input as a product of symmetric kernels. This approach achieves competitive performance to the current state of the art model with less computation. In our experiments, we empirically study different kernel construction strategies on two widely used tasks: neural machine translation and sequence prediction.",27회,"Transformer Dissection: A Unified Understanding of Transformer's Attention via the Lens of Kernel
YHH Tsai, S Bai, M Yamada, LP Morency… - arXiv preprint arXiv:1908.11775, 2019
27회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
MineRL: A large-scale dataset of Minecraft demonstrations,"William H Guss, Brandon Houghton, Nicholay Topin, Phillip Wang, Cayden Codel, Manuela Veloso, Ruslan Salakhutdinov",2019/7/29,arXiv preprint arXiv:1907.13440,,,,,"The sample inefficiency of standard deep reinforcement learning methods precludes their application to many real-world problems. Methods which leverage human demonstrations require fewer samples but have been researched less. As demonstrated in the computer vision and natural language processing communities, large-scale datasets have the capacity to facilitate research by serving as an experimental and benchmarking platform for new methods. However, existing datasets compatible with reinforcement learning simulators do not have sufficient scale, structure, and quality to enable the further development and evaluation of methods focused on using human examples. Therefore, we introduce a comprehensive, large-scale, simulator-paired dataset of human demonstrations: MineRL. The dataset consists of over 60 million automatically annotated state-action pairs across a variety of related tasks in Minecraft, a dynamic, 3D, open-world environment. We present a novel data collection scheme which allows for the ongoing introduction of new tasks and the gathering of complete state information suitable for a variety of methods. We demonstrate the hierarchality, diversity, and scale of the MineRL dataset. Further, we show the difficulty of the Minecraft domain along with the potential of MineRL in developing techniques to solve key research challenges within it.",27회,"MineRL: A large-scale dataset of Minecraft demonstrations
WH Guss, B Houghton, N Topin, P Wang, C Codel… - arXiv preprint arXiv:1907.13440, 2019
27회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Structured control nets for deep reinforcement learning,"Mario Srouji, Jian Zhang, Ruslan Salakhutdinov",2018/7/3,,,,4742-4751,PMLR,"In recent years, Deep Reinforcement Learning has made impressive advances in solving several important benchmark problems for sequential decision making. Many control applications use a generic multilayer perceptron (MLP) for non-vision parts of the policy network. In this work, we propose a new neural network architecture for the policy network representation that is simple yet effective. The proposed Structured Control Net (SCN) splits the generic MLP into two separate sub-modules: a nonlinear control module and a linear control module. Intuitively, the nonlinear control is for forward-looking and global control, while the linear control stabilizes the local dynamics around the residual of global control. We hypothesize that this will bring together the benefits of both linear and nonlinear policies: improve training sample efficiency, final episodic reward, and generalization of learned policy, while requiring a smaller network and being generally applicable to different training methods. We validated our hypothesis with competitive results on simulations from OpenAI MuJoCo, Roboschool, Atari, and a custom urban driving environment, with various ablation and generalization tests, trained with multiple black-box and policy gradient training methods. The proposed architecture has the potential to improve upon broader control tasks by incorporating problem specific priors into the architecture. As a case study, we demonstrate much improved performance for locomotion tasks by emulating the biological central pattern generators (CPGs) as the nonlinear part of the architecture.",27회,"Structured control nets for deep reinforcement learning
M Srouji, J Zhang, R Salakhutdinov - International Conference on Machine Learning, 2018
27회 인용 관련 학술자료 전체 6개의 버전",International Conference on Machine Learning,,,,,,,
Glomo: Unsupervisedly learned relational graphs as transferable representations,"Zhilin Yang, Jake Zhao, Bhuwan Dhingra, Kaiming He, William W Cohen, Ruslan Salakhutdinov, Yann LeCun",2018/6/14,arXiv preprint arXiv:1806.05662,,,,,"Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (eg, words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden unit), or embedding-free units such as image pixels.",27회,"Glomo: Unsupervisedly learned relational graphs as transferable representations
Z Yang, J Zhao, B Dhingra, K He, WW Cohen… - arXiv preprint arXiv:1806.05662, 2018
27회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
How many samples are needed to estimate a convolutional neural network?,"Simon S Du, Yining Wang, Xiyu Zhai, Sivaraman Balakrishnan, Ruslan Salakhutdinov, Aarti Singh",2018/1/1,,,,371-381,,"A widespread folklore for explaining the success of Convolutional Neural Networks (CNNs) is that CNNs use a more compact representation than the Fullyconnected Neural Network (FNN) and thus require fewer training samples to accurately estimate their parameters. We initiate the study of rigorously characterizing the sample complexity of estimating CNNs. We show that for an m-dimensional convolutional filter with linear activation acting on a d-dimensional input, the sample complexity of achieving population prediction error of ϵ is rOpm {ϵ2 q 2, whereas the sample-complexity for its FNN counterpart is lower bounded by Ωpd {ϵ2 q samples. Since, in typical settings m! d, this result demonstrates the advantage of using a CNN. We further consider the sample complexity of estimating a onehidden-layer CNN with linear activation where both the m-dimensional convolutional filter and the r-dimensional output weights are unknown. For this model, we show that the sample complexity is rOpmrq {ϵ2 when the ratio between the stride size and the filter size is a constant. For both models, we also present lower bounds showing our sample complexities are tight up to logarithmic factors. Our main tools for deriving these results are a localized empirical process analysis and a new lemma characterizing the convolutional structure. We believe that these tools may inspire further developments in understanding CNNs.",27회,"How many samples are needed to estimate a convolutional neural network?
SS Du, Y Wang, X Zhai, S Balakrishnan… - NeurIPS, 2018
27회 인용 관련 학술자료 전체 4개의 버전",NeurIPS,,,,,,,
Improving one-shot learning through fusing side information,"Yao-Hung Hubert Tsai, Ruslan Salakhutdinov",2017/10/23,arXiv preprint arXiv:1710.08347,,,,,"Deep Neural Networks (DNNs) often struggle with one-shot learning where we have only one or a few labeled training examples per category. In this paper, we argue that by using side information, we may compensate the missing information across classes. We introduce two statistical approaches for fusing side information into data representation learning to improve one-shot learning. First, we propose to enforce the statistical dependency between data representations and multiple types of side information. Second, we introduce an attention mechanism to efficiently treat examples belonging to the'lots-of-examples' classes as quasi-samples (additional training samples) for'one-example'classes. We empirically show that our learning architecture improves over traditional softmax regression networks as well as state-of-the-art attentional regression networks on one-shot recognition tasks.",27회,"Improving one-shot learning through fusing side information
YHH Tsai, R Salakhutdinov - arXiv preprint arXiv:1710.08347, 2017
27회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Object goal navigation using goal-oriented semantic exploration,"Devendra Singh Chaplot, Dhiraj Prakashchand Gandhi, Abhinav Gupta, Russ R Salakhutdinov",2020,Advances in Neural Information Processing Systems,33,,,,"This work studies the problem of object goal navigation which involves navigating to an instance of the given object category in unseen environments. End-to-end learning-based navigation methods struggle at this task as they are ineffective at exploration and long-term planning. We propose a modular system called,Goal-Oriented Semantic Exploration'which builds an episodic semantic map and uses it to explore the environment efficiently based on the goal object category. Empirical results in visually realistic simulation environments show that the proposed model outperforms a wide range of baselines including end-to-end learning-based methods as well as modular map-based methods and led to the winning entry of the CVPR-2020 Habitat ObjectNav Challenge. Ablation analysis indicates that the proposed model learns semantic priors of the relative arrangement of objects in a scene, and uses them to explore efficiently. Domain-agnostic module design allows us to transfer our model to a mobile robot platform and achieve similar performance for object goal navigation in the real-world.",26회,"Object goal navigation using goal-oriented semantic exploration
DS Chaplot, DP Gandhi, A Gupta, RR Salakhutdinov - Advances in Neural Information Processing Systems, 2020
26회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Linguistic knowledge as memory for recurrent neural networks,"Bhuwan Dhingra, Zhilin Yang, William W Cohen, Ruslan Salakhutdinov",2017/3/7,arXiv preprint arXiv:1703.02620,,,,,"Training recurrent neural networks to model long term dependencies is difficult. Hence, we propose to use external linguistic knowledge as an explicit signal to inform the model which memories it should utilize. Specifically, external knowledge is used to augment a sequence with typed edges between arbitrarily distant elements, and the resulting graph is decomposed into directed acyclic subgraphs. We introduce a model that encodes such graphs as explicit memory in recurrent neural networks, and use it to model coreference relations in text. We apply our model to several text comprehension tasks and achieve new state-of-the-art results on all considered benchmarks, including CNN, bAbi, and LAMBADA. On the bAbi QA tasks, our model solves 15 out of the 20 tasks with only 1000 training examples per task. Analysis of the learned representations further demonstrates the ability of our model to encode fine-grained entity information across a document.",26회,"Linguistic knowledge as memory for recurrent neural networks
B Dhingra, Z Yang, WW Cohen, R Salakhutdinov - arXiv preprint arXiv:1703.02620, 2017
26회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations,"Behnam Neyshabur, Yuhuai Wu, Ruslan Salakhutdinov, Nathan Srebro",2016/5/23,NIPS 2016,,,,,"We investigate the parameter-space geometry of recurrent neural networks (RNNs), and develop an adaptation of path-SGD optimization method, attuned to this geometry, that can learn plain RNNs with ReLU activations. On several datasets that require capturing long-term dependency structure, we show that path-SGD can significantly improve trainability of ReLU RNNs compared to RNNs trained with SGD, even with various recently suggested initialization schemes.",26회,"Path-normalized optimization of recurrent neural networks with relu activations
B Neyshabur, Y Wu, R Salakhutdinov, N Srebro - arXiv preprint arXiv:1605.07154, 2016
26회 인용 관련 학술자료 전체 6개의 버전
Supplementary: Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations*
B Neyshabur, Y Wu, R Salakhutdinov, N Srebro",,,,,,,,
Guest editors' introduction: Special section on learning deep architectures,"Samy Bengio, Li Deng, Hugo Larochelle, Honglak Lee, Ruslan Salakhutdinov",2013/6/17,IEEE transactions on pattern analysis and machine intelligence,35,8,1795-1797,IEEE,"There has been a resurgence of research in the design of deep architecture models and learning algorithms, i.e., methods that rely on the extraction of a multilayer representation of the data. Often referred to as deep learning, this topic of research has been building on and contributing to many different research topics, such as neural networks, graphical models, feature learning, unsupervised learning, optimization, pattern recognition, and signal processing. Deep learning is also motivated and inspired by neuroscience and has had a tremendous impact on various applications such as computer vision, speech recognition, and natural language processing. The clearly multidisciplinary nature of deep learning led to a call for papers for a special issue dedicated to learning deep architectures.",26회,"Guest editors' introduction: Special section on learning deep architectures
S Bengio, L Deng, H Larochelle, H Lee… - IEEE transactions on pattern analysis and machine …, 2013
26회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
Neural topological slam for visual navigation,"Devendra Singh Chaplot, Ruslan Salakhutdinov, Abhinav Gupta, Saurabh Gupta",2020,,,,12875-12884,,"This paper studies the problem of image-goal navigation which involves navigating to the location indicated by a goal image in a novel previously unseen environment. To tackle this problem, we design topological representations for space that effectively leverage semantics and afford approximate geometric reasoning. At the heart of our representations are nodes with associated semantic features, that are interconnected using coarse geometric information. We describe supervised learning-based algorithms that can build, maintain and use such representations under noisy actuation. Experimental study in visually and physically realistic simulation suggests that our method builds effective representations that capture structural regularities and efficiently solve long-horizon navigation problems. We observe a relative improvement of more than 50% over existing methods that study this task.",25회,"Neural topological slam for visual navigation
DS Chaplot, R Salakhutdinov, A Gupta, S Gupta - Proceedings of the IEEE/CVF Conference on Computer …, 2020
25회 인용 관련 학술자료 전체 11개의 버전",Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,,,,,,,
Deep gamblers: Learning to abstain with portfolio theory,"Liu Ziyin, Zhikang Wang, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency, Masahito Ueda",2019/6/29,arXiv preprint arXiv:1907.00208,,,,,"We deal with the\textit {selective classification} problem (supervised-learning problem with a rejection option), where we want to achieve the best performance at a certain level of coverage of the data. We transform the original -class classification problem to -class where the -th class represents the model abstaining from making a prediction due to disconfidence. Inspired by portfolio theory, we propose a loss function for the selective classification problem based on the doubling rate of gambling. Minimizing this loss function corresponds naturally to maximizing the return of a\textit {horse race}, where a player aims to balance between betting on an outcome (making a prediction) when confident and reserving one's winnings (abstaining) when not confident. This loss function allows us to train neural networks and characterize the disconfidence of prediction in an end-to-end fashion. In comparison with previous methods, our method requires almost no modification to the model inference algorithm or model architecture. Experiments show that our method can identify uncertainty in data points, and achieves strong results on SVHN and CIFAR10 at various coverages of the data.",25회,"Deep gamblers: Learning to abstain with portfolio theory
L Ziyin, Z Wang, PP Liang, R Salakhutdinov… - arXiv preprint arXiv:1907.00208, 2019
25회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Multi-modal Bayesian embeddings for learning social knowledge graphs,"Zhilin Yang, Jie Tang, William Cohen",2015/8/4,arXiv preprint arXiv:1508.00715,,,,,"We study the extent to which online social networks can be connected to open knowledge bases. The problem is referred to as learning social knowledge graphs. We propose a multi-modal Bayesian embedding model, GenVector, to learn latent topics that generate word and network embeddings. GenVector leverages large-scale unlabeled data with embeddings and represents data of two modalities---ie, social network users and knowledge concepts---in a shared latent topic space. Experiments on three datasets show that the proposed method clearly outperforms state-of-the-art methods. We then deploy the method on AMiner, a large-scale online academic search system with a network of 38,049,189 researchers with a knowledge base with 35,415,011 concepts. Our method significantly decreases the error rate in an online A/B test with live users.",25회,"Multi-modal Bayesian embeddings for learning social knowledge graphs
Z Yang, J Tang, W Cohen - arXiv preprint arXiv:1508.00715, 2015
25회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Deep determinantal point process for large-scale multi-label classification,"Pengtao Xie, Ruslan Salakhutdinov, Luntian Mou, Eric P Xing",2017,,,,473-482,,"We study large-scale multi-label classification (MLC) on two recently released datasets: Youtube-8M and Open Images that contain millions of data instances and thousands of classes. The unprecedented problem scale poses great challenges for MLC. First, finding out the correct label subset out of exponentially many choices incurs substantial ambiguity and uncertainty. Second, the large data-size and class-size entail considerable computational cost. To address the first challenge, we investigate two strategies: capturing label-correlations from the training data and incorporating label co-occurrence relations obtained from external knowledge, which effectively eliminate semantically inconsistent labels and provide contextual clues to differentiate visually ambiguous labels. Specifically, we propose a Deep Determinantal Point Process (DDPP) model which seamlessly integrates a DPP with deep neural networks (DNNs) and supports end-to-end multi-label learning and deep representation learning. The DPP is able to capture label-correlations of any order with a polynomial computational cost, while the DNNs learn hierarchical features of images/videos and capture the dependency between input data and labels. To incorporate external knowledge about label co-occurrence relations, we impose a relational regularization over the kernel matrix in DDPP. To address the second challenge, we study an efficient low-rank kernel learning algorithm based on inducing point methods. Experiments on the two datasets demonstrate the efficacy and efficiency of the proposed methods.",24회,"Deep determinantal point process for large-scale multi-label classification
P Xie, R Salakhutdinov, L Mou, EP Xing - Proceedings of the IEEE International Conference on …, 2017
24회 인용 관련 학술자료 전체 7개의 버전",Proceedings of the IEEE International Conference on Computer Vision,,,,,,,
Transfer deep reinforcement learning in 3d environments: An empirical study,"Devendra Singh Chaplot, Guillaume Lample, Kanthashree Mysore Sathyendra, Ruslan Salakhutdinov",2016/12,NIPS Deep Reinforcemente Leaning Workshop,,,,,"The ability to transfer knowledge from previous experiences is critical for an agent to rapidly adapt to different environments and effectively learn new tasks. In this paper we conduct an empirical study of Deep Q-Networks (DQNs) where the agent is evaluated on previously unseen environments. We show that we can train a robust network for navigation in 3D environments and demonstrate its effectiveness in generalizing to unknown maps with unknown background textures. We further investigate the effectiveness of pretraining and finetuning for transferring knowledge between various scenarios in 3D environments. In particular, we show that the features learnt by the navigation network can be effectively utilized to transfer knowledge between a diverse set of tasks, such as object collection, deathmatch, and self-localization.",24회,"Transfer deep reinforcement learning in 3d environments: An empirical study
DS Chaplot, G Lample, KM Sathyendra… - NIPS Deep Reinforcemente Leaning Workshop, 2016
24회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Matrix reconstruction with the local max norm,"Rina Foygel, Nathan Srebro, Ruslan Salakhutdinov",2012/10/18,arXiv preprint arXiv:1210.5196,,,,,"We introduce a new family of matrix norms, the"" local max"" norms, generalizing existing methods such as the max norm, the trace norm (nuclear norm), and the weighted or smoothed weighted trace norms, which have been extensively used in the literature as regularizers for matrix reconstruction problems. We show that this new family can be used to interpolate between the (weighted or unweighted) trace norm and the more conservative max norm. We test this interpolation on simulated data and on the large-scale Netflix and MovieLens ratings data, and find improved accuracy relative to the existing matrix norms. We also provide theoretical results showing learning guarantees for some of the new norms.",24회,"Matrix reconstruction with the local max norm
R Foygel, N Srebro, R Salakhutdinov - arXiv preprint arXiv:1210.5196, 2012
24회 인용 관련 학술자료 전체 15개의 버전",,,,,,,,
Concept learning as motor program induction: A large-scale empirical study,"Brenden Lake, Ruslan Salakhutdinov, Joshua Tenenbaum",2012,Proceedings of the Annual Meeting of the Cognitive Science Society,34,34,,,"Human concept learning is particularly impressive in two respects: the internal structure of concepts can be representationally rich, and yet the very same concepts can also be learned from just a few examples. Several decades of research have dramatically advanced our understanding of these two aspects of concepts. While the richness and speed of concept learning are most often studied in isolation, the power of human concepts may be best explained through their synthesis. This paper presents a large-scale empirical study of one-shot concept learning, suggesting that rich generative knowledge in the form of a motor program can be induced from just a single example of a novel concept. Participants were asked to draw novel handwritten characters given a reference form, and we recorded the motor data used for production. Multiple drawers of the same character not only produced visually similar drawings, but they also showed a striking correspondence in their strokes, as measured by their number, shape, order, and direction. This suggests that participants can infer a rich motorbased concept from a single example. We also show that the motor programs induced by individual subjects provide a powerful basis for one-shot classification, yielding far higher accuracy than state-of-the-art pattern recognition methods based on just the visual form.",24회,"Concept learning as motor program induction: A large-scale empirical study
B Lake, R Salakhutdinov, J Tenenbaum - Proceedings of the Annual Meeting of the Cognitive …, 2012
24회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
Provably efficient reinforcement learning with general value function approximation,"Ruosong Wang, Ruslan Salakhutdinov, Lin F Yang",2020/5/21,arXiv preprint arXiv:2005.10804,,,,,"Value function approximation has demonstrated phenomenal empirical success in reinforcement learning (RL). Nevertheless, despite a handful of recent progress on developing theory for RL with linear function approximation, the understanding of general function approximation schemes largely remains missing. In this paper, we establish the first provable efficiently RL algorithm with general value function approximation. In particular, we show that if the value functions admit an approximation with a function class , our algorithm achieves a regret bound of where is a complexity measure of , is the planning horizon, and is the number interactions with the environment. Our theory strictly generalizes recent progress on RL with linear function approximation and does not make explicit assumptions on the model of the environment. Moreover, our algorithm is model-free and provides a framework to justify algorithms used in practice.",23회,"Provably efficient reinforcement learning with general value function approximation
R Wang, R Salakhutdinov, LF Yang - arXiv preprint arXiv:2005.10804, 2020
23회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Capsules with inverted dot-product attention routing,"Yao-Hung Hubert Tsai, Nitish Srivastava, Hanlin Goh, Ruslan Salakhutdinov",2020/2/12,arXiv preprint arXiv:2002.04764,,,,,"We introduce a new routing algorithm for capsule networks, in which a child capsule is routed to a parent based only on agreement between the parent's state and the child's vote. The new mechanism 1) designs routing via inverted dot-product attention; 2) imposes Layer Normalization as normalization; and 3) replaces sequential iterative routing with concurrent iterative routing. When compared to previously proposed routing algorithms, our method improves performance on benchmark datasets such as CIFAR-10 and CIFAR-100, and it performs at-par with a powerful CNN (ResNet-18) with 4x fewer parameters. On a different task of recognizing digits from overlayed digit images, the proposed capsule model performs favorably against CNNs given the same number of layers and neurons per layer. We believe that our work raises the possibility of applying capsule networks to complex real-world tasks. Our code is publicly available at: this https URL",23회,"Capsules with inverted dot-product attention routing
YHH Tsai, N Srivastava, H Goh, R Salakhutdinov - arXiv preprint arXiv:2002.04764, 2020
23회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Learning representations from imperfect time series data via tensor rank regularization,"Paul Pu Liang, Zhun Liu, Yao-Hung Hubert Tsai, Qibin Zhao, Ruslan Salakhutdinov, Louis-Philippe Morency",2019/7/1,arXiv preprint arXiv:1907.01011,,,,,"There has been an increased interest in multimodal language processing including multimodal dialog, question answering, sentiment analysis, and speech recognition. However, naturally occurring multimodal data is often imperfect as a result of imperfect modalities, missing entries or noise corruption. To address these concerns, we present a regularization method based on tensor rank minimization. Our method is based on the observation that high-dimensional multimodal time series data often exhibit correlations across time and modalities which leads to low-rank tensor representations. However, the presence of noise or incomplete values breaks these correlations and results in tensor representations of higher rank. We design a model to learn such tensor representations and effectively regularize their rank. Experiments on multimodal language data show that our model achieves good results across various levels of imperfection.",23회,"Learning representations from imperfect time series data via tensor rank regularization
PP Liang, Z Liu, YHH Tsai, Q Zhao, R Salakhutdinov… - arXiv preprint arXiv:1907.01011, 2019
23회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Strong and simple baselines for multimodal utterance embeddings,"Paul Pu Liang, Yao Chong Lim, Yao-Hung Hubert Tsai, Ruslan Salakhutdinov, Louis-Philippe Morency",2019/5/14,arXiv preprint arXiv:1906.02125,,,,,"Human language is a rich multimodal signal consisting of spoken words, facial expressions, body gestures, and vocal intonations. Learning representations for these spoken utterances is a complex research problem due to the presence of multiple heterogeneous sources of information. Recent advances in multimodal learning have followed the general trend of building more complex models that utilize various attention, memory and recurrent components. In this paper, we propose two simple but strong baselines to learn embeddings of multimodal utterances. The first baseline assumes a conditional factorization of the utterance into unimodal factors. Each unimodal factor is modeled using the simple form of a likelihood function obtained via a linear transformation of the embedding. We show that the optimal embedding can be derived in closed form by taking a weighted average of the unimodal features. In order to capture richer representations, our second baseline extends the first by factorizing into unimodal, bimodal, and trimodal factors, while retaining simplicity and efficiency during learning and inference. From a set of experiments across two tasks, we show strong performance on both supervised and semi-supervised multimodal prediction, as well as significant (10 times) speedups over neural models during inference. Overall, we believe that our strong baseline models offer new benchmarking options for future research in multimodal learning.",20회,"Strong and simple baselines for multimodal utterance embeddings
PP Liang, YC Lim, YHH Tsai, R Salakhutdinov… - arXiv preprint arXiv:1906.02125, 2019
20회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Data-Dependent Path Normalization in Neural Networks,"Behnam Neyshabur, Ryota Tomioka, Ruslan Salakhutdinov, Nathan Srebro",2015/11/20,,,,,,"We propose a unified framework for neural net normalization, regularization and optimization, which includes Path-SGD and Batch-Normalization and interpolates between them across two different dimensions. Through this framework we investigate issue of invariance of the optimization, data dependence and the connection with natural gradients.",20회,"Data-dependent path normalization in neural networks
B Neyshabur, R Tomioka, R Salakhutdinov, N Srebro - arXiv preprint arXiv:1511.06747, 2015
20회 인용 관련 학술자료 전체 3개의 버전",International Conference on Learning Representations (ICLR),,,,,,,
Politeness transfer: A tag and generate approach,"Aman Madaan, Amrith Setlur, Tanmay Parekh, Barnabas Poczos, Graham Neubig, Yiming Yang, Ruslan Salakhutdinov, Alan W Black, Shrimai Prabhumoye",2020/4/29,arXiv preprint arXiv:2004.14257,,,,,"This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the meaning. We also provide a dataset of more than 1.39 instances automatically labeled for politeness to encourage benchmark evaluations on this new task. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For politeness as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for grammaticality, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at this https URL.",19회,"Politeness transfer: A tag and generate approach
A Madaan, A Setlur, T Parekh, B Poczos, G Neubig… - arXiv preprint arXiv:2004.14257, 2020
19회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
A closer look at accuracy vs. robustness,"Yao-Yuan Yang, Cyrus Rashtchian, Hongyang Zhang, Ruslan Salakhutdinov, Kamalika Chaudhuri",2020/3/5,Advances in Neural Information Processing Systems,33,,,,"Current methods for training robust networks lead to a drop in test accuracy, which has led prior works to posit that a robustness-accuracy tradeoff may be inevitable in deep learning. We take a closer look at this phenomenon and first show that real image datasets are actually separated. With this property in mind, we then prove that robustness and accuracy should both be achievable for benchmark datasets through locally Lipschitz functions, and hence, there should be no inherent tradeoff between robustness and accuracy. Through extensive experiments with robustness methods, we argue that the gap between theory and practice arises from two limitations of current methods: either they fail to impose local Lipschitzness or they are insufficiently generalized. We explore combining dropout with robust training methods and obtain better generalization. We conclude that achieving robustness and accuracy in practice may require using methods that impose local Lipschitzness and augmenting them with deep learning generalization techniques. 1",18회,"A closer look at accuracy vs. robustness
YY Yang, C Rashtchian, H Zhang, R Salakhutdinov… - Advances in Neural Information Processing Systems, 2020
18회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Transformer-xl: Language modeling with longer-term dependency,"Zihang Dai, Zhilin Yang, Yiming Yang, William W Cohen, Jaime Carbonell, Quoc V Le, Ruslan Salakhutdinov",2018/9/27,,,,,,"We propose a novel neural architecture, Transformer-XL, for modeling longer-term dependency. To address the limitation of fixed-length contexts, we introduce a notion of recurrence by reusing the representations from the history. Empirically, we show state-of-the-art (SoTA) results on both word-level and character-level language modeling datasets, including WikiText-103, One Billion Word, Penn Treebank, and enwiki8. Notably, we improve the SoTA results from 1.06 to 0.99 in bpc on enwiki8, from 33.0 to 18.9 in perplexity on WikiText-103, and from 28.0 to 23.5 in perplexity on One Billion Word. Performance improves when the attention length increases during evaluation, and our best model attends to up to 1,600 words and 3,800 characters. To quantify the effective length of dependency, we devise a new metric and show that on WikiText-103 Transformer-XL manages to model dependency that is about 80 …",18회,"Transformer-xl: Language modeling with longer-term dependency
Z Dai, Z Yang, Y Yang, WW Cohen, J Carbonell, QV Le… - 2018
18회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Bayesian probabilistic matrix factorization using MCMC,"Ruslan Salakhutdinov, Andriy Mnih",2008,Proceedings of the International Conference in Machine Learning,,,872-879,,"Page 1. BAYESIAN PROBABILISTIC MATRIX FACTORIZATION USING MCMC Ruslan Salakhutdinov joint work Andriy Mnih Machine Learning, University of Toronto 1 Page 2. Preliminaries 1 2 3 4 5 6 7 ... 1 2 3 4 5 6 7 ... 5 3 ? 1 ... 3 ? 4 ? 3 2 ... ~ R U V User Features Features Movie • Suppose we have M movies, N users, and integer rating values from 1 to K. • Let Rij be the rating of user i for movie j, and U ∈ R D×N, V ∈ R D×M be latent user and movie feature matrices. • We will use Ui and Vj to denote the latent feature vectors for user i and movie j respectively. 2 Page 3. Probabilistic Matrix Factorization (PMF) U Vj i R ij j=1,...,M i=1,...,N V σ U σ σ • PMF is a simple probabilistic linear model with Gaussian observation noise. • Given the feature vectors for the user and the movie, the distribution of the corresponding rating is: p(Rij|Ui, Vj, σ 2 ) = N(Rij|U T i Vj, σ 2 ). • The user and movie feature vectors …",17회,"Bayesian probabilistic matrix factorization using MCMC
R Salakhutdinov, A Mnih - Proceedings of the International Conference in …, 2008
17회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Worst cases policy gradients,"Yichuan Charlie Tang, Jian Zhang, Ruslan Salakhutdinov",2019/11/9,arXiv preprint arXiv:1911.03618,,,,,"Recent advances in deep reinforcement learning have demonstrated the capability of learning complex control policies from many types of environments. When learning policies for safety-critical applications, it is essential to be sensitive to risks and avoid catastrophic events. Towards this goal, we propose an actor-critic framework that models the uncertainty of the future and simultaneously learns a policy based on that uncertainty model. Specifically, given a distribution of the future return for any state and action, we optimize policies for varying levels of conditional Value-at-Risk. The learned policy can map the same state to different actions depending on the propensity for risk. We demonstrate the effectiveness of our approach in the domain of driving simulations, where we learn maneuvers in two scenarios. Our learned controller can dynamically select actions along a continuous axis, where safe and conservative behaviors are found at one end while riskier behaviors are found at the other. Finally, when testing with very different simulation parameters, our risk-averse policies generalize significantly better compared to other reinforcement learning approaches.",16회,"Worst cases policy gradients
YC Tang, J Zhang, R Salakhutdinov - arXiv preprint arXiv:1911.03618, 2019
16회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Connecting the dots between MLE and RL for sequence generation,"Bowen Tan, Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, Eric P Xing",2018/9/27,,,,,,"Sequence generation models such as recurrent networks can be trained with a diverse set of learning algorithms. For example, maximum likelihood learning is simple and efficient, yet suffers from the exposure bias problem. Reinforcement learning like policy gradient addresses the problem but can have prohibitively poor exploration efficiency. A variety of other algorithms such as RAML, SPG, and data noising, have also been developed in different perspectives. This paper establishes a formal connection between these algorithms. We present a generalized entropy regularized policy optimization formulation, and show that the apparently divergent algorithms can all be reformulated as special instances of the framework, with the only difference being the configurations of reward function and a couple of hyperparameters. The unified interpretation offers a systematic view of the varying properties of exploration and learning efficiency. Besides, based on the framework, we present a new algorithm that dynamically interpolates among the existing algorithms for improved learning. Experiments on machine translation and text summarization demonstrate the superiority of the proposed algorithm.",16회,"Connecting the dots between MLE and RL for sequence generation
B Tan, Z Hu, Z Yang, R Salakhutdinov, EP Xing - 2018
16회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Normalized gradient with adaptive stepsize method for deep neural network training,"Adams Wei Yu, Qihang Lin, Ruslan Salakhutdinov, Jaime Carbonell",2017/1/1,arXiv preprint arXiv:1707.04822,1,1,,,"In this paper, we propose a generic and simple algorithmic framework for first order optimization. The framework essentially contains two consecutive steps in each iteration: 1) computing and normalizing the mini-batch stochastic gradient; 2) selecting adaptive step size to update the decision variable (parameter) towards the negative of the normalized gradient. We show that the proposed approach, when customized to the popular adaptive stepsize methods, such as AdaGrad, can enjoy a sublinear convergence rate, if the objective is convex. We also conduct extensive empirical studies on various non-convex neural network optimization problems, including multi layer perceptron, convolution neural networks and recurrent neural networks. The results indicate the normalized gradient with adaptive step size can help accelerate the training of neural networks. In particular, significant speedup can be observed if the networks are deep or the dependencies are long.",16회,"Normalized gradient with adaptive stepsize method for deep neural network training
AW Yu, Q Lin, R Salakhutdinov, J Carbonell - arXiv preprint arXiv:1707.04822, 2017
16회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Towards debiasing sentence representations,"Paul Pu Liang, Irene Mengze Li, Emily Zheng, Yao Chong Lim, Ruslan Salakhutdinov, Louis-Philippe Morency",2020/7/16,arXiv preprint arXiv:2007.08100,,,,,"As natural language processing methods are increasingly deployed in real-world scenarios such as healthcare, legal systems, and social science, it becomes necessary to recognize the role they potentially play in shaping social biases and stereotypes. Previous work has revealed the presence of social biases in widely used word embeddings involving gender, race, religion, and other social constructs. While some methods were proposed to debias these word-level embeddings, there is a need to perform debiasing at the sentence-level given the recent shift towards new contextualized sentence representations such as ELMo and BERT. In this paper, we investigate the presence of social biases in sentence-level representations and propose a new method, Sent-Debias, to reduce these biases. We show that Sent-Debias is effective in removing biases, and at the same time, preserves performance on sentence-level downstream tasks such as sentiment analysis, linguistic acceptability, and natural language understanding. We hope that our work will inspire future research on characterizing and removing social biases from widely adopted sentence representations for fairer NLP.",15회,"Towards debiasing sentence representations
PP Liang, IM Li, E Zheng, YC Lim, R Salakhutdinov… - arXiv preprint arXiv:2007.08100, 2020
15회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
On reward-free reinforcement learning with linear function approximation,"Ruosong Wang, Simon S Du, Lin F Yang, Ruslan Salakhutdinov",2020/6/19,arXiv preprint arXiv:2006.11274,,,,,"Reward-free reinforcement learning (RL) is a framework which is suitable for both the batch RL setting and the setting where there are many reward functions of interest. During the exploration phase, an agent collects samples without using a pre-specified reward function. After the exploration phase, a reward function is given, and the agent uses samples collected during the exploration phase to compute a near-optimal policy. Jin et al.[2020] showed that in the tabular setting, the agent only needs to collect polynomial number of samples (in terms of the number states, the number of actions, and the planning horizon) for reward-free RL. However, in practice, the number of states and actions can be large, and thus function approximation schemes are required for generalization. In this work, we give both positive and negative results for reward-free RL with linear function approximation. We give an algorithm for reward-free RL in the linear Markov decision process setting where both the transition and the reward admit linear representations. The sample complexity of our algorithm is polynomial in the feature dimension and the planning horizon, and is completely independent of the number of states and actions. We further give an exponential lower bound for reward-free RL in the setting where only the optimal -function admits a linear representation. Our results imply several interesting exponential separations on the sample complexity of reward-free RL.",15회,"On reward-free reinforcement learning with linear function approximation
R Wang, SS Du, LF Yang, R Salakhutdinov - arXiv preprint arXiv:2006.11274, 2020
15회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Reinforcement learning with general value function approximation: Provably efficient approach via bounded eluder dimension,"Ruosong Wang, Russ R Salakhutdinov, Lin Yang",2020,Advances in Neural Information Processing Systems,33,,,,"Value function approximation has demonstrated phenomenal empirical success in reinforcement learning (RL). Nevertheless, despite a handful of recent progress on developing theory for RL with linear function approximation, the understanding of\emph {general} function approximation schemes largely remains missing. In this paper, we establish the first provably efficient RL algorithm with general value function approximation. We show that if the value functions admit an approximation with a function class , our algorithm achieves a regret bound of where is a complexity measure of that depends on the eluder dimension~[Russo and Van Roy, 2013] and log-covering numbers, is the planning horizon, and is the number interactions with the environment. Our theory generalizes the linear MDP assumption to general function classes. Moreover, our algorithm is model-free and provides a …",15회,"Reinforcement learning with general value function approximation: Provably efficient approach via bounded eluder dimension
R Wang, RR Salakhutdinov, L Yang - Advances in Neural Information Processing Systems, 2020
15회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Deep neural networks with multi-branch architectures are intrinsically less non-convex,"Hongyang Zhang, Junru Shao, Ruslan Salakhutdinov",2019/4/11,,,,1099-1109,PMLR,"Several recently proposed architectures of neural networks such as ResNeXt, Inception, Xception, SqueezeNet and Wide ResNet are based on the designing idea of having multiple branches and have demonstrated improved performance in many applications. We show that one cause for such success is due to the fact that the multi-branch architecture is less non-convex in terms of duality gap. The duality gap measures the degree of intrinsic non-convexity of an optimization problem: smaller gap in relative value implies lower degree of intrinsic non-convexity. The challenge is to quantitatively measure the duality gap of highly non-convex problems such as deep neural networks. In this work, we provide strong guarantees of this quantity for two classes of network architectures. For the neural networks with arbitrary activation functions, multi-branch architecture and a variant of hinge loss, we show that the duality gap of both population and empirical risks shrinks to zero as the number of branches increases. This result sheds light on better understanding the power of over-parametrization where increasing the number of branches tends to make the loss surface less non-convex. For the neural networks with linear activation function and loss, we show that the duality gap of empirical risk is zero. Our two results work for arbitrary depths, while the analytical techniques might be of independent interest to non-convex optimization more broadly. Experiments on both synthetic and real-world datasets validate our results.",15회,"Deep neural networks with multi-branch architectures are intrinsically less non-convex
H Zhang, J Shao, R Salakhutdinov - The 22nd International Conference on Artificial …, 2019
15회 인용 관련 학술자료 전체 2개의 버전",The 22nd International Conference on Artificial Intelligence and Statistics,,,,,,,
Glomo: Unsupervised learning of transferable relational graphs,"Zhilin Yang, Jake Junbo Zhao, Bhuwan Dhingra, Kaiming He, William W Cohen, Ruslan Salakhutdinov, Yann LeCun",2018/12/3,,,,8964-8975,,"Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (eg, words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden units), or embedding-free units such as image pixels.",15회,"Glomo: Unsupervised learning of transferable relational graphs
Z Yang, JJ Zhao, B Dhingra, K He, WW Cohen… - Proceedings of the 32nd International Conference on …, 2018
15회 인용 관련 학술자료 전체 6개의 버전",,Proceedings of the 32nd International Conference on Neural Information Processing Systems,,,,,,
Autoloss: Learning discrete schedules for alternate optimization,"Haowen Xu, Hao Zhang, Zhiting Hu, Xiaodan Liang, Ruslan Salakhutdinov, Eric Xing",2018/10/4,arXiv preprint arXiv:1810.02442,,,,,"Many machine learning problems involve iteratively and alternately optimizing different task objectives with respect to different sets of parameters. Appropriately scheduling the optimization of a task objective or a set of parameters is usually crucial to the quality of convergence. In this paper, we present AutoLoss, a meta-learning framework that automatically learns and determines the optimization schedule. AutoLoss provides a generic way to represent and learn the discrete optimization schedule from metadata, allows for a dynamic and data-driven schedule in ML problems that involve alternating updates of different parameters or from different loss objectives. We apply AutoLoss on four ML tasks: d-ary quadratic regression, classification using a multi-layer perceptron (MLP), image generation using GANs, and multi-task neural machine translation (NMT). We show that the AutoLoss controller is able to capture the distribution of better optimization schedules that result in higher quality of convergence on all four tasks. The trained AutoLoss controller is generalizable--it can guide and improve the learning of a new task model with different specifications, or on different datasets.",15회,"Autoloss: Learning discrete schedules for alternate optimization
H Xu, H Zhang, Z Hu, X Liang, R Salakhutdinov, E Xing - arXiv preprint arXiv:1810.02442, 2018
15회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Question answering from unstructured text by retrieval and comprehension,"Yusuke Watanabe, Bhuwan Dhingra, Ruslan Salakhutdinov",2017/3/26,arXiv preprint arXiv:1703.08885,,,,,"Open domain Question Answering (QA) systems must interact with external knowledge sources, such as web pages, to find relevant information. Information sources like Wikipedia, however, are not well structured and difficult to utilize in comparison with Knowledge Bases (KBs). In this work we present a two-step approach to question answering from unstructured text, consisting of a retrieval step and a comprehension step. For comprehension, we present an RNN based attention model with a novel mixture mechanism for selecting answers from either retrieved articles or a fixed vocabulary. For retrieval we introduce a hand-crafted model and a neural model for ranking relevant articles. We achieve state-of-the-art performance on W IKI M OVIES dataset, reducing the error by 40%. Our experimental results further demonstrate the importance of each of the introduced components.",14회,"Question answering from unstructured text by retrieval and comprehension
Y Watanabe, B Dhingra, R Salakhutdinov - arXiv preprint arXiv:1703.08885, 2017
14회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Training a deep autoencoder or a classifier on MNIST digits,"Geoffrey Hinton, R Salakhutdinov",2014/10,,,,,,,14회,"Training a deep autoencoder or a classifier on MNIST digits
G Hinton, R Salakhutdinov - 2014
14회 인용 관련 학술자료",,,,,,,,
Bayesian probabilistic matrix factorization using markov chain monte carlo,"Salakhutdinov Ruslan, M Andriy",2008,,,,,,,14회,"Bayesian probabilistic matrix factorization using markov chain monte carlo
S Ruslan, M Andriy - Proceedings of the 25th international conference on …, 2008
14회 인용 관련 학술자료",Proceedings of the 25th international conference on Machine learning. ACM,,,,,,,
Generating video descriptions with latent topic guidance,"Shizhe Chen, Qin Jin, Jia Chen, Alexander G Hauptmann",2019/1/30,IEEE Transactions on Multimedia,21,9,2407-2418,IEEE,"Automatic video description generation (a.k.a video captioning) is one of the ultimate goals for video understanding. Despite the wide range of applications such as video indexing and retrieval etc., the video captioning task remains quite challenging due to the complexity and diversity of video content. First, open-domain videos cover a broad range of topics, which results in highly variable vocabularies and expression styles to describe the video contents. Second, videos naturally contain multiple modalities including image, motion, and acoustic media. The information provided by different modalities differs in different conditions. In this paper, we propose a novel topic-guided video captioning model to address the above-mentioned challenges in video captioning. Our model consists of two joint tasks, namely, latent topic generation and topic-guided caption generation. The topic generation task aims to automatically …",13회,"Generating video descriptions with latent topic guidance
S Chen, Q Jin, J Chen, AG Hauptmann - IEEE Transactions on Multimedia, 2019
13회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Block-normalized gradient method: An empirical study for training deep neural network,"Adams Wei Yu, Lei Huang, Qihang Lin, Ruslan Salakhutdinov, Jaime Carbonell",2017/7/16,arXiv preprint arXiv:1707.04822,,,,,"In this paper, we propose a generic and simple strategy for utilizing stochastic gradient information in optimization. The technique essentially contains two consecutive steps in each iteration: 1) computing and normalizing each block (layer) of the mini-batch stochastic gradient; 2) selecting appropriate step size to update the decision variable (parameter) towards the negative of the block-normalized gradient. We conduct extensive empirical studies on various non-convex neural network optimization problems, including multi-layer perceptron, convolution neural networks and recurrent neural networks. The results indicate the block-normalized gradient can help accelerate the training of neural networks. In particular, we observe that the normalized gradient methods having constant step size with occasionally decay, such as SGD with momentum, have better performance in the deep convolution neural networks, while those with adaptive step sizes, such as Adam, perform better in recurrent neural networks. Besides, we also observe this line of methods can lead to solutions with better generalization properties, which is confirmed by the performance improvement over strong baselines.",13회,"Block-normalized gradient method: An empirical study for training deep neural network
AW Yu, L Huang, Q Lin, R Salakhutdinov, J Carbonell - arXiv preprint arXiv:1707.04822, 2017
13회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Semi-supervised mixture-of-experts classification,"Grigoris Karakoulas, Ruslan Salakhutdinov",2004/11/1,,,,138-145,IEEE,"We introduce a mixture-of-experts technique that is a generalization of mixture modeling techniques previously suggested for semi-supervised learning. We apply the bias-variance decomposition to semi-supervised classification and use the decomposition to study the effects from adding unlabeled data when learning a mixture model. Our empirical results indicate that the biggest gain from adding unlabeled data comes from the reduction of the model variance, whereas the behavior of the bias error term heavily depends on the correctness of the underlying model assumptions.",13회,"Semi-supervised mixture-of-experts classification
G Karakoulas, R Salakhutdinov - Fourth IEEE International Conference on Data Mining …, 2004
13회 인용 관련 학술자료 전체 3개의 버전",Fourth IEEE International Conference on Data Mining (ICDM'04),,,,,,,
Adversarial robustness through local lipschitzness,"Yao-Yuan Yang, Cyrus Rashtchian, Hongyang Zhang, Ruslan Salakhutdinov, Kamalika Chaudhuri",2020/3/5,arXiv preprint arXiv:2003.02460,,,,,"A standard method for improving the robustness of neural networks is adversarial training, where the network is trained on adversarial examples that are close to the training inputs. This produces classifiers that are robust, but it often decreases clean accuracy. Prior work even posits that the tradeoff between robustness and accuracy may be inevitable. We investigate this tradeoff in more depth through the lens of local Lipschitzness. In many image datasets, the classes are separated in the sense that images with different labels are not extremely close in distance. Using this separation as a starting point, we argue that it is possible to achieve both accuracy and robustness by encouraging the classifier to be locally smooth around the data. More precisely, we consider classifiers that are obtained by rounding locally Lipschitz functions. Theoretically, we show that such classifiers exist for any dataset such that there is a positive distance between the support of different classes. Empirically, we compare the local Lipschitzness of classifiers trained by several methods. Our results show that having a small Lipschitz constant correlates with achieving high clean and robust accuracy, and therefore, the smoothness of the classifier is an important property to consider in the context of adversarial examples. Code available at this https URL.",12회,"Adversarial robustness through local lipschitzness
YY Yang, C Rashtchian, H Zhang, R Salakhutdinov… - arXiv preprint arXiv:2003.02460, 2020
12회 인용 관련 학술자료",,,,,,,,
"Reducing the dimensionality of data with neural networks. science, 313 (5786), 504-507","GE Hinton, RR Salakhutdinov",2006,DOI= https://doi. org/10.1126/science,1127647,,,,,12회,"Reducing the dimensionality of data with neural networks. science, 313 (5786), 504-507
GE Hinton, RR Salakhutdinov - DOI= https://doi. org/10.1126/science, 2006
12회 인용 관련 학술자료",,,,,,,,
Generative multiple-instance learning models for quantitative electromyography,"Tameem Adel, Benn Smith, Ruth Urner, Daniel Stashuk, Daniel J Lizotte",2013/9/26,arXiv preprint arXiv:1309.6811,,,,,"We present a comprehensive study of the use of generative modeling approaches for Multiple-Instance Learning (MIL) problems. In MIL a learner receives training instances grouped together into bags with labels for the bags only (which might not be correct for the comprised instances). Our work was motivated by the task of facilitating the diagnosis of neuromuscular disorders using sets of motor unit potential trains (MUPTs) detected within a muscle which can be cast as a MIL problem. Our approach leads to a state-of-the-art solution to the problem of muscle classification. By introducing and analyzing generative models for MIL in a general framework and examining a variety of model structures and components, our work also serves as a methodological guide to modelling MIL tasks. We evaluate our proposed methods both on MUPT datasets and on the MUSK1 dataset, one of the most widely used benchmarks for MIL.",11회,"Generative multiple-instance learning models for quantitative electromyography
T Adel, B Smith, R Urner, D Stashuk, DJ Lizotte - arXiv preprint arXiv:1309.6811, 2013
11회 인용 관련 학술자료 전체 17개의 버전",,,,,,,,
Learning cognitive models using neural networks,"Devendra Singh Chaplot, Christopher MacLellan, Ruslan Salakhutdinov, Kenneth Koedinger",2018/6/27,,,,43-56,"Springer, Cham","A cognitive model of human learning provides information about skills a learner must acquire to perform accurately in a task domain. Cognitive models of learning are not only of scientific interest, but are also valuable in adaptive online tutoring systems. A more accurate model yields more effective tutoring through better instructional decisions. Prior methods of automated cognitive model discovery have typically focused on well-structured domains, relied on student performance data or involved substantial human knowledge engineering. In this paper, we propose Cognitive Representation Learner (CogRL), a novel framework to learn accurate cognitive models in ill-structured domains with no data and little to no human knowledge engineering. Our contribution is two-fold: firstly, we show that representations learnt using CogRL can be used for accurate automatic cognitive model discovery without using …",10회,"Learning cognitive models using neural networks
DS Chaplot, C MacLellan, R Salakhutdinov… - International Conference on Artificial Intelligence in …, 2018
10회 인용 관련 학술자료 전체 6개의 버전",International Conference on Artificial Intelligence in Education,,,,,,,
Deep neural networks with multi-branch architectures are less non-convex,"Hongyang Zhang, Junru Shao, Ruslan Salakhutdinov",2018/6/6,arXiv preprint arXiv:1806.01845,,,,,"Several recently proposed architectures of neural networks such as ResNeXt, Inception, Xception, SqueezeNet and Wide ResNet are based on the designing idea of having multiple branches and have demonstrated improved performance in many applications. We show that one cause for such success is due to the fact that the multi-branch architecture is less non-convex in terms of duality gap. The duality gap measures the degree of intrinsic non-convexity of an optimization problem: smaller gap in relative value implies lower degree of intrinsic non-convexity. The challenge is to quantitatively measure the duality gap of highly non-convex problems such as deep neural networks. In this work, we provide strong guarantees of this quantity for two classes of network architectures. For the neural networks with arbitrary activation functions, multi-branch architecture and a variant of hinge loss, we show that the duality gap of both population and empirical risks shrinks to zero as the number of branches increases. This result sheds light on better understanding the power of over-parametrization where increasing the network width tends to make the loss surface less non-convex. For the neural networks with linear activation function and loss, we show that the duality gap of empirical risk is zero. Our two results work for arbitrary depths and adversarial data, while the analytical techniques might be of independent interest to non-convex optimization more broadly. Experiments on both synthetic and real-world datasets validate our results.",10회,"Deep neural networks with multi-branch architectures are less non-convex
H Zhang, J Shao, R Salakhutdinov - arXiv preprint arXiv:1806.01845, 2018
10회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Investigating the working of text classifiers,"Devendra Singh Sachan, Manzil Zaheer, Ruslan Salakhutdinov",2018/1/19,arXiv preprint arXiv:1801.06261,,,,,"Text classification is one of the most widely studied tasks in natural language processing. Motivated by the principle of compositionality, large multilayer neural network models have been employed for this task in an attempt to effectively utilize the constituent expressions. Almost all of the reported work train large networks using discriminative approaches, which come with a caveat of no proper capacity control, as they tend to latch on to any signal that may not generalize. Using various recent state-of-the-art approaches for text classification, we explore whether these models actually learn to compose the meaning of the sentences or still just focus on some keywords or lexicons for classifying the document. To test our hypothesis, we carefully construct datasets where the training and test splits have no direct overlap of such lexicons, but overall language structure would be similar. We study various text classifiers and observe that there is a big performance drop on these datasets. Finally, we show that even simple models with our proposed regularization techniques, which disincentivize focusing on key lexicons, can substantially improve classification accuracy.",10회,"Investigating the working of text classifiers
DS Sachan, M Zaheer, R Salakhutdinov - arXiv preprint arXiv:1801.06261, 2018
10회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Rewriting history with inverse rl: Hindsight inference for policy improvement,"Benjamin Eysenbach, Xinyang Geng, Sergey Levine, Ruslan Salakhutdinov",2020/2/25,arXiv preprint arXiv:2002.11089,,,,,"Multi-task reinforcement learning (RL) aims to simultaneously learn policies for solving many tasks. Several prior works have found that relabeling past experience with different reward functions can improve sample efficiency. Relabeling methods typically ask: if, in hindsight, we assume that our experience was optimal for some task, for what task was it optimal? In this paper, we show that hindsight relabeling is inverse RL, an observation that suggests that we can use inverse RL in tandem for RL algorithms to efficiently solve many tasks. We use this idea to generalize goal-relabeling techniques from prior work to arbitrary classes of tasks. Our experiments confirm that relabeling data using inverse RL accelerates learning in general multi-task settings, including goal-reaching, domains with discrete sets of rewards, and those with linear reward functions.",9회,"Rewriting history with inverse rl: Hindsight inference for policy improvement
B Eysenbach, X Geng, S Levine, R Salakhutdinov - arXiv preprint arXiv:2002.11089, 2020
9회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
“My Way of Telling a Story”: Persona based Grounded Story Generation,"Khyathi Chandu, Shrimai Prabhumoye, Ruslan Salakhutdinov, Alan W Black",2019/8,,,,11-21,,"Visual storytelling is the task of generating stories based on a sequence of images. Inspired by the recent works in neural generation focusing on controlling the form of text, this paper explores the idea of generating these stories in different personas. However, one of the main challenges of performing this task is the lack of a dataset of visual stories in different personas. Having said that, there are independent datasets for both visual storytelling and annotated sentences for various persona. In this paper we describe an approach to overcome this by getting labelled persona data from a different task and leveraging those annotations to perform persona based story generation. We inspect various ways of incorporating personality in both the encoder and the decoder representations to steer the generation in the target direction. To this end, we propose five models which are incremental extensions to the baseline model to perform the task at hand. In our experiments we use five different personas to guide the generation process. We find that the models based on our hypotheses perform better at capturing words while generating stories in the target persona.",9회,"“My Way of Telling a Story”: Persona based Grounded Story Generation
K Chandu, S Prabhumoye, R Salakhutdinov, AW Black - Proceedings of the Second Workshop on Storytelling, 2019
9회 인용 관련 학술자료 전체 2개의 버전",Proceedings of the Second Workshop on Storytelling,,,,,,,
Concurrent meta reinforcement learning,"Emilio Parisotto, Soham Ghosh, Sai Bhargav Yalamanchi, Varsha Chinnaobireddy, Yuhuai Wu, Ruslan Salakhutdinov",2019/3/7,arXiv preprint arXiv:1903.02710,,,,,"State-of-the-art meta reinforcement learning algorithms typically assume the setting of a single agent interacting with its environment in a sequential manner. A negative side-effect of this sequential execution paradigm is that, as the environment becomes more and more challenging, and thus requiring more interaction episodes for the meta-learner, it needs the agent to reason over longer and longer time-scales. To combat the difficulty of long time-scale credit assignment, we propose an alternative parallel framework, which we name"" Concurrent Meta-Reinforcement Learning""(CMRL), that transforms the temporal credit assignment problem into a multi-agent reinforcement learning one. In this multi-agent setting, a set of parallel agents are executed in the same environment and each of these"" rollout"" agents are given the means to communicate with each other. The goal of the communication is to coordinate, in a collaborative manner, the most efficient exploration of the shared task the agents are currently assigned. This coordination therefore represents the meta-learning aspect of the framework, as each agent can be assigned or assign itself a particular section of the current task's state space. This framework is in contrast to standard RL methods that assume that each parallel rollout occurs independently, which can potentially waste computation if many of the rollouts end up sampling the same part of the state space. Furthermore, the parallel setting enables us to define several reward sharing functions and auxiliary losses that are non-trivial to apply in the sequential setting. We demonstrate the effectiveness of our proposed CMRL at …",9회,"Concurrent meta reinforcement learning
E Parisotto, S Ghosh, SB Yalamanchi… - arXiv preprint arXiv:1903.02710, 2019
9회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Post selection inference with incomplete maximum mean discrepancy estimator,"Makoto Yamada, Denny Wu, Yao-Hung Hubert Tsai, Ichiro Takeuchi, Ruslan Salakhutdinov, Kenji Fukumizu",2018/2/17,arXiv preprint arXiv:1802.06226,,,,,"Measuring divergence between two distributions is essential in machine learning and statistics and has various applications including binary classification, change point detection, and two-sample test. Furthermore, in the era of big data, designing divergence measure that is interpretable and can handle high-dimensional and complex data becomes extremely important. In the paper, we propose a post selection inference (PSI) framework for divergence measure, which can select a set of statistically significant features that discriminate two distributions. Specifically, we employ an additive variant of maximum mean discrepancy (MMD) for features and introduce a general hypothesis test for PSI. A novel MMD estimator using the incomplete U-statistics, which has an asymptotically Normal distribution (under mild assumptions) and gives high detection power in PSI, is also proposed and analyzed theoretically. Through synthetic and real-world feature selection experiments, we show that the proposed framework can successfully detect statistically significant features. Last, we propose a sample selection framework for analyzing different members in the Generative Adversarial Networks (GANs) family.",9회,"Post selection inference with incomplete maximum mean discrepancy estimator
M Yamada, D Wu, YHH Tsai, I Takeuchi… - arXiv preprint arXiv:1802.06226, 2018
9회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Learning not to learn in the presence of noisy labels,"Liu Ziyin, Blair Chen, Ru Wang, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency, Masahito Ueda",2020/2/16,arXiv preprint arXiv:2002.06541,,,,,"Learning in the presence of label noise is a challenging yet important task: it is crucial to design models that are robust in the presence of mislabeled datasets. In this paper, we discover that a new class of loss functions called the gambler's loss provides strong robustness to label noise across various levels of corruption. We show that training with this loss function encourages the model to"" abstain"" from learning on the data points with noisy labels, resulting in a simple and effective method to improve robustness and generalization. In addition, we propose two practical extensions of the method: 1) an analytical early stopping criterion to approximately stop training before the memorization of noisy labels, as well as 2) a heuristic for setting hyperparameters which do not require knowledge of the noise corruption rate. We demonstrate the effectiveness of our method by achieving strong results across three image and text classification tasks as compared to existing baselines.",8회,"Learning not to learn in the presence of noisy labels
L Ziyin, B Chen, R Wang, PP Liang, R Salakhutdinov… - arXiv preprint arXiv:2002.06541, 2020
8회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
External vs. internal: an essay on machine learning agents for autonomous database management systems,"Andrew Pavlo, Matthew Butrovich, Ananya Joshi, Lin Ma, Prashanth Menon, Dana Van Aken, Lisa Lee, Ruslan Salakhutdinov",2019/6,IEEE bulletin,42,2,,,"The limitless number of possible ways to configure database management systems (DBMSs) has rightfully earned them the reputation of being difficult to manage and tune. Optimizing a DBMS to meet the needs of an application has surpassed the abilities of humans. This is because the correct configuration of a DBMS is highly dependent on a number of factors that are beyond what humans can reason about. The problem is further exacerbated in large-scale deployments with thousands or even millions of individual DBMS installations that each have their own tuning requirements. To overcome this problem, recent research has explored using machine learning-based (ML) agents for automated tuning of DBMSs. These agents extract performance metrics and behavioral information from the DBMS and then train models with this data to select tuning actions that they predict will have the most benefit. They then observe how these actions affect the DBMS and update their models to further improve their efficacy.
In this paper, we discuss two engineering approaches for integrating ML agents in a DBMS. The first is to build an external tuning controller that treats the DBMS as a black-box. The second is to integrate the ML agents natively in the DBMS’s architecture. We consider the trade-offs of these approaches in the context of two projects from Carnegie Mellon University (CMU).",8회,"External vs. internal: an essay on machine learning agents for autonomous database management systems
A Pavlo, M Butrovich, A Joshi, L Ma, P Menon… - IEEE bulletin, 2019
8회 인용 관련 학술자료 전체 14개의 버전",,,,,,,,
Stackelberg gan: Towards provable minimax equilibrium via multi-generator architectures,"Hongyang Zhang, Susu Xu, Jiantao Jiao, Pengtao Xie, Ruslan Salakhutdinov, Eric P Xing",2018/11/19,arXiv preprint arXiv:1811.08010,,,,,"We study the problem of alleviating the instability issue in the GAN training procedure via new architecture design. The discrepancy between the minimax and maximin objective values could serve as a proxy for the difficulties that the alternating gradient descent encounters in the optimization of GANs. In this work, we give new results on the benefits of multi-generator architecture of GANs. We show that the minimax gap shrinks to as the number of generators increases with rate . This improves over the best-known result of . At the core of our techniques is a novel application of Shapley-Folkman lemma to the generic minimax problem, where in the literature the technique was only known to work when the objective function is restricted to the Lagrangian function of a constraint optimization problem. Our proposed Stackelberg GAN performs well experimentally in both synthetic and real-world datasets, improving Fréchet Inception Distance by over the previous multi-generator GANs on the benchmark datasets.",8회,"Stackelberg gan: Towards provable minimax equilibrium via multi-generator architectures
H Zhang, S Xu, J Jiao, P Xie, R Salakhutdinov, EP Xing - arXiv preprint arXiv:1811.08010, 2018
8회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Improving neural networks by preventing co-adaptation of feature detectors. arXiv: Neural and Evolutionary Computing,"Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov",2012,,,,,,,8회,"Improving neural networks by preventing co-adaptation of feature detectors. arXiv: Neural and Evolutionary Computing
GE Hinton, N Srivastava, A Krizhevsky, I Sutskever… - 2012
8회 인용 관련 학술자료",,,,,,,,
Relationship between gradient and EM steps in latent variable models,"Ruslan Salakhutdinov, Sam Roweis, Zoubin Ghahramani",2003,,,,,"Technical Report Unpublished, University of Toronto Department of Computer Science","We present a close relationship between Expectation-Maximization algorithm and direct optimization approaches such as gradient-based methods for parameter learning. We show that the step EM takes in the parameter space and true gradient are related by the symmetric positive definite P matrix, and provide an explicit form of this matrix for several widely used latent variable models. We then go on deriving a general form of the P matrix for the regular exponential family in terms of its natural parameters.",8회,"Relationship between gradient and EM steps in latent variable models
R Salakhutdinov, S Roweis, Z Ghahramani - 2003
8회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Demystifying self-supervised learning: An information-theoretical framework,"Yao-Hung Hubert Tsai, Yue Wu, Ruslan Salakhutdinov, Louis-Philippe Morency",2020/6/10,arXiv preprint arXiv:2006.05576,,,,,"Self-supervised representation learning adopts self-defined signals as supervision and uses the learned representation for downstream tasks, such as masked language modeling (eg, BERT) for natural language processing and contrastive visual representation learning (eg, SimCLR) for computer vision applications. In this paper, we present a theoretical framework explaining that self-supervised learning is likely to work under the assumption that only the shared information (eg, contextual information or content) between the input (eg, non-masked words or original images) and self-supervised signals (eg, masked-words or augmented images) contributes to downstream tasks. Under this assumption, we demonstrate that self-supervisedly learned representation can extract task-relevant and discard task-irrelevant information. We further connect our theoretical analysis to popular contrastive and predictive (self-supervised) learning objectives. In the experimental section, we provide controlled experiments on two popular tasks: 1) visual representation learning with various self-supervised learning objectives to empirically support our analysis; and 2) visual-textual representation learning to challenge that input and self-supervised signal lie in different modalities.",7회,"Demystifying self-supervised learning: An information-theoretical framework
YHH Tsai, Y Wu, R Salakhutdinov, LP Morency - arXiv preprint arXiv:2006.05576, 2020
7회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Geometric capsule autoencoders for 3d point clouds,"Nitish Srivastava, Hanlin Goh, Ruslan Salakhutdinov",2019/12/6,arXiv preprint arXiv:1912.03310,,,,,"We propose a method to learn object representations from 3D point clouds using bundles of geometrically interpretable hidden units, which we call geometric capsules. Each geometric capsule represents a visual entity, such as an object or a part, and consists of two components: a pose and a feature. The pose encodes where the entity is, while the feature encodes what it is. We use these capsules to construct a Geometric Capsule Autoencoder that learns to group 3D points into parts (small local surfaces), and these parts into the whole object, in an unsupervised manner. Our novel Multi-View Agreement voting mechanism is used to discover an object's canonical pose and its pose-invariant feature vector. Using the ShapeNet and ModelNet40 datasets, we analyze the properties of the learned representations and show the benefits of having multiple votes agree. We perform alignment and retrieval of arbitrarily rotated objects--tasks that evaluate our model's object identification and canonical pose recovery capabilities--and obtained insightful results.",7회,"Geometric capsule autoencoders for 3d point clouds
N Srivastava, H Goh, R Salakhutdinov - arXiv preprint arXiv:1912.03310, 2019
7회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Learning neural networks with adaptive regularization,"Han Zhao, Yao-Hung Hubert Tsai, Ruslan Salakhutdinov, Geoffrey J Gordon",2019/7/14,arXiv preprint arXiv:1907.06288,,,,,"Feed-forward neural networks can be understood as a combination of an intermediate representation and a linear hypothesis. While most previous works aim to diversify the representations, we explore the complementary direction by performing an adaptive and data-dependent regularization motivated by the empirical Bayes method. Specifically, we propose to construct a matrix-variate normal prior (on weights) whose covariance matrix has a Kronecker product structure. This structure is designed to capture the correlations in neurons through backpropagation. Under the assumption of this Kronecker factorization, the prior encourages neurons to borrow statistical strength from one another. Hence, it leads to an adaptive and data-dependent regularization when training networks on small datasets. To optimize the model, we present an efficient block coordinate descent algorithm with analytical solutions. Empirically, we demonstrate that the proposed method helps networks converge to local optima with smaller stable ranks and spectral norms. These properties suggest better generalizations and we present empirical results to support this expectation. We also verify the effectiveness of the approach on multiclass classification and multitask regression problems with various network structures.",7회,"Learning neural networks with adaptive regularization
H Zhao, YHH Tsai, R Salakhutdinov, GJ Gordon - arXiv preprint arXiv:1907.06288, 2019
7회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
How many samples are needed to estimate a convolutional or recurrent neural network?,"Simon S Du, Yining Wang, Xiyu Zhai, Sivaraman Balakrishnan, Ruslan Salakhutdinov, Aarti Singh",2018/5/21,arXiv preprint arXiv:1805.07883,,,,,"It is widely believed that the practical success of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) owes to the fact that CNNs and RNNs use a more compact parametric representation than their Fully-Connected Neural Network (FNN) counterparts, and consequently require fewer training examples to accurately estimate their parameters. We initiate the study of rigorously characterizing the sample-complexity of estimating CNNs and RNNs. We show that the sample-complexity to learn CNNs and RNNs scales linearly with their intrinsic dimension and this sample-complexity is much smaller than for their FNN counterparts. For both CNNs and RNNs, we also present lower bounds showing our sample complexities are tight up to logarithmic factors. Our main technical tools for deriving these results are a localized empirical process analysis and a new technical lemma characterizing the convolutional and recurrent structure. We believe that these tools may inspire further developments in understanding CNNs and RNNs.",7회,"How many samples are needed to estimate a convolutional or recurrent neural network?
SS Du, Y Wang, X Zhai, S Balakrishnan… - arXiv preprint arXiv:1805.07883, 2018
7회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
LSTM iteration networks: An exploration of differentiable path finding,"Lisa Lee, Emilio Parisotto, Devendra Singh Chaplot, Ruslan Salakhutdinov",2018/2/12,,,,,,"Our motivation is to scale value iteration to larger environments without a huge increase in computational demand, and fix the problems inherent to Value Iteration Networks (VIN) such as spatial invariance and unstable optimization. We show that VINs, and even extended VINs which improve some of their shortcomings, are empirically difficult to optimize, exhibiting instability during training and sensitivity to random seeds. Furthermore, we explore whether the inductive biases utilized in past differentiable path planning modules are even necessary, and demonstrate that the requirement that the architectures strictly resemble path-finding algorithms does not hold. We do this by designing a new path planning architecture called the LSTM-Iteration Network, which achieves better performance than VINs in metrics such as success rate, training stability, and sensitivity to random seeds.",7회,"LSTM iteration networks: An exploration of differentiable path finding
L Lee, E Parisotto, DS Chaplot, R Salakhutdinov - 2018
7회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
BBN VISER TRECVID 2014 Multimedia Event Detection and Multimedia Event Recounting Systems.,"Florian Luisier, Manasvi Tickoo, Walter Andrews, Guangnan Ye, Dong Liu, Shih-Fu Chang, Ruslan Salakhutdinov, Vlad I Morariu, Larry Davis, Abhinav Gupta, Ismail Haritaoglu, Sadiye Guler, Ashutosh Morde",2014,,,,,,"In this paper, we describe the Raytheon BBN Technologies (BBN) led VISER system for the TRECVID 2014 Multimedia Event Detection (MED) and Recounting (MER) tasks. We present a comprehensive analysis of the different modules:(1) Metadata Generator (MG)–a large suite of audio-visual low-level and sematic features; a set of deep convolutional neural network (DCNN) features trained on the ImageNet dataset; automatic speech recognition (ASR); videotext detection and recognition (OCR). For the low-level features, we used D-SIFT, Opponent SIFT, dense trajectories (HOG+ HOF+ MBH), MFCC and Fisher Vector (FV) representation. For the semantic concepts, we have trained 1,800 weakly supervised concepts from the Research Set videos and a set of YouTube videos. These concepts include objects, actions, scenes, as well as noun-verb bigrams. We also consider the output layer of the DCNN as a 1,000-dimensional semantic feature. For the speech and videotext content, we leveraged rich confidence-weighted keywords and phrases obtained from the BBN ASR and OCR systems.(2) Event Query Generation (EQG)-linear SVM event models are trained for each feature and combined using probabilistic late fusion framework. Our system involves both SVM-based and query-based detections, to achieve superior performance despite the varying number of positive videos in the different training conditions. We present a thorough study and evaluation of different features used in our system.(3) Event Search (ES)-At search time, simple dot products with the SVM hyperplane are computed for each feature and consequently rescaled into a …",7회,"BBN VISER TRECVID 2014 Multimedia Event Detection and Multimedia Event Recounting Systems.
F Luisier, M Tickoo, W Andrews, G Ye, D Liu, SF Chang… - TRECVID, 2014
7회 인용 관련 학술자료 전체 5개의 버전",TRECVID,,,,,,,
Deep belief networks,"Ruslan Salakhutdinov, Geoff Hinton",2007,,,,4-5,Scholarpedia,"Recently, Hinton et al.[6] derived a way to perform fast, greedy learning of deep belief networks (DBN) one layer at a time, with the top two layers forming an undirected bipartite graph (associate memory).",7회,"Deep belief networks
R Salakhutdinov, G Hinton - 2007
7회 인용 관련 학술자료",,,,,,,,
Embodied multimodal multitask learning,"Devendra Singh Chaplot, Lisa Lee, Ruslan Salakhutdinov, Devi Parikh, Dhruv Batra",2019/2/4,arXiv preprint arXiv:1902.01385,,,,,"Recent efforts on training visual navigation agents conditioned on language using deep reinforcement learning have been successful in learning policies for different multimodal tasks, such as semantic goal navigation and embodied question answering. In this paper, we propose a multitask model capable of jointly learning these multimodal tasks, and transferring knowledge of words and their grounding in visual objects across the tasks. The proposed model uses a novel Dual-Attention unit to disentangle the knowledge of words in the textual representations and visual concepts in the visual representations, and align them with each other. This disentangled task-invariant alignment of representations facilitates grounding and knowledge transfer across both tasks. We show that the proposed model outperforms a range of baselines on both tasks in simulated 3D environments. We also show that this disentanglement of representations makes our model modular, interpretable, and allows for transfer to instructions containing new words by leveraging object detectors.",6회,"Embodied multimodal multitask learning
DS Chaplot, L Lee, R Salakhutdinov, D Parikh, D Batra - arXiv preprint arXiv:1902.01385, 2019
6회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Partially shared neural networks for multiple tasks,,2018/6/7,,,,,,"A system includes a neural network organized into layers corresponding to stages of inferences. The neural network includes a common portion, a first portion, and a second portion. The first portion includes a first set of layers dedicated to performing a first inference task on an input data. The second portion includes a second set of layers dedicated to performing a second inference task on the same input data. The common portion includes a third set of layers, which may include an input layer to the neural network, that are used in the performance of both the first and second inference tasks. The system may receive an input data and perform both inference tasks on the input data in a single pass. During training, a training sample with annotations for both inference tasks may be used to train the neural network in a single pass.",6회,"Partially shared neural networks for multiple tasks
R Hu, K Garg, H Goh, R Salakhutdinov, N Srivastava… - US Patent App. 15/828,399, 2018
6회 인용 관련 학술자료 전체 3개의 버전",,,,,"Rui Hu, Kshitiz Garg, Hanlin Goh, Ruslan Salakhutdinov, Nitish Srivastava, Yichuan Tang",US,15828399,
How many samples are needed to learn a convolutional neural network,"Simon S Du, Yining Wang, Xiyu Zhai, Sivaraman Balakrishnan, Ruslan Salakhutdinov, Aarti Singh",2018/5/22,arXiv preprint arXiv:1805.07883,,,,,"A widespread folklore for explaining the success of convolutional neural network (CNN) is that CNN is a more compact representation than the fully connected neural network (FNN) and thus requires fewer samples for learning. We initiate the study of rigorously characterizing the sample complexity of learning convolutional neural networks. We show that for learning an m-dimensional convolutional filter with linear activation acting on a d-dimensional input, the sample complexity of achieving population prediction error of ϵ is O (m/ϵ2) 1, whereas its FNN counterpart needs at least Ω (d/ϵ2) samples. Since m≪ d, this result demonstrates the advantage of using CNN. We further consider the sample complexity of learning a one-hiddenlayer CNN with linear activation where both the m-dimensional convolutional filter and the r-dimensional output weights are unknown. For this model, we show the sample complexity is O ((m+ r)/ϵ2) when the ratio between the stride size and the filter size is a constant. For both models, we also present lower bounds showing our sample complexities are tight up to logarithmic factors. Our main tools for deriving these results are localized empirical process and a new lemma characterizing the convolutional structure. We believe these tools may inspire further developments in understanding CNN.",6회,"How many samples are needed to learn a convolutional neural network
SS Du, Y Wang, X Zhai, S Balakrishnan… - arXiv preprint arXiv:1805.07883, 2018
6회 인용 관련 학술자료",,,,,,,,
Efficient Optimization Algorithms for Learning,Ruslan Salakhutdinov,2003,Magister Thesis of University of Toronto,,,,,"Many problems in machine learning and pattern recognition ultimately reduce to the optimization of a scalar valued function L (Θ) of a free parameter vector Θ. For example, in supervised and unsupervised probabilistic modeling the objective function may be the (conditional) data likelihood or the posterior over parameters. In discriminative learning we may use a classification or regression score; in reinforcement learning we may use average discounted reward. Optimization may also arise during inference; for example we may want to reduce the cross entropy between two distributions or minimize a function such as the Bethe and Kikuchi free energy.
A variety of general techniques exist for optimizing such objective functions. Broadly, they can be placed into one of two categories: direct optimization (DO) algorithms and what we will refer to as bound optimization (BO) algorithms. Direct optimization methods for the parameter learning work directly with the objective function and its derivatives (or estimates thereof), trying to maximize or minimize it by adjusting the free parameters in a local search. This category of algorithms includes standard gradient-based algorithms, line search methods such as popular conjugate gradient, and more",6회,"Efficient Optimization Algorithms for Learning
R Salakhutdinov - Magister Thesis of University of Toronto, 2003
6회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
HuBERT: How much can a bad teacher benefit ASR pre-training?,"Wei-Ning Hsu, Yao-Hung Hubert Tsai, Benjamin Bolte, Ruslan Salakhutdinov, Abdelrahman Mohamed",2021/6/6,,,,6533-6537,IEEE,"Compared to vision and language applications, self-supervised pre-training approaches for ASR are challenged by three unique problems: (1) There are multiple sound units in each input utterance, (2) With audio-only pre-training, there is no lexicon of sound units, and (3) Sound units have variable lengths with no explicit segmentation. In this paper, we propose the Hidden-Unit BERT (HUBERT) model which utilizes a cheap k-means clustering step to provide aligned target labels for pre-training of a BERT model. A key ingredient of our approach is applying the predictive loss over the masked regions only. This allows the pre-training stage to benefit from the consistency of the unsupervised teacher rather that its intrinsic quality. Starting with a simple k-means teacher of 100 cluster, and using two iterations of clustering, the HUBERT model matches the state-of-the-art wav2vec 2.0 performance on the ultra low …",5회,"HuBERT: How much can a bad teacher benefit ASR pre-training?
WN Hsu, YHH Tsai, B Bolte, R Salakhutdinov… - ICASSP 2021-2021 IEEE International Conference on …, 2021
5회 인용","ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",,,,,,,
Inspection neural network for assessing neural network reliability,,2021/3/9,,,,,,"A system employs an inspection neural network (INN) to inspect data generated during an inference process of a primary neural network (PNN) to generate an indication of reliability for an output generated by the PNN. The system includes a sensor configured to capture sensor data. Sensor data captured by the sensor is provided to a data analyzer to generate an output using the PNN. An analyzer inspector is configured to capture inspection data associated with the generation of the output by the data analyzer, and use the INN to generate an indication of reliability for the PNN's output based on the inspection data. The INN is trained using a set of training data that is distinct from the training data used to train the PNN.",5회,"Inspection neural network for assessing neural network reliability
R Hu, R Salakhutdinov, N Srivastava, Y Tang - US Patent 10,943,148, 2021
5회 인용 관련 학술자료 전체 3개의 버전",,,,,"Rui Hu, Ruslan Salakhutdinov, Nitish Srivastava, Yichuan Tang",US,15828408,10943148
Graph Adversarial Networks: Protecting Information against Adversarial Attacks,"Peiyuan Liao, Han Zhao, Keyulu Xu, Tommi Jaakkola, Geoffrey Gordon, Stefanie Jegelka, Ruslan Salakhutdinov",2020/9/28,arXiv preprint arXiv:2009.13504,,,,,"We explore the problem of protecting information when learning with graph-structured data. While the advent of Graph Neural Networks (GNNs) has greatly improved node and graph representational learning in many applications, the neighborhood aggregation paradigm exposes additional vulnerabilities to attackers seeking to extract node-level information about sensitive attributes. To counter this, we propose a minimax game between the desired GNN encoder and the worst-case attacker. The resulting adversarial training creates a strong defense against inference attacks, while only suffering small loss in task performance. We analyze the effectiveness of our framework against a worst-case adversary, and characterize the trade-off between predictive accuracy and adversarial defense. Experiments across multiple datasets from recommender systems, knowledge graphs and quantum chemistry demonstrate that the proposed approach provides a robust defense across various graph structures and tasks, while producing competitive GNN encoders.",5회,"Graph Adversarial Networks: Protecting Information against Adversarial Attacks
P Liao, H Zhao, K Xu, T Jaakkola, G Gordon, S Jegelka… - arXiv preprint arXiv:2009.13504, 2020
5회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Guaranteeing reproducibility in deep learning competitions,"Brandon Houghton, Stephanie Milani, Nicholay Topin, William Guss, Katja Hofmann, Diego Perez-Liebana, Manuela Veloso, Ruslan Salakhutdinov",2020/5/12,arXiv preprint arXiv:2005.06041,,,,,"To encourage the development of methods with reproducible and robust training behavior, we propose a challenge paradigm where competitors are evaluated directly on the performance of their learning procedures rather than pre-trained agents. Since competition organizers re-train proposed methods in a controlled setting they can guarantee reproducibility, and--by retraining submissions using a held-out test set--help ensure generalization past the environments on which they were trained.",5회,"Guaranteeing reproducibility in deep learning competitions
B Houghton, S Milani, N Topin, W Guss, K Hofmann… - arXiv preprint arXiv:2005.06041, 2020
5회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Connecting the dots between mle and rl for sequence prediction,"Bowen Tan, Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, Eric Xing",2018/11/24,arXiv preprint arXiv:1811.09740,,,,,"Sequence prediction models can be learned from example sequences with a variety of training algorithms. Maximum likelihood learning is simple and efficient, yet can suffer from compounding error at test time. Reinforcement learning such as policy gradient addresses the issue but can have prohibitively poor exploration efficiency. A rich set of other algorithms such as RAML, SPG, and data noising, have also been developed from different perspectives. This paper establishes a formal connection between these algorithms. We present a generalized entropy regularized policy optimization formulation, and show that the apparently distinct algorithms can all be reformulated as special instances of the framework, with the only difference being the configurations of a reward function and a couple of hyperparameters. The unified interpretation offers a systematic view of the varying properties of exploration and learning efficiency. Besides, inspired from the framework, we present a new algorithm that dynamically interpolates among the family of algorithms for scheduled sequence model learning. Experiments on machine translation, text summarization, and game imitation learning demonstrate the superiority of the proposed algorithm.",5회,"Connecting the dots between mle and rl for sequence prediction
B Tan, Z Hu, Z Yang, R Salakhutdinov, E Xing - arXiv preprint arXiv:1811.09740, 2018
5회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Deep learning.,Ruslan Salakhutdinov,2014/1/1,,,,1973,,"Page 1. Deep Learning Russ Salakhutdinov Machine Learning Department Carnegie Mellon University Canadian Institute for Advanced Research MLSS 2017: Lecture 1 Page 2. Images & Video Relational Data/ Social Network Massive increase in both computational power and the amount of data available from web, video cameras, laboratory measurements. Mining for Structure Speech & Audio Gene Expression Text & Language Geological Data Product Recommendation Climate Change • Develop statistical models that can discover underlying structure, semantic relations, constraints, or invariances from data. • Robust, adaptive models models that can deal with missing measurements, nonstationary distributions, multimodal data. Page 3. Impact of Deep Learning • Speech Recognition • Computer Vision • Language Understanding • Recommender Systems • Drug Discovery and Medical Image Analysis Page …",5회,"Deep learning.
R Salakhutdinov - KDD, 2014
5회 인용 관련 학술자료 전체 5개의 버전",KDD,,,,,,,
A new learning algorithm for stochastic feedforward neural nets,"Yichuan Tang, Ruslan Salakhutdinov",2013,ICML’2013 Workshop on Challenges in Representation Learning,,,,,"Multilayer perceptrons (MLPs) or artificial neural nets are popular models used for nonlinear regression and classification tasks. As regressors, MLPs model the conditional distribution of the predictor variables y given the input variables x. However, this predictive distribution is assumed to be unimodal (eg Normal distribution). For tasks such as structured prediction problems, the conditional distribution should be multi-modal, or one-to-many mappings. By turning the hidden variables in a MLP into stochastic nodes rather than deterministic ones, Sigmoid Belief Nets can induce a rich multimodal distribution in the output space. Learning Sigmoid Belief Nets is very slow and modeling real-valued data is difficult. In this paper, we propose a stochastic feedforward network where its hidden layers have both deterministic and stochastic variables. A new Generalized EM training procedure using importance sampling allows us to efficiently learn complicated conditional distributions. We demonstrate the superiority of our model to conditional Restricted Boltzmann Machines and Mixture Density Networks on 3 synthetic datasets and modeling facial expressions. Moreover, we show that latent features of our model improves classification and provide additional qualitative results on color images.",5회,"A new learning algorithm for stochastic feedforward neural nets
Y Tang, R Salakhutdinov - ICML'2013 Workshop on Challenges in Representation …, 2013
5회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Learning to learn with compound HD models,"Antonio Torralba, Joshua Tenenbaum, Russ R Salakhutdinov",2011,Advances in neural information processing systems,24,,2061-2069,,"We introduce HD (or``Hierarchical-Deep'') models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian models. Specifically we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a Deep Boltzmann Machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training examples, by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.",5회,"Learning to learn with compound HD models
A Torralba, J Tenenbaum, RR Salakhutdinov - Advances in neural information processing systems, 2011
5회 인용 관련 학술자료",,,,,,,,
"Practical large-scale optimization for max-norm regularization: Presented at the Advances in Neural Information Processing Systems, 2010","J Lee, B Recht, R Salakhutdinov, N Srebro, J Tropp",2010,,,,,,,5회,"Practical large-scale optimization for max-norm regularization: Presented at the Advances in Neural Information Processing Systems, 2010
J Lee, B Recht, R Salakhutdinov, N Srebro, J Tropp - 2010
5회 인용 관련 학술자료",,,,,,,,
Expectation-conjugate gradient: An alternative to EM,"Ruslan Salakhutdinov, Sam Roweis, Zoubin Ghahramani",2004,IEEE Signal Processing Letters,11,7,,,"We show a close relationship between bound optimization (BO) algorithms such as Expectation-Maximization and direct optimization (DO) algorithms such as gradient-based methods for parameter learning. We identify analytic conditions under which BO algorithms exhibit Quasi-Newton convergence behavior, and conditions under which these algorithms possess poor, first-order convergence. In particular, for the EM algorithm we show that if a certain measure of the proportion of missing information is small, then EM exhibits Quasi-Newton behavior; when it is large, EM converges slowly. Based on this analysis, we present a new Expectation-Conjugate-Gradient (ECG) algorithm for maximum likelihood estimation, and report empirical results, showing that, as predicted by the theory, ECG outperforms EM in certain cases.",5회,"Expectation-conjugate gradient: An alternative to EM
R Salakhutdinov, S Roweis, Z Ghahramani - IEEE Signal Processing Letters, 2004
5회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
Complex Transformer: A Framework for Modeling Complex-Valued Sequence,"Muqiao Yang, Martin Q Ma, Dongyu Li, Yao-Hung Hubert Tsai, Ruslan Salakhutdinov",2020/5/4,,,,4232-4236,IEEE,"While deep learning has received a surge of interest in a variety of fields in recent years, major deep learning models barely use complex numbers. However, speech, signal and audio data are naturally complex-valued after Fourier Transform, and studies have shown a potentially richer representation of complex nets. In this paper, we propose a Complex Transformer, which incorporates the transformer model as a backbone for sequence modeling; we also develop attention and encoder-decoder network operating for complex input. The model achieves state-of-the-art performance on the MusicNet dataset and an In-phase Quadrature (IQ) signal dataset. The GitHub implementation to reproduce the experimental results is available at https://github.com/muqiaoy/dl_signal.",4회,"Complex Transformer: A Framework for Modeling Complex-Valued Sequence
M Yang, MQ Ma, D Li, YHH Tsai, R Salakhutdinov - ICASSP 2020-2020 IEEE International Conference on …, 2020
4회 인용 관련 학술자료 전체 4개의 버전","ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",,,,,,,
Computational modeling of human multimodal language: The mosei dataset and interpretable dynamic fusion,"Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency",2018,First Workshop and Grand Challenge on Computational Modeling of Human Multimodal Language,,,,,"Computational modeling of human multimodal language is an emerging research area in natural language processing spanning the language, visual and acoustic modalities. Comprehending multimodal language requires not only the modeling of interactions within each modality (intramodal interactions), but more importantly the interactions between modalities (crossmodal interactions). Modeling these interactions lie at the core of multimodal language analysis. From a resource perspective, there is a genuine need for large scale datasets that allow for in-depth studies of human multimodal language. In this paper we introduce CMU-Multimodal Opinion Sentiment and Emotion Intensity (CMUMOSEI), the largest dataset for multimodal sentiment analysis and emotion recognition. In addition, we propose a novel multimodal fusion technique called the Graph Memory Fusion Network (GMFN) that dynamically fuses modalities in a hierarchical manner. Using data from CMU-MOSEI and GMFN, we conduct experiments to investigate the hierarchical interactions between modalities in human multimodal language. Unlike previously proposed fusion techniques, GMFN is highly interpretable and achieves superior performance when compared to the previous state of the art, demonstrating that GMFN is highly suitable for multimodal language analysis.",4회,"Computational modeling of human multimodal language: The mosei dataset and interpretable dynamic fusion
PP Liang, R Salakhutdinov, LP Morency - First Workshop and Grand Challenge on …, 2018
4회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Scaling up natural gradient by factorizing Fisher information,"Roger Grosse, Ruslan Salakhutdinov",2015,Proceedings of the 32nd International Conference on Machine Learning (ICML),,,,,"Page 1. Scaling up natural gradient by factorizing Fisher information Roger Grosse Page 2. • Restricted Boltzmann machines (RBMs) and related models have had a lot of success at modeling complex visual datasets Introduction ood$Generative$Model?$ itten$Digit$Dataset$rative$Model$ of$3@D$Objects$ Good$Generative$Model Handwritten$Characters$ Page 3. • Training RBMs is still a black art for several reasons • We can't evaluate the likelihood since this requires the intractable partition function • We can't compute the gradient exactly • The optimization problem has ill-conditioned curvature since small changes to the model parameters can dramatically change the distribution it represents • I will focus on the third issue Introduction Page 4. • RBMs are an undirected graphical model: v W h hidden units weights visible units p(v,h) = 1 Zexp(v T Wh + a T v + b T h) Z is the partition function, which is …",4회,"Scaling up natural gradient by factorizing Fisher information
R Grosse, R Salakhutdinov - Proceedings of the 32nd International Conference on …, 2015
4회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Deep learning methods for vision,"Rob Fergus, M Ranzato, R Salakhutdinov, G Taylor, K Yu",2012,CVPR 2012 Tutorial,,,,,"Page 1. Deep Learning Methods for Vision Rob Fergus Dept. of Computer Science, Courant Institute, New York University Page 2. Overview • Learning Feature Hierarchies for Vision – Mainly for recognition • Many possible titles: – Deep Learning – Feature Learning • his talk: Basic concepts Links to existing vision approaches Page 3. Overview • Learning Feature Hierarchies for Vision – For object recognition • his talk: Basic concepts Links to existing vision approaches Page 4. Existing Recognition Approach Hand-designed Feature Extraction Trainable Classifier Image/Video Pixels • Features are not learned • Trainable classifier is often generic (eg SVM) Object Class Slide: Y.LeCun Page 5. Motivation • Features are key to recent progress in recognition • Multitude of hand-designed features currently in use – SIFT, HOG, LBP, MSER, Color-SIFT…………. Where next? Better classifiers? Or keep building more features …",4회,"Deep learning methods for vision
R Fergus, M Ranzato, R Salakhutdinov, G Taylor, K Yu - CVPR 2012 Tutorial, 2012
4회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Nonlinear dimensionality reduction using neural networks,Ruslan Salakhutdinov,2000,RBM,2,,1000,,"Discovering low-dimensional structure from high-dimensional observations has always been an important task in machine learning. The compact representation can be used for exploratory data analysis, preprocessing, and data visualization. There exist a variety of dimensionality reduction techniques, which can be broadly classified into: Linear methods (such as Principal Component Analysis (PCA)), Non-linear mappings (such as autoencoders), and Proximity based methods (such as Local Linear Embedding (LLE)[6]).
Most of the existing algorithms suffer from various drawbacks. If the data lie on an embedded lowdimensional nonlinear manifold, then linear methods, even though computationally efficient, cannot recover this structure. Proximity based methods are more powerful, but their computational cost scales quadratically with the number of observations, so they generally cannot be applied to very large high-dimensional data sets. Nonlinear mapping algorithms, such as autoencoders, are generally painfully slow to train, and are prone to getting stuck in local minima.",4회,"Nonlinear dimensionality reduction using neural networks
R Salakhutdinov - RBM, 2000
4회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
C-Learning: Learning to Achieve Goals via Recursive Classification,"Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine",2020/11/17,arXiv preprint arXiv:2011.08909,,,,,"We study the problem of predicting and controlling the future state distribution of an autonomous agent. This problem, which can be viewed as a reframing of goal-conditioned reinforcement learning (RL), is centered around learning a conditional probability density function over future states. Instead of directly estimating this density function, we indirectly estimate this density function by training a classifier to predict whether an observation comes from the future. Via Bayes' rule, predictions from our classifier can be transformed into predictions over future states. Importantly, an off-policy variant of our algorithm allows us to predict the future state distribution of a new policy, without collecting new experience. This variant allows us to optimize functionals of a policy's future state distribution, such as the density of reaching a particular goal state. While conceptually similar to Q-learning, our work lays a principled foundation for goal-conditioned RL as density estimation, providing justification for goal-conditioned methods used in prior work. This foundation makes hypotheses about Q-learning, including the optimal goal-sampling ratio, which we confirm experimentally. Moreover, our proposed method is competitive with prior goal-conditioned RL methods.",3회,"C-Learning: Learning to Achieve Goals via Recursive Classification
B Eysenbach, R Salakhutdinov, S Levine - arXiv preprint arXiv:2011.08909, 2020
3회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Neural methods for point-wise dependency estimation,"Yao-Hung Hubert Tsai, Han Zhao, Makoto Yamada, Louis-Philippe Morency, Ruslan Salakhutdinov",2020/6/9,arXiv preprint arXiv:2006.05553,,,,,"Since its inception, the neural estimation of mutual information (MI) has demonstrated the empirical success of modeling expected dependency between high-dimensional random variables. However, MI is an aggregate statistic and cannot be used to measure point-wise dependency between different events. In this work, instead of estimating the expected dependency, we focus on estimating point-wise dependency (PD), which quantitatively measures how likely two outcomes co-occur. We show that we can naturally obtain PD when we are optimizing MI neural variational bounds. However, optimizing these bounds is challenging due to its large variance in practice. To address this issue, we develop two methods (free of optimizing MI variational bounds): Probabilistic Classifier and Density-Ratio Fitting. We demonstrate the effectiveness of our approaches in 1) MI estimation, 2) self-supervised representation learning, and 3) cross-modal retrieval task.",3회,"Neural methods for point-wise dependency estimation
YHH Tsai, H Zhao, M Yamada, LP Morency… - arXiv preprint arXiv:2006.05553, 2020
3회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Topological Sort for Sentence Ordering,"Shrimai Prabhumoye, Ruslan Salakhutdinov, Alan W Black",2020/5/1,arXiv preprint arXiv:2005.00432,,,,,"Sentence ordering is the task of arranging the sentences of a given text in the correct order. Recent work using deep neural networks for this task has framed it as a sequence prediction problem. In this paper, we propose a new framing of this task as a constraint solving problem and introduce a new technique to solve it. Additionally, we propose a human evaluation for this task. The results on both automatic and human metrics across four different datasets show that this new technique is better at capturing coherence in documents.",3회,"Topological Sort for Sentence Ordering
S Prabhumoye, R Salakhutdinov, AW Black - arXiv preprint arXiv:2005.00432, 2020
3회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Weakly-supervised reinforcement learning for controllable behavior,"Lisa Lee, Benjamin Eysenbach, Ruslan Salakhutdinov, Shixiang Shane Gu, Chelsea Finn",2020/4/6,arXiv preprint arXiv:2004.02860,,,,,"Reinforcement learning (RL) is a powerful framework for learning to take actions to solve tasks. However, in many settings, an agent must winnow down the inconceivably large space of all possible tasks to the single task that it is currently being asked to solve. Can we instead constrain the space of tasks to those that are semantically meaningful? In this work, we introduce a framework for using weak supervision to automatically disentangle this semantically meaningful subspace of tasks from the enormous space of nonsensical ""chaff"" tasks. We show that this learned subspace enables efficient exploration and provides a representation that captures distance between states. On a variety of challenging, vision-based continuous control problems, our approach leads to substantial performance gains, particularly as the complexity of the environment grows.",3회,"Weakly-supervised reinforcement learning for controllable behavior
L Lee, B Eysenbach, R Salakhutdinov, SS Gu, C Finn - arXiv preprint arXiv:2004.02860, 2020
3회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
On emergent communication in competitive multi-agent teams,"Paul Pu Liang, Jeffrey Chen, Ruslan Salakhutdinov, Louis-Philippe Morency, Satwik Kottur",2020/3/4,arXiv preprint arXiv:2003.01848,,,,,"Several recent works have found the emergence of grounded compositional language in the communication protocols developed by mostly cooperative multi-agent systems when learned end-to-end to maximize performance on a downstream task. However, human populations learn to solve complex tasks involving communicative behaviors not only in fully cooperative settings but also in scenarios where competition acts as an additional external pressure for improvement. In this work, we investigate whether competition for performance from an external, similar agent team could act as a social influence that encourages multi-agent populations to develop better communication protocols for improved performance, compositionality, and convergence speed. We start from Task & Talk, a previously proposed referential game between two cooperative agents as our testbed and extend it into Task, Talk & Compete, a game involving two competitive teams each consisting of two aforementioned cooperative agents. Using this new setting, we provide an empirical study demonstrating the impact of competitive influence on multi-agent teams. Our results show that an external competitive influence leads to improved accuracy and generalization, as well as faster emergence of communicative languages that are more informative and compositional.",3회,"On emergent communication in competitive multi-agent teams
PP Liang, J Chen, R Salakhutdinov, LP Morency… - arXiv preprint arXiv:2003.01848, 2020
3회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Bayesian Probabilistic Matrix Factorization: A User Frequency Analysis,"Cody Severinski, Ruslan Salakhutdinov",2014/7/29,arXiv preprint arXiv:1407.7840,,,,,"Matrix factorization (MF) has become a common approach to collaborative filtering, due to ease of implementation and scalability to large data sets. Two existing drawbacks of the basic model is that it does not incorporate side information on either users or items, and assumes a common variance for all users. We extend the work of constrained probabilistic matrix factorization by deriving the Gibbs updates for the side feature vectors for items (Salakhutdinov and Minh, 2008). We show that this Bayesian treatment to the constrained PMF model outperforms simple MAP estimation. We also consider extensions to heteroskedastic precision introduced in the literature (Lakshminarayanan, Bouchard, and Archambeau, 2011). We show that this tends result in overfitting for deterministic approximation algorithms (ex: Variational inference) when the observed entries in the user/item matrix are distributed in an non-uniform manner. In light of this, we propose a truncated precision model. Our experimental results suggest that this model tends to delay overfitting.",3회,"Bayesian Probabilistic Matrix Factorization: A User Frequency Analysis
C Severinski, R Salakhutdinov - arXiv preprint arXiv:1407.7840, 2014
3회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Fast inference and learning for modeling documents with a deep boltzmann machine,"Nitish Srivastava, Ruslan Salakhutdinov, Geoffrey Hinton",2013/4/26,,,,,,"We introduce a type of Deep Boltzmann Machine (DBM) that is suitable for extracting distributed semantic representations from a large unstructured collection of documents. We propose an approximate inference method that interacts with learning in a way that makes it possible to train the DBM more efficiently than previously proposed methods. Even though the model has two hidden layers, it can be trained just as efficiently as a standard Restricted Boltzmann Machine. Our experiments show that the model assigns better log probability to unseen data than the Replicated Softmax model. Features extracted from our model outperform LDA, Replicated Softmax, and DocNADE models on document retrieval and document classification tasks.",3회,"Fast inference and learning for modeling documents with a deep boltzmann machine
N Srivastava, R Salakhutdinov, G Hinton - 2013
3회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
The MineRL 2020 Competition on Sample Efficient Reinforcement Learning using Human Priors,"William H Guss, Mario Ynocente Castro, Sam Devlin, Brandon Houghton, Noboru Sean Kuno, Crissman Loomis, Stephanie Milani, Sharada Mohanty, Keisuke Nakata, Ruslan Salakhutdinov, John Schulman, Shinya Shiroshita, Nicholay Topin, Avinash Ummadisingu, Oriol Vinyals",2021/1/26,arXiv preprint arXiv:2101.11071,,,,,"Although deep reinforcement learning has led to breakthroughs in many difficult domains, these successes have required an ever-increasing number of samples, affording only a shrinking segment of the AI community access to their development. Resolution of these limitations requires new, sample-efficient methods. To facilitate research in this direction, we propose this second iteration of the MineRL Competition. The primary goal of the competition is to foster the development of algorithms which can efficiently leverage human demonstrations to drastically reduce the number of samples needed to solve complex, hierarchical, and sparse environments. To that end, participants compete under a limited environment sample-complexity budget to develop systems which solve the MineRL ObtainDiamond task in Minecraft, a sequential decision making environment requiring long-term planning, hierarchical control, and efficient exploration methods. The competition is structured into two rounds in which competitors are provided several paired versions of the dataset and environment with different game textures and shaders. At the end of each round, competitors submit containerized versions of their learning algorithms to the AIcrowd platform where they are trained from scratch on a hold-out dataset-environment pair for a total of 4-days on a pre-specified hardware platform. In this follow-up iteration to the NeurIPS 2019 MineRL Competition, we implement new features to expand the scale and reach of the competition. In response to the feedback of the previous participants, we introduce a second minor track focusing on solutions without access to …",2회,"The MineRL 2020 Competition on Sample Efficient Reinforcement Learning using Human Priors
WH Guss, MY Castro, S Devlin, B Houghton, NS Kuno… - arXiv preprint arXiv:2101.11071, 2021
2회 인용 전체 4개의 버전",,,,,,,,
Multimodal Routing: Improving Local and Global Interpretability of Multimodal Language Analysis,"Yao-Hung Hubert Tsai, Martin Ma, Muqiao Yang, Ruslan Salakhutdinov, Louis-Philippe Morency",2020/11,,,,1823-1833,,"The human language can be expressed through multiple sources of information known as modalities, including tones of voice, facial gestures, and spoken language. Recent multimodal learning with strong performances on human-centric tasks such as sentiment analysis and emotion recognition are often blackbox, with very limited interpretability. In this paper we propose Multimodal Routing, which dynamically adjusts weights between input modalities and output representations differently for each input sample. Multimodal routing can identify relative importance of both individual modalities and cross-modality features. Moreover, the weight assignment by routing allows us to interpret modalityprediction relationships not only globally (ie general trends over the whole dataset), but also locally for each single input sample, meanwhile keeping competitive performance compared to state-of-the-art methods.",2회,"Multimodal Routing: Improving Local and Global Interpretability of Multimodal Language Analysis
YHH Tsai, M Ma, M Yang, R Salakhutdinov… - Proceedings of the 2020 Conference on Empirical …, 2020
2회 인용 관련 학술자료 전체 2개의 버전",Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),,,,,,,
Interpretable Multimodal Routing for Human Multimodal Language,"Yao-Hung Hubert Tsai, Martin Q Ma, Muqiao Yang, Ruslan Salakhutdinov, Louis-Philippe Morency",2020/4/29,arXiv preprint arXiv:2004.14198,,,,,"The human language has heterogeneous sources of information, including tones of voice, facial gestures, and spoken language. Recent advances introduced computational models to combine these multimodal sources and yielded strong performance on human-centric tasks. Nevertheless, most of the models are often black-box, which comes with the price of lacking interpretability. In this paper, we propose Multimodal Routing to separate the contributions to the prediction from each modality and the interactions between modalities. At the heart of our method is a routing mechanism that represents each prediction as a concept, ie, a vector in a Euclidean space. The concept assumes a linear aggregation from the contributions of multimodal features. Then, the routing procedure iteratively 1) associates a feature and a concept by checking how this concept agrees with this feature and 2) updates the concept based on the associations. In our experiments, we provide both global and local interpretation using Multimodal Routing on sentiment analysis and emotion prediction, without loss of performance compared to state-of-the-art methods. For example, we observe that our model relies mostly on the text modality for neutral sentiment predictions, the acoustic modality for extremely negative predictions, and the text-acoustic bimodal interaction for extremely positive predictions.",2회,"Interpretable Multimodal Routing for Human Multimodal Language
YHH Tsai, MQ Ma, M Yang, R Salakhutdinov… - arXiv preprint arXiv:2004.14198, 2020
2회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Self-supervised learning from a multi-view perspective,"Yao-Hung Hubert Tsai, Yue Wu, Ruslan Salakhutdinov, Louis-Philippe Morency",2020,arXiv preprint arXiv:2006.05576,,,,,,2회,"Self-supervised learning from a multi-view perspective
YHH Tsai, Y Wu, R Salakhutdinov, LP Morency - arXiv preprint arXiv:2006.05576, 2020
2회 인용",,,,,,,,
On Universal Approximation by Neural Networks with Uniform Guarantees on Approximation of Infinite Dimensional Maps,"William H Guss, Ruslan Salakhutdinov",2019/10/3,arXiv preprint arXiv:1910.01545,,,,,"The study of universal approximation of arbitrary functions by neural networks has a rich and thorough history dating back to Kolmogorov (1957). In the case of learning finite dimensional maps, many authors have shown various forms of the universality of both fixed depth and fixed width neural networks. However, in many cases, these classical results fail to extend to the recent use of approximations of neural networks with infinitely many units for functional data analysis, dynamical systems identification, and other applications where either or become infinite dimensional. Two questions naturally arise: which infinite dimensional analogues of neural networks are sufficient to approximate any map , and when do the finite approximations to these analogues used in practice approximate uniformly over its infinite dimensional domain ?
In this paper, we answer the open question of universal approximation of nonlinear operators when and are both infinite dimensional. We show that for a large class of different infinite analogues of neural networks, any continuous map can be approximated arbitrarily closely with some mild topological conditions on . Additionally, we provide the first lower-bound on the minimal number of input and output units required by a finite approximation to an infinite neural network to guarantee that it can uniformly approximate any nonlinear operator using samples from its inputs and outputs.",2회,"On Universal Approximation by Neural Networks with Uniform Guarantees on Approximation of Infinite Dimensional Maps
WH Guss, R Salakhutdinov - arXiv preprint arXiv:1910.01545, 2019
2회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
A Simple Approach to the Noisy Label Problem Through the Gambler's Loss,"Liu Ziyin, Ru Wang, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency, Masahito Ueda",2019/9/25,,,,,,"Learning in the presence of label noise is a challenging yet important task. It is crucial to design models that are robust to noisy labels. In this paper, we discover that a new class of loss functions called the gambler's loss provides strong robustness to label noise across various levels of corruption. Training with this modified loss function reduces memorization of data points with noisy labels and is a simple yet effective method to improve robustness and generalization. Moreover, using this loss function allows us to derive an analytical early stopping criterion that accurately estimates when memorization of noisy labels begins to occur. Our overall approach achieves strong results and outperforming existing baselines.",2회,"A Simple Approach to the Noisy Label Problem Through the Gambler's Loss
L Ziyin, R Wang, PP Liang, R Salakhutdinov… - 2019
2회 인용 관련 학술자료",,,,,,,,
Neurips 2019 competition: The minerl competition on sample efficient reinforcement learning using human priors,"William H Guss, Cayden Codel, Katja Hofmann, Brandon Houghton, Noboru Kuno, Stephanie Milani, Sharada Mohanty, Diego Perez Liebana, Ruslan Salakhutdinov, Nicholay Topin, Manuela Veloso, Phillip Wang",2019/4,arXiv preprint arXiv:1904.10079,,,,,"Though deep reinforcement learning has led to breakthroughs in many difficult domains, these successes have required an ever-increasing number of samples. As state-ofthe-art reinforcement learning (RL) systems require an exponentially increasing number of samples, their development is restricted to a continually shrinking segment of the AI community. Likewise, many of these systemss cannot be applied to real-world problems, where environment samples are expensive. Resolution of these limitations requires new, sample-efficient methods. To facilitate research in this direction, we propose the MineRL Competition on Sample Efficient Reinforcement Learning using Human Priors.
The primary goal of the competition is to foster the development of algorithms which can efficiently leverage human demonstrations to drastically reduce the number of samples needed to solve complex, hierarchical, and sparse environments. To that end, we introduce:(1) the Minecraft ObtainDiamond task, a sequential decision making environment requiring long-term planning, hierarchical control, and efficient exploration methods; and (2) the MineRL-v0 dataset, a large-scale collection of over 60 million state-action pairs of human demonstrations that can be resimulated into embodied agent trajectories with arbitrary modifications to game state and visuals.",2회,"Neurips 2019 competition: The minerl competition on sample efficient reinforcement learning using human priors
WH Guss, C Codel, K Hofmann, B Houghton, N Kuno… - arXiv preprint arXiv:1904.10079, 2019
2회 인용 관련 학술자료",,,,,,,,
Mixtape: Breaking the softmax bottleneck efficiently,"Zhilin Yang, Thang Luong, Russ R Salakhutdinov, Quoc V Le",2019,Advances in Neural Information Processing Systems,32,,5775-5783,,"The softmax bottleneck has been shown to limit the expressiveness of neural lan-guage models. Mixture of Softmaxes (MoS) is an effective approach to address such a theoretical limitation, but are expensive compared to softmax in terms of both memory and time. We propose Mixtape, an output layer that breaks the softmax bottleneck more efficiently with three novel techniques—logit space vector gating, sigmoid tree decomposition, and gate sharing. On four benchmarks including language modeling and machine translation, the Mixtape layer substantially improves the efficiency over the MoS layer by 3.5 x to 10.5 x while obtaining similar performance. A network equipped with Mixtape is only 20% to 34% slower than a softmax-based network with 10-30K vocabulary sizes, and outperforms softmax in perplexity and translation quality.",2회,"Mixtape: Breaking the softmax bottleneck efficiently
Z Yang, T Luong, RR Salakhutdinov, QV Le - Advances in Neural Information Processing Systems, 2019
2회 인용 관련 학술자료",,,,,,,,
On the complexity of exploration in goal-driven navigation,"Maruan Al-Shedivat, Lisa Lee, Ruslan Salakhutdinov, Eric Xing",2018/11/16,arXiv preprint arXiv:1811.06889,,,,,"Building agents that can explore their environments intelligently is a challenging open problem. In this paper, we make a step towards understanding how a hierarchical design of the agent's policy can affect its exploration capabilities. First, we design EscapeRoom environments, where the agent must figure out how to navigate to the exit by accomplishing a number of intermediate tasks (\emph {subgoals}), such as finding keys or opening doors. Our environments are procedurally generated and vary in complexity, which can be controlled by the number of subgoals and relationships between them. Next, we propose to measure the complexity of each environment by constructing dependency graphs between the goals and analytically computing\emph {hitting times} of a random walk in the graph. We empirically evaluate Proximal Policy Optimization (PPO) with sparse and shaped rewards, a variation of policy sketches, and a hierarchical version of PPO (called HiPPO) akin to h-DQN. We show that analytically estimated\emph {hitting time} in goal dependency graphs is an informative metric of the environment complexity. We conjecture that the result should hold for environments other than navigation. Finally, we show that solving environments beyond certain level of complexity requires hierarchical approaches.",2회,"On the complexity of exploration in goal-driven navigation
M Al-Shedivat, L Lee, R Salakhutdinov, E Xing - arXiv preprint arXiv:1811.06889, 2018
2회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Style transfer through multilingual and feedback-based back-translation,"Shrimai Prabhumoye, Yulia Tsvetkov, Alan W Black, Ruslan Salakhutdinov",2018/9/17,arXiv preprint arXiv:1809.06284,,,,,"Style transfer is the task of transferring an attribute of a sentence (eg, formality) while maintaining its semantic content. The key challenge in style transfer is to strike a balance between the competing goals, one to preserve meaning and the other to improve the style transfer accuracy. Prior research has identified that the task of meaning preservation is generally harder to attain and evaluate. This paper proposes two extensions of the state-of-the-art style transfer models aiming at improving the meaning preservation in style transfer. Our evaluation shows that these extensions help to ground meaning better while improving the transfer accuracy.",2회,"Style transfer through multilingual and feedback-based back-translation
S Prabhumoye, Y Tsvetkov, AW Black, R Salakhutdinov - arXiv preprint arXiv:1809.06284, 2018
2회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Connecting visual experiences using max-flow network with application to visual localization,"AH Hafez, Nakul Agarwal, CV Jawahar",2018/8/1,arXiv preprint arXiv:1808.00208,,,,,"We are motivated by the fact that multiple representations of the environment are required to stand for the changes in appearance with time and for changes that appear in a cyclic manner. These changes are, for example, from day to night time, and from day to day across seasons. In such situations, the robot visits the same routes multiple times and collects different appearances of it. Multiple visual experiences usually find robotic vision applications like visual localization, mapping, place recognition, and autonomous navigation. The novelty in this paper is an algorithm that connects multiple visual experiences via aligning multiple image sequences. This problem is solved by finding the maximum flow in a directed graph flow-network, whose vertices represent the matches between frames in the test and reference sequences. Edges of the graph represent the cost of these matches. The problem of finding the best match is reduced to finding the minimum-cut surface, which is solved as a maximum flow network problem. Application to visual localization is considered in this paper to show the effectiveness of the proposed multiple image sequence alignment method, without loosing its generality. Experimental evaluations show that the precision of sequence matching is improved by considering multiple visual sequences for the same route, and that the method performs favorably against state-of-the-art single representation methods like SeqSLAM and ABLE-M.",2회,"Connecting visual experiences using max-flow network with application to visual localization
AH Hafez, N Agarwal, CV Jawahar - arXiv preprint arXiv:1808.00208, 2018
2회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Discovering order in unordered datasets: Generative markov networks,"Yao-Hung Hubert Tsai, Han Zhao, Nebojsa Jojic, Ruslan Salakhutdinov",2018/2/15,,,,,,"The assumption that data samples are independently identically distributed is the backbone of many learning algorithms. Nevertheless, datasets often exhibit rich structures in practice, and we argue that there exist some unknown orders within the data instances. Aiming to find such orders, we introduce a novel Generative Markov Network (GMN) which we use to extract the order of data instances automatically. Specifically, we assume that the instances are sampled from a Markov chain. Our goal is to learn the transitional operator of the chain as well as the generation order by maximizing the generation probability under all possible data permutations. One of our key ideas is to use neural networks as a soft lookup table for approximating the possibly huge, but discrete transition matrix. This strategy allows us to amortize the space complexity with a single model and make the transitional operator generalizable to …",2회,"Discovering order in unordered datasets: Generative markov networks
YHH Tsai, H Zhao, N Jojic, R Salakhutdinov - 2018
2회 인용 관련 학술자료",,,,,,,,
Domain adaptation: overfitting and small sample statistics,"Dean Foster, Sham Kakade, Ruslan Salakhutdinov",2011/5/4,,,,,,"We study the prevalent problem when a test distribution differs from the training distribution. We consider a setting where our training set consists of a small number of sample domains, but where we have many samples in each domain. Our goal is to generalize to a new domain. For example, we may want to learn a similarity function using only certain classes of objects, but we desire that this similarity function be applicable to object classes not present in our training sample (eg we might seek to learn that"" dogs are similar to dogs"" even though images of dogs were absent from our training set). Our theoretical analysis shows that we can select many more features than domains while avoiding overfitting by utilizing data-dependent variance properties. We present a greedy feature selection algorithm based on using T-statistics. Our experiments validate this theory showing that our T-statistic based greedy feature selection is more robust at avoiding overfitting than the classical greedy procedure.",2회,"Domain adaptation: overfitting and small sample statistics
D Foster, S Kakade, R Salakhutdinov - arXiv preprint arXiv:1105.0857, 2011
2회 인용 관련 학술자료 전체 8개의 버전",International Conference on Artificial Intelligence and Statistics (AISTATS),,,,,,,
Notes on the KL-divergence between a Markov chain and its equilibrium distribution,"Iain Murray, Ruslan Salakhutdinov",2008/6/24,preprint,,,,,"After drawing a sample from a distribution, further correlated samples can be obtained by simulating a Markov chain that leaves the target distribution stationary. Often drawing even one sample from a distribution of interest is intractable, so the Markov chain is initialized arbitrarily. This note considers the marginal distribution over the Markov chain’s position at each time step. We show that this marginal never moves further away from the chain’s stationary distribution, as measured by KL-divergence either way around. This is a known result (Cover and Thomas, 1991). The presentation here is for review purposes only.",2회,"Notes on the KL-divergence between a Markov chain and its equilibrium distribution
I Murray, R Salakhutdinov - preprint, 2008
2회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Simultaneous localization and surveying with multiple agents,"Sam T Roweis, Ruslan R Salakhutdinov",2005,,,,313-332,"Springer, Berlin, Heidelberg","We apply a constrained Hidden Markov Model architecture to the problem of simultaneous localization and surveying from sensor logs of mobile agents navigating in unknown environments. We show the solution of this problem for the case of one robot and extend our model to the more interesting case of multiple agents, that interact with each other through proximity sensors. Since exact learning in this case becomes exponentially expensive, we develop an approximate method for inference using loopy belief propagation and apply it to the localization and surveying problem with multiple interacting robots. In support of our analysis, we report experimental results showing that with the same amount of data, approximate learning with the interaction signals outperforms exact learning ignoring interactions.",2회,"Simultaneous localization and surveying with multiple agents
ST Roweis, RR Salakhutdinov - Switching and Learning in Feedback Systems, 2005
2회 인용 관련 학술자료 전체 14개의 버전
Simultaneous Localization and Surveying with Multiple Agents*
RR Salakhutdinov, ST Roweis
관련 학술자료 전체 8개의 버전",,Switching and Learning in Feedback Systems,,,,,,
Learning Deep Boltzmann Machines,Ruslan Salakhutdinov,,,,,,,"Page 1. Learning Deep Boltzmann Machines Ruslan Salakhutdinov CSAIL, MIT Page 2. Outline • Boltzmann Machines, Restricted Boltzmann Machines. • Learning: MCMC + Variational Inference. • Deep Boltzmann Machines. • Evaluation: Estimating partition function. • Results. Page 3. Boltzmann Machines P(v,h;θ) = 1 Z(θ)exp[v ⊤ Wh + 1 2 v ⊤ Lv + 1 2 h ⊤ Jh]. h v J W L P(v;θ) = ∑h P(v,h;θ). Set of visible v and hidden h binary stochastic units. θ = {W, L, J} are model parameters. Inference and maximum likelihood learning are hard. This talk: Learning θ. Page 4. Restricted Boltzmann Machines P(v) = 1 Z∑hexp[v ⊤ Wh] ︸ ︷︷ ︸ P ∗ (v), tractable . Computing P(h|v) is easy. Maximum likelihood learning is hard. Page 5. Boltzmann Machines: Learning Pmodel(v,h) = 1 Zexp[v ⊤ Wh + 1 2 v ⊤ Lv + 1 2 h ⊤ Jh]. h v J W L Maximum Likelihood Learning: ∂ lnP(v) ∂W = EPdata[vh ⊤ ] − EPmodel[vh ⊤ ] …",2회,"Learning Deep Boltzmann Machines
R Salakhutdinov
2회 인용 관련 학술자료",,,,,,,,
Relationship between gradient and EM steps for several latent variable models,"Ruslan Salakhutdinov, Sam Roweis, Zoubin Ghahramani",,,,,,,"2 N diag∗ Λ (t)(Λ (t)) T+ Ψ (t)⊗ Ψ (t)(5) where E (x n)≡ I− βΛ+ β (x n− µ)(x n− µ) T β T with β≡ Λ T (ΛΛ T+ Ψ), diag∗(A) sets all the rows of A to zero except for rows j (d+ 1)− d, j= 1, 2,..., d, and”⊗” denotes the Kroneker product.",2회,"Relationship between gradient and EM steps for several latent variable models
R Salakhutdinov, S Roweis, Z Ghahramani
2회 인용 관련 학술자료",,,,,,,,
A Note on Connecting Barlow Twins with Negative-Sample-Free Contrastive Learning,"Yao-Hung Hubert Tsai, Shaojie Bai, Louis-Philippe Morency, Ruslan Salakhutdinov",2021/4/28,arXiv preprint arXiv:2104.13712,,,,,"In this report, we relate the algorithmic design of Barlow Twins' method to the Hilbert-Schmidt Independence Criterion (HSIC), thus establishing it as a contrastive learning approach that is free of negative samples. Through this perspective, we argue that Barlow Twins (and thus the class of negative-sample-free contrastive learning methods) suggests a possibility to bridge the two major families of self-supervised learning philosophies: non-contrastive and contrastive approaches. In particular, Barlow twins exemplified how we could combine the best practices of both worlds: avoiding the need of large training batch size and negative sample pairing (like non-contrastive methods) and avoiding symmetry-breaking network designs (like contrastive methods).",1회,"A Note on Connecting Barlow Twins with Negative-Sample-Free Contrastive Learning
YHH Tsai, S Bai, LP Morency, R Salakhutdinov - arXiv preprint arXiv:2104.13712, 2021
1회 인용 전체 3개의 버전",,,,,,,,
Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation,"Emilio Parisotto, Ruslan Salakhutdinov",2021/4/4,arXiv preprint arXiv:2104.01655,,,,,"Many real-world applications such as robotics provide hard constraints on power and compute that limit the viable model complexity of Reinforcement Learning (RL) agents. Similarly, in many distributed RL settings, acting is done on un-accelerated hardware such as CPUs, which likewise restricts model size to prevent intractable experiment run times. These ""actor-latency"" constrained settings present a major obstruction to the scaling up of model complexity that has recently been extremely successful in supervised learning. To be able to utilize large model capacity while still operating within the limits imposed by the system during acting, we develop an ""Actor-Learner Distillation"" (ALD) procedure that leverages a continual form of distillation that transfers learning progress from a large capacity learner model to a small capacity actor model. As a case study, we develop this procedure in the context of partially-observable environments, where transformer models have had large improvements over LSTMs recently, at the cost of significantly higher computational complexity. With transformer models as the learner and LSTMs as the actor, we demonstrate in several challenging memory environments that using Actor-Learner Distillation recovers the clear sample-efficiency gains of the transformer learner model while maintaining the fast inference and reduced total training time of the LSTM actor model.",1회,"Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation
E Parisotto, R Salakhutdinov - arXiv preprint arXiv:2104.01655, 2021
1회 인용 전체 3개의 버전",,,,,,,,
Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification,"Benjamin Eysenbach, Sergey Levine, Ruslan Salakhutdinov",2021/3/23,arXiv preprint arXiv:2103.12656,,,,,"In the standard Markov decision process formalism, users specify tasks by writing down a reward function. However, in many scenarios, the user is unable to describe the task in words or numbers, but can readily provide examples of what the world would look like if the task were solved. Motivated by this observation, we derive a control algorithm from first principles that aims to visit states that have a high probability of leading to successful outcomes, given only examples of successful outcome states. Prior work has approached similar problem settings in a two-stage process, first learning an auxiliary reward function and then optimizing this reward function using another reinforcement learning algorithm. In contrast, we derive a method based on recursive classification that eschews auxiliary reward functions and instead directly learns a value function from transitions and successful outcomes. Our method therefore requires fewer hyperparameters to tune and lines of code to debug. We show that our method satisfies a new data-driven Bellman equation, where examples take the place of the typical reward function term. Experiments show that our approach outperforms prior methods that learn explicit reward functions.",1회,"Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification
B Eysenbach, S Levine, R Salakhutdinov - arXiv preprint arXiv:2103.12656, 2021
1회 인용 전체 2개의 버전",,,,,,,,
Self-supervised Representation Learning with Relative Predictive Coding,"Yao-Hung Hubert Tsai, Martin Q Ma, Muqiao Yang, Han Zhao, Louis-Philippe Morency, Ruslan Salakhutdinov",2021/3/21,arXiv preprint arXiv:2103.11275,,,,,"This paper introduces Relative Predictive Coding (RPC), a new contrastive representation learning objective that maintains a good balance among training stability, minibatch size sensitivity, and downstream task performance. The key to the success of RPC is two-fold. First, RPC introduces the relative parameters to regularize the objective for boundedness and low variance. Second, RPC contains no logarithm and exponential score functions, which are the main cause of training instability in prior contrastive objectives. We empirically verify the effectiveness of RPC on benchmark vision and speech self-supervised learning tasks. Lastly, we relate RPC with mutual information (MI) estimation, showing RPC can be used to estimate MI with low variance.",1회,"Self-supervised Representation Learning with Relative Predictive Coding
YHH Tsai, MQ Ma, M Yang, H Zhao, LP Morency… - arXiv preprint arXiv:2103.11275, 2021
1회 인용 전체 4개의 버전",,,,,,,,
Reasoning Over Virtual Knowledge Bases With Open Predicate Relations,"Haitian Sun, Pat Verga, Bhuwan Dhingra, Ruslan Salakhutdinov, William W Cohen",2021/2/14,arXiv preprint arXiv:2102.07043,,,,,"We present the Open Predicate Query Language (OPQL); a method for constructing a virtual KB (VKB) trained entirely from text. Large Knowledge Bases (KBs) are indispensable for a wide-range of industry applications such as question answering and recommendation. Typically, KBs encode world knowledge in a structured, readily accessible form derived from laborious human annotation efforts. Unfortunately, while they are extremely high precision, KBs are inevitably highly incomplete and automated methods for enriching them are far too inaccurate. Instead, OPQL constructs a VKB by encoding and indexing a set of relation mentions in a way that naturally enables reasoning and can be trained without any structured supervision. We demonstrate that OPQL outperforms prior VKB methods on two different KB reasoning tasks and, additionally, can be used as an external memory integrated into a language model (OPQL-LM) leading to improvements on two open-domain question answering tasks.",1회,"Reasoning Over Virtual Knowledge Bases With Open Predicate Relations
H Sun, P Verga, B Dhingra, R Salakhutdinov… - arXiv preprint arXiv:2102.07043, 2021
1회 인용 전체 2개의 버전",,,,,,,,
Understanding the Tradeoffs in Client-Side Privacy for Speech Recognition,"Peter Wu, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency",2021/1/22,arXiv preprint arXiv:2101.08919,,,,,"Existing approaches to ensuring privacy of user speech data primarily focus on server-side approaches. While improving server-side privacy reduces certain security concerns, users still do not retain control over whether privacy is ensured on the client-side. In this paper, we define, evaluate, and explore techniques for client-side privacy in speech recognition, where the goal is to preserve privacy on raw speech data before leaving the client's device. We first formalize several tradeoffs in ensuring client-side privacy between performance, compute requirements, and privacy. Using our tradeoff analysis, we perform a large-scale empirical study on existing approaches and find that they fall short on at least one metric. Our results call for more research in this crucial area as a step towards safer real-world deployment of speech recognition systems at scale across mobile devices.",1회,"Understanding the Tradeoffs in Client-Side Privacy for Speech Recognition
P Wu, PP Liang, R Salakhutdinov, LP Morency - arXiv preprint arXiv:2101.08919, 2021
1회 인용 관련 학술자료",,,,,,,,
Case Study: Deontological Ethics in NLP,"Shrimai Prabhumoye, Brendon Boldt, Ruslan Salakhutdinov, Alan W Black",2020/10/9,arXiv preprint arXiv:2010.04658,,,,,"Recent work in natural language processing (NLP) has focused on ethical challenges such as understanding and mitigating bias in data and algorithms; identifying objectionable content like hate speech, stereotypes and offensive language; and building frameworks for better system design and data handling practices. However, there has been little discussion about the ethical foundations that underlie these efforts. In this work, we study one ethical theory, namely deontological ethics, from the perspective of NLP. In particular, we focus on the generalization principle and the respect for autonomy through informed consent. We provide four case studies to demonstrate how these principles can be used with NLP systems. We also recommend directions to avoid the ethical issues in these systems.",1회,"Case Study: Deontological Ethics in NLP
S Prabhumoye, B Boldt, R Salakhutdinov, AW Black - arXiv preprint arXiv:2010.04658, 2020
1회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Feature Robust Optimal Transport for High-dimensional Data,"Mathis Petrovich, Chao Liang, Ryoma Sato, Yanbin Liu, Yao-Hung Hubert Tsai, Linchao Zhu, Yi Yang, Ruslan Salakhutdinov, Makoto Yamada",2020/5/25,arXiv preprint arXiv:2005.12123,,,,,"Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min--max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank--Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets.",1회,"Feature Robust Optimal Transport for High-dimensional Data
M Petrovich, C Liang, R Sato, Y Liu, YHH Tsai, L Zhu… - arXiv preprint arXiv:2005.12123, 2020
1회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Exploring Controllable Text Generation Techniques,"Shrimai Prabhumoye, Alan W Black, Ruslan Salakhutdinov",2020/5/4,arXiv preprint arXiv:2005.01822,,,,,"Neural controllable text generation is an important area gaining attention due to its plethora of applications. In this work, we provide a new schema of the pipeline of the generation process by classifying it into five modules. We present an overview of the various techniques used to modulate each of these five modules to provide with control of attributes in the generation process. We also provide an analysis on the advantages and disadvantages of these techniques and open paths to develop new architectures based on the combination of the modules described in this paper.",1회,"Exploring Controllable Text Generation Techniques
S Prabhumoye, AW Black, R Salakhutdinov - arXiv preprint arXiv:2005.01822, 2020
1회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Planning with General Objective Functions: Going Beyond Total Rewards,"Ruosong Wang, Peilin Zhong, Simon S Du, Russ R Salakhutdinov, Lin F Yang",2020/1,Annual Conference on Neural Information Processing Systems,,,,,"Standard sequential decision-making paradigms aim to maximize the cumulative reward when interacting with the unknown environment., ie, maximize Ph h= 1 rh where H is the planning horizon. However, this paradigm fails to model important practical applications, eg, safe control that aims to maximize the lowest reward, ie, maximize minH h= 1 rh. In this paper, based on techniques in sketching algorithms, we propose a novel planning algorithm in deterministic systems which deals with a large class of objective functions of the form f (r1, r2,... rH) that are of interest to practical applications. We show that efficient planning is possible if f is symmetric under permutation of coordinates and satisfies certain technical conditions. Complementing our algorithm, we further prove that removing any of the conditions will make the problem intractable in the worst case and thus demonstrate the necessity of our conditions.",1회,"Planning with General Objective Functions: Going Beyond Total Rewards
R Wang, P Zhong, SS Du, RR Salakhutdinov, LF Yang - Annual Conference on Neural Information Processing …, 2020
1회 인용 관련 학술자료",,,,,,,,
LSMI-Sinkhorn: Semi-supervised Squared-Loss Mutual Information Estimation with Optimal Transport,"Yanbin Liu, Makoto Yamada, Yao-Hung Hubert Tsai, Tam Le, Ruslan Salakhutdinov, Yi Yang",2019/9/5,arXiv preprint arXiv:1909.02373,,,,,"Estimating mutual information is an important machine learning and statistics problem. To estimate the mutual information from data, a common practice is preparing a set of paired samples. However, in some cases, it is difficult to obtain a large number of data pairs. To address this problem, we propose squared-loss mutual information (SMI) estimation using a small number of paired samples and the available unpaired ones. We first represent SMI through the density ratio function, where the expectation is approximated by the samples from marginals and its assignment parameters. The objective is formulated using the optimal transport problem and quadratic programming. Then, we introduce the least-square mutual information-Sinkhorn algorithm (LSMI-Sinkhorn) for efficient optimization. Through experiments, we first demonstrate that the proposed method can estimate the SMI without a large number of paired samples. We also evaluate and show the effectiveness of the proposed LSMI-Sinkhorn on various types of machine learning problems such as image matching and photo album summarization.",1회,"LSMI-Sinkhorn: Semi-supervised Squared-Loss Mutual Information Estimation with Optimal Transport
Y Liu, M Yamada, YHH Tsai, T Le, R Salakhutdinov… - arXiv preprint arXiv:1909.02373, 2019
1회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Integrating Domain-Knowledge into Deep Learning.,Ruslan Salakhutdinov,2019/7/25,,,,3176,,"Her plain face broke into a huge smile when she saw Terry.“Terry!” she called out. She rushed to meet him and they embraced.“Hon, I want you to meet an old friend, Owen McKenna. Owen, please meet Emily.'’She gave me a quick nod and turned back to X",1회,"Integrating Domain-Knowledge into Deep Learning.
R Salakhutdinov - KDD, 2019
1회 인용 관련 학술자료 전체 2개의 버전",KDD,,,,,,,
""" My Way of Telling a Story"": Persona based Grounded Story Generation","Shrimai Prabhumoye, Khyathi Raghavi Chandu, Ruslan Salakhutdinov, Alan W Black",2019/6/14,arXiv preprint arXiv:1906.06401,,,,,"Visual storytelling is the task of generating stories based on a sequence of images. Inspired by the recent works in neural generation focusing on controlling the form of text, this paper explores the idea of generating these stories in different personas. However, one of the main challenges of performing this task is the lack of a dataset of visual stories in different personas. Having said that, there are independent datasets for both visual storytelling and annotated sentences for various persona. In this paper we describe an approach to overcome this by getting labelled persona data from a different task and leveraging those annotations to perform persona based story generation. We inspect various ways of incorporating personality in both the encoder and the decoder representations to steer the generation in the target direction. To this end, we propose five models which are incremental extensions to the baseline model to perform the task at hand. In our experiments we use five different personas to guide the generation process. We find that the models based on our hypotheses perform better at capturing words while generating stories in the target persona.",1회,""" My Way of Telling a Story"": Persona based Grounded Story Generation
S Prabhumoye, KR Chandu, R Salakhutdinov… - arXiv preprint arXiv:1906.06401, 2019
1회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Modular Visual Navigation Using Active Neural Mapping,"Devendra Singh Chaplot, Saurabh Gupta, Abhinav Gupta, Ruslan Salakhutdinov",2019,,,,,,"Learning-based navigation algorithms exploit the semantic structure of the world and are effective at handling sensor noise and noisy maps. However, they are sample inefficient, do not transfer across domains, and fail at long-term planning. On the other hand, classical algorithms are effective at long-term planning and need little to no training data but do not exploit the semantic structure and fail with noisy maps/observations. In this work, we present a modular and hierarchical navigation algorithm which leverages the strengths of both classical and learningbased methods. Our model consists of long-term+ short-term goal generators and long-term+ short-term planners. We use learning to generate long-term goals and a deterministic planner to solve for long-term paths. Short-term goals are generated based on the planned paths but the short-term planner is learned, making it robust to sensor noise. Our modular approach provides efficient, exhaustive exploration; accurate long-term planning; and transferability across domains and tasks. We perform experiments on the Gibson and Matterport real-world reconstruction datasets in the Habitat simulator. We show that the proposed model outperforms prior methods on both exploration (43% relative improvement in coverage) and PointGoal navigation (21% absolute improvement in success rate), while also improving sample efficiency. 2",1회,"Modular Visual Navigation Using Active Neural Mapping
DS Chaplot, S Gupta, A Gupta, R Salakhutdinov - 2019
1회 인용 관련 학술자료",,,,,,,,
Reinforcement learning with unknown reward functions,"Benjamin Eysenbach, Jacob Tyo, Shane Gu, G Brain, R Salakhutdinov, Z Lipton, S Levine",2019,,,,,,"In practical reinforcement learning (RL) scenarios, algorithm designers might express uncertainty over which reward function best captures real-world desiderata. However, academic papers typically treat the reward function as either (i) exactly known, leading to the standard reinforcement learning problem, or (ii) unknown, motivating a body of work on intrinsically-motivated exploration, where agents learn the dynamics of their environment and visit diverse states, often as a pretraining step to task-specific learning. We propose a framework for reinforcement learning given a distribution over possible reward functions. Our contributions include derivations of the Bayes-optimal and minimax policies in this setting as well as efficient algorithms for approximating these policies.",1회,"Reinforcement learning with unknown reward functions
B Eysenbach, J Tyo, S Gu, G Brain, R Salakhutdinov… - Task-Agnostic Reinforcement Learning Workshop at …, 2019
1회 인용 관련 학술자료",Task-Agnostic Reinforcement Learning Workshop at ICLR 2019,,,,,,,
Learning from the experience of others: approximate empirical Bayes in neural networks,"Han Zhao, Yao-Hung Hubert Tsai, Ruslan Salakhutdinov, Geoff Gordon",2018/9/27,,,,,,"Learning deep neural networks could be understood as the combination of representation learning and learning halfspaces. While most previous work aims to diversify representation learning by data augmentations and regularizations, we explore the opposite direction through the lens of empirical Bayes method. Specifically, we propose a matrix-variate normal prior whose covariance matrix has a Kronecker product structure to capture the correlations in learning different neurons through backpropagation. The prior encourages neurons to learn from the experience of others, hence it provides an effective regularization when training large networks on small datasets. To optimize the model, we design an efficient block coordinate descent algorithm with analytic solutions. Empirically, we show that the proposed method helps the network converge to better local optima that also generalize better, and we verify the effectiveness of the approach on both multiclass classification and multitask regression problems with various network structures.",1회,"Learning from the experience of others: approximate empirical Bayes in neural networks
H Zhao, YHH Tsai, R Salakhutdinov, G Gordon - 2018
1회 인용 관련 학술자료",,,,,,,,
""" Dependency Bottleneck"" in Auto-encoding Architectures: an Empirical Study","Denny Wu, Yixiu Zhao, Yao-Hung Hubert Tsai, Makoto Yamada, Ruslan Salakhutdinov",2018/2/15,arXiv preprint arXiv:1802.05408,,,,,"Recent works investigated the generalization properties in deep neural networks (DNNs) by studying the Information Bottleneck in DNNs. However, the mea-surement of the mutual information (MI) is often inaccurate due to the density estimation. To address this issue, we propose to measure the dependency instead of MI between layers in DNNs. Specifically, we propose to use Hilbert-Schmidt Independence Criterion (HSIC) as the dependency measure, which can measure the dependence of two random variables without estimating probability densities. Moreover, HSIC is a special case of the Squared-loss Mutual Information (SMI). In the experiment, we empirically evaluate the generalization property using HSIC in both the reconstruction and prediction auto-encoding (AE) architectures.",1회,""" Dependency Bottleneck"" in Auto-encoding Architectures: an Empirical Study
D Wu, Y Zhao, YHH Tsai, M Yamada, R Salakhutdinov - arXiv preprint arXiv:1802.05408, 2018
1회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Selecting the Best in GANs Family: a Post Selection Inference Framework,"Yao-Hung Hubert Tsai, Makoto Yamada, Denny Wu, Ruslan Salakhutdinov, Ichiro Takeuchi, Kenji Fukumizu",2018/2/15,arXiv preprint arXiv:1802.05411,,,,,""" Which Generative Adversarial Networks (GANs) generates the most plausible images?"" has been a frequently asked question among researchers. To address this problem, we first propose an\emph {incomplete} U-statistics estimate of maximum mean discrepancy to measure the distribution discrepancy between generated and real images. enjoys the advantages of asymptotic normality, computation efficiency, and model agnosticity. We then propose a GANs analysis framework to select and test the"" best"" member in GANs family using the Post Selection Inference (PSI) with . In the experiments, we adopt the proposed framework on 7 GANs variants and compare their scores.",1회,"Selecting the Best in GANs Family: a Post Selection Inference Framework
YHH Tsai, M Yamada, D Wu, R Salakhutdinov… - arXiv preprint arXiv:1802.05411, 2018
1회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Learning Deep Generative Models With Discrete Latent Variables,"Hengyuan Hu, Ruslan Salakhutdinov",2018/2/15,,,,,,"There have been numerous recent advancements on learning deep generative models with latent variables thanks to the reparameterization trick that allows to train deep directed models effectively. However, since reparameterization trick only works on continuous variables, deep generative models with discrete latent variables still remain hard to train and perform considerably worse than their continuous counterparts. In this paper, we attempt to shrink this gap by introducing a new architecture and its learning procedure. We develop a hybrid generative model with binary latent variables that consists of an undirected graphical model and a deep neural network. We propose an efficient two-stage pretraining and training procedure that is crucial for learning these models. Experiments on binarized digits and images of natural scenes demonstrate that our model achieves close to the state-of-the-art performance in terms of density estimation and is capable of generating coherent images of natural scenes.",1회,"Learning Deep Generative Models With Discrete Latent Variables
H Hu, R Salakhutdinov - 2018
1회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
GAN Connoisseur: Can GANs Learn Simple 1D Parametric Distributions?,"Manzil Zaheer, Chun-Liang Li, Barnabás Póczos, Ruslan Salakhutdinov",2018,,,,,,"Generative Adversarial Network (GAN) has been shown to possess the capability to learn distributions of data, given infinite capacity of models [1, 2]. Empirically, approximations with deep neural networks seem to have “sufficiently large” capacity and lead to several success in many applications, such as image generation. However, most of the results are difficult to evaluate because of the curse of dimensionality and the unknown distribution of the data. To evaluate GANs, in this paper, we consider simple one-dimensional data coming from parametric distributions circumventing the aforementioned problems. We formulate rigorous techniques for evaluation under this setting. Based on this evaluation, we find that many state-ofthe-art GANs are very difficult to train to learn the true distribution and can usually only find some of the modes. If the GAN has learned, such as MMD GAN, we observe it has some generalization capabilities.",1회,"GAN Connoisseur: Can GANs Learn Simple 1D Parametric Distributions?
M Zaheer, CL Li, B Póczos, R Salakhutdinov - 2018
1회 인용 관련 학술자료",,,,,,,,
Spatially adaptive computation time for residual networks,"Dmitry P Vetrov, Jonathan Huang, Li Zhang, Maxwell Collins, Michael Figurnov, Ruslan Salakhutdinov, Yukun Zhu",2017,,,,,,"This paper proposes a deep learning architecture based on Residual Network that dynamically adjusts the number of executed layers for the regions of the image. This architecture is end-to-end trainable, deterministic and problem-agnostic. It is therefore applicable without any modifications to a wide range of computer vision problems such as image classification, object detection and image segmentation. We present experimental results showing that this model improves the computational efficiency of ResNet on the challenging ImageNet classification and COCO object detection datasets. Additionally, we evaluate the computation time maps on the image saliency dataset cat2000 and find that they correlate surprisingly well with human eye fixation positions.",1회,"Spatially adaptive computation time for residual networks
DP Vetrov, J Huang, L Zhang, M Collins, M Figurnov… - 2017
1회 인용 관련 학술자료",,,,,,,,
End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,"Haitian Sun, William W Cohen, Ruslan Salakhutdinov",2021/6/1,arXiv preprint arXiv:2106.00200,,,,,"Answering complex questions from long documents requires aggregating multiple pieces of evidence and then predicting the answers. In this paper, we propose a multi-hop retrieval method, DocHopper, to answer compositional questions over long documents. At each step, DocHopper retrieves a paragraph or sentence embedding from the document, mixes the retrieved result with the query, and updates the query for the next step. In contrast to many other retrieval-based methods (e.g., RAG or REALM) the query is not augmented with a token sequence: instead, it is augmented by ""numerically"" combining it with another neural representation. This means that model is end-to-end differentiable. We demonstrate that utilizing document structure in this was can largely improve question-answering and retrieval performance on long documents. We experimented with DocHopper on three different QA tasks that require reading long documents to answer compositional questions: discourse entailment reasoning, factual QA with table and text, and information seeking QA from academic papers. DocHopper outperforms all baseline models and achieves state-of-the-art results on all datasets. Additionally, DocHopper is efficient at inference time, being 3~10 times faster than the baselines.",,"End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents
H Sun, WW Cohen, R Salakhutdinov - arXiv preprint arXiv:2106.00200, 2021
전체 2개의 버전",,,,,,,,
Proceedings of the Third Workshop on Multimodal Artificial Intelligence,"Amir Zadeh, Louis-Philippe Morency, Paul Pu Liang, Candace Ross, Ruslan Salakhutdinov, Soujanya Poria, Erik Cambria, Kelly Shi",2021/6,,,,,,"The NAACL 2021 Workshop on Multimodal Artificial Intelligence (MAI-Workshop) offers a unique opportunity for interdisciplinary researchers to study and model interactions between (but not limited to) modalities of language, vision, and acoustic. Advances in multimodal learning allows the field of NLP to take the leap towards better generalization to real-world (as opposed to limitation to textual applications), and better downstream performance in Conversational AI, Virtual Reality, Robotics, HCI, Healthcare, and Education. We invite researchers from NLP, Computer Vision, Speech Processing, Robotics, HCI, and Affective Computing to submit their papers.",,"Proceedings of the Third Workshop on Multimodal Artificial Intelligence
A Zadeh, LP Morency, PP Liang, C Ross… - Proceedings of the Third Workshop on Multimodal …, 2021",Proceedings of the Third Workshop on Multimodal Artificial Intelligence,,,,,,,
Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning,"Yue Wu, Shuangfei Zhai, Nitish Srivastava, Joshua Susskind, Jian Zhang, Ruslan Salakhutdinov, Hanlin Goh",2021/5/17,arXiv preprint arXiv:2105.08140,,,,,"Offline Reinforcement Learning promises to learn effective policies from previously-collected, static datasets without the need for exploration. However, existing Q-learning and actor-critic based off-policy RL algorithms fail when bootstrapping from out-of-distribution (OOD) actions or states. We hypothesize that a key missing ingredient from the existing methods is a proper treatment of uncertainty in the offline setting. We propose Uncertainty Weighted Actor-Critic (UWAC), an algorithm that detects OOD state-action pairs and down-weights their contribution in the training objectives accordingly. Implementation-wise, we adopt a practical and effective dropout-based uncertainty estimation method that introduces very little overhead over existing RL algorithms. Empirically, we observe that UWAC substantially improves model stability during training. In addition, UWAC out-performs existing offline RL methods on a variety of competitive tasks, and achieves significant performance gains over the state-of-the-art baseline on datasets with sparse demonstrations collected from human experts.",,"Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning
Y Wu, S Zhai, N Srivastava, J Susskind, J Zhang… - arXiv preprint arXiv:2105.08140, 2021
전체 2개의 버전",,,,,,,,
Focused Attention Improves Document-Grounded Generation,"Shrimai Prabhumoye, Kazuma Hashimoto, Yingbo Zhou, Alan W Black, Ruslan Salakhutdinov",2021/4/26,arXiv preprint arXiv:2104.12714,,,,,"Document grounded generation is the task of using the information provided in a document to improve text generation. This work focuses on two different document grounded generation tasks: Wikipedia Update Generation task and Dialogue response generation. Our work introduces two novel adaptations of large scale pre-trained encoder-decoder models focusing on building context driven representation of the document and enabling specific attention to the information in the document. Additionally, we provide a stronger BART baseline for these tasks. Our proposed techniques outperform existing methods on both automated (at least 48% increase in BLEU-4 points) and human evaluation for closeness to reference and relevance to the document. Furthermore, we perform comprehensive manual inspection of the generated output and categorize errors to provide insights into future directions in modeling these tasks.",,"Focused Attention Improves Document-Grounded Generation
S Prabhumoye, K Hashimoto, Y Zhou, AW Black… - arXiv preprint arXiv:2104.12714, 2021
전체 4개의 버전",,,,,,,,
StylePTB: A Compositional Benchmark for Fine-grained Controllable Text Style Transfer,"Yiwei Lyu, Paul Pu Liang, Hai Pham, Eduard Hovy, Barnabás Póczos, Ruslan Salakhutdinov, Louis-Philippe Morency",2021/4/12,arXiv preprint arXiv:2104.05196,,,,,"Text style transfer aims to controllably generate text with targeted stylistic changes while maintaining core meaning from the source sentence constant. Many of the existing style transfer benchmarks primarily focus on individual high-level semantic changes (e.g. positive to negative), which enable controllability at a high level but do not offer fine-grained control involving sentence structure, emphasis, and content of the sentence. In this paper, we introduce a large-scale benchmark, StylePTB, with (1) paired sentences undergoing 21 fine-grained stylistic changes spanning atomic lexical, syntactic, semantic, and thematic transfers of text, as well as (2) compositions of multiple transfers which allow modeling of fine-grained stylistic changes as building blocks for more complex, high-level transfers. By benchmarking existing methods on StylePTB, we find that they struggle to model fine-grained changes and have an even more difficult time composing multiple styles. As a result, StylePTB brings novel challenges that we hope will encourage future research in controllable text style transfer, compositional models, and learning disentangled representations. Solving these challenges would present important steps towards controllable text generation.",,"StylePTB: A Compositional Benchmark for Fine-grained Controllable Text Style Transfer
Y Lyu, PP Liang, H Pham, E Hovy, B Póczos… - arXiv preprint arXiv:2104.05196, 2021
전체 3개의 버전",,,,,,,,
Encoding Three-Dimensional Data For Processing By Capsule Neural Networks,,2021/3/25,,,,,,"A method includes defining a geometric capsule that is interpretable by a capsule neural network, wherein the geometric capsule includes a feature representation and a pose. The method also includes determining multiple viewpoints relative to the geometric capsule and determining a first appearance representation of the geometric capsule for each of the multiple viewpoints. The method also includes determining a transform for each of the multiple viewpoints that moves each of the multiple viewpoints to a respective transformed viewpoint and determining second appearance representations that each correspond to one of the transformed viewpoints. The method also includes combining the second appearance representations to define an agreed appearance representation. The method also includes updating the feature representation for the geometric capsule based on the agreed appearance representation.",,"Encoding Three-Dimensional Data For Processing By Capsule Neural Networks
N Srivastava, R Salakhutdinov, H Goh - US Patent App. 16/836,028, 2021
전체 2개의 버전",,,,,"Nitish Srivastava, Ruslan Salakhutdinov, Hanlin Goh",US,16836028,
Instabilities of Offline RL with Pre-Trained Neural Representation,"Ruosong Wang, Yifan Wu, Ruslan Salakhutdinov, Sham M Kakade",2021/3/8,arXiv preprint arXiv:2103.04947,,,,,"In offline reinforcement learning (RL), we seek to utilize offline data to evaluate (or learn) policies in scenarios where the data are collected from a distribution that substantially differs from that of the target policy to be evaluated. Recent theoretical advances have shown that such sample-efficient offline RL is indeed possible provided certain strong representational conditions hold, else there are lower bounds exhibiting exponential error amplification (in the problem horizon) unless the data collection distribution has only a mild distribution shift relative to the target policy. This work studies these issues from an empirical perspective to gauge how stable offline RL methods are. In particular, our methodology explores these ideas when using features from pre-trained neural networks, in the hope that these representations are powerful enough to permit sample efficient offline RL. Through extensive experiments on a range of tasks, we see that substantial error amplification does occur even when using such pre-trained representations (trained on the same task itself); we find offline RL is stable only under extremely mild distribution shift. The implications of these results, both from a theoretical and an empirical perspective, are that successful offline RL (where we seek to go beyond the low distribution shift regime) requires substantially stronger conditions beyond those which suffice for successful supervised learning.",,"Instabilities of Offline RL with Pre-Trained Neural Representation
R Wang, Y Wu, R Salakhutdinov, SM Kakade - arXiv preprint arXiv:2103.04947, 2021
전체 4개의 버전",,,,,,,,
On Proximal Policy Optimization's Heavy-tailed Gradients,"Saurabh Garg, Joshua Zhanson, Emilio Parisotto, Adarsh Prasad, J Zico Kolter, Sivaraman Balakrishnan, Zachary C Lipton, Ruslan Salakhutdinov, Pradeep Ravikumar",2021/2/20,arXiv preprint arXiv:2102.10264,,,,,"Modern policy gradient algorithms, notably Proximal Policy Optimization (PPO), rely on an arsenal of heuristics, including loss clipping and gradient clipping, to ensure successful learning. These heuristics are reminiscent of techniques from robust statistics, commonly used for estimation in outlier-rich (""heavy-tailed"") regimes. In this paper, we present a detailed empirical study to characterize the heavy-tailed nature of the gradients of the PPO surrogate reward function. We demonstrate that the gradients, especially for the actor network, exhibit pronounced heavy-tailedness and that it increases as the agent's policy diverges from the behavioral policy (i.e., as the agent goes further off policy). Further examination implicates the likelihood ratios and advantages in the surrogate reward as the main sources of the observed heavy-tailedness. We then highlight issues arising due to the heavy-tailed nature of the gradients. In this light, we study the effects of the standard PPO clipping heuristics, demonstrating that these tricks primarily serve to offset heavy-tailedness in gradients. Thus motivated, we propose incorporating GMOM, a high-dimensional robust estimator, into PPO as a substitute for three clipping tricks. Despite requiring less hyperparameter tuning, our method matches the performance of PPO (with all heuristics enabled) on a battery of MuJoCo continuous control tasks.",,"On Proximal Policy Optimization's Heavy-tailed Gradients
S Garg, J Zhanson, E Parisotto, A Prasad, JZ Kolter… - arXiv preprint arXiv:2102.10264, 2021
전체 3개의 버전",,,,,,,,
Cross-Modal Generalization: Learning in Low Resource Modalities via Meta-Alignment,"Paul Pu Liang, Peter Wu, Liu Ziyin, Louis-Philippe Morency, Ruslan Salakhutdinov",2020/12/4,arXiv preprint arXiv:2012.02813,,,,,"The natural world is abundant with concepts expressed via visual, acoustic, tactile, and linguistic modalities. Much of the existing progress in multimodal learning, however, focuses primarily on problems where the same set of modalities are present at train and test time, which makes learning in low-resource modalities particularly difficult. In this work, we propose algorithms for cross-modal generalization: a learning paradigm to train a model that can (1) quickly perform new tasks in a target modality (ie meta-learning) and (2) doing so while being trained on a different source modality. We study a key research question: how can we ensure generalization across modalities despite using separate encoders for different source and target modalities? Our solution is based on meta-alignment, a novel method to align representation spaces using strongly and weakly paired cross-modal data while ensuring quick generalization to new tasks across different modalities. We study this problem on 3 classification tasks: text to image, image to audio, and text to speech. Our results demonstrate strong performance even when the new target modality has only a few (1-10) labeled samples and in the presence of noisy labels, a scenario particularly prevalent in low-resource modalities.",,"Cross-Modal Generalization: Learning in Low Resource Modalities via Meta-Alignment
PP Liang, P Wu, L Ziyin, LP Morency, R Salakhutdinov - arXiv preprint arXiv:2012.02813, 2020
관련 학술자료 전체 2개의 버전",,,,,,,,
Method and device for improved localization and mapping,,2020/11/26,,,,,,"In accordance with some embodiments, a method is performed at a device with one or more processors and non-transitory memory. The method includes obtaining location vector data characterizing an object. The method includes determining a neural pose graph associated with a respective time-period based on an initial local pose estimation as a function of respective location vector data. The method includes determining a meta pose estimation associated with the respective time-period by aggregating the neural pose graph associated with the respective time-period and one or more other neural pose graphs associated with one or more temporally adjacent time-periods. The method includes synthesizing a corrected pose estimation by correcting the meta pose estimation associated with the respective time-period based on a function of the meta pose estimation associated with the respective time-period and …",,"Method and device for improved localization and mapping
E Parisotto, J Zhang, R Salakhutdinov, DS Chaplot - US Patent App. 16/990,510, 2020
전체 2개의 버전",,,,,"Emilio Parisotto, Jian Zhang, Ruslan Salakhutdinov, Devendra Singh Chaplot",US,16990510,
Close Category Generalization,"Yao-Yuan Yang, Cyrus Rashtchian, Ruslan Salakhutdinov, Kamalika Chaudhuri",2020/11/17,arXiv preprint arXiv:2011.08485,,,,,"Out-of-distribution generalization is a core challenge in machine learning. We introduce and propose a solution to a new type of out-of-distribution evaluation, which we call close category generalization. This task specifies how a classifier should extrapolate to unseen classes by considering a bi-criteria objective:(i) on in-distribution examples, output the correct label, and (ii) on out-of-distribution examples, output the label of the nearest neighbor in the training set. In addition to formalizing this problem, we present a new training algorithm to improve the close category generalization of neural networks. We compare to many baselines, including robust algorithms and out-of-distribution detection methods, and we show that our method has better or comparable close category generalization. Then, we investigate a related representation learning task, and we find that performing well on close category generalization correlates with learning a good representation of an unseen class and with finding a good initialization for few-shot learning. Code available at this https URL",,"Close Category Generalization
YY Yang, C Rashtchian, R Salakhutdinov, K Chaudhuri - arXiv preprint arXiv:2011.08485, 2020
관련 학술자료 전체 3개의 버전",,,,,,,,
Unsupervised Domain Adaptation for Visual Navigation,"Shangda Li, Devendra Singh Chaplot, Yao-Hung Hubert Tsai, Yue Wu, Louis-Philippe Morency, Ruslan Salakhutdinov",2020/10/27,arXiv preprint arXiv:2010.14543,,,,,"Advances in visual navigation methods have led to intelligent embodied navigation agents capable of learning meaningful representations from raw RGB images and perform a wide variety of tasks involving structural and semantic reasoning. However, most learning-based navigation policies are trained and tested in simulation environments. In order for these policies to be practically useful, they need to be transferred to the real-world. In this paper, we propose an unsupervised domain adaptation method for visual navigation. Our method translates the images in the target domain to the source domain such that the translation is consistent with the representations learned by the navigation policy. The proposed method outperforms several baselines across two different navigation tasks in simulation. We further show that our method can be used to transfer the navigation policies learned in simulation to the real world.",,"Unsupervised Domain Adaptation for Visual Navigation
S Li, DS Chaplot, YHH Tsai, Y Wu, LP Morency… - arXiv preprint arXiv:2010.14543, 2020
관련 학술자료 전체 4개의 버전",,,,,,,,
Planning with Submodular Objective Functions,"Ruosong Wang, Hanrui Zhang, Devendra Singh Chaplot, Denis Garagić, Ruslan Salakhutdinov",2020/10/22,arXiv preprint arXiv:2010.11863,,,,,"We study planning with submodular objective functions, where instead of maximizing the cumulative reward, the goal is to maximize the objective value induced by a submodular function. Our framework subsumes standard planning and submodular maximization with cardinality constraints as special cases, and thus many practical applications can be naturally formulated within our framework. Based on the notion of multilinear extension, we propose a novel and theoretically principled algorithmic framework for planning with submodular objective functions, which recovers classical algorithms when applied to the two special cases mentioned above. Empirically, our approach significantly outperforms baseline algorithms on synthetic environments and navigation tasks.",,"Planning with Submodular Objective Functions
R Wang, H Zhang, DS Chaplot, D Garagić… - arXiv preprint arXiv:2010.11863, 2020
관련 학술자료 전체 2개의 버전",,,,,,,,
Learning in Low-resource Modalities via Cross-modal Generalization,"Paul Pu Liang, Peter Wu, Liu Ziyin, Louis-Philippe Morency, Ruslan Salakhutdinov",2020/10/9,,,,,,"The natural world is abundant with underlying concepts expressed naturally in multiple heterogeneous sources such as the visual, acoustic, tactile, and linguistic modalities. Despite vast differences in these raw modalities, humans seamlessly perceive multimodal data, learn new concepts, and show extraordinary capabilities in generalizing across input modalities. Much of the existing progress in multimodal learning, however, focuses primarily on problems where the same set of modalities are present at train and test time, which makes learning in low-resource modalities particularly difficult. In this work, we propose a general algorithm for cross-modal generalization: a learning paradigm where data from more abundant source modalities is used to learn useful representations for scarce target modalities. Our algorithm is based on meta-alignment, a novel method to align representation spaces across modalities while ensuring quick generalization to new concepts across different modalities. Experimental results on generalizing from image to audio classification and from text to speech classification demonstrate strong performance on classifying data from an entirely new target modality with only a few (1-10) labeled samples. In addition, our method works particularly well when the target modality suffers from noisy or limited labels, a scenario particularly prevalent in low-resource modalities.",,"Learning in Low-resource Modalities via Cross-modal Generalization
PP Liang, P Wu, L Ziyin, LP Morency, R Salakhutdinov - 2020
관련 학술자료 전체 2개의 버전",,,,,,,,
Method and device for improved localization and mapping,,2020/9/15,,,,,,"In accordance with some embodiments, a method is performed at a device with one or more processors and non-transitory memory. The method includes obtaining location vector data characterizing an object. The method includes determining a neural pose graph associated with a respective time-period based on an initial local pose estimation as a function of respective location vector data. The method includes determining a meta pose estimation associated with the respective time-period by aggregating the neural pose graph associated with the respective time-period and one or more other neural pose graphs associated with one or more temporally adjacent time-periods. The method includes synthesizing a corrected pose estimation by correcting the meta pose estimation associated with the respective time-period based on a function of the meta pose estimation associated with the respective time-period and …",,"Method and device for improved localization and mapping
E Parisotto, J Zhang, R Salakhutdinov, DS Chaplot - US Patent 10,776,948, 2020
관련 학술자료 전체 2개의 버전",,,,,"Emilio Parisotto, Jian Zhang, Ruslan Salakhutdinov, Devendra Singh Chaplot",US,16113647,10776948
Revisiting LSTM Networks for Semi-Supervised Text Classification via Mixed Objective Function,"Devendra Singh Sachan, Manzil Zaheer, Ruslan Salakhutdinov",2020/9,arXiv e-prints,,,arXiv: 2009.04007,,"In this paper, we study bidirectional LSTM network for the task of text classification using both supervised and semi-supervised approaches. Several prior works have suggested that either complex pretraining schemes using unsupervised methods such as language modeling (Dai and Le 2015; Miyato, Dai, and Goodfellow 2016) or complicated models (Johnson and Zhang 2017) are necessary to achieve a high classification accuracy. However, we develop a training strategy that allows even a simple BiLSTM model, when trained with cross-entropy loss, to achieve competitive results compared with more complex approaches. Furthermore, in addition to cross-entropy loss, by using a combination of entropy minimization, adversarial, and virtual adversarial losses for both labeled and unlabeled data, we report state-of-the-art results for text classification task on several benchmark datasets. In particular, on the ACL …",,"Revisiting LSTM Networks for Semi-Supervised Text Classification via Mixed Objective Function
D Singh Sachan, M Zaheer, R Salakhutdinov - arXiv e-prints, 2020",,,,,,,,
Few-Shot Learning with Intra-Class Knowledge Transfer,"Vivek Roy, Yan Xu, Yu-Xiong Wang, Kris Kitani, Ruslan Salakhutdinov, Martial Hebert",2020/8/22,arXiv preprint arXiv:2008.09892,,,,,"We consider the few-shot classification task with an unbalanced dataset, in which some classes have sufficient training samples while other classes only have limited training samples. Recent works have proposed to solve this task by augmenting the training data of the few-shot classes using generative models with the few-shot training samples as the seeds. However, due to the limited number of the few-shot seeds, the generated samples usually have small diversity, making it difficult to train a discriminative classifier for the few-shot classes. To enrich the diversity of the generated samples, we propose to leverage the intra-class knowledge from the neighbor many-shot classes with the intuition that neighbor classes share similar statistical information. Such intra-class information is obtained with a two-step mechanism. First, a regressor trained only on the many-shot classes is used to evaluate the few-shot class means from only a few samples. Second, superclasses are clustered, and the statistical mean and feature variance of each superclass are used as transferable knowledge inherited by the children few-shot classes. Such knowledge is then used by a generator to augment the sparse training data to help the downstream classification tasks. Extensive experiments show that our method achieves state-of-the-art across different datasets and -shot settings.",,"Few-Shot Learning with Intra-Class Knowledge Transfer
V Roy, Y Xu, YX Wang, K Kitani, R Salakhutdinov… - arXiv preprint arXiv:2008.09892, 2020
관련 학술자료 전체 2개의 버전",,,,,,,,
Object Goal Navigation using Goal-Oriented Semantic Exploration,"Devendra Singh Chaplot, Dhiraj Gandhi, Abhinav Gupta, Ruslan Salakhutdinov",2020/7,arXiv e-prints,,,arXiv: 2007.00643,,"This work studies the problem of object goal navigation which involves navigating to an instance of the given object category in unseen environments. End-to-end learning-based navigation methods struggle at this task as they are ineffective at exploration and long-term planning. We propose a modular system called,Goal-Oriented Semantic Exploration'which builds an episodic semantic map and uses it to explore the environment efficiently based on the goal object category. Empirical results in visually realistic simulation environments show that the proposed model outperforms a wide range of baselines including end-to-end learning-based methods as well as modular map-based methods and led to the winning entry of the CVPR-2020 Habitat ObjectNav Challenge. Ablation analysis indicates that the proposed model learns semantic priors of the relative arrangement of objects in a scene, and uses them to …",,"Object Goal Navigation using Goal-Oriented Semantic Exploration
D Singh Chaplot, D Gandhi, A Gupta, R Salakhutdinov - arXiv e-prints, 2020",,,,,,,,
Off-Dynamics Reinforcement Learning: Training for Transfer with Domain Classifiers,"Benjamin Eysenbach, Swapnil Asawa, Shreyas Chaudhari, Sergey Levine, Ruslan Salakhutdinov",2020/6/24,arXiv preprint arXiv:2006.13916,,,,,"We propose a simple, practical, and intuitive approach for domain adaptation in reinforcement learning. Our approach stems from the idea that the agent's experience in the source domain should look similar to its experience in the target domain. Building off of a probabilistic view of RL, we formally show that we can achieve this goal by compensating for the difference in dynamics by modifying the reward function. This modified reward function is simple to estimate by learning auxiliary classifiers that distinguish source-domain transitions from target-domain transitions. Intuitively, the modified reward function penalizes the agent for visiting states and taking actions in the source domain which are not possible in the target domain. Said another way, the agent is penalized for transitions that would indicate that the agent is interacting with the source domain, rather than the target domain. Our approach is applicable to domains with continuous states and actions and does not require learning an explicit model of the dynamics. On discrete and continuous control tasks, we illustrate the mechanics of our approach and demonstrate its scalability to high-dimensional tasks.",,"Off-Dynamics Reinforcement Learning: Training for Transfer with Domain Classifiers
B Eysenbach, S Asawa, S Chaudhari, S Levine… - arXiv preprint arXiv:2006.13916, 2020
관련 학술자료 전체 4개의 버전",,,,,,,,
Neural Topological SLAM for Visual Navigation,"Devendra Singh Chaplot, Ruslan Salakhutdinov, Abhinav Gupta, Saurabh Gupta",2020/5,arXiv e-prints,,,arXiv: 2005.12256,,"This paper studies the problem of image-goal navigation which involves navigating to the location indicated by a goal image in a novel previously unseen environment. To tackle this problem, we design topological representations for space that effectively leverage semantics and afford approximate geometric reasoning. At the heart of our representations are nodes with associated semantic features, that are interconnected using coarse geometric information. We describe supervised learning-based algorithms that can build, maintain and use such representations under noisy actuation. Experimental study in visually and physically realistic simulation suggests that our method builds effective representations that capture structural regularities and efficiently solve long-horizon navigation problems. We observe a relative improvement of more than 50% over existing methods that study this task.",,"Neural Topological SLAM for Visual Navigation
D Singh Chaplot, R Salakhutdinov, A Gupta, S Gupta - arXiv e-prints, 2020",,,,,,,,
Learning to Explore using Active Neural SLAM,"Devendra Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta, Ruslan Salakhutdinov",2020/4,arXiv e-prints,,,arXiv: 2004.05155,,"This work presents a modular and hierarchical approach to learn policies for exploring 3D environments, calledActive Neural SLAM'. Our approach leverages the strengths of both classical and learning-based methods, by using analytical path planners with learned SLAM module, and global and local policies. The use of learning provides flexibility with respect to input modalities (in the SLAM module), leverages structural regularities of the world (in global policies), and provides robustness to errors in state estimation (in local policies). Such use of learning within each module retains its benefits, while at the same time, hierarchical decomposition and modular training allow us to sidestep the high sample complexities associated with training end-to-end policies. Our experiments in visually and physically realistic simulated 3D environments demonstrate the effectiveness of our approach over past learning and …",,"Learning to Explore using Active Neural SLAM
D Singh Chaplot, D Gandhi, S Gupta, A Gupta… - arXiv e-prints, 2020",,,,,,,,
DIFFERENTIABLE MULTI-HOP REASONING OVER A VIRTUAL KNOWLEDGE BASE,"Bhuwan Dhingra, Graham Neubig, Manzil Zaheer, Ruslan Salakhutdinov, Vidhisha Balachandran, William Weston Cohen",2020,,,,,,"We wish to put forward an approach for accessing text as a knowledge base which is useful for question-answering (QA). This approach relies centrally on development of a differentiable operator which allows us to traverse textual data like a``virtual''KB. The core of the approach is a neural module that inputs and outputs sets of entities: in particular, this module uses maximum inner product search (MIPS) on a special index to map a set of entities to all entities related to something in (by some specified relations), as witnessed by some text in the corpus. For multi-hop questions, the set of output entities can be again used recursively as the input to a second copy of the module, enabling us to answer complex questions. This module is differentiable, so the full system can be trained completely end-to-end using gradient based methods. Thus, we name it DrKIT: Differentiable Reasoning over a virtual Knowledge …",,"DIFFERENTIABLE MULTI-HOP REASONING OVER A VIRTUAL KNOWLEDGE BASE
B Dhingra, G Neubig, M Zaheer, R Salakhutdinov… - 2020",,,,,,,,
Progressive Knowledge Distillation For Generative Modeling,"Yu-Xiong Wang, Adrien Bardes, Ruslan Salakhutdinov, Martial Hebert",2019/9/25,,,,,,"While modern generative models are able to synthesize high-fidelity, visually appealing images, successfully generating examples that are useful for recognition tasks remains an elusive goal. To this end, our key insight is that the examples should be synthesized to recover classifier decision boundaries that would be learned from a large amount of real examples. More concretely, we treat a classifier trained on synthetic examples as''student''and a classifier trained on real examples as''teacher''. By introducing knowledge distillation into a meta-learning framework, we encourage the generative model to produce examples in a way that enables the student classifier to mimic the behavior of the teacher. To mitigate the potential gap between student and teacher classifiers, we further propose to distill the knowledge in a progressive manner, either by gradually strengthening the teacher or weakening the student. We demonstrate the use of our model-agnostic distillation approach to deal with data scarcity, significantly improving few-shot learning performance on miniImageNet and ImageNet1K benchmarks.",,"Progressive Knowledge Distillation For Generative Modeling
YX Wang, A Bardes, R Salakhutdinov, M Hebert - 2019
관련 학술자료",,,,,,,,
Learning Data Manipulation for Augmentation and Weighting,"Bowen Tan, Ruslan Salakhutdinov, Tom Mitchell, Eric Xing",2019/9/6,,,,,,"Manipulating data, such as weighting data examples or augmenting with new instances, has been increasingly used to improve model training. Previous work has studied various rule-or learning-based approaches designed for specific types of data manipulation. In this work, we propose a new method that supports learning different manipulation schemes with the same algorithm. Our approach builds upon a recent connection of supervised learning and reinforcement learning, and adapts an off-the-shelf reward learning algorithm for joint data manipulation learning and model training. Different parameterization of the``reward''function instantiates different manipulation schemes. We showcase data augmentation that learns a text transformation network, and data weighting that dynamically adapts the data sample importance. Experiments show the resulting algorithms significantly improve the image and text classification performance in low data regime and class-imbalance problems.",,"Learning Data Manipulation for Augmentation and Weighting
B Tan, R Salakhutdinov, T Mitchell, E Xing - 2019
관련 학술자료",,,,,,,,
Embodied Multimodal Multitask Learning,"Devendra Singh Chaplot, Lisa Lee, Ruslan Salakhutdinov, Devi Parikh, Dhruv Batra",2019/2,arXiv e-prints,,,arXiv: 1902.01385,,"Recent efforts on training visual navigation agents conditioned on language using deep reinforcement learning have been successful in learning policies for different multimodal tasks, such as semantic goal navigation and embodied question answering. In this paper, we propose a multitask model capable of jointly learning these multimodal tasks, and transferring knowledge of words and their grounding in visual objects across the tasks. The proposed model uses a novel Dual-Attention unit to disentangle the knowledge of words in the textual representations and visual concepts in the visual representations, and align them with each other. This disentangled task-invariant alignment of representations facilitates grounding and knowledge transfer across both tasks. We show that the proposed model outperforms a range of baselines on both tasks in simulated 3D environments. We also show that this …",,"Embodied Multimodal Multitask Learning
D Singh Chaplot, L Lee, R Salakhutdinov, D Parikh… - arXiv e-prints, 2019",,,,,,,,
Neural map,,2018/12/27,,,,,,"A computer-implemented system and method for storing data associated with an agent in a multi-dimensional environment via a memory architecture. The memory architecture is structured so that each unique position in the environment corresponds to a unique position within the memory architecture, thereby allowing the memory architecture to store features located at a particular position in the environment in a memory location specific to that location. As the agent traverses the environment, the agent compares the features at the agent's particular position to a summary of the features stored throughout the memory architecture and writes the features that correspond to the summary to the coordinates in the memory architecture that correspond to the agent's position. The system and method allows agents to learn, using a reinforcement signal, how to behave when acting in an environment that requires storing …",,"Neural map
R Salakhutdinov, E Parisotto - US Patent App. 16/017,483, 2018
전체 3개의 버전",,,,,"Ruslan Salakhutdinov, Emilio Parisotto",US,16017483,
Cross-Task Knowledge Transfer for Visually-Grounded Navigation,"Devendra Singh Chaplot, Lisa Lee, Ruslan Salakhutdinov, Devi Parikh, Dhruv Batra",2018/9/27,,,,,,"Recent efforts on training visual navigation agents conditioned on language using deep reinforcement learning have been successful in learning policies for two different tasks: learning to follow navigational instructions and embodied question answering. In this paper, we aim to learn a multitask model capable of jointly learning both tasks, and transferring knowledge of words and their grounding in visual objects across tasks. The proposed model uses a novel Dual-Attention unit to disentangle the knowledge of words in the textual representations and visual objects in the visual representations, and align them with each other. This disentangled task-invariant alignment of representations facilitates grounding and knowledge transfer across both tasks. We show that the proposed model outperforms a range of baselines on both tasks in simulated 3D environments. We also show that this disentanglement of representations makes our model modular, interpretable, and allows for zero-shot transfer to instructions containing new words by leveraging object detectors.",,"Cross-Task Knowledge Transfer for Visually-Grounded Navigation
DS Chaplot, L Lee, R Salakhutdinov, D Parikh, D Batra - 2018
관련 학술자료",,,,,,,,
Learning Cognitive Models using Neural Networks,"Devendra Singh Chaplot, Christopher MacLellan, Ruslan Salakhutdinov, Kenneth Koedinger",2018/6,arXiv e-prints,,,arXiv: 1806.08065,,"A cognitive model of human learning provides information about skills a learner must acquire to perform accurately in a task domain. Cognitive models of learning are not only of scientific interest, but are also valuable in adaptive online tutoring systems. A more accurate model yields more effective tutoring through better instructional decisions. Prior methods of automated cognitive model discovery have typically focused on well-structured domains, relied on student performance data or involved substantial human knowledge engineering. In this paper, we propose Cognitive Representation Learner (CogRL), a novel framework to learn accurate cognitive models in ill-structured domains with no data and little to no human knowledge engineering. Our contribution is two-fold: firstly, we show that representations learnt using CogRL can be used for accurate automatic cognitive model discovery without using any student …",,"Learning Cognitive Models using Neural Networks
D Singh Chaplot, C MacLellan, R Salakhutdinov… - arXiv e-prints, 2018",,,,,,,,
Investigating the Working of Text Classifiers,"Devendra Singh Sachan, Manzil Zaheer, Ruslan Salakhutdinov",2018/1,arXiv e-prints,,,arXiv: 1801.06261,,"Text classification is one of the most widely studied tasks in natural language processing. Motivated by the principle of compositionality, large multilayer neural network models have been employed for this task in an attempt to effectively utilize the constituent expressions. Almost all of the reported work train large networks using discriminative approaches, which come with a caveat of no proper capacity control, as they tend to latch on to any signal that may not generalize. Using various recent state-of-the-art approaches for text classification, we explore whether these models actually learn to compose the meaning of the sentences or still just focus on some keywords or lexicons for classifying the document. To test our hypothesis, we carefully construct datasets where the training and test splits have no direct overlap of such lexicons, but overall language structure would be similar. We study various text classifiers and …",,"Investigating the Working of Text Classifiers
D Singh Sachan, M Zaheer, R Salakhutdinov - arXiv e-prints, 2018",,,,,,,,
Active Neural Localization,"Devendra Singh Chaplot, Emilio Parisotto, Ruslan Salakhutdinov",2018/1,arXiv e-prints,,,arXiv: 1801.08214,,"Localization is the problem of estimating the location of an autonomous agent from an observation and a map of the environment. Traditional methods of localization, which filter the belief based on the observations, are sub-optimal in the number of steps required, as they do not decide the actions taken by the agent. We propose"" Active Neural Localizer"", a fully differentiable neural network that learns to localize accurately and efficiently. The proposed model incorporates ideas of traditional filtering-based localization methods, by using a structured belief of the state with multiplicative interactions to propagate belief, and combines it with a policy model to localize accurately while minimizing the number of steps required for localization. Active Neural Localizer is trained end-to-end with reinforcement learning. We use a variety of simulation environments for our experiments which include random 2D mazes, random …",,"Active Neural Localization
D Singh Chaplot, E Parisotto, R Salakhutdinov - arXiv e-prints, 2018",,,,,,,,
Linguo-psychological model of depressive personality.,O Karpina,2018,Linguistic studies,,,158-163,,"The psychological diagnostics of a depressive personality and the semantic components included in the vocabulary definitions demonstrate a close correlation which is traced in the components of meaning, united in the semes sadness and anxiety.",,"Linguo-psychological model of depressive personality.
O Karpina - Linguistic studies, 2018
관련 학술자료 전체 3개의 버전",,,,,,,,
Learning Markov Chain in Unordered Dataset,"Yao-Hung Hubert Tsai, Han Zhao, Ruslan Salakhutdinov, Nebojsa Jojic",2017/11/8,arXiv preprint arXiv:1711.03167,,,,,"The assumption that data samples are independently identically distributed is the backbone of many learning algorithms. Nevertheless, datasets often exhibit rich structure in practice, and we argue that there exist some unknown order within the data instances. In this technical report, we introduce OrderNet that can be used to extract the order of data instances in an unsupervised way. By assuming that the instances are sampled from a Markov chain, our goal is to learn the transitional operator of the underlying Markov chain, as well as the order by maximizing the generation probability under all possible data permutations. Specifically, we use neural network as a compact and soft lookup table to approximate the possibly huge, but discrete transition matrix. This strategy allows us to amortize the space complexity with a single model. Furthermore, this simple and compact representation also provides a short description to the dataset and generalizes to unseen instances as well. To ensure that the learned Markov chain is ergodic, we propose a greedy batch-wise permutation scheme that allows fast training. Empirically, we show that OrderNet is able to discover an order among data instances. We also extend the proposed OrderNet to one-shot recognition task and demonstrate favorable results.",,"Learning Markov Chain in Unordered Dataset
YHH Tsai, H Zhao, R Salakhutdinov, N Jojic - arXiv preprint arXiv:1711.03167, 2017
관련 학술자료 전체 2개의 버전",,,,,,,,
Gated-Attention Architectures for Task-Oriented Language Grounding,"Devendra Singh Chaplot, Kanthashree Mysore Sathyendra, Rama Kumar Pasumarthi, Dheeraj Rajagopal, Ruslan Salakhutdinov",2017/6,arXiv e-prints,,,arXiv: 1706.07230,,"To perform tasks specified by natural language instructions, autonomous agents need to extract semantically meaningful representations of language and map it to visual elements and actions in the environment. This problem is called task-oriented language grounding. We propose an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments which assumes no prior linguistic or perceptual knowledge and requires only raw pixels from the environment and the natural language instruction as input. The proposed model combines the image and text representations using a Gated-Attention mechanism and learns a policy to execute the natural language instruction using standard reinforcement and imitation learning methods. We show the effectiveness of the proposed model on unseen instructions as well as unseen maps, both quantitatively and qualitatively. We also introduce …",,"Gated-Attention Architectures for Task-Oriented Language Grounding
D Singh Chaplot, K Mysore Sathyendra… - arXiv e-prints, 2017",,,,,,,,
"Manzil Zaheer1, 2, Satwik Kottur1, Siamak Ravanbhakhsh1, Barnabás Póczos1, Ruslan Salakhutdinov1, Alexander J Smola1, 2 Carnegie Mellon University 2 Amazon Web Services …","Barnabás Póczos, Ruslan Salakhutdinov",2017/3,arXiv preprint arXiv:1703.06114,,,,,"We study the problem of designing models for machine learning tasks defined on sets. In contrast to traditional approach of operating on fixed dimensional vectors, we consider objective functions defined on sets that are invariant to permutations. Such problems are widespread, ranging from estimation of population statistics [1], to anomaly detection in piezometer data of embankment dams [2], to cosmology [3, 4]. Our main theorem characterizes the permutation invariant functions and provides a family of functions to which any permutation invariant objective function must belong. This family of functions has a special structure which enables us to design a deep network architecture that can operate on sets and which can be deployed on a variety of scenarios including both unsupervised and supervised learning tasks. We also derive the necessary and sufficient conditions for permutation equivariance in deep models. We demonstrate the applicability of our method on population statistic estimation, point cloud classification, set expansion, and outlier detection.",,"Manzil Zaheer1, 2, Satwik Kottur1, Siamak Ravanbhakhsh1, Barnabás Póczos1, Ruslan Salakhutdinov1, Alexander J Smola1, 2 Carnegie Mellon University 2 Amazon Web Services {manzilz, skottur, mravanba, bapoczos, rsalakhu, smola}@ cs. cmu. edu
B Póczos, R Salakhutdinov - arXiv preprint arXiv:1703.06114, 2017
관련 학술자료 전체 3개의 버전",,,,,,,,
Package ‘darch’,"Martin Drees, Johannes Rueckert, Christoph M Friedrich, Geoffrey Hinton, Ruslan Salakhutdinov, Carl Edward Rasmussen, Maintainer Martin Drees, YW Teh, LinkingTo Rcpp",2016/7/19,,,,,,"Description The darch package is built on the basis of the code from GE Hinton and RR Salakhutdinov (available under Matlab Code for deep belief nets). This package is for generating neural networks with many layers (deep architectures) and train them with the method introduced by the publications``A fast learning algorithm for deep belief nets''(GE Hinton, S. Osindero, YW Teh; doi: 10.1162/neco. 2006.18. 7.1527) and``Reducing the dimensionality of data with neural networks''(GE Hinton, RR Salakhutdinov; doi: 10.1126/science. 1127647). This method includes a pre training with the contrastive divergence method published by GE Hinton (2002; doi: 10.1162/089976602760128018) and a fine tuning with common known training algorithms like backpropagation or conjugate gradients. Additionally, supervised fine-tuning can be enhanced with maxout and dropout, two recently developed techniques to improve fine-tuning for deep learning.",,"Package ‘darch’
M Drees, J Rueckert, CM Friedrich, G Hinton… - 2016
관련 학술자료 전체 5개의 버전",,,,,,,,
Visual attention for deep neural nets [captioning],"K Xu, J Ba, R Kiros, K Cho, A Courville, R Salakhutdinov, R Zemel, Y Bengio",2016/6/16,,,,,,"Page 1. Visual attention [with and for] deep neural nets June 16, 2016 Adobe CTL Vision and Learning Reading Group Zoya Bylinskii Page 2. Visual attention for deep neural nets [captioning] Paper discussion: “Show, Attend and Tell: Neural Image Caption Generation with Visual Attention” K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhutdinov, R. Zemel, Y. Bengio [ICML 2015] Page 3. ? A bird flying over a body of water Visual Attention for Image Captioning Page 4. Visual Attention for Image Captioning ? A bird flying over a body of water CNN for image feature extraction RNN with attention over image features for caption generation 1 2 Page 5. Visual Attention for Image Captioning ? CNN for image feature extraction Last convolutional layer before max pooling eg VGGnet: 14x14x512 feature map -> 196 image feature vectors of dimension 512 1 Page 6. Visual Attention for Image Captioning ? CNN for image …",,"Visual attention for deep neural nets [captioning]
K Xu, J Ba, R Kiros, K Cho, A Courville… - 2016
전체 2개의 버전",,,,,,,,
Iterative Refinement of the Approximate Posterior for Directed Belief Networks,"R Devon Hjelm, Kyunghyun Cho, Junyoung Chung, Russ Salakhutdinov, Vince Calhoun, Nebojsa Jojic",2015/11,arXiv e-prints,,,arXiv: 1511.06382,,"Variational methods that rely on a recognition network to approximate the posterior of directed graphical models offer better inference and learning than previous methods. Recent advances that exploit the capacity and flexibility in this approach have expanded what kinds of models can be trained. However, as a proposal for the posterior, the capacity of the recognition network is limited, which can constrain the representational power of the generative model and increase the variance of Monte Carlo estimates. To address these issues, we introduce an iterative refinement procedure for improving the approximate posterior of the recognition network and show that training with the refined posterior is competitive with state-of-the-art methods. The advantages of refinement are further evident in an increased effective sample size, which implies a lower variance of gradient estimates.",,"Iterative Refinement of the Approximate Posterior for Directed Belief Networks
R Devon Hjelm, K Cho, J Chung, R Salakhutdinov… - arXiv e-prints, 2015",,,,,,,,
"Show, Attend and Tell","Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, Yoshua Bengio",2015/7/8,,,,,,"Kelvin Xu*, Jimmy Ba†, Ryan Kiros†, Kyunghyun Cho*, Aaron Courville*, Ruslan Salakhutdinov†, Richard Zemel†, Yoshua Bengio* Université de Montréal*/ University of Toronto1 (some figures from Hugo Larochelle) … Figure: adapted from a figure from Feifei Li … Figure: A bird flying over a body of water … Recent work in image caption generation Encoder-decoder models from a number of groups: (Berkeley, Google, Stanford, Toronto, others) … Our proposed attention model Model Description Quantitative/Qualitative Results  … Recent work in image caption generation Encoder-decoder models from a number of groups: (Berkeley, Google, Stanford, Toronto, others) … Our proposed attention model Model Description Quantitative/Qualitative Results … Recent surge of interest in image captioning  … ▶ Submissions on this topic at CVPR 2015 (from groups at Google, Berkeley …",,"Show, Attend and Tell
K Xu, J Ba, R Kiros, K Cho, A Courville… - 2015",,,,,,,,
"Learning Structured, Robust, and Multimodal Models",Russ Salakhutdinov,2014/3/5,,,,,Banff International Research Station for Mathematical Innovation and Discovery,"Search. The University of British Columbia. UBC - A Place of Mind. The University of British Columbia. UBC Search UBC Search. Library. Library Home; Search Collections: Search; General (Summon); Books & Media (Catalogue); Indexes, Databases & Articles; Journals; Research Guides; UBC Research; UBC Open Collections. Hours & Locations: UBC Vancouver; Asian Library; Biomedical Branch Library; Chapman Learning Commons Help Desk; David Lam Management Research Library; Education Library; Irving K. Barber Learning Centre; Koerner Library; Law Library; Music, Art and Architecture Library; Rare Books and Special Collections; University Archives; Woodward Library; Xwi7xwa Library. UBC Okanagan; Innovation Library; Okanagan Library; Special Collections & Archives; The Commons (Okanagan). Use The Library: Borrowing Services; My Library Account; Materials Pick-Up Service; See More …",,"Learning Structured, Robust, and Multimodal Models
R Salakhutdinov - 2014",,,,,,,,
Annealing Between Distributions by Averaging Moments,Russ Salakhutdinov,2014/2/13,,,,,Banff International Research Station for Mathematical Innovation and Discovery,"Description Many powerful Monte Carlo techniques for estimating partition functions, such as annealed importance sampling (AIS), are based on sampling from a sequence of intermediate distributions which interpolate between a tractable initial distribution and the intractable target distribution. The near-universal practice is to use geometric averages of the initial and target distributions, but alternative paths can perform substantially better. We present a novel sequence of intermediate distributions for exponential families defined by averaging the moments of the initial and target distributions. We analyze the asymptotic performance of both the geometric and moment averages paths and derive an asymptotically optimal piecewise linear schedule. AIS with moment averaging performs well empirically at estimating partition functions of restricted Boltzmann machines (RBMs), which form the building blocks of many deep learning models, including Deep Belief Networks and Deep Boltzmann Machines. Joint work with Roger Grosse and Chris Maddison. References: Annealing between Distributions by Averaging Moments. Roger Grosse, Chris Maddison, and Ruslan Salakhutdinov. In Neural Information Processing Systems (NIPS 27) www. cs. toronto. edu/~ rsalakhu/papers/nips2013_moment. pdf",,"Annealing Between Distributions by Averaging Moments
R Salakhutdinov - 2014",,,,,,,,
Domain Adaptation: A Small Sample Statistical Approach,"Ruslan Salakhutdinov, Sham Kakade, Dean Foster",2012/3/21,,,,960-968,PMLR,"We study the prevalent problem when a test distribution differs from the training distribution. We consider a setting where our training set consists of a small number of sample domains, but where we have many samples in each domain. Our goal is to generalize to a new domain. For example, we may want to learn a similarity function using only certain classes of objects, but we desire that this similarity function be applicable to object classes not present in our training sample (eg we might seek to learn that “dogs are similar to dogs” even though images of dogs were absent from our training set). Our theoretical analysis shows that we can select many more features than domains while avoiding overfitting by utilizing data-dependent variance properties. We present a greedy feature selection algorithm based on using T-statistics. Our experiments validate this theory showing that our T-statistic based greedy feature selection is more robust at avoiding overfitting than the classical greedy procedure.",,"Domain Adaptation: A Small Sample Statistical Approach
R Salakhutdinov, S Kakade, D Foster - Artificial Intelligence and Statistics, 2012
관련 학술자료 전체 2개의 버전
Domain Adaptation: A Small Sample Statistical Approach*
D Foster, S Kakade, R Salakhutdinov - Appearing in Proceedings of the 15th International …, 2012
관련 학술자료 전체 11개의 버전",Artificial Intelligence and Statistics,,,,,,,
Workshop summary: Workshop on learning feature hierarchies,"Kay Yu, Ruslan Salakhutdinov, Yann LeCun, Geoff Hinton, Yoshua Bengio",2009/6/14,,,,1-1,,,,"Workshop summary: Workshop on learning feature hierarchies
K Yu, R Salakhutdinov, Y LeCun, G Hinton, Y Bengio - Proceedings of the 26th Annual International …, 2009
전체 2개의 버전",,Proceedings of the 26th Annual International Conference on Machine Learning,,,,,,
Undirected Topic Models,Ruslan Salakhutdinov,2009,,,,8,,,,"Undirected Topic Models*
R Salakhutdinov
관련 학술자료 전체 2개의 버전",NIPS workshop on Topic Models,,,,,,,
SELF-SUPERVISED LEARNING FROM A MULTI-VIEW,"Yao-Hung Hubert Tsai, Yue Wu, Ruslan Salakhutdinov, Louis-Philippe Morency",,,,,,,"As a subset of unsupervised representation learning, self-supervised representation learning adopts self-defined signals as supervision and uses the learned representation for downstream tasks, such as object detection and image captioning. Many proposed approaches for self-supervised learning follow naturally a multi-view perspective, where the input (eg, original images) and the self-supervised signals (eg, augmented images) can be seen as two redundant views of the data. Building from this multi-view perspective, this paper provides an information-theoretical framework to better understand the properties that encourage successful self-supervised learning. Specifically, we demonstrate that self-supervised learned representations can extract task-relevant information and discard task-irrelevant information. Our theoretical framework paves the way to a larger space of self-supervised learning objective design. In particular, we propose a composite objective that bridges the gap between prior contrastive and predictive learning objectives, and introduce an additional objective term to discard task-irrelevant information. To verify our analysis, we conduct controlled experiments to evaluate the impact of the composite objectives. We also explore our framework’s empirical generalization beyond the multi-view perspective, where the cross-view redundancy may not be clearly observed.",,"SELF-SUPERVISED LEARNING FROM A MULTI-VIEW
YHH Tsai, Y Wu, R Salakhutdinov, LP Morency",,,,,,,,
ScholarWorks@ Georgia State Universit y,"Sergey M Plis, Devon R Hjelm, Ruslan Salakhutdinov, Elena A Allen, Henry J Bockholt",,,,,,,"Deep learning methods have recently made notable advances in the tasks of classification and representation learning. These tasks are important for brain imaging and neuroscience discovery, making the methods attractive for porting to a neuroimager’s toolbox. Success of these methods is, in part, explained by the flexibility of deep learning models. However, this flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. These methods include deep belief networks and their building block the restricted Boltzmann machine. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep …",,"ScholarWorks@ Georgia State Universit y
SM Plis, DR Hjelm, R Salakhutdinov, EA Allen…
관련 학술자료",,,,,,,,
Point Cloud GAN Download PDF,"Chun-Liang Li, Manzil Zaheer, Yang Zhang, Barnabás Póczos, Ruslan Salakhutdinov",,,,,,,"Generative Adversarial Networks (GAN) can achieve promising performance on learning complex data distributions on different types of data. In this paper, we first show a straightforward extension of existing GAN algorithm is not applicable to point clouds, because the constraint required for discriminators is undefined for set data. We propose a two fold modification to GAN algorithm for learning to generate point clouds (PC-GAN). First, we combine ideas from hierarchical Bayesian modeling and implicit generative models by learning a hierarchical and interpretable sampling process. A key component of our method is that we train a posterior inference network for the hidden variables. Second, instead of using only state-of-the-art Wasserstein GAN objective, we propose a sandwiching objective, which results in a tighter Wasserstein distance estimate than the commonly used dual form. Thereby, PC-GAN defines a …",,"Point Cloud GAN Download PDF
CL Li, M Zaheer, Y Zhang, B Póczos, R Salakhutdinov",,,,,,,,
Supplementary for Neural Methods for Point-wise Dependency Estimation,"Yao-Hung Hubert Tsai, Han Zhao, Makoto Yamada34, Louis-Philippe Morency, Ruslan Salakhutdinov",,,,,,,"In this section, we shall show detailed derivations for the point-wise dependency estimation methods. Four approaches are discussed: Variational Bounds of Mutual Information, Density Matching, Probabilistic Classifier, and Density-Ratio Fitting. For convenience, we define Ω= X× Y. We have PX, Y and PXPY (can also be written as PX⊗ PY) be the probability measures over σ− algebras over Ω with their probability densities being the Radon-Nikodym derivatives (ie, p (x, y)= dPX, Y/dµ and p (x) p (y)= dPXPY/dµ with µ being the Lebesgue measure).",,"Supplementary for Neural Methods for Point-wise Dependency Estimation
YHH Tsai, H Zhao, M Yamada34, LP Morency…
관련 학술자료",,,,,,,,
Differentiable Reasoning over a Virtual Knowledge Base Download PDF,"Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig, Ruslan Salakhutdinov, William W Cohen",,,,,,,"We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art …",,"Differentiable Reasoning over a Virtual Knowledge Base Download PDF
B Dhingra, M Zaheer, V Balachandran, G Neubig…",,,,,,,,
Investigating the Working of Text Classifiers Download PDF,"Devendra Singh Sachan, Manzil Zaheer, Ruslan Salakhutdinov",,,,,,,"Text classification is one of the most widely studied tasks in natural language processing. Motivated by the principle of compositionality, large multilayer neural network models have been employed for this task in an attempt to effectively utilize the constituent expressions. Almost all of the reported work train large networks using discriminative approaches, which come with a caveat of no proper capacity control, as they tend to latch on to any signal that may not generalize. Using various recent state-of-the-art approaches for text classification, we explore whether these models actually learn to compose the meaning of the sentences or still just focus on some keywords or lexicons for classifying the document. To test our hypothesis, we carefully construct datasets where the training and test splits have no direct overlap of such lexicons, but overall language structure would be similar. We study various text classifiers and …",,"Investigating the Working of Text Classifiers Download PDF
DS Sachan, M Zaheer, R Salakhutdinov",,,,,,,,
Demystifying Self-Supervised Learning: An Information-Theoretical Framework Download PDF,"Yao-Hung Hubert Tsai, Yue Wu, Ruslan Salakhutdinov, Louis-Philippe Morency",,,,,,,"Self-supervised representation learning adopts self-defined signals as supervision and uses the learned representation for downstream tasks, such as masked language modeling (eg, BERT) for natural language processing and contrastive visual representation learning (eg, SimCLR) for computer vision applications. In this paper, we present a theoretical framework explaining that self-supervised learning is likely to work under the assumption that only the shared information (eg, contextual information or content) between the input (eg, non-masked words or original images) and self-supervised signals (eg, masked-words or augmented images) contributes to downstream tasks. Under this assumption, we demonstrate that self-supervisedly learned representation can extract task-relevant and discard task-irrelevant information. We further connect our theoretical analysis to popular contrastive and predictive (self …",,"Demystifying Self-Supervised Learning: An Information-Theoretical Framework Download PDF
YHH Tsai, Y Wu, R Salakhutdinov, LP Morency",,,,,,,,
Neural Methods for Point-wise Dependency Estimation Download PDF,"Yao-Hung Hubert Tsai, Han Zhao, Makoto Yamada, Louis-Philippe Morency, Ruslan Salakhutdinov",,,,,,,"Since its inception, the neural estimation of mutual information (MI) has demonstrated the empirical success of modeling expected dependency between high dimensional random variables. However, MI is an aggregate statistic and cannot be used to measure point-wise dependency between different events. In this work, instead of estimating the expected dependency, we focus on estimating point-wise dependency (PD), which quantitatively measures how likely two outcomes cooccur. We show that we can naturally obtain PD when we are optimizing MI neural variational bounds. However, optimizing these bounds is challenging due to its large variance in practice. To address this issue, we develop two methods (free of optimizing MI variational bounds): Probabilistic Classifier and Density-Ratio Fitting. We demonstrate the effectiveness of our approaches in 1) MI estimation, 2) self-supervised representation …",,"Neural Methods for Point-wise Dependency Estimation Download PDF
YHH Tsai, H Zhao, M Yamada, LP Morency…",,,,,,,,
Weakly-Supervised Reinforcement Learning for Controllable Behavior Download PDF,"Lisa Lee, Benjamin Eysenbach, Ruslan Salakhutdinov, Shixiang Shane Gu, Chelsea Finn",,,,,,,"Reinforcement learning (RL) is a powerful framework for learning to take actions to solve tasks. However, in many settings, an agent must winnow down the inconceivably large space of all possible tasks to the single task that it is currently being asked to solve. Can we instead constrain the space of tasks to those that are semantically meaningful? In this work, we introduce a framework for using weak supervision to automatically disentangle this semantically meaningful subspace of tasks from the enormous space of nonsensical"" chaff"" tasks. We show that this learned subspace enables efficient exploration and provides a representation that captures distance between states. On a variety of challenging, vision-based continuous control problems, our approach leads to substantial performance gains, particularly as the complexity of the environment grows.",,"Weakly-Supervised Reinforcement Learning for Controllable Behavior Download PDF
L Lee, B Eysenbach, R Salakhutdinov, SS Gu, C Finn",,,,,,,,
Neural Topological SLAM for Visual Navigation: Supplementary Material,"Devendra Singh Chaplot, Ruslan Salakhutdinov, Abhinav Gupta, Saurabh Gupta",,,,,,,"Figure 1: NTS Multi-task Learning Model. Figure showing an overview of the NTS Multi-task Learning Model. It takes a Source Image (IS) and a Goal Image (IG) as input and encodes them using a shared ResNet18 encoder. It first predicts whether the two images belong to the same node or not using the Connection model. If they belong to the same node, it makes Intra-Node predictions which include the direction and score (or equivalently) distance of the Goal Image relative to the Source Image. If they belong to different nodes, it makes Inter-Node Predictions which include directions of explorable areas and a semantic score corresponding to each explorable area denoting its proximity to the Goal Image.",,"Neural Topological SLAM for Visual Navigation: Supplementary Material
DS Chaplot, R Salakhutdinov, A Gupta, S Gupta
관련 학술자료",,,,,,,,
Probabilistic Matrix Factorization,"Probabilistic Matrix Factorization, Ruslan Salakhutdinov, Andriy Mnih",,,,,,,"Many existing approaches to collaborative ﬁltering can neither handle very large datasets nor easily deal with users who have very few ratings. In this paper we present the Probabilistic Matrix Factorization (PMF) model which scales linearly with the number of observations and, more importantly, performs well on the large, sparse, and very imbalanced Netﬂix dataset.",,"Probabilistic Matrix Factorization
PM Factorization, R Salakhutdinov, A Mnih
관련 학술자료",,,,,,,,
GTC 2018,"Yao-Hung Hubert Tsai, Han Zhao, Nebojsa Jojic, Ruslan Salakhutdinov",,,,,,,Page 1. GTC 2018 …,,"GTC 2018
YHH Tsai, H Zhao, N Jojic, R Salakhutdinov
관련 학술자료",,,,,,,,
Data-Driven Visual Forecasting,"Martial Hebert, Abhinav Gupta, Ruslan Salakhutdinov, David Forsyth",,,,,,,"Understanding the temporal dimension of images is a fundamental part of computer vision. Humans are able to interpret how the entities in an image will change over time. However, it has only been relatively recently that researchers have focused on visual forecasting—getting machines to anticipate events in the visual world before they actually happen. This aspect of vision has many practical implications in tasks ranging from human-‐ computer interaction to anomaly detection. In addition, temporal prediction can serve as a task for representation learning, useful for various other recognition problems … In this thesis, we focus on visual forecasting that is data-‐driven, self-‐supervised, and relies on little to no explicit semantic information. Towards this goal, we explore prediction at different timeframes. We first consider predicting instantaneous pixel motion-‐-‐-‐optical flow. We apply convolutional neural networks to predict optical …",,"Data-Driven Visual Forecasting
M Hebert, A Gupta, R Salakhutdinov, D Forsyth
전체 2개의 버전",,,,,,,,
IS EM REALLY BETTER?,"Russ Salakhutdinov, Sam Roweis",,,,,,,"Unsupervised learning plays an important role in many areas of machine learning. Two major research fields in unsupervied learning are density estimation, where one seeks to find a descriptive model of data, and dimensionality reduction, where one tries to discover a compact representation of data. Both of those classic problems often involve fitting models with unobserved or latent variables.
A commonly used technique for Maximum Likelihood Learning of model parameters in the presence of latent variables is Expectation-Maximization (EM) algorithm We propose a new approach for Maximum Likelihood Estimation of the model parameters using the method of conjugate gradients, which we call the Expectation Conjuagte Gradient (ECG) algorithm.",,"IS EM REALLY BETTER?
R Salakhutdinov, S Roweis
관련 학술자료 전체 8개의 버전",,,,,,,,
Learning Multimodal Representations with Factorized Deep Generative Models,"Yao-Hung Hubert Tsai, Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency, Ruslan Salakhutdinov",,,,,,,"Learning multimodal representations is a fundamentally complex research problem due to the presence of multiple heterogeneous sources of information. Although the presence of multiple modalities provides additional valuable information, there are two key challenges to address when learning from multimodal data: 1) models must learn the complex intra-modal and cross-modal interactions for prediction and 2) models must be robust to unexpected missing or noisy modalities during testing. In this paper, we propose to optimize for a joint generative-discriminative objective across multimodal data and labels. We introduce a model that factorizes representations into two sets of independent factors: multimodal discriminative and modality-specific generative factors. Multimodal discriminative factors are shared across all modalities and contain joint multimodal features required for discriminative tasks such as sentiment prediction. Modality-specific generative factors are unique for each modality and contain the information required for generating data. Experimental results show that our model is able to learn meaningful multimodal representations that achieve state-of-the-art or competitive performance on six multimodal datasets. Our model demonstrates flexible generative capabilities by conditioning on independent factors and can reconstruct missing modalities without significantly impacting performance. Lastly, we interpret our factorized representations to understand the interactions that influence multimodal learning.",,"Learning Multimodal Representations with Factorized Deep Generative Models
YHH Tsai, PP Liang, A Zadeh, LP Morency…
관련 학술자료",,,,,,,,
PROPRIOCEPTIVE SPATIAL REPRESENTATIONS FOR GENERALIZED LOCOMOTION,"Joshua Zhanson, Emilio Parisotto, Ruslan Salakhutdinov",,,,,,,"In this work, we explore incorporating spatial information into feature and action representations of deep reinforcement learning in the pursuit of a single multi-body locomotion policy. Instead of the traditional feature vectors used in continuous RL, we introduce a body-space state representation that maps sensor readings onto a spatial grid overlay of the robot’s body, implicitly encoding relative positional information. Additionally, we introduce a motor-space action representation that projects motor torques out of a similar spatial grid. Models map from input body-space to output motor-space, instead of from the observation space of joint velocities and angles to the action space of joint torques. To demonstrate the multitask and transfer capabilities of models trained with our representations, we introduce an environment based on the Box2D physics simulator that allows creation of robot bodies with arbitrary structure …",,"PROPRIOCEPTIVE SPATIAL REPRESENTATIONS FOR GENERALIZED LOCOMOTION
J Zhanson, E Parisotto, R Salakhutdinov
관련 학술자료",,,,,,,,
STATE MARGINAL MATCHING WITH MIXTURES OF POLICIES,"Lisa Lee, Benjamin Eysenbach, Emilio Parisotto, Ruslan Salakhutdinov, Sergey Levine",,,,,,,"Reinforcement learning (RL) algorithms today are hindered by their slothful rate of learning. When faced with a new task, RL algorithms fail to efficiently explore and learn which states have high reward. While most previous work on exploration in RL has focused on the single-task setting, we consider the multi-task setting, where many different reward functions can be provided for the same set of states and dynamics. To avoid re-inventing the wheel for each task, our method learns a single exploration policy that can quickly solve many downstream tasks. In this work, we define our exploration objective as the distance between the distribution over states visited by the policy and some prior distribution over states. In the absence of any prior information, this objective reduces to simply maximizing the marginal state entropy. We will illustrate how both standard RL and maximum action-entropy RL fail to solve state distribution matching problems. We propose a straightforward algorithm that iteratively fits a state density model and then updates the policy to visit states with low density under this model. Extending our approach to use mixtures of policies, we discover connections between distribution matching and the intrinsic motivation objectives based on mutual information in prior work. We demonstrate empirically that our method can effectively solve state distribution matching and reward-maximization tasks on complex navigation tasks, outperforming strong baselines.",,"STATE MARGINAL MATCHING WITH MIXTURES OF POLICIES
L Lee, B Eysenbach, E Parisotto, R Salakhutdinov…
관련 학술자료",,,,,,,,
Semi-Supervised Pairing via Basis-Sharing Wasserstein Matching Auto-Encoder,"Ziyin Liu, Yao-Hung Hubert Tsai, Makoto Yamada, Ruslan Salakhutdinov",,,,,,,"Semi-supervised pairing, learning explicit pairing relation between unlabeled input and target distribution in an otherwise semisupervised setting, has recently attracted lots of attention [16, 12], since data labeling is often time-consuming and requires lots of human labor. In this paper, we propose Basis-Sharing Wasserstein Matching Auto-Encoder to tackle the problem of semi-supervised pairing. Our model inspired by the success of robust representation learning for matching cross-modal latent space distribution [15, 10] and good statistical properties of optimal transport [1, 4]. In particular, Wasserstein distance in the optimal transport family has been shown to work on GANs and autoencoders [2, 14]. We propose to match the latent code distribution of the unlabeled dataset, with the labeled data points as “anchor points”. This should help the network making association between the distributions from two different domains. A similar idea that uses a different method has been shown to work on some language tasks [3]; our work explores a new approach based on distribution matching. Through preliminary experiments, we show that the proposed algorithm can successfully incorporate the unlabeled data for improving the classification accuracy on MNIST and CIFAR10 datasets.",,"Semi-Supervised Pairing via Basis-Sharing Wasserstein Matching Auto-Encoder
Z Liu, YHH Tsai, M Yamada, R Salakhutdinov
관련 학술자료",,,,,,,,
Approximate Empirical Bayes for Deep Neural Networks,"Han Zhao, Yao-Hung Hubert Tsai, Ruslan Salakhutdinov, Geoff Gordon",,,,,,,"We propose an approximate empirical Bayes framework and an efficient algorithm for learning the weight matrix of deep neural networks. Empirically, we show the proposed method works as a regularization approach that helps generalization when training neural networks on small datasets.",,"Approximate Empirical Bayes for Deep Neural Networks
H Zhao, YHH Tsai, R Salakhutdinov, G Gordon
관련 학술자료 전체 3개의 버전",,,,,,,,
Supplementary for Learning Factorized Multimodal Representations,"Yao-Hung Hubert Tsai, Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency, Ruslan Salakhutdinov",,,,,,,"Fig. 1 illustrates how MFM operates on multimodal time series data. The encoder Q (Zy X1∶ M) can be parametrized by any model that performs multimodal fusion [10, 18]. We choose the Memory Fusion Network (MFN)[18] as our encoder Q (Zy X1∶ M). We use encoder LSTM networks and decoder LSTM networks [1] to parametrize functions Q (Za1∶ M X1∶ M) and F1∶ M respectively, and FCNNs to parametrize functions Gy, Ga {1∶ M} and D.",,"Supplementary for Learning Factorized Multimodal Representations
YHH Tsai, PP Liang, A Zadeh, LP Morency…
관련 학술자료",,,,,,,,
Gated-Attention Architectures for Task-Oriented Language Grounding,"Devendra Singh Chaplot Kanthashree Mysore Sathyendra, Rama Kumar Pasumarthi, Dheeraj Rajagopal, Ruslan Salakhutdinov",,,,,,,"To perform tasks specified by natural language instructions, autonomous agents need to extract semantically meaningful representations of language and map it to visual elements and actions in the environment. This problem is called taskoriented language grounding. We propose an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments which assumes no prior linguistic or perceptual knowledge and requires only raw pixels from the environment and the natural language instruction as input. The proposed model combines the image and text representations using a Gated-Attention mechanism and learns a policy to execute the natural language instruction using standard reinforcement and imitation learning methods. We show the effectiveness of the proposed model on unseen instructions as well as unseen maps, both quantitatively and qualitatively. We also introduce a novel environment based on a 3D game engine to simulate the challenges of task-oriented language grounding over a rich set of instructions and environment states.",,"Gated-Attention Architectures for Task-Oriented Language Grounding
DSCKM Sathyendra, RK Pasumarthi, D Rajagopal…
관련 학술자료",,,,,,,,
Supplementary Material for Learning Robust Visual-Semantic Embeddings,"Yao-Hung Hubert Tsai, Liang-Kang Huang, Ruslan Salakhutdinov, I Network Design",,,,,,,"Fig. 1 provides an easy-to-understand design of ReViSE. In all of our experiments, GoogLeNet is pre-trained on ImageNet [2] images. Without fine-tuning, we directly extract the top layer activations (1024-dim) as our input image features followed by a common log (1+ v) pre-processing step. For the textual attributes, we pre-process them through a standard l2 normalization.
In ReViSE, we set α= 1.0 in eq.(11), so that we place equal importance on supervised and unsupervised objectives. For the visual auto-encoder, we fix the parameter of the contraction strength γ= 0.1 in eq.(2). In the following, we omit the bias term in each layer for simplicity. The encoding of visual features is parameterized by a twohidden layer fully-connected neural network with architecture dv1-dv2-dc, where dv1= 1024 is the input dimension of the visual features, dv2= 500 is the intermediate layer, and dc denotes the dimension of the visual codes vh. To encode textual attributes, we consider a single-hidden layer neural network dt1-dc, where dt1 is the input dimension of the textual attributes. We choose dc= 100 when dt1> 100 and dc= 75 when dt1< 100. Furthermore, we do not tie the weights to be learned between the decoding and encoding parts. Parameters for associating distributions of visual and textual codes (MMD Loss) in eqs.(5)(12), and (6) are set as β= 10.1, 1.0 l (chosen by cross-validation) and κ= 32.0. For the remaining part of our model, we set the architecture of visual and textual code mapping as a single-hidden layer fully-connected neural network with dimension dc-50. We also adopt a dropout of 0.7. During the first 100 iterations of training, we set λ= 0 so …",,"Supplementary Material for Learning Robust Visual-Semantic Embeddings
YHH Tsai, LK Huang, R Salakhutdinov, IN Design
관련 학술자료 전체 2개의 버전",,,,,,,,
Image Analysis-Motivation,"Yukun Zhu, Ryan Kiros, Richard Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, Sanja Fidler",,,,,,,"0 10 20 30 40 50 60 0 10 20 30 40 50 60 … 0 10 20 30 40 50 60 0 10 20 30 40 50 60 … • http://www.cs.nyu.edu/~yann/talks/lecun-ranzato-icml2013.pdf … • http://www.robots.ox.ac.uk /~vgg/practicals/cnn … • Classification model (x feature vector, (w,b) … • ML estimate of parameters (w,b) is a convex … • Filter: Filter kernal block w of size … ∑u ∑vx(i - u, j - v, l)w(u, v, l) … Input: image x of size mxnxk, typically k=1 (gray … Output: vector y of size 1 x 1 x N, which we interpret … The probability that the image x is of class j … Input: image x of size mxnxk, typically k=1 (gray … Output: vector y of size 1 x 1 x N, which we interpret … The probability that the image x is of class j … • Evaluate one example (x_k,c_k) (like adding another layer) … • Requires going through all examples (all N) … • If N is large and/or if computing y(x_k,w) is time-consuming, use … • Jittering - construct a larger training set by perturbing the",,"Image Analysis-Motivation
Y Zhu, R Kiros, R Zemel, R Salakhutdinov, R Urtasun…
전체 5개의 버전",,,,,,,,
Supplementary Material: Stochastic Variational Deep Kernel Learning,"Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, Eric P Xing",,,,,,,"The second evaluation of our proposed algorithm (SV-DKL) is conducted on a number of commonly used UCI classification tasks of varying sizes and properties. Table 1 lists the classification accuracy of SVM, DNN, DNN+(a stand-alone DNN with an extra Q× c fully-connected hidden layer with Q, c defined as in Figure 1 of the main text, DNN+ GP (a GP trained on the top level features of a trained DNN without the extra hidden layer), and SV-DKL (same architecture as DNN).
The plain DNN, which learns salient features effectively from raw data, gives notably higher accuracy compared to an SVM, the mostly widely used kernel method for classification problems. We see that the extra layer in DNN+ GP can sometimes harm performance. By contrast, non-parametric flexibility of DNN+ GP consistently improves upon DNN. And SV-DKL, by training a DNN through a GP marginal likelihood objective, consistently provides further enhancements (with particularly notable performance on the Connect4 and Covtype datasets).",,"Supplementary Material: Stochastic Variational Deep Kernel Learning
AG Wilson, Z Hu, R Salakhutdinov, EP Xing
관련 학술자료",,,,,,,,
Joint work with Geoff Hinton,Ruslan Salakhutdinov,,,,,,,"Page 1. NON-LINEAR DIMENSIONALITY REDUCTION USING NEURAL NETWORKS Ruslan Salakhutdinov Joint work with Geoff Hinton University of Toronto, Machine Learning Group 1 Page 2. Overview Document Retrieval – Present layer-by-layer pretraining and the fine-tuning of the multi-layer network that discovers binary codes in the top layer. This allows us to significantly speed-up retrieval time. – We also show how we can use our model to allow retrieval in constant time (a time independent of the number of documents). Show how to perform nonlinear embedding by preserving class neighbouthood structure (supervised, semi-supervised). 2 Page 3. Motivation For the document retrieval tasks, we want to retrieve a small set of documents, relevant to the given query. Popular and widely used in practice text retrieval algorithm is based on TF-IDF (term frequency / inverse document frequency) …",,"Joint work with Geoff Hinton
R Salakhutdinov",,,,,,,,
Annealing Between Distributions by Averaging Moments,"Chris J Maddison, Roger Grosse, Ruslan Salakhutdinov",,,,,,,Page 1. Annealing Between Distributions by Averaging Moments Chris J. Maddison Dept. of Comp. Sci. University of Toronto …,,"Annealing Between Distributions by Averaging Moments
CJ Maddison, R Grosse, R Salakhutdinov
전체 3개의 버전",,,,,,,,
用神经网络减少数据维数,"GE Hinton, RR Salakhutdinov",,,,,,,通过训练小中间层（ small central layer） 的多层神经网络（ 神经元个数小于维数）， 可以将高维数据（ high-dimensional data） 转换为低维编码（ low-dimensional codes）， 以此（ 通过此网络） 来重建（ reconstruct） 高维输入向量（ high-dimensional input vectors）. 梯度下降法（ gradient descent） 可以用来在这个 “自编码（ autoencode） 网络” 上微调（ fine-tuning） 权值， 但是这（ 梯度下降） 只在初始权值接近较好方案时有效. 本文介绍（ describe） 了一种有效初始权重方法来作为减少数据维度的工具， 这种方法使得深度自编码网络学习低维编码的效果优于主成分分析（ PCA， principal components analysis）.,,"用神经网络减少数据维数
GE Hinton, RR Salakhutdinov
관련 학술자료",,,,,,,,
Supplementary Material: Deep Kernel Learning,"Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, Eric P Xing",,,,,,,"We test the ability of DKL to recover step functions, a challenging benchmark problem for kernel learning methods due to the underlying smoothness assumptions. We consider a particularly complicated step function with many discontinuities. The training data consists of 60,000 points (shown as black dots in Figure 1) and the test data contains 2,000 points, both uniformly distributed over (− 1, 1). The DKL-SM model uses a DNN with an 1-1000-1000-500-50-2 architecture, which is the same as what used in the UCI regression tasks (section 5.1).
Because of the number of discontinuities in this step function, and the strong smoothness assumptions in the RBF kernel, most of the structure in the data is discounted as noise. The GP with SM kernel performs much better, but is unable to capture the sharpness of the discontinuities. By contrast, the DKL-SM model",,"Supplementary Material: Deep Kernel Learning
AG Wilson, Z Hu, R Salakhutdinov, EP Xing
전체 4개의 버전",,,,,,,,
"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention (Supplementary Material)","Kelvin Xu, UMONTREAL CA, Jimmy Lei Ba, UTORONTO CA, Ryan Kiros, TORONTO EDU, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard S Zemel, Yoshua Bengio",,,,,,,"Page 1. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention (Supplementary Material) Kelvin Xu KELVIN.XU@UMONTREAL.CA Université de Montréal Jimmy Lei Ba JIMMY@PSI.UTORONTO.CA University of Toronto Ryan Kiros RKIROS@CS.TORONTO. EDU University of Toronto Kyunghyun Cho KYUNGHYUN.CHO@UMONTREAL.CA Université de Montréal Aaron Courville AARON.COURVILLE@UMONTREAL.CA Université de Montréal Ruslan Salakhutdinov RSALAKHU@CS.TORONTO.EDU University of Toronto Richard S. Zemel ZEMEL@CS.TORONTO.EDU University of Toronto Yoshua Bengio YOSHUA.BENGIO@ UMONTREAL.CA Université de Montréal Page 2. Neural Image Caption Generation with Visual Attention 1. Additional Visualizations Visualizations from our “hard” (a) and “soft” (b) attention model. White indicates the regions where the model roughly attends to …",,"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention (Supplementary Material)
K Xu, U CA, JL Ba, U CA, R Kiros, T EDU, K Cho…",,,,,,,,
Supplementary Materials for Learning Stochastic Feedforward Neural Networks,"Yichuan Tang, Ruslan Salakhutdinov",,,,,,,//Approximate E-step: 1 Compute p (h2| x (n))= Bernoulli (σ (W2σ (W1x (n)))) 2 h2 determ← p (h2 determ| x (n)) for m= 1 to M (importance samples) do 3 Sample: h2 stoch∼ p (h2 stoch| x (n)). let h2 be the concatenation of h2 stoch and h2 determ. 4 p (h3| x (n))= Bernoulli (σ (W3h2)) 5 h3 determ← p (h3 determ| x (n)) 6 Sample: h3 stoch∼ p (h3 stoch| x (n)) let h3 be the concatenation of h3 stoch and h3 determ. 7 Compute p (y| x (n))= N (σ (W5σ (W4h3)); σ2 y) end for,,"Supplementary Materials for Learning Stochastic Feedforward Neural Networks
Y Tang, R Salakhutdinov
전체 8개의 버전",,,,,,,,
Supplementary Materials for Tensor Analyzers,"Yichuan Tang, Ruslan Salakhudinov, Geoffrey Hinton",,,,,,,"Posterior inference in TA using alternating Gibbs sampling is efficient. We present trace plots of the 6 random latent factors of two TAs in the figure below. Left panel is from a TA learned on 2D synthetic datasets of Sec. 4, while the right panel is from a TA modeling high dimensional face images under illumination variations. The plots demonstrate that samples mixes very quickly after around 20 Gibbs iterations.",,"Supplementary Materials for Tensor Analyzers
Y Tang, R Salakhudinov, G Hinton
전체 8개의 버전",,,,,,,,
Report from the NSF Workshop on Integrating Approaches to Computational Cognition,"Matt Jones, Richard M Shiffrin, Alan L Yuille, Jun Zhang, Xiaojin Zhu, Thomas L Griffiths, Charles Kemp, Yann LeCun, Hongjing Lu, David A McAllester, Ruslan Salakhutdinov, Bernhard Schölkopf, Satinder Singh, Robin D Thomas",,,,,,,"At a workshop sponsored by the National Science Foundation, 18 distinguished researchers from the fields of Cognitive Science(CS) and Machine Learning(ML) met in Arlington, VA in May 2013 to discuss computational approaches to cognition in human and artificial systems. The purpose of the workshop was to identify frontiers for collaborative research integrating(a) mathematical and computational modeling of human cognition with (b) machine learning and machine intelligence. The researchers discussed opportunities and challenges for how the two fields can advance each other and what sort of joint efforts are likely to be most fruitful.
There are several reasons to believe that theories of human cognition and of machine intelligence are currently in position to greatly benefit from each other. The mathematical and computational tools developed for designing artificial systems are beginning to make an impact on theoretical and empirical work in CS, and conversely CS offers a range of complex problems that challenge and test ML",,"Report from the NSF Workshop on Integrating Approaches to Computational Cognition
M Jones, RM Shiffrin, AL Yuille, J Zhang, X Zhu…
관련 학술자료 전체 4개의 버전",,,,,,,,
Deep Learning & Feature Learning Methods for Vision,"Rob Fergus NYU, Kai Yu, Marc’Aurelio Ranzato, Honglak Lee, Ruslan Salakhutdinov, Graham Taylor",,,,,,,Page 1. Deep Learning & Feature Learning Methods for Vision Rob Fergus (NYU) Kai Yu (Baidu) Marc'Aurelio Ranzato (Google) Honglak Lee (Michigan) Ruslan Salakhutdinov (U. Toronto) Graham Taylor (University of Guelph) CVPR 2012 Tutorial: 9am-5:30pm Page 2. Tutorial Overview 9.00am: Introduction Rob Fergus (NYU) 10.00am: Coffee Break 10.30am: Sparse Coding Kai Yu (Baidu) 11.30am: Neural Networks Marc'Aurelio Ranzato (Google) 12.30pm: Lunch 1.30pm: Restricted Boltzmann Honglak Lee (Michigan) Machines 2.30pm: Deep Boltzmann Ruslan Salakhutdinov (Toronto) Machines 3.00pm: Coffee Break 3.30pm: Transfer Learning Ruslan Salakhutdinov (Toronto) 4.00pm: Motion & Video Graham Taylor (Guelph) 5.00pm: Summary / Q & A All 5.30pm: End Page 3. Overview • Learning Feature Hierarchies for Vision – Mainly for recognition • Many possible titles: – Deep Learning – Feature Learning …,,"Deep Learning & Feature Learning Methods for Vision
RF NYU, K Yu, MA Ranzato, H Lee, R Salakhutdinov…
관련 학술자료 전체 5개의 버전",,,,,,,,
Learning Feature Hierarchies by Learning Deep Generative Models,Ruslan Salakhutdinov,,,,,,,"Many real-world applications are characterized by high-dimensional, highly-structured data with a large supply of unlabeled data and a very limited amount of labeled data. Applications such as information retrieval and machine vision are examples where unlabeled data is readily available. Many models, including logistic regression, Gaussian processes, and Support Vector Machines, are discriminative models by nature, and within the standard regression or classification scenario, unlabeled data is of no use. Given a set of iid labeled input vectors Xl={xn} N n= 1 and their associated target labels {yn} N n= 1∈ R for regression or {yn} N n= 1∈{− 1, 1} for classification, discriminative methods model p (yn| xn) directly. Unless some assumptions are made about the underlying distribution of the input data X=[Xl, Xu], unlabeled data, Xu, cannot be used. Many researchers have tried to use unlabeled data by incorporating a model of P (X). For classification tasks,[11] model P (X) as a mixture∑ yn p (xn| yn) p (yn) and then infer p (yn| xn),[15] attempts to learn a covariance kernel for a Gaussian process based on P (X), and [10] assume that the decision boundaries should occur in regions where the data density, P (X), is low. When faced with high-dimensional, highlystructured data, however, none of the existing approaches have proved to be particularly successful.
To make use of unlabeled data, we propose to first learn a deep generative model, eg a Deep Belief Network (DBN), of P (X) in an entirely unsupervised way using the fast, greedy learning algorithm introduced in [7](for details see [2, 13, 14]). We then use the learned parameters W of the deep …",,"Learning Feature Hierarchies by Learning Deep Generative Models
R Salakhutdinov
관련 학술자료 전체 3개의 버전",,,,,,,,
Learning and Evaluaing Deep Bolztmann Machines,"Ruslan Salakhutdinov, Geoffrey Hinton",,,,,,,"Building intelligent systems that are capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many AI related tasks, including object recognition, speech perception, and language understanding. Theoretical and biological arguments strongly suggest that building such systems requires deep architectures that involve many layers of nonlinear processing. Hinton et. al.[2] introduced a fast, greedy learning algorithm for Deep Belief Networks that would learn one layer of features at a time. This new learning algorithm has generated substantial interest in academia and many variants of it have been successfully applied in many application domains. However, a crucial disadvantage of these deep probabilistic models is that the approximate inference is very limited, because it is performed in a single bottom-up pass, and will fail to adequately account for uncertainty when interpreting ambiguous sensory inputs.
In this work, we present a new learning algorithms for a different type of hierarchical probabilistic model: a deep Boltzmann machine (DBM). Unlike deep belief networks, a DBM is a type of Markov random field, or undirected graphical model, where all connections between layers are undirected. Deep Boltzmann machines are interesting for several reasons. First, like deep belief networks, DBM’s have the potential of learning internal representations that become increasingly complex, which is considered to be a promising way of solving object and speech recognition problems. High-level representations can be built from a large supply of unlabeled sensory inputs and the very limited labeled …",,"Learning and Evaluaing Deep Bolztmann Machines
R Salakhutdinov, G Hinton
관련 학술자료 전체 2개의 버전",,,,,,,,
Long short-term memory,"Sepp Hochreiter, Jürgen Schmidhuber",1997/11/15,Neural computation,9,8,1735-1780,MIT Press,"Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through …",49272회,"Long short-term memory
S Hochreiter, J Schmidhuber - Neural computation, 1997
49032회 인용 관련 학술자료 전체 47개의 버전
Long short-term memory*
J Schmidhuber, S Hochreiter - Neural Comput, 1997
281회 인용 관련 학술자료 전체 3개의 버전
LONG SHORT-TERM MEMOR $ &eural ComputatHon 9 (T): 13c-1T0, 199Sepp Hochreiter Fakult at f ur Informatik Technische jniversit at M unchen*
S Hochreiter
관련 학술자료",,,,,,,,
Fast and accurate deep network learning by exponential linear units (elus),"Djork-Arné Clevert, Thomas Unterthiner, Sepp Hochreiter",2015/11/23,arXiv preprint arXiv:1511.07289,,,,,"We introduce the"" exponential linear unit""(ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with batch normalization while batch normalization does not improve ELU networks. ELU networks are among the top 10 reported CIFAR-10 results and yield the best published result on CIFAR-100, without resorting to multi-view evaluation or model averaging. On ImageNet …",3435회,"Fast and accurate deep network learning by exponential linear units (elus)
DA Clevert, T Unterthiner, S Hochreiter - arXiv preprint arXiv:1511.07289, 2015
3435회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
Gans trained by a two time-scale update rule converge to a local nash equilibrium,"Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter",2017/6/26,arXiv preprint arXiv:1706.08500,,,,,"Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the"" Fréchet Inception Distance""(FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark.",2775회,"Gans trained by a two time-scale update rule converge to a local nash equilibrium
M Heusel, H Ramsauer, T Unterthiner, B Nessler… - arXiv preprint arXiv:1706.08500, 2017
2775회 인용 관련 학술자료 전체 8개의 버전
GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium–Supplementary Material*
M Heusel, H Ramsauer, T Unterthiner, B Nessler…
관련 학술자료",,,,,,,,
Gradient flow in recurrent nets: the difficulty of learning long-term dependencies,"Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, Jürgen Schmidhuber",2001,,1,,,A field guide to dynamical recurrent neural networks. IEEE Press,"Recurrent networks (crossreference Chapter 12) can, in principle, use their feedback connections to store representations of recent input events in the form of activations. The most widely used algorithms for learning what to put in short-term memory, however, take too much time to be feasible or do not work well at all, especially when minimal time lags between inputs and corresponding teacher signals are long. Although theoretically fascinating, they do not provide clear practical advantages over, say, backprop in feedforward networks with limited time windows (see crossreference Chapters 11 and 12). With conventional “algorithms based on the computation of the complete gradient”, such as “Back-Propagation Through Time”(BPTT, eg,[23, 28, 27]) or “Real-Time Recurrent Learning”(RTRL, eg,[22]) error signals “flowing backwards in time” tend to either (1) blow up or (2) vanish: the temporal evolution of the …",1909회,"Gradient flow in recurrent nets: the difficulty of learning long-term dependencies
S Hochreiter, Y Bengio, P Frasconi, J Schmidhuber - 2001
1648회 인용 관련 학술자료 전체 14개의 버전
A field guide to dynamical recurrent networks*
JF Kolen, SC Kremer - 2001
243회 인용 관련 학술자료 전체 2개의 버전
Gradient flow in recurrent nets: the difficulty of learning long-term dependencies.(2001)*
S Hochreiter, Y Bengio, P Frasconi, J Schmidhuber - Cited on, 2001
39회 인용 관련 학술자료
P. Frasconi, and Schmidhuber, J.(2001) Gradient flow in recurrent nets: the difficulty of learning long-term dependencies*
S Hochreiter, Y Bengio
3회 인용 관련 학술자료",,,,,,,,
The vanishing gradient problem during learning recurrent neural nets and problem solutions,Sepp Hochreiter,1998/4/1,INTERNATIONAL JOURNAL OF UNCERTAINTY FUZZINESS AND KNOWLEDGE BASED SYSTEMS,6,,107-115,WORLD SCIENTIFIC SINGAPORE,"Recurrent nets are in principle capable to store past inputs to produce the currently desired output. Because of this property recurrent nets are used in time series prediction and process control. Practical applications involve temporal dependencies spanning many time steps, e.g. between relevant inputs and desired outputs. In this case, however, gradient based learning methods take too much time. The extremely increased learning time arises because the error vanishes as it gets propagated back. In this article the de-caying error flow is theoretically analyzed. Then methods trying to overcome vanishing gradients are briefly discussed. Finally, experiments comparing conventional algorithms and alternative methods are presented. With advanced methods long time lag problems can be solved in reasonable time.",1571회,"The vanishing gradient problem during learning recurrent neural nets and problem solutions
S Hochreiter - International Journal of Uncertainty, Fuzziness and …, 1998
1571회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
Self-normalizing neural networks,"Günter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter",2017/6/8,arXiv preprint arXiv:1706.02515,,,,,"Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are"" scaled exponential linear units""(SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance--even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers,(2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks …",1473회,"Self-normalizing neural networks
G Klambauer, T Unterthiner, A Mayr, S Hochreiter - arXiv preprint arXiv:1706.02515, 2017
1473회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Untersuchungen zu dynamischen neuronalen Netzen,Sepp Hochreiter,1991/6,,,,,,,860회,"Untersuchungen zu dynamischen neuronalen Netzen
S Hochreiter - Diploma, Technische Universität München, 1991
860회 인용 관련 학술자료",,,"Master's thesis, Institut fur Informatik, Technische Universitat, Munchen",,,,,
"A comprehensive assessment of RNA-seq accuracy, reproducibility and information content by the Sequencing Quality Control consortium",SEQC Consortium,2014/9,Nature Biotechnology,32,9,903–914,Springer Nature,"We present primary results from the Sequencing Quality Control (SEQC) project, coordinated by the United States Food and Drug Administration. Examining Illumina HiSeq, Life Technologies SOLiD and Roche 454 platforms at multiple laboratory sites using reference RNA samples with built-in controls, we assess RNA sequencing (RNA-seq) performance for junction discovery and differential expression profiling and compare it to microarray and quantitative PCR (qPCR) data using complementary metrics. At all sequencing depths, we discover unannotated exon-exon junctions, with> 80% validated by qPCR. We find that measurements of relative expression are accurate and reproducible across sites and platforms if specific filters are used. In contrast, RNA-seq and microarrays do not provide accurate absolute measurements, and gene-specific biases are observed, for these and qPCR. Measurement performance …",601회,"A comprehensive assessment of RNA-seq accuracy, reproducibility and information content by the Sequencing Quality Control Consortium
SEQC Consortium - Nature biotechnology, 2014
601회 인용 관련 학술자료 전체 18개의 버전",,,,,,,,
"A comprehensive assessment of RNA-seq accuracy, reproducibility and information content by the Sequencing Quality Control Consortium",SEQC Consortium,2014/9,Nature biotechnology,32,9,903,NIH Public Access,"We present primary results from the Sequencing Quality Control (SEQC) project, coordinated by the United States Food and Drug Administration. Examining Illumina HiSeq, Life Technologies SOLiD and Roche 454 platforms at multiple laboratory sites using reference RNA samples with built-in controls, we assess RNA sequencing (RNA-seq) performance for junction discovery and differential expression profiling and compare it to microarray and quantitative PCR (qPCR) data using complementary metrics. At all sequencing depths, we discover unannotated exon-exon junctions, with> 80% validated by qPCR. We find that measurements of relative expression are accurate and reproducible across sites and platforms if specific filters are used. In contrast, RNA-seq and microarrays do not provide accurate absolute measurements, and gene-specific biases are observed, for these and qPCR. Measurement performance …",601회,"A comprehensive assessment of RNA-seq accuracy, reproducibility and information content by the Sequencing Quality Control Consortium
SEQC Consortium - Nature biotechnology, 2014
601회 인용 관련 학술자료 전체 18개의 버전",,,,,,,,
LSTM can solve hard long time lag problems,"Sepp Hochreiter, Jurgen Schmidhuber",1997/5/5,Advances in Neural Information Processing Systems 9: Proceedings of The 1996 Conference,9,,473,MIT Press,"Standard recurrent nets cannot deal with long minimal time lags between relevant signals. Several recent NIPS papers propose alternative methods. We first show: problems used to promote various previous algorithms can be solved more quickly by random weight guessing than by the proposed algorithms. We then use LSTM, our own recent algorithm, to solve a hard problem that can neither be quickly solved by random search nor by any other recurrent net algorithm we are aware of.",600회,"LSTM can solve hard long time lag problems
S Hochreiter, J Schmidhuber - Advances in neural information processing systems, 1997
600회 인용 관련 학술자료 전체 15개의 버전",,,,,,,,
DeepTox: toxicity prediction using deep learning,"Andreas Mayr, Günter Klambauer, Thomas Unterthiner, Sepp Hochreiter",2016/2/2,Frontiers in Environmental Science,3,,80,Frontiers,"The Tox21 Data Challenge has been the largest effort of the scientific community to compare computational methods for toxicity prediction. This challenge comprised 12,000 environmental chemicals and drugs which were measured for 12 different toxic effects by specifically designed assays. We participated in this challenge to assess the performance of Deep Learning in computational toxicity prediction. Deep Learning has already revolutionized image processing, speech recognition, and language understanding but has not yet been applied to computational toxicity. Deep Learning is founded on novel algorithms and architectures for artificial neural networks together with the recent availability of very fast computers and massive datasets. It discovers multiple levels of distributed representations of the input, with higher levels representing more abstract concepts. We hypothesized that the construction of a hierarchy of chemical features gives Deep Learning the edge over other toxicity prediction methods. Furthermore, Deep Learning naturally enables multi-task learning, that is, learning of all toxic effects in one neural network and thereby learning of highly informative chemical features. In order to utilize Deep Learning for toxicity prediction, we have developed the DeepTox pipeline. First, DeepTox normalizes the chemical representations of the compounds. Then it computes a large number of chemical descriptors that are used as input to machine learning methods. In its next step, DeepTox trains models, evaluates them, and combines the best of them to ensembles. Finally, DeepTox predicts the toxicity of new compounds. In the Tox21 Data …",433회,"DeepTox: toxicity prediction using deep learning
A Mayr, G Klambauer, T Unterthiner, S Hochreiter - Frontiers in Environmental Science, 2016
433회 인용 관련 학술자료 전체 17개의 버전",,,,,,,,
Flat minima,"Sepp Hochreiter, Jürgen Schmidhuber",1997/1/1,Neural Computation,9,1,1-42,MIT Press,"We present a new algorithm for finding low-complexity neural networks with high generalization capability. The algorithm searches for a “flat” minimum of the error function. A flat minimum is a large connected region in weight space where the error remains approximately constant. An MDL-based, Bayesian argument suggests that flat minima correspond to “simple” networks and low expected overfitting. The argument is based on a Gibbs algorithm variant and a novel way of splitting generalization error into underfitting and overfitting error. Unlike many previous approaches, ours does not require gaussian assumptions and does not depend on a “good” weight prior. Instead we have a prior over input output functions, thus taking into account net architecture and training set. Although our algorithm requires the computation of second-order derivatives, it has backpropagation's order of complexity. Automatically, it …",429회,"Flat minima
S Hochreiter, J Schmidhuber - Neural computation, 1997
429회 인용 관련 학술자료 전체 20개의 버전",,,,,,,,
Learning to learn using gradient descent,"Sepp Hochreiter, A Younger, Peter Conwell",2001,Artificial Neural Networks—ICANN 2001,,,87-94,Springer Berlin/Heidelberg,"This paper introduces the application of gradient descent methods to meta-learning. The concept of “meta-learning”, i.e. of a system that improves or discovers a learning algorithm, has been of interest in machine learning for decades because of its appealing applications. Previous meta-learning approaches have been based on evolutionary methods and, therefore, have been restricted to small models with few free parameters. We make meta-learning in large systems feasible by using recurrent neural networks with their attendant learning routines as meta-learning systems. Our system derived complex well performing learning algorithms from scratch. In this paper we also show that our approach performs non-stationary time series prediction.",409회,"Learning to learn using gradient descent
S Hochreiter, AS Younger, PR Conwell - International Conference on Artificial Neural Networks, 2001
409회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
cn. MOPS: mixture of Poissons for discovering copy number variations in next-generation sequencing data with a low false discovery rate,"Günter Klambauer, Karin Schwarzbauer, Andreas Mayr, Djork-Arné Clevert, Andreas Mitterecker, Ulrich Bodenhofer, Sepp Hochreiter",2012/5/1,Nucleic Acids Research,40,9,e69-e69,Oxford University Press,"Quantitative analyses of next-generation sequencing (NGS) data, such as the detection of copy number variations (CNVs), remain challenging. Current methods detect CNVs as changes in the depth of coverage along chromosomes. Technological or genomic variations in the depth of coverage thus lead to a high false discovery rate (FDR), even upon correction for GC content. In the context of association studies between CNVs and disease, a high FDR means many false CNVs, thereby decreasing the discovery power of the study after correction for multiple testing. We propose ‘Copy Number estimation by a Mixture Of PoissonS’ (cn.MOPS), a data processing pipeline for CNV detection in NGS data. In contrast to previous approaches, cn.MOPS incorporates modeling of depths of coverage across samples at each genomic position. Therefore, cn.MOPS is not affected by read count variations along …",341회,"cn. MOPS: mixture of Poissons for discovering copy number variations in next-generation sequencing data with a low false discovery rate
G Klambauer, K Schwarzbauer, A Mayr, DA Clevert… - Nucleic acids research, 2012
341회 인용 관련 학술자료 전체 24개의 버전
cn. MOPS: Mixture of Poissons for Discovering Copy Number Variations in Next Generation Sequencing Data*
G Klambauer, K Schwarzbauer, A Mayr, DA Clevert… - 2011
관련 학술자료",,,,,,,,
APCluster: an R package for affinity propagation clustering,"Ulrich Bodenhofer, Andreas Kothmeier, Sepp Hochreiter",2011/9/1,Bioinformatics,27,17,2463-2464,Oxford University Press,"Affinity propagation (AP) clustering has recently gained increasing popularity in bioinformatics. AP clustering has the advantage that it allows for determining typical cluster members, the so-called exemplars. We provide an R implementation of this promising new clustering technique to account for the ubiquity of R in bioinformatics. This article introduces the package and presents an application from structural biology. Availability: The R package apcluster is available via CRAN—The Comprehensive R Archive Network: http://cran. r-project. org/web/packages/apcluster Contact: apcluster@ bioinf. jku. at; bodenhofer@ bioinf. jku. at",339회,"APCluster: an R package for affinity propagation clustering
U Bodenhofer, A Kothmeier, S Hochreiter - Bioinformatics, 2011
339회 인용 관련 학술자료 전체 17개의 버전",,,,,,,,
FABIA: factor analysis for bicluster acquisition,"Sepp Hochreiter, Ulrich Bodenhofer, Martin Heusel, Andreas Mayr, Andreas Mitterecker, Adetayo Kasim, Tatsiana Khamiakova, Suzy Van Sanden, Dan Lin, Willem Talloen, Luc Bijnens, Hinrich WH Göhlmann, Ziv Shkedy, Djork-Arné Clevert",2010/6/15,Bioinformatics,26,12,1520-1527,Oxford University Press,"Motivation: Biclustering of transcriptomic data groups genes and samples simultaneously. It is emerging as a standard tool for extracting knowledge from gene expression measurements. We propose a novel generative approach for biclustering called ‘FABIA: Factor Analysis for Bicluster Acquisition’. FABIA is based on a multiplicative model, which accounts for linear dependencies between gene expression and conditions, and also captures heavy-tailed distributions as observed in real-world transcriptomic data. The generative framework allows to utilize well-founded model selection methods and to apply Bayesian techniques.
Results: On 100 simulated datasets with known true, artificially implanted biclusters, FABIA clearly outperformed all 11 competitors. On these datasets, FABIA was able to separate spurious biclusters from true biclusters by ranking biclusters according to their information …",307회,"FABIA: factor analysis for bicluster acquisition
S Hochreiter, U Bodenhofer, M Heusel, A Mayr… - Bioinformatics, 2010
307회 인용 관련 학술자료 전체 34개의 버전",,,,,,,,
A new summarization method for Affymetrix probe level data,"Sepp Hochreiter, Djork-Arne Clevert, Klaus Obermayer",2006/4/15,Bioinformatics,22,8,943-949,Oxford University Press,"Motivation: We propose a new model-based technique for summarizing high-density oligonucleotide array data at probe level for Affymetrix GeneChips. The new summarization method is based on a factor analysis model for which a Bayesian maximum a posteriori method optimizes the model parameters under the assumption of Gaussian measurement noise. Thereafter, the RNA concentration is estimated from the model. In contrast to previous methods our new method called ‘Factor Analysis for Robust Microarray Summarization (FARMS)’ supplies both P-values indicating interesting information and signal intensity values.
Results: We compare FARMS on Affymetrix's spike-in and Gene Logic's dilution data to established algorithms like Affymetrix Microarray Suite (MAS) 5.0, Model Based Expression Index (MBEI), Robust Multi-array Average (RMA). Further, we compared FARMS with 43 …",299회,"A new summarization method for Affymetrix probe level data
S Hochreiter, DA Clevert, K Obermayer - Bioinformatics, 2006
299회 인용 관련 학술자료 전체 22개의 버전",,,,,,,,
GANs Trained by a Two Time-Scale Update Rule Converge to a Nash Equilibrium.,"Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Günter Klambauer, Sepp Hochreiter",2017/1/1,,,,,,"Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the"" Fréchet Inception Distance""(FID) which captures the similarity of generated …",273회,"GANs Trained by a Two Time-Scale Update Rule Converge to a Nash Equilibrium.
M Heusel, H Ramsauer, T Unterthiner, B Nessler… - 2017
273회 인용 관련 학술자료",,,,,,,,
msa: an R package for multiple sequence alignment,"Ulrich Bodenhofer, Enrico Bonatesta, Christoph Horejš-Kainrath, Sepp Hochreiter",2015/12/15,Bioinformatics,31,24,3997-3999,Oxford University Press,"Summary: Although the R platform and the add-on packages of the Bioconductor project are widely used in bioinformatics, the standard task of multiple sequence alignment has been neglected so far. The msa package, for the first time, provides a unified R interface to the popular multiple sequence alignment algorithms ClustalW, ClustalOmega and MUSCLE. The package requires no additional software and runs on all major platforms. Moreover, the msa package provides an R interface to the powerful package shade which allows for flexible and customizable plotting of multiple sequence alignments.
Availability and implementation: msa is available via the Bioconductor project: http://bioconductor.org/packages/release/bioc/html/msa.html. Further information and the R code of the example presented in this paper are available at http://www.bioinf.jku.at/software/msa/.
Contact …",218회,"msa: an R package for multiple sequence alignment
U Bodenhofer, E Bonatesta, C Horejš-Kainrath… - Bioinformatics, 2015
218회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Large-scale comparison of machine learning methods for drug target prediction on ChEMBL,"Andreas Mayr, Günter Klambauer, Thomas Unterthiner, Marvin Steijaert, Jörg K Wegner, Hugo Ceulemans, Djork-Arné Clevert, Sepp Hochreiter",2018,Chemical science,9,24,5441-5451,Royal Society of Chemistry,"Deep learning is currently the most successful machine learning technique in a wide range of application areas and has recently been applied successfully in drug discovery research to predict potential drug targets and to screen for active molecules. However, due to (1) the lack of large-scale studies, (2) the compound series bias that is characteristic of drug discovery datasets and (3) the hyperparameter selection bias that comes with the high number of potential deep learning architectures, it remains unclear whether deep learning can indeed outperform existing computational methods in drug discovery tasks. We therefore assessed the performance of several deep learning methods on a large-scale drug discovery dataset and compared the results with those of other machine learning and target prediction methods. To avoid potential biases from hyperparameter selection or compound series, we used a nested …",201회,"Large-scale comparison of machine learning methods for drug target prediction on ChEMBL
A Mayr, G Klambauer, T Unterthiner, M Steijaert… - Chemical science, 2018
201회 인용 관련 학술자료 전체 21개의 버전",,,,,,,,
Reinforcement driven information acquisition in non-deterministic environments,"Jan Storck, Sepp Hochreiter, Jürgen Schmidhuber",1995/10,"Proceedings of the international conference on artificial neural networks, Paris",2,,159-164,,"For an agent living in a non-deterministic Markov environment (NME), what is, in theory, the fastest way of acquiring information about its statistical properties? The answer is: to design\optimal"" sequences of\experiments"" by performing action sequences that maximize expected information gain. This notion is implemented by combining concepts from information theory and reinforcement learning. Experiments show that the resulting method, reinforcement driven information acquisition, can explore certain NMEs much faster than conventional random exploration.",186회,"Reinforcement driven information acquisition in non-deterministic environments
J Storck, S Hochreiter, J Schmidhuber - Proceedings of the international conference on artificial …, 1995
186회 인용 관련 학술자료 전체 14개의 버전",,,,,,,,
Speeding up semantic segmentation for autonomous driving,"Michael Treml, José Arjona-Medina, Thomas Unterthiner, Rupesh Durgesh, Felix Friedmann, Peter Schuberth, Andreas Mayr, Martin Heusel, Markus Hofmarcher, Michael Widrich, Bernhard Nessler, Sepp Hochreiter",2016/12/9,"MLITS, NIPS Workshop",2,7,,,"Deep learning has considerably improved semantic image segmentation. However, its high accuracy is traded against larger computational costs which makes it unsuitable for embedded devices in self-driving cars. We propose a novel deep network architecture for image segmentation that keeps the high accuracy while being efficient enough for embedded devices. The architecture consists of ELU activation functions, a SqueezeNet-like encoder, followed by parallel dilated convolutions, and a decoder with SharpMask-like refinement modules. On the Cityscapes dataset, the new network achieves higher segmentation accuracy than other networks that are tailored to embedded devices. Simultaneously the frame-rate is still sufficiently high for the deployment in autonomous vehicles.",170회,"Speeding up semantic segmentation for autonomous driving
M Treml, J Arjona-Medina, T Unterthiner, R Durgesh… - MLITS, NIPS Workshop, 2016
170회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Deep learning as an opportunity in virtual screening,"Thomas Unterthiner, Andreas Mayr, Günter Klambauer, Marvin Steijaert, Jörg K Wegner, Hugo Ceulemans, Sepp Hochreiter",2014/12/12,Proceedings of the deep learning workshop at NIPS,27,,1-9,,"Deep learning excels in vision and speech applications where it pushed the stateof-the-art to a new level. However its impact on other fields remains to be shown. The Merck Kaggle challenge on chemical compound activity was won by Hinton’s group with deep networks. This indicates the high potential of deep learning in drug design and attracted the attention of big pharma. However, the unrealistically small scale of the Kaggle dataset does not allow to assess the value of deep learning in drug target prediction if applied to in-house data of pharmaceutical companies. Even a publicly available drug activity data base like ChEMBL is magnitudes larger than the Kaggle dataset. ChEMBL has 13 M compound descriptors, 1.3 M compounds, and 5 k drug targets, compared to the Kaggle dataset with 11 k descriptors, 164 k compounds, and 15 drug targets.
On the ChEMBL database, we compared the performance of deep learning to seven target prediction methods, including two commercial predictors, three predictors deployed by pharma, and machine learning methods that we could scale to this dataset. Deep learning outperformed all other methods with respect to the area under ROC curve and was significantly better than all commercial products. Deep learning surpassed the threshold to make virtual compound screening possible and has the potential to become a standard tool in industrial drug design.",159회,"Deep learning as an opportunity in virtual screening
T Unterthiner, A Mayr, G Klambauer, M Steijaert… - Proceedings of the deep learning workshop at NIPS, 2014
159회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
DeepSynergy: predicting anti-cancer drug synergy with Deep Learning,"Kristina Preuer, Richard PI Lewis, Sepp Hochreiter, Andreas Bender, Krishna C Bulusu, Günter Klambauer",2018/5/1,Bioinformatics,34,9,1538-1546,Oxford University Press,"Motivation
While drug combination therapies are a well-established concept in cancer treatment, identifying novel synergistic combinations is challenging due to the size of combinatorial space. However, computational approaches have emerged as a time- and cost-efficient way to prioritize combinations to test, based on recently available large-scale combination screening data. Recently, Deep Learning has had an impact in many research areas by achieving new state-of-the-art model performance. However, Deep Learning has not yet been applied to drug synergy prediction, which is the approach we present here, termed DeepSynergy. DeepSynergy uses chemical and genomic information as input information, a normalization strategy to account for input data heterogeneity, and conical layers to model drug synergies.
Results
DeepSynergy was compared to other machine …",142회,"DeepSynergy: predicting anti-cancer drug synergy with Deep Learning
K Preuer, RPI Lewis, S Hochreiter, A Bender… - Bioinformatics, 2018
142회 인용 관련 학술자료 전체 18개의 버전",,,,,,,,
I/NI-calls for the exclusion of non-informative genes: a highly effective filtering tool for microarray data,"Willem Talloen, Djork-Arné Clevert, Sepp Hochreiter, Dhammika Amaratunga, Luc Bijnens, Stefan Kass, Hinrich WH Göhlmann",2007/11/1,Bioinformatics,23,21,2897-2902,Oxford University Press,"Motivation: DNA microarray technology typically generates many measurements of which only a relatively small subset is informative for the interpretation of the experiment. To avoid false positive results, it is therefore critical to select the informative genes from the large noisy data before the actual analysis. Most currently available filtering techniques are supervised and therefore suffer from a potential risk of overfitting. The unsupervised filtering techniques, on the other hand, are either not very efficient or too stringent as they may mix up signal with noise. We propose to use the multiple probes measuring the same target mRNA as repeated measures to quantify the signal-to-noise ratio of that specific probe set. A Bayesian factor analysis with specifically chosen prior settings, which models this probe level information, is providing an objective feature filtering technique, named informative/non-informative …",142회,"I/NI-calls for the exclusion of non-informative genes: a highly effective filtering tool for microarray data
W Talloen, DA Clevert, S Hochreiter, D Amaratunga… - Bioinformatics, 2007
142회 인용 관련 학술자료 전체 15개의 버전",,,,,,,,
Fast model-based protein homology detection without alignment,"Sepp Hochreiter, Martin Heusel, Klaus Obermayer",2007/7/15,Bioinformatics,23,14,1728-1736,Oxford University Press,"Motivation: As more genomes are sequenced, the demand for fast gene classification techniques is increasing. To analyze a newly sequenced genome, first the genes are identified and translated into amino acid sequences which are then classified into structural or functional classes. The best-performing protein classification methods are based on protein homology detection using sequence alignment methods. Alignment methods have recently been enhanced by discriminative methods like support vector machines (SVMs) as well as by position-specific scoring matrices (PSSM) as obtained from PSI-BLAST.
However, alignment methods are time consuming if a new sequence must be compared to many known sequences—the same holds for SVMs. Even more time consuming is to construct a PSSM for the new sequence. The best-performing methods would take about 25 days on present-day …",132회,"Fast model-based protein homology detection without alignment
S Hochreiter, M Heusel, K Obermayer - Bioinformatics, 2007
132회 인용 관련 학술자료 전체 17개의 버전",,,,,,,,
Support vector machines for dyadic data,"Sepp Hochreiter, Klaus Obermayer",2006/6,Neural Computation,18,6,1472-1510,MIT Press,"We describe a new technique for the analysis of dyadic data, where two sets of objects (row and column objects) are characterized by a matrix of numerical values that describe their mutual relationships. The new technique, called potential support vector machine (P-SVM), is a large-margin method for the construction of classifiers and regression functions for the column objects. Contrary to standard support vector machine approaches, the P-SVM minimizes a scale-invariant capacity measure and requires a new set of constraints. As a result, the P-SVM method leads to a usually sparse expansion of the classification and regression functions in terms of the row rather than the column objects and can handle data and kernel matrices that are neither positive definite nor square. We then describe two complementary regularization schemes. The first scheme improves generalization performance for classification and …",116회,"Support vector machines for dyadic data
S Hochreiter, K Obermayer - Neural Computation, 2006
116회 인용 관련 학술자료 전체 15개의 버전",,,,,,,,
Repurposing high-throughput image assays enables biological activity prediction for drug discovery,"Jaak Simm, Günter Klambauer, Adam Arany, Marvin Steijaert, Jörg Kurt Wegner, Emmanuel Gustin, Vladimir Chupakhin, Yolanda T Chong, Jorge Vialard, Peter Buijnsters, Ingrid Velter, Alexander Vapirev, Shantanu Singh, Anne E Carpenter, Roel Wuyts, Sepp Hochreiter, Yves Moreau, Hugo Ceulemans",2018/5/17,Cell chemical biology,25,5,611-618. e3,Cell Press,"In both academia and the pharmaceutical industry, large-scale assays for drug discovery are expensive and often impractical, particularly for the increasingly important physiologically relevant model systems that require primary cells, organoids, whole organisms, or expensive or rare reagents. We hypothesized that data from a single high-throughput imaging assay can be repurposed to predict the biological activity of compounds in other assays, even those targeting alternate pathways or biological processes. Indeed, quantitative information extracted from a three-channel microscopy-based screen for glucocorticoid receptor translocation was able to predict assay-specific biological activity in two ongoing drug discovery projects. In these projects, repurposing increased hit rates by 50- to 250-fold over that of the initial project assays while increasing the chemical structure diversity of the hits. Our results suggest that …",111회,"Repurposing high-throughput image assays enables biological activity prediction for drug discovery
J Simm, G Klambauer, A Arany, M Steijaert, JK Wegner… - Cell chemical biology, 2018
111회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
Fast and accurate deep network learning by exponential linear units (elus). arXiv 2015,"Djork-Arné Clevert, Thomas Unterthiner, Sepp Hochreiter",2016,arXiv preprint arXiv:1511.07289,2,,,,,95회,"Fast and accurate deep network learning by exponential linear units (elus). arXiv 2015
DA Clevert, T Unterthiner, S Hochreiter - arXiv preprint arXiv:1511.07289, 2016
95회 인용 관련 학술자료",,,,,,,,
Feature extraction through LOCOCODE,"Sepp Hochreiter, Jürgen Schmidhuber",1999/4/1,Neural Computation,11,3,679-714,MIT Press,"Low-complexity coding and decoding (LOCOCODE) is a novel approach to sensory coding and unsupervised learning. Unlike previous methods, it explicitly takes into account the information-theoretic complexity of the code generator. It computes lococodes that convey information about the input data and can be computed and decoded by low-complexity mappings. We implement LOCOCODE by training autoassociators with flat minimum search, a recent, general method for discovering low-complexity neural nets. It turns out that this approach can unmix an unknown number of independent data sources by extracting a minimal number of low-complexity features necessary for representing the data. Experiments show that unlike codes obtained with standard autoencoders, lococodes are based on feature detectors, never unstructured, usually sparse, and sometimes factorial or local (depending on statistical …",94회,"Feature extraction through LOCOCODE
S Hochreiter, J Schmidhuber - Neural Computation, 1999
94회 인용 관련 학술자료 전체 20개의 버전",,,,,,,,
Prediction of human population responses to toxic compounds by a collaborative competition,"Federica Eduati, Lara M Mangravite, Tao Wang, Hao Tang, J Christopher Bare, Ruili Huang, Thea Norman, Mike Kellen, Michael P Menden, Jichen Yang, Xiaowei Zhan, Rui Zhong, Guanghua Xiao, Menghang Xia, Nour Abdo, Oksana Kosyk, Stephen Friend, Allen Dearry, Anton Simeonov, Raymond R Tice, Ivan Rusyn, Fred A Wright, Gustavo Stolovitzky, Yang Xie, Julio Saez-Rodriguez",2015/9,Nature biotechnology,33,9,933-940,Nature Publishing Group,"The ability to computationally predict the effects of toxic compounds on humans could help address the deficiencies of current chemical safety testing. Here, we report the results from a community-based DREAM challenge to predict toxicities of environmental compounds with potential adverse health effects for human populations. We measured the cytotoxicity of 156 compounds in 884 lymphoblastoid cell lines for which genotype and transcriptional data are available as part of the Tox21 1000 Genomes Project. The challenge participants developed algorithms to predict interindividual variability of toxic response from genomic profiles and population-level cytotoxicity data from structural attributes of the compounds. 179 submitted predictions were evaluated against an experimental data set to which participants were blinded. Individual cytotoxicity predictions were better than random, with modest correlations …",93회,"Prediction of human population responses to toxic compounds by a collaborative competition
F Eduati, LM Mangravite, T Wang, H Tang, JC Bare… - Nature biotechnology, 2015
93회 인용 관련 학술자료 전체 38개의 버전",,,,,,,,
Simplifying neural nets by discovering flat minima,"Sepp Hochreiter, Jiurgen Schmidhuber",1995,Advances in Neural Information Processing Systems,,,529-536,MORGAN KAUFMANN PUBLISHERS,"We present a new algorithm for finding low complexity networks with high generalization capability. The algorithm searches for large connected regions of so-called''fiat''minima of the error function. In the weight-space environment of a"" flat"" minimum, the error remains approximately constant. Using an MDL-based argument, flat minima can be shown to correspond to low expected overfitting. Although our algorithm requires the computation of second order derivatives, it has backprop's order of complexity. Experiments with feedforward and recurrent nets are described. In an application to stock market prediction, the method outperforms conventional backprop, weight decay, and"" optimal brain surgeon"".",91회,"Simplifying neural nets by discovering flat minima
S Hochreiter, J Schmidhuber - Advances in neural information processing systems, 1995
91회 인용 관련 학술자료 전체 15개의 버전",,,,,,,,
Assessing technical performance in differential gene expression experiments with external spike-in RNA control ratio mixtures,,2014/9/25,Nature Communications,5,,,,"There is a critical need for standard approaches to assess, report and compare the technical performance of genome-scale differential gene expression experiments. Here we assess technical performance with a proposed standard ‘dashboard’of metrics derived from analysis of external spike-in RNA control ratio mixtures. These control ratio mixtures with defined abundance ratios enable assessment of diagnostic performance of differentially expressed transcript lists, limit of detection of ratio (LODR) estimates and expression ratio variability and measurement bias. The performance metrics suite is applicable to analysis of a typical experiment, and here we also apply these metrics to evaluate technical performance among laboratories. An interlaboratory study using identical samples shared among 12 laboratories with three different measurement processes demonstrates generally consistent diagnostic power …",88회,"Assessing technical performance in differential gene expression experiments with external spike-in RNA control ratio mixtures
SA Munro, SP Lund, PS Pine, H Binder, DA Clevert… - Nature communications, 2014
88회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
Toxicity prediction using deep learning,"Thomas Unterthiner, Andreas Mayr, Günter Klambauer, Sepp Hochreiter",2015/3/4,arXiv preprint arXiv:1503.01445,,,,,"Everyday we are exposed to various chemicals via food additives, cleaning and cosmetic products and medicines--and some of them might be toxic. However testing the toxicity of all existing compounds by biological experiments is neither financially nor logistically feasible. Therefore the government agencies NIH, EPA and FDA launched the Tox21 Data Challenge within the"" Toxicology in the 21st Century""(Tox21) initiative. The goal of this challenge was to assess the performance of computational methods in predicting the toxicity of chemical compounds. State of the art toxicity prediction methods build upon specifically-designed chemical descriptors developed over decades. Though Deep Learning is new to the field and was never applied to toxicity prediction before, it clearly outperformed all other participating methods. In this application paper we show that deep nets automatically learn features resembling well-established toxicophores. In total, our Deep Learning approach won both of the panel-challenges (nuclear receptors and stress response) as well as the overall Grand Challenge, and thereby sets a new standard in tox prediction.",77회,"Toxicity prediction using deep learning
T Unterthiner, A Mayr, G Klambauer, S Hochreiter - arXiv preprint arXiv:1503.01445, 2015
77회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Fréchet ChemNet distance: a metric for generative models for molecules in drug discovery,"Kristina Preuer, Philipp Renz, Thomas Unterthiner, Sepp Hochreiter, Günter Klambauer",2018/8/17,Journal of chemical information and modeling,58,9,1736-1741,American Chemical Society,"The new wave of successful generative models in machine learning has increased the interest in deep learning driven de novo drug design. However, method comparison is difficult because of various flaws of the currently employed evaluation metrics. We propose an evaluation metric for generative models called Fréchet ChemNet distance (FCD). The advantage of the FCD over previous metrics is that it can detect whether generated molecules are diverse and have similar chemical and biological properties as real molecules.",75회,"Fréchet ChemNet distance: a metric for generative models for molecules in drug discovery
K Preuer, P Renz, T Unterthiner, S Hochreiter… - Journal of chemical information and modeling, 2018
75회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Rudder: Return decomposition for delayed rewards,"Jose A Arjona-Medina, Michael Gillhofer, Michael Widrich, Thomas Unterthiner, Johannes Brandstetter, Sepp Hochreiter",2018/6/20,arXiv preprint arXiv:1806.07857,,,,,"We propose RUDDER, a novel reinforcement learning approach for delayed rewards in finite Markov decision processes (MDPs). In MDPs the Q-values are equal to the expected immediate reward plus the expected future rewards. The latter are related to bias problems in temporal difference (TD) learning and to high variance problems in Monte Carlo (MC) learning. Both problems are even more severe when rewards are delayed. RUDDER aims at making the expected future rewards zero, which simplifies Q-value estimation to computing the mean of the immediate reward. We propose the following two new concepts to push the expected future rewards toward zero.(i) Reward redistribution that leads to return-equivalent decision processes with the same optimal policies and, when optimal, zero expected future rewards.(ii) Return decomposition via contribution analysis which transforms the reinforcement learning task into a regression task at which deep learning excels. On artificial tasks with delayed rewards, RUDDER is significantly faster than MC and exponentially faster than Monte Carlo Tree Search (MCTS), TD ({\lambda}), and reward shaping approaches. At Atari games, RUDDER on top of a Proximal Policy Optimization (PPO) baseline improves the scores, which is most prominent at games with delayed rewards. Source code is available at\url {this https URL} and demonstration videos at\url {this https URL}.",74회,"Rudder: Return decomposition for delayed rewards
JA Arjona-Medina, M Gillhofer, M Widrich, T Unterthiner… - arXiv preprint arXiv:1806.07857, 2018
74회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Using transcriptomics to guide lead optimization in drug discovery projects: Lessons learned from the QSTAR project,"Bie Verbist, Günter Klambauer, Liesbet Vervoort, Willem Talloen, Ziv Shkedy, Olivier Thas, Andreas Bender, Hinrich WH Göhlmann, Sepp Hochreiter, QSTAR Consortium",2015/5/1,,20,5,505-513,Elsevier Current Trends,"The pharmaceutical industry is faced with steadily declining R&D efficiency which results in fewer drugs reaching the market despite increased investment. A major cause for this low efficiency is the failure of drug candidates in late-stage development owing to safety issues or previously undiscovered side-effects. We analyzed to what extent gene expression data can help to de-risk drug development in early phases by detecting the biological effects of compounds across disease areas, targets and scaffolds. For eight drug discovery projects within a global pharmaceutical company, gene expression data were informative and able to support go/no-go decisions. Our studies show that gene expression profiling can detect adverse effects of compounds, and is a valuable tool in early-stage drug discovery decision making.",72회,"Using transcriptomics to guide lead optimization in drug discovery projects: Lessons learned from the QSTAR project
B Verbist, G Klambauer, L Vervoort, W Talloen… - Drug discovery today, 2015
72회 인용 관련 학술자료 전체 16개의 버전",,,Drug discovery today,,,,,
"Towards learning universal, regional, and local hydrological behaviors via machine learning applied to large-sample datasets","Frederik Kratzert, Daniel Klotz, Guy Shalev, Günter Klambauer, Sepp Hochreiter, Grey Nearing",2019/12/17,Hydrology and Earth System Sciences,23,12,5089-5110,Copernicus GmbH,"Regional rainfall–runoff modeling is an old but still mostly outstanding problem in the hydrological sciences. The problem currently is that traditional hydrological models degrade significantly in performance when calibrated for multiple basins together instead of for a single basin alone. In this paper, we propose a novel, data-driven approach using Long Short-Term Memory networks (LSTMs) and demonstrate that under a “big data” paradigm, this is not necessarily the case. By training a single LSTM model on 531 basins from the CAMELS dataset using meteorological time series data and static catchment attributes, we were able to significantly improve performance compared to a set of several different hydrological benchmark models. Our proposed approach not only significantly outperforms hydrological models that were calibrated regionally, but also achieves better performance than hydrological models that were calibrated for each basin individually. Furthermore, we propose an adaption to the standard LSTM architecture, which we call an Entity-Aware-LSTM (EA-LSTM), that allows for learning catchment similarities as a feature layer in a deep learning model. We show that these learned catchment similarities correspond well to what we would expect from prior hydrological understanding.",69회,"Towards learning universal, regional, and local hydrological behaviors via machine learning applied to large-sample datasets
F Kratzert, D Klotz, G Shalev, G Klambauer… - Hydrology and Earth System Sciences, 2019
69회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Toward improved predictions in ungauged basins: Exploiting the power of machine learning,"Frederik Kratzert, Daniel Klotz, Mathew Herrnegger, Alden K Sampson, Sepp Hochreiter, Grey S Nearing",2019/12,Water Resources Research,55,12,11344-11354,,"Long short‐term memory (LSTM) networks offer unprecedented accuracy for prediction in ungauged basins. We trained and tested several LSTMs on 531 basins from the CAMELS data set using k‐fold validation, so that predictions were made in basins that supplied no training data. The training and test data set included ∼30 years of daily rainfall‐runoff data from catchments in the United States ranging in size from 4 to 2,000 km2 with aridity index from 0.22 to 5.20, and including 12 of the 13 IGPB vegetated land cover classifications. This effectively “ungauged” model was benchmarked over a 15‐year validation period against the Sacramento Soil Moisture Accounting (SAC‐SMA) model and also against the NOAA National Water Model reanalysis. SAC‐SMA was calibrated separately for each basin using 15 years of daily data. The out‐of‐sample LSTM had higher median Nash‐Sutcliffe Efficiencies across the …",61회,"Toward improved predictions in ungauged basins: Exploiting the power of machine learning
F Kratzert, D Klotz, M Herrnegger, AK Sampson… - Water Resources Research, 2019
61회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
A field guide to dynamical recurrent neural networks,"Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, Jürgen Schmidhuber, JF Kolen, SC Kremer",2001,chapter Gradient Flow in Recurrent Nets: The Difficulty of Learning Long-Term Dependencies,,,237-243,Wiley-IEEE Press,,56회,"A field guide to dynamical recurrent neural networks
S Hochreiter, Y Bengio, P Frasconi, J Schmidhuber… - chapter Gradient Flow in Recurrent Nets: The Difficulty …, 2001
56회 인용 관련 학술자료",,,,,,,,
Recurrent neural net learning and vanishing gradient,Sepp Hochreiter,1998/11,"International Journal Of Uncertainity, Fuzziness and Knowledge-Based Systems",6,2,107-116,,"Recurrent nets are in principle capable to store past inputs to produce the currently desired output. This recurrent net property is used in time series prediction and process control. Practical applications involve temporal dependencies spanning many time steps between relevant inputs and desired outputs. In this case, however, gradient descent learning methods take to much time. The learning time problem appears because the error vanishes as it gets propagated back. The decaying error ow is theoretically analyzed. Then methods trying to overcome vanishing gradient are mentioned. Finally, experiments comparing conventional algorithms and alternative methods are presented. Experiments using advanced methods show that learning long time lags problems can be done in reasonable time.",53회,"Recurrent neural net learning and vanishing gradient
S Hochreiter - International Journal Of Uncertainity, Fuzziness and …, 1998
53회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Coulomb GANs: Provably optimal nash equilibria via potential fields,"Thomas Unterthiner, Bernhard Nessler, Calvin Seward, Günter Klambauer, Martin Heusel, Hubert Ramsauer, Sepp Hochreiter",2017/8/29,arXiv preprint arXiv:1708.08819,,,,,"Generative adversarial networks (GANs) evolved into one of the most successful unsupervised techniques for generating realistic images. Even though it has recently been shown that GAN training converges, GAN models often end up in local Nash equilibria that are associated with mode collapse or otherwise fail to model the target distribution. We introduce Coulomb GANs, which pose the GAN learning problem as a potential field of charged particles, where generated samples are attracted to training set samples but repel each other. The discriminator learns a potential field while the generator decreases the energy by moving its samples along the vector (force) field determined by the gradient of the potential field. Through decreasing the energy, the GAN model learns to generate samples according to the whole target distribution and does not only cover some of its modes. We prove that Coulomb GANs possess only one Nash equilibrium which is optimal in the sense that the model distribution equals the target distribution. We show the efficacy of Coulomb GANs on a variety of image datasets. On LSUN and celebA, Coulomb GANs set a new state of the art and produce a previously unseen variety of different samples.",51회,"Coulomb GANs: Provably optimal nash equilibria via potential fields
T Unterthiner, B Nessler, C Seward, G Klambauer… - arXiv preprint arXiv:1708.08819, 2017
51회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Bridging Long Time Lags by Weight Guessing and “Long Short Term Memory”,FL Silva,1997,Spatiotemporal models in biological and artificial systems,37,,65,IOS Press,"Numerous recent papers (including many NIPS papers) focus on standard recurrent nets' inability to deal with long time lags between relevant input signals and teacher signals. Rather sophisticated, alternative methods were proposed. We first show: problems used to promote certain algorithms in numerous previous papers can be solved more quickly by random weight guessing than by the proposed algo-rithms. This does not mean that guessing is a good algorithm. It just casts doubt on whether the other algorithms are, or whether the chosen problems are meaningful. We then use long short term memory (LSTM), our own recent algorithm, to solve hard problems that can neither be quickly solved by random weight guessing nor by any other recurrent net algorithm we are aware of.",48회,"Bridging Long Time Lags by Weight Guessing and “Long Short Term Memory”
FL Silva - Spatiotemporal models in biological and artificial …, 1997
48회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
Bridging long time lags by weight guessing and Long Short-Term Memory,"Sepp Hochreiter, Jürgen Schmidhuber",1996,Spatiotemporal models in biological and artificial systems,37,,65-72,,,48회,"Bridging Long Time Lags by Weight Guessing and “Long Short Term Memory”*
FL Silva - Spatiotemporal models in biological and artificial …, 1997
48회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
Interpretable deep learning in drug discovery,"Kristina Preuer, Günter Klambauer, Friedrich Rippmann, Sepp Hochreiter, Thomas Unterthiner",2019,,,,331-345,"Springer, Cham","Without any means of interpretation, neural networks that predict molecular properties and bioactivities are merely black boxes. We will unravel these black boxes and will demonstrate approaches to understand the learned representations which are hidden inside these models. We show how single neurons can be interpreted as classifiers which determine the presence or absence of pharmacophore- or toxicophore-like structures, thereby generating new insights and relevant knowledge for chemistry, pharmacology and biochemistry. We further discuss how these novel pharmacophores/toxicophores can be determined from the network by identifying the most relevant components of a compound for the prediction of the network. Additionally, we propose a method which can be used to extract new pharmacophores from a model and will show that these extracted structures are consistent with literature findings. We …",47회,"Interpretable deep learning in drug discovery
K Preuer, G Klambauer, F Rippmann, S Hochreiter… - Explainable AI: Interpreting, Explaining and Visualizing …, 2019
47회 인용 관련 학술자료 전체 8개의 버전",,"Explainable AI: Interpreting, Explaining and Visualizing Deep Learning",,,,,,
Furby: fuzzy force-directed bicluster visualization,"Marc Streit, Samuel Gratzl, Michael Gillhofer, Andreas Mayr, Andreas Mitterecker, Sepp Hochreiter",2014/5,BMC bioinformatics,15,6,1-13,BioMed Central,"Cluster analysis is widely used to discover patterns in multi-dimensional data. Clustered heatmaps are the standard technique for visualizing one-way and two-way clustering results. In clustered heatmaps, rows and/or columns are reordered, resulting in a representation that shows the clusters as contiguous blocks. However, for biclustering results, where clusters can overlap, it is not possible to reorder the matrix in this way without duplicating rows and/or columns. We present Furby, an interactive visualization technique for analyzing biclustering results. Our contribution is twofold. First, the technique provides an overview of a biclustering result, showing the actual data that forms the individual clusters together with the information which rows and columns they share. Second, for fuzzy clustering results, the proposed technique additionally enables analysts to interactively set the thresholds that transform the fuzzy …",45회,"Furby: fuzzy force-directed bicluster visualization
M Streit, S Gratzl, M Gillhofer, A Mayr, A Mitterecker… - BMC bioinformatics, 2014
45회 인용 관련 학술자료 전체 21개의 버전",,,,,,,,
Meta-learning with backpropagation,"A Steven Younger, Sepp Hochreiter, Peter R Conwell",2001/7/15,,3,,,IEEE,"Introduces gradient descent methods applied to meta-learning (learning how to learn) in neural networks. Meta-learning has been of interest in the machine learning field for decades because of its appealing applications to intelligent agents, non-stationary time series, autonomous robots, and improved learning algorithms. Many previous neural network-based approaches toward meta-learning have been based on evolutionary methods. We show how to use gradient descent for meta-learning in recurrent neural networks. Based on previous work on fixed-weight learning neural networks, we hypothesize that any recurrent network topology and its corresponding learning algorithm(s) is a potential meta-learning system. We tested several recurrent neural network topologies and their corresponding forms of backpropagation for their ability to meta-learn. One of our systems, based on the long short-term memory …",45회,"Meta-learning with backpropagation
AS Younger, S Hochreiter, PR Conwell - IJCNN'01. International Joint Conference on Neural …, 2001
45회 인용 관련 학술자료 전체 11개의 버전",IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No. 01CH37222),,,,,,,
panelcn. MOPS: Copy‐number detection in targeted NGS panel data for clinical diagnostics,"Gundula Povysil, Antigoni Tzika, Julia Vogt, Verena Haunschmid, Ludwine Messiaen, Johannes Zschocke, Günter Klambauer, Sepp Hochreiter, Katharina Wimmer",2017/7,Human mutation,38,7,889-897,,"Targeted next‐generation‐sequencing (NGS) panels have largely replaced Sanger sequencing in clinical diagnostics. They allow for the detection of copy‐number variations (CNVs) in addition to single‐nucleotide variants and small insertions/deletions. However, existing computational CNV detection methods have shortcomings regarding accuracy, quality control (QC), incidental findings, and user‐friendliness. We developed panelcn.MOPS, a novel pipeline for detecting CNVs in targeted NGS panel data. Using data from 180 samples, we compared panelcn.MOPS with five state‐of‐the‐art methods. With panelcn.MOPS leading the field, most methods achieved comparably high accuracy. panelcn.MOPS reliably detected CNVs ranging in size from part of a region of interest (ROI), to whole genes, which may comprise all ROIs investigated in a given sample. The latter is enabled by analyzing reads from all ROIs of …",44회,"panelcn. MOPS: Copy‐number detection in targeted NGS panel data for clinical diagnostics
G Povysil, A Tzika, J Vogt, V Haunschmid, L Messiaen… - Human mutation, 2017
44회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Complex networks govern coiled-coil oligomerization–predicting and profiling by means of a machine learning approach,"Carsten C Mahrenholz, Ingrid G Abfalter, Ulrich Bodenhofer, Rudolf Volkmer, Sepp Hochreiter",2011/5/1,Molecular & Cellular Proteomics,10,5,M110. 004994,Elsevier,"Understanding the relationship between protein sequence and structure is one of the great challenges in biology. In the case of the ubiquitous coiled-coil motif, structure and occurrence have been described in extensive detail, but there is a lack of insight into the rules that govern oligomerization, i.e. how many α-helices form a given coiled coil. To shed new light on the formation of two- and three-stranded coiled coils, we developed a machine learning approach to identify rules in the form of weighted amino acid patterns. These rules form the basis of our classification tool, PrOCoil, which also visualizes the contribution of each individual amino acid to the overall oligomeric tendency of a given coiled-coil sequence. We discovered that sequence positions previously thought irrelevant to direct coiled-coil interaction have an undeniable impact on stoichiometry. Our rules also demystify the oligomerization behavior of …",44회,"Complex networks govern coiled-coil oligomerization–predicting and profiling by means of a machine learning approach
CC Mahrenholz, IG Abfalter, U Bodenhofer, R Volkmer… - Molecular & Cellular Proteomics, 2011
44회 인용 관련 학술자료 전체 17개의 버전",,,,,,,,
An SMO algorithm for the potential support vector machine,"Tilman Knebel, Sepp Hochreiter, Klaus Obermayer",2008/1,Neural computation,20,1,271-287,MIT Press,"We describe a fast sequential minimal optimization (SMO) procedure for solving the dual optimization problem of the recently proposed potential support vector machine (P-SVM). The new SMO consists of a sequence of iteration steps in which the Lagrangian is optimized with respect to either one (single SMO) or two (dual SMO) of the Lagrange multipliers while keeping the other variables fixed. An efficient selection procedure for Lagrange multipliers is given, and two heuristics for improving the SMO procedure are described: block optimization and annealing of the regularization parameter ε. A comparison of the variants shows that the dual SMO, including block optimization and annealing, performs efficiently in terms of computation time. In contrast to standard support vector machines (SVMs), the P-SVM is applicable to arbitrary dyadic data sets, but benchmarks are provided against libSVM's ε-SVR and C-SVC …",40회,"An SMO algorithm for the potential support vector machine
T Knebel, S Hochreiter, K Obermayer - Neural computation, 2008
39회 인용 관련 학술자료 전체 20개의 버전
OBERMA gER K*
T KNEBEL, S HOCHREITER - An SMO
2회 인용 관련 학술자료",,,,,,,,
Hopfield networks is all you need,"Hubert Ramsauer, Bernhard Schäfl, Johannes Lehner, Philipp Seidl, Michael Widrich, Thomas Adler, Lukas Gruber, Markus Holzleitner, Milena Pavlović, Geir Kjetil Sandve, Victor Greiff, David Kreil, Michael Kopp, Günter Klambauer, Johannes Brandstetter, Sepp Hochreiter",2020/7/16,arXiv preprint arXiv:2008.02217,,,,,"We introduce a modern Hopfield network with continuous states and a corresponding update rule. The new Hopfield network can store exponentially (with the dimension of the associative space) many patterns, retrieves the pattern with one update, and has exponentially small retrieval errors. It has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. The new update rule is equivalent to the attention mechanism used in transformers. This equivalence enables a characterization of the heads of transformer models. These heads perform in the first layers preferably global averaging and in higher layers partial averaging via metastable states. The new modern Hopfield network can be integrated into deep learning architectures as layers to allow the storage of and access to raw input data, intermediate results, or learned prototypes. These Hopfield layers enable new ways of deep learning, beyond fully-connected, convolutional, or recurrent networks, and provide pooling, memory, association, and attention mechanisms. We demonstrate the broad applicability of the Hopfield layers across various domains. Hopfield layers improved state-of-the-art on three out of four considered multiple instance learning problems as well as on immune repertoire classification with several hundreds of thousands of instances. On the UCI benchmark collections of small classification tasks, where deep learning methods typically struggle, Hopfield layers yielded a new state-of-the-art when compared to different …",36회,"Hopfield networks is all you need
H Ramsauer, B Schäfl, J Lehner, P Seidl, M Widrich… - arXiv preprint arXiv:2008.02217, 2020
36회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Guessing can outperform many long time lag algorithms,"Jürgen Schmidhuber, Sepp Hochreiter",1996,,,,,,"Numerous recent papers focus on standard recurrent nets' problems with long time lags between relevant signals. Some propose rather sophisticated, alternative methods. We show: many problems used to test previous methods can be solved more quickly by random weight guessing.",36회,"Guessing can outperform many long time lag algorithms
J Schmidhuber, S Hochreiter - 1996
36회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Accurate prediction of biological assays with high-throughput microscopy images and convolutional networks,"Markus Hofmarcher, Elisabeth Rumetshofer, Djork-Arne Clevert, Sepp Hochreiter, Günter Klambauer",2019/3/6,Journal of chemical information and modeling,59,3,1163-1171,American Chemical Society,"Predicting the outcome of biological assays based on high-throughput imaging data is a highly promising task in drug discovery since it can tremendously increase hit rates and suggest novel chemical scaffolds. However, end-to-end learning with convolutional neural networks (CNNs) has not been assessed for the task biological assay prediction despite the success of these networks at visual recognition. We compared several CNNs trained directly on high-throughput imaging data to a) CNNs trained on cell-centric crops and to b) the current state-of-the-art: fully connected networks trained on precalculated morphological cell features. The comparison was performed on the Cell Painting data set, the largest publicly available data set of microscopic images of cells with approximately 30,000 compound treatments. We found that CNNs perform significantly better at predicting the outcome of assays than fully …",31회,"Accurate prediction of biological assays with high-throughput microscopy images and convolutional networks
M Hofmarcher, E Rumetshofer, DA Clevert… - Journal of chemical information and modeling, 2019
31회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Explaining and interpreting LSTMs,"Leila Arras, José Arjona-Medina, Michael Widrich, Grégoire Montavon, Michael Gillhofer, Klaus-Robert Müller, Sepp Hochreiter, Wojciech Samek",2019,,,,211-238,"Springer, Cham","While neural networks have acted as a strong unifying force in the design of modern AI systems, the neural network architectures themselves remain highly heterogeneous due to the variety of tasks to be solved. In this chapter, we explore how to adapt the Layer-wise Relevance Propagation (LRP) technique used for explaining the predictions of feed-forward networks to the LSTM architecture used for sequential data modeling and forecasting. The special accumulators and gated interactions present in the LSTM require both a new propagation scheme and an extension of the underlying theoretical framework to deliver faithful explanations.",31회,"Explaining and interpreting LSTMs
L Arras, J Arjona-Medina, M Widrich, G Montavon… - Explainable ai: Interpreting, explaining and visualizing …, 2019
31회 인용 관련 학술자료 전체 8개의 버전",,"Explainable ai: Interpreting, explaining and visualizing deep learning",,,,,,
Filtering data from high-throughput experiments based on measurement reliability,"Willem Talloen, Sepp Hochreiter, Luc Bijnens, Adetayo Kasim, Ziv Shkedy, Dhammika Amaratunga, Hinrich Göhlmann",2010/11/16,Proceedings of the National Academy of Sciences,107,46,E173-E174,National Academy of Sciences,"In the context of the plethora of data currently generated in molecular biology, the paper by Bourgon et al. in PNAS (1) is pivotal, because it shows that an initial data filter can appropriately increase the detection power of a high-throughput experiment. Bourgon et al.(1) showed that filtering on overall variance outperforms filtering on overall mean, but they do not address two weaknesses of the methodology. First, because filtering is done on the overall variance, it does not disentangle the biological variation (containing the potentially interesting signals) from the technical variation (ie, the measurement noise). Second, the threshold choice when the overall variation should be considered too low is very arbitrary and makes the method subjective (2). Filtering on reliability alleviates both problems. Furthermore, filtering on reliability will typically remove more irrelevant genes compared with overall variance filtering …",31회,"Filtering data from high-throughput experiments based on measurement reliability
W Talloen, S Hochreiter, L Bijnens, A Kasim, Z Shkedy… - Proceedings of the National Academy of Sciences, 2010
31회 인용 관련 학술자료 전체 17개의 버전",,,,,,,,
LOCOCODE performs nonlinear ICA without knowing the number of sources,"Sepp Hochreiter, Jürgen Schmidhuber",1999/1,Proceedings of the ICA,99,,149,,"Low-complexity coding and decoding (Lococode), a novel approach to sensory coding, trains autoassociators (AAs) by Flat Minimum Search (FMS), a recent general method for nding low-complexity networks with high generalization capability. FMS works by minimizing both training error and required weight precision. We nd that as a by-product Lococode separates nonlinear superpositions of sources without knowing their number. Assuming that the input data can be reduced to few simple causes (this is often the case with visual data), according to our theoretical analysis the hidden layer of an FMS-trained AA tends to code each input by a sparse code based on as few simple, independent features as possible. In experiments Lococode extracts optimal codes for di cult, nonlinear versions of the\noisy bars"" benchmark problem, while traditional ICA and PCA do not.",31회,"LOCOCODE performs nonlinear ICA without knowing the number of sources
S Hochreiter, J Schmidhuber - Proceedings of the ICA, 1999
23회 인용 관련 학술자료 전체 8개의 버전
Lococode*
S Hochreiter, J Schmidhuber - 1997
10회 인용 관련 학술자료
Technical Report FKI-222-97 (revised)*
S Hochreiter, J Schmidhuber
관련 학술자료
Feature extraction through LOCOCODE Technical Report FKI-222-97 (revised)*
S Hochreiter, J urgen Schmidhuber
관련 학술자료 전체 8개의 버전",,,,,,,,
HapFABIA: identification of very short segments of identity by descent characterized by rare variants in large sequencing data,Sepp Hochreiter,2013/12/1,Nucleic acids research,41,22,e202-e202,Oxford University Press,"Identity by descent (IBD) can be reliably detected for long shared DNA segments, which are found in related individuals. However, many studies contain cohorts of unrelated individuals that share only short IBD segments. New sequencing technologies facilitate identification of short IBD segments through rare variants, which convey more information on IBD than common variants. Current IBD detection methods, however, are not designed to use rare variants for the detection of short IBD segments. Short IBD segments reveal genetic structures at high resolution. Therefore, they can help to improve imputation and phasing, to increase genotyping accuracy for low-coverage sequencing and to increase the power of association studies. Since short IBD segments are further assumed to be old, they can shed light on the evolutionary history of humans. We propose HapFABIA, a computational method that applies …",30회,"HapFABIA: identification of very short segments of identity by descent characterized by rare variants in large sequencing data
S Hochreiter - Nucleic acids research, 2013
30회 인용 관련 학술자료 전체 14개의 버전",,,,,,,,
DEXUS: identifying differential expression in RNA-Seq studies with unknown conditions,"Günter Klambauer, Thomas Unterthiner, Sepp Hochreiter",2013/11/1,Nucleic acids research,41,21,e198-e198,Oxford University Press,"Detection of differential expression in RNA-Seq data is currently limited to studies in which two or more sample conditions are known a priori. However, these biological conditions are typically unknown in cohort, cross-sectional and nonrandomized controlled studies such as the HapMap, the ENCODE or the 1000 Genomes project. We present DEXUS for detecting differential expression in RNA-Seq data for which the sample conditions are unknown. DEXUS models read counts as a finite mixture of negative binomial distributions in which each mixture component corresponds to a condition. A transcript is considered differentially expressed if modeling of its read counts requires more than one condition. DEXUS decomposes read count variation into variation due to noise and variation due to differential expression. Evidence of differential expression is measured by the informative/noninformative (I/NI) value …",30회,"DEXUS: identifying differential expression in RNA-Seq studies with unknown conditions
G Klambauer, T Unterthiner, S Hochreiter - Nucleic acids research, 2013
30회 인용 관련 학술자료 전체 13개의 버전",,,,,,,,
Applied biclustering methods for big and high-dimensional data using R,"Adetayo Kasim, Ziv Shkedy, Sebastian Kaiser, Sepp Hochreiter, Willem Talloen",2016/10/3,,,,,CRC Press,"Proven Methods for Big Data Analysis As big data has become standard in many application areas, challenges have arisen related to methodology and software development, including how to discover meaningful patterns in the vast amounts of data. Addressing these problems, Applied Biclustering Methods for Big and High-Dimensional Data Using R shows how to apply biclustering methods to find local patterns in a big data matrix. The book presents an overview of data analysis using biclustering methods from a practical point of view. Real case studies in drug discovery, genetics, marketing research, biology, toxicity, and sports illustrate the use of several biclustering methods. References to technical details of the methods are provided for readers who wish to investigate the full theoretical background. All the methods are accompanied with R examples that show how to conduct the analyses. The examples, software, and other materials are available on a supplementary website.",29회,"Applied biclustering methods for big and high-dimensional data using R
A Kasim, Z Shkedy, S Kaiser, S Hochreiter, W Talloen - 2016
29회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
cn. FARMS: a latent variable model to detect copy number variations in microarray data with a low false discovery rate,"Djork-Arné Clevert, Andreas Mitterecker, Andreas Mayr, Günter Klambauer, Marianne Tuefferd, An De Bondt, Willem Talloen, Hinrich Göhlmann, Sepp Hochreiter",2011/7/1,Nucleic acids research,39,12,e79-e79,Oxford University Press,"Cost-effective oligonucleotide genotyping arrays like the Affymetrix SNP 6.0 are still the predominant technique to measure DNA copy number variations (CNVs). However, CNV detection methods for microarrays overestimate both the number and the size of CNV regions and, consequently, suffer from a high false discovery rate (FDR). A high FDR means that many CNVs are wrongly detected and therefore not associated with a disease in a clinical study, though correction for multiple testing takes them into account and thereby decreases the study's discovery power. For controlling the FDR, we propose a probabilistic latent variable model, ‘cn.FARMS’, which is optimized by a Bayesian maximum a posteriori approach. cn.FARMS controls the FDR through the information gain of the posterior over the prior. The prior represents the null hypothesis of copy number 2 for all samples from which the posterior …",29회,"cn. FARMS: a latent variable model to detect copy number variations in microarray data with a low false discovery rate
DA Clevert, A Mitterecker, A Mayr, G Klambauer… - Nucleic Acids Research, 2011
28회 인용 관련 학술자료 전체 16개의 버전
cn. FARMS: a probabilistic model to detect DNA copy numbers*
DA Clevert, A Mitterecker, A Mayr, R Burger… - Nature Precedings, 2010
1회 인용 관련 학술자료 전체 13개의 버전",,,,,,,,
KeBABS: an R package for kernel-based analysis of biological sequences,"Johannes Palme, Sepp Hochreiter, Ulrich Bodenhofer",2015/8/1,Bioinformatics,31,15,2574-2576,Oxford University Press,"Summary: KeBABS provides a powerful, flexible and easy to use framework for kernel-based analysis of biological sequences in R. It includes efficient implementations of the most important sequence kernels, also including variants that allow for taking sequence annotations and positional information into account. KeBABS seamlessly integrates three common support vector machine (SVM) implementations with a unified interface. It allows for hyperparameter selection by cross validation, nested cross validation and also features grouped cross validation. The biological interpretation of SVM models is supported by (1) the computation of weights of sequence patterns and (2) prediction profiles that highlight the contributions of individual sequence positions or sections.
Availability and implementation: The R package kebabs is available via the Bioconductor project: http://bioconductor.org …",28회,"KeBABS: an R package for kernel-based analysis of biological sequences
J Palme, S Hochreiter, U Bodenhofer - Bioinformatics, 2015
28회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
Gene Selection for Microarray Data,"Sepp Hochreiter, Klaus Obermayer",2004/8/1,Kernel methods in computational biology,,,319,MIT Press,"Gene expression profiles obtained by the microarray technique provide a snapshot of the expression values of up to some 10000 genes in a particular tissue sample. The advantage of the microarray method—namely to monitor a large number of variables of a cell's (or a piece of tissue's) state, however, often turns out to be difficult to exploit. The number of samples is small and the level of noise is high, which makes it difficult to detect the small number of genes relevant to the task at hand. Therefore, specific gene selection methods must be designed to reliably extract relevant genes.",28회,"15 Gene Selection for Microarray Data
S Hochreiter, K Obermayer - Kernel methods in computational biology, 2004
24회 인용 관련 학술자료 전체 6개의 버전
Kernel Methods in Computational Biology, chapter Gene Selection for Microarray Data*
S Hochreiter, K Obermayer - Eds.: Schölkopf B., Tsuda K. and Vert J.-P., MIT Press …, 2004
4회 인용 관련 학술자료",,,,,,,,
Nonlinear feature selection with the potential support vector machine,"Sepp Hochreiter, Klaus Obermayer",2006,Feature Extraction,,,419-438,Springer Berlin/Heidelberg,"We describe the “Potential Support Vector Machine” (P-SVM) which is a new filter method for feature selection. The idea of the P-SVM feature selection is to exchange the role of features and data points in order to construct “support features”. The “support features” are the selected features. The P-SVM uses a novel objective function and novel constraints — one constraint for each feature. As with standard SVMs, the objective function represents a complexity or capacity measure whereas the constraints enforce low empirical error. In this contribution we extend the P-SVM in two directions. First, we introduce a parameter which controls the redundancy among the selected features. Secondly, we propose a nonlinear version of the P-SVM feature selection which is based on neural network techniques. Finally, the linear and nonlinear P-SVM feature selection approach is demonstrated on toy data sets and on …",26회,"Nonlinear feature selection with the potential support vector machine
S Hochreiter, K Obermayer - Feature Extraction, 2006
24회 인용 관련 학술자료 전체 13개의 버전
Nonlinear Feature Selection with the Potential Support Vector Machine*
H Sepp, O Klaus, I Guyon, S Gunn, M Nikrav - Feature extraction, Foundations and Applications, 2004
2회 인용 관련 학술자료",,,,,,,,
Feature selection and classification on matrix data: From large margins to small covering numbers,"Sepp Hochreiter, Klaus Obermayer",2002,Advances in Neural Information Processing Systems,15,,889-896,,"We investigate the problem of learning a classification task for datasets which are described by matrices. Rows and columns of these matrices correspond to objects, where row and column objects may belong to different sets, and the entries in the matrix express the relationships between them. We interpret the matrix elements as being produced by an unknown kernel which operates on object pairs and we show that-under mild assumptions-these kernels correspond to dot products in some (unknown) feature space. Minimizing a bound for the generalization error of a linear classifier which has been obtained using covering numbers we derive an objective function for model selection according to the principle of structural risk minimization. The new objective function has the advantage that it allows the analysis of matrices which are not positive definite, and not even symmetric or square. We then consider the case that row objects are interpreted as features. We suggest an additional constraint, which imposes sparseness on the row objects and show, that the method can then be used for feature selection. Finally, we apply this method to data obtained from DNA microarrays, where “column” objects correspond to samples,“row” objects correspond to genes and matrix elements correspond to expression levels. Benchmarks are conducted using standard one-gene classification and support vector machines and K-nearest neighbors after standard feature selection. Our new method extracts a sparse set of genes and provides superior classification results.",26회,"Classification, regression, and feature selection on matrix data*
S Hochreiter, K Obermayer - 2004
15회 인용 관련 학술자료 전체 10개의 버전
Feature selection and classification on matrix data: From large margins to small covering numbers
S Hochreiter, K Obermayer - Advances in Neural Information Processing Systems, 2002
8회 인용 관련 학술자료 전체 12개의 버전
Feature selection and matrix data*
S Hochreiter, K Obermayer - Technical Report, Technische Universität Berlin, 2003
3회 인용 관련 학술자료
Classification and feature selection on matrix data with application to gene-expression analysis*
S Hochreiter, K Obermayer - 54th Session of the International Statistical Institute, 2003
1회 인용 관련 학술자료 전체 8개의 버전
Potential Support Vector Machines for Matrix Data Supplement: Significance Tests*
S Hochreiter, K Obermayer - 2004
관련 학술자료
Classification, Regression, and Feature Selection on Matrix Data*
SHK Obermayer, SHK Obermayer, HBSHK Obermayer… - 54",,,,,,,,
Neuralhydrology–interpreting lstms in hydrology,"Frederik Kratzert, Mathew Herrnegger, Daniel Klotz, Sepp Hochreiter, Günter Klambauer",2019,,,,347-362,"Springer, Cham","Despite the huge success of Long Short-Term Memory networks, their applications in environmental sciences are scarce. We argue that one reason is the difficulty to interpret the internals of trained networks. In this study, we look at the application of LSTMs for rainfall-runoff forecasting, one of the central tasks in the field of hydrology, in which the river discharge has to be predicted from meteorological observations. LSTMs are particularly well-suited for this problem since memory cells can represent dynamic reservoirs and storages, which are essential components in state-space modelling approaches of the hydrological system. On basis of two different catchments, one with snow influence and one without, we demonstrate how the trained model can be analyzed and interpreted. In the process, we show that the network internally learns to represent patterns that are consistent with our qualitative understanding of …",24회,"Neuralhydrology–interpreting lstms in hydrology
F Kratzert, M Herrnegger, D Klotz, S Hochreiter… - Explainable ai: Interpreting, explaining and visualizing …, 2019
24회 인용 관련 학술자료 전체 5개의 버전",,"Explainable ai: Interpreting, explaining and visualizing deep learning",,,,,,
Large-scale ligand-based virtual screening for SARS-CoV-2 inhibitors using deep neural networks,"Markus Hofmarcher, Andreas Mayr, Elisabeth Rumetshofer, Peter Ruch, Philipp Renz, Johannes Schimunek, Philipp Seidl, Andreu Vall, Michael Widrich, Sepp Hochreiter, Günter Klambauer",2020/3/23,Available at SSRN 3561442,,,,,"Due to the current severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic, there is an urgent need for novel therapies and drugs. We conducted a large-scale virtual screening for small molecules that are potential CoV-2 inhibitors. To this end, we utilized ChemAI, a deep neural network trained on more than 220M data points across 3.6 M molecules from three public drug-discovery databases. With ChemAI, we screened and ranked one billion molecules from the ZINC database for favourable effects against CoV-2. We then reduced the result to the 30,000 top-ranked compounds, which are readily accessible and purchasable via the ZINC database. We provide these top-ranked compounds as a library for further screening with bioassays at https://github. com/ml-jku/sars-cov-inhibitors-chemai.",21회,"Large-scale ligand-based virtual screening for SARS-CoV-2 inhibitors using deep neural networks
M Hofmarcher, A Mayr, E Rumetshofer, P Ruch, P Renz… - Available at SSRN 3561442, 2020
21회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Benchmarking a catchment-aware long short-term memory network (LSTM) for large-scale hydrological modeling,"Frederik Kratzert, Daniel Klotz, Guy Shalev, Günter Klambauer, Sepp Hochreiter, Grey Nearing",2019/7,Hydrology and Earth System Sciences Discussions,,,1-32,,"Regional rainfall-runoff modeling is an old but still mostly out-standing problem in Hydrological Sciences. The problem currently is that traditional hydrological models degrade significantly in performance when calibrated for multiple basins together instead of for a single basin alone. In this paper, we propose a novel, data-driven approach using Long Short-Term Memory networks (LSTMs), and demonstrate that under a’big data’paradigm, this is not necessarily the case. By training a single LSTM model on 531 basins from the CAMELS data set using meteorological time series data and static catchment 5 attributes, we were able to significantly improve performance compared to a set of several different hydrological benchmark models. Our proposed approach not only significantly outperforms hydrological models that were calibrated regionally but also achieves better performance than hydrological models that were calibrated for each basin individually. Furthermore, we propose an adaption to the standard LSTM architecture, which we call an Entity-Aware-LSTM (EA-LSTM), that allows for learning, and embedding as a feature layer in a deep learning model, catchment similarities. We show that this learned catchment 10 similarity corresponds well with what we would expect from prior hydrological understanding.",20회,"Benchmarking a catchment-aware long short-term memory network (LSTM) for large-scale hydrological modeling
F Kratzert, D Klotz, G Shalev, G Klambauer… - Hydrology and Earth System Sciences Discussions, 2019
20회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Recurrent neural networks,"Jurgen Schmidhuber, A Graves, F Gomez, S Hochreiter",2015,URL http://people. idsia. ch/~ juergen/rnn. html,,,,,,20회,"Recurrent neural networks
J Schmidhuber, A Graves, F Gomez, S Hochreiter - URL http://people. idsia. ch/~ juergen/rnn. html, 2015
20회 인용 관련 학술자료",,,,,,,,
Coulomb classifiers: Generalizing support vector machines via an analogy to electrostatic systems,"Sepp Hochreiter, Michael C Mozer, Klaus Obermayer",2003,Advances in neural information processing systems,,,561-568,MIT; 1998,"We introduce a family of classifiers based on a physical analogy to an electrostatic system of charged conductors. The family, called Coulomb classifiers, includes the two best-known support-vector machines (SVMs), the ν–SVM and the C–SVM. In the electrostatics analogy, a training example corresponds to a charged conductor at a given location in space, the classification function corresponds to the electrostatic potential function, and the training objective function corresponds to the Coulomb energy. The electrostatic framework provides not only a novel interpretation of existing algorithms and their interrelationships, but it suggests a variety of new methods for SVMs including kernels that bridge the gap between polynomial and radial-basis functions, objective functions that do not require positive-definite kernels, regularization techniques that allow for the construction of an optimal classifier in Minkowski space. Based on the framework, we propose novel SVMs and perform simulation studies to show that they are comparable or superior to standard SVMs. The experiments include classification tasks on data which are represented in terms of their pairwise proximities, where a Coulomb Classifier outperformed standard SVMs.",19회,"Coulomb classifiers: Generalizing support vector machines via an analogy to electrostatic systems
S Hochreiter, MC Mozer, K Obermayer - Advances in neural information processing systems, 2003
16회 인용 관련 학술자료 전체 12개의 버전
Coulomb classifiers: Reinterpreting SVMs as electrostatic systems*
S Hochreiter, MC Mozer - 2001
7회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Patch Refinement--Localized 3D Object Detection,"Johannes Lehner, Andreas Mitterecker, Thomas Adler, Markus Hofmarcher, Bernhard Nessler, Sepp Hochreiter",2019/10/9,arXiv preprint arXiv:1910.04093,,,,,"We introduce Patch Refinement a two-stage model for accurate 3D object detection and localization from point cloud data. Patch Refinement is composed of two independently trained Voxelnet-based networks, a Region Proposal Network (RPN) and a Local Refinement Network (LRN). We decompose the detection task into a preliminary Bird's Eye View (BEV) detection step and a local 3D detection step. Based on the proposed BEV locations by the RPN, we extract small point cloud subsets ("" patches""), which are then processed by the LRN, which is less limited by memory constraints due to the small area of each patch. Therefore, we can apply encoding with a higher voxel resolution locally. The independence of the LRN enables the use of additional augmentation techniques and allows for an efficient, regression focused training as it uses only a small fraction of each scene. Evaluated on the KITTI 3D object detection benchmark, our submission from January 28, 2019, outperformed all previous entries on all three difficulties of the class car, using only 50% of the available training data and only LiDAR information.",18회,"Patch Refinement--Localized 3D Object Detection
J Lehner, A Mitterecker, T Adler, M Hofmarcher… - arXiv preprint arXiv:1910.04093, 2019
18회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Rectified factor networks,"Djork-Arné Clevert, Andreas Mayr, Thomas Unterthiner, Sepp Hochreiter",2015/2/23,arXiv preprint arXiv:1502.06464,,,,,"We propose rectified factor networks (RFNs) to efficiently construct very sparse, non-linear, high-dimensional representations of the input. RFN models identify rare and small events in the input, have a low interference between code units, have a small reconstruction error, and explain the data covariance structure. RFN learning is a generalized alternating minimization algorithm derived from the posterior regularization method which enforces non-negative and normalized posterior means. We proof convergence and correctness of the RFN learning algorithm. On benchmarks, RFNs are compared to other unsupervised methods like autoencoders, RBMs, factor analysis, ICA, and PCA. In contrast to previous sparse coding methods, RFNs yield sparser codes, capture the data's covariance structure more precisely, and have a significantly smaller reconstruction error. We test RFNs as pretraining technique for deep networks on different vision datasets, where RFNs were superior to RBMs and autoencoders. On gene expression data from two pharmaceutical drug discovery studies, RFNs detected small and rare gene modules that revealed highly relevant new biological insights which were so far missed by other unsupervised methods.",18회,"Rectified factor networks
DA Clevert, A Mayr, T Unterthiner, S Hochreiter - arXiv preprint arXiv:1502.06464, 2015
18회 인용 관련 학술자료 전체 17개의 버전",,,,,,,,
Informative or noninformative calls for gene expression: a latent variable approach,"Adetayo Kasim, Dan Lin, Suzy Van Sanden, Djork-Arné Clevert, Luc Bijnens, Hinrich Göhlmann, Dhammika Amaratunga, Sepp Hochreiter, Ziv Shkedy, Willem Talloen",2010/1/6,Statistical applications in genetics and molecular biology,9,1,,De Gruyter,"The strength and weakness of microarray technology can be attributed to the enormous amount of information it is generating. To fully enhance the benefit of microarray technology for testing differentially expressed genes and classification, there is a need to minimize the amount of irrelevant genes present in microarray data. A major interest is to use probe-level data to call genes informative or noninformative based on the trade-off between the array-to-array variability and the measurement error. Existing works in this direction include filtering likely uninformative sets of hybridization (FLUSH; Calza et al., 2007) and I/NI calls for the exclusion of noninformative genes using FARMS (I/NI calls; Talloen et al., 2007; Hochreiter et al., 2006). In this paper, we propose a linear mixed model as a more flexible method that performs equally good as I/NI calls and outperforms FLUSH. We also introduce other criteria for gene …",18회,"Informative or noninformative calls for gene expression: a latent variable approach
A Kasim, D Lin, S Van Sanden, DA Clevert, L Bijnens… - Statistical applications in genetics and molecular …, 2010
18회 인용 관련 학술자료 전체 19개의 버전",,,,,,,,
Informative or noninformative calls for gene expression: a latent variable approach,"Adetayo Kasim, Dan Lin, Suzy Van Sanden, Djork-Arné Clevert, Luc Bijnens, Hinrich Göhlmann, Dhammika Amaratunga, Sepp Hochreiter, Ziv Shkedy, Willem Talloen",2010/1/6,Statistical applications in genetics and molecular biology,9,1,,De Gruyter,"The strength and weakness of microarray technology can be attributed to the enormous amount of information it is generating. To fully enhance the benefit of microarray technology for testing differentially expressed genes and classification, there is a need to minimize the amount of irrelevant genes present in microarray data. A major interest is to use probe-level data to call genes informative or noninformative based on the trade-off between the array-to-array variability and the measurement error. Existing works in this direction include filtering likely uninformative sets of hybridization (FLUSH; Calza et al., 2007) and I/NI calls for the exclusion of noninformative genes using FARMS (I/NI calls; Talloen et al., 2007; Hochreiter et al., 2006). In this paper, we propose a linear mixed model as a more flexible method that performs equally good as I/NI calls and outperforms FLUSH. We also introduce other criteria for gene …",18회,"Informative or noninformative calls for gene expression: a latent variable approach
A Kasim, D Lin, S Van Sanden, DA Clevert, L Bijnens… - Statistical applications in genetics and molecular …, 2010
18회 인용 관련 학술자료 전체 19개의 버전",,,,,,,,
Informative or noninformative calls for gene expression: a latent variable approach,"Adetayo Kasim, Dan Lin, Suzy Van Sanden, Djork-Arné Clevert, Luc Bijnens, Hinrich Göhlmann, Dhammika Amaratunga, Sepp Hochreiter, Ziv Shkedy, Willem Talloen",2010/1/6,Statistical applications in genetics and molecular biology,9,1,4,Berkeley Electronic Press,"The strength and weakness of microarray technology can be attributed to the enormous amount of information it is generating. To fully enhance the benefit of microarray technology for testing differentially expressed genes and classification, there is a need to minimize the amount of irrelevant genes present in microarray data. A major interest is to use probe-level data to call genes informative or noninformative based on the trade-off between the array-to-array variability and the measurement error. Existing works in this direction include filtering likely uninformative sets of hybridization (FLUSH; Calza et al., 2007) and I/NI calls for the exclusion of noninformative genes using FARMS (I/NI calls; Talloen et al., 2007; Hochreiter et al., 2006). In this paper, we propose a linear mixed model as a more flexible method that performs equally good as I/NI calls and outperforms FLUSH. We also introduce other criteria for gene …",18회,"Informative or noninformative calls for gene expression: a latent variable approach
A Kasim, D Lin, S Van Sanden, DA Clevert, L Bijnens… - Statistical applications in genetics and molecular …, 2010
18회 인용 관련 학술자료 전체 19개의 버전",,,,,,,,
Unsupervised coding with lococode,"Sepp Hochreiter, Jürgen Schmidhuber",1997,Artificial Neural Networks—ICANN'97,,,655-660,Springer Berlin/Heidelberg,"Traditional approaches to sensory coding use code component-oriented objective functions (COCOFs) to evaluate code quality. Previous COCOFs do not take into account the information-theoretic complexity of the code-generating mapping itself. We do: “Low-complexity coding and decoding” (LOCOCODE) generates so-called lococodes that (1) convey information about the input data, (2) can be computed from the data by a low-complexity mapping (LCM), and (3) can be decoded by a LCM. We implement LococoDE by training autoassociators with Flat Minimum Search (FMS), a general method for finding lowcomplexity neural nets. LococoDE extracts optimal codes for difficult versions of the “bars” benchmark problem. As a preprocessor for a vowel recognition benchmark problem it sets the stage for excellent classification performance.",17회,"Unsupervised coding with lococode
S Hochreiter, J Schmidhuber - International Conference on Artificial Neural Networks, 1997
14회 인용 관련 학술자료 전체 15개의 버전
Lococode versus PCA and ICA*
S Hochreiter, J Schmidhuber - International Conference on Artificial Neural Networks, 1998
7회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
Machine learning in drug discovery,"Günter Klambauer, Sepp Hochreiter, Matthias Rarey",2019/3/25,,59,3,945-946,American Chemical Society,"QSAR. Despite this long tradition, machine learning methods gained substantial momentum recently triggered by the success of deep learning in many application areas. 1 A wide range of tasks in modeling and cheminformatics have been influenced by machine learning, such as chemical synthesis planing 2 and library design, 3 bioactivity and toxicity prediction, 4 and virtual screening. 5, 6 Machine learning methods are no more restricted to traditional data types, such as compounds and protein sequences, but also extend to protein structures, imaging, textual, and transcriptomics data. We are pleased to see that the works included in this special issue reflect this variety of tasks, data types, and methods. From the methodological point of view, the most notable effect is the tendency toward deep learning and deep neural networks. In a large majority of papers, a deep neural network is used as the central machine …",16회,"Machine learning in drug discovery
G Klambauer, S Hochreiter, M Rarey - 2019
16회 인용 관련 학술자료 전체 6개의 버전",,,Journal of chemical information and modeling,,,,,
Machine learning in drug discovery,"Sepp Hochreiter, Guenter Klambauer, Matthias Rarey",2018/8/15,,58,9,1723-1724,American Chemical Society,"Currently, machine learning methods drive the success of artificial intelligence in academia and industry. Among machine learning methods, Deep Learning has emerged as a game-changer in many fields and has already impacted a wide range of scientific areas. 1 Deep Learning is founded on novel algorithms and architectures together with the recent availability of very fast computers and massive data sets. In its core, Deep Learning discovers multiple levels of distributed representations of the input, with higher levels representing more abstract concepts. These representations considerably improved data analysis in many research areas. In particular, deep neural networks (DNNs) substantially increased the performance in computer vision, speech recognition, among many other fields. Surprisingly, models developed in a number of fields have reached human performance or above. Nevertheless, the risk of …",16회,"Machine learning in drug discovery
S Hochreiter, G Klambauer, M Rarey - 2018
16회 인용 관련 학술자료 전체 4개의 버전",,,Journal of chemical information and modeling,,,,,
Monaural separation and classification of mixed signals: A support-vector regression perspective,"Sepp Hochreiter, Michael C Mozer",2001/12/9,"3rd International Conference on Independent Component Analysis and Blind Signal Separation, San Diego, CA",,,,,"We address the problem of extracting multiple independent sources from a single mixture signal. Standard independentcomponent analysis approaches fail when the number of sources is greater than the number of mixtures. For this case, the sparse-decomposition method [1] has been proposed. The method relies on a dictionary of atomic signals and recovers the degree to which various dictionary atoms are present in the mixture. We show that the sparse-decomposition method is equivalent to a form of support-vector regression (SVR). The training inputs for the SVR are the dictionary atoms, and the corresponding targets are the dot product of the mixture and atom vectors. The SVR perspective provides a new interpretation of the sparse-decomposition method’s hyperparameter, and allows us to generalize and improve the method. The most important insight is that the sources do not have to be identical to dictionary atoms, but rather we can accommodate a many-to-one mapping of source signals to dictionary atoms—a classification of sorts—characterized by a known nonlinear transformation with unknown parameters. The limitation of the SVR perspective is that it cannot recover the signal strength of an atom in the mixture; rather, it can only recover whether or not a particular atom was present. In experiments, we show that our model can handle difficult problems involving classification of sources. Our model may be particularly useful for speech signal processing and CDMA-based mobile communication, where in both cases we have knowledge about the invariances in the signal.",16회,"Monaural separation and classification of mixed signals: A support-vector regression perspective
S Hochreiter, MC Mozer - … Conference on Independent Component Analysis and …, 2001
16회 인용 관련 학술자료 전체 14개의 버전
Monaural Separation and Classification of Non-Linear Transformed Independent Signals: An SVM Perspective*
S Hochreiter, MC Mozer
관련 학술자료 전체 9개의 버전",,,,,,,,
"Rchemcpp: a web service for structural analoging in ChEMBL, Drugbank and the Connectivity Map","Günter Klambauer, Martin Wischenbart, Michael Mahr, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter",2015/10/15,Bioinformatics,31,20,3392-3394,Oxford University Press,"Summary: We have developed Rchempp, a web service that identifies structurally similar compounds (structural analogs) in large-scale molecule databases. The service allows compounds to be queried in the widely used ChEMBL, DrugBank and the Connectivity Map databases. Rchemcpp utilizes the best performing similarity functions, i.e. molecule kernels, as measures for structural similarity. Molecule kernels have proven superior performance over other similarity measures and are currently excelling at machine learning challenges. To considerably reduce computational time, and thereby make it feasible as a web service, a novel efficient prefiltering strategy has been developed, which maintains the sensitivity of the method. By exploiting information contained in public databases, the web service facilitates many applications crucial for the drug development process, such as prioritizing compounds …",15회,"Rchemcpp: a web service for structural analoging in ChEMBL, Drugbank and the Connectivity Map
G Klambauer, M Wischenbart, M Mahr, T Unterthiner… - Bioinformatics, 2015
15회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Multi-task deep networks for drug target prediction,"Thomas Unterthiner, Andreas Mayr, Günter Klambauer, Marvin Steijaert, Jörg K Wegner, Hugo Ceulemans, Sepp Hochreiter",2014,Neural Information Processing System,2014,,1-4,NeurIPS,"An important computational tool in drug design is target prediction where either for a given chemical structure the interacting biomolecules (eg proteins) must be identified. Chemical structures interact with different biomolecules if they have similar 3D structure. Thus, the outputs of the prediction are highly interdependent from each other. Furthermore, we have partially labelled molecules since not all training molecules are measured of being active on each biomolecule. The Merck Kaggle challenge on chemical compound activity was won by Hinton’s group with deep networks. This indicates the high potential of deep learning in drug design and attracted the attention of big pharma. However, the unrealistically small scale of the Kaggle dataset does not allow to assess the value of deep learning in drug target prediction if applied to in-house data of pharmaceutical companies. Even a publicly available drug activity data base like ChEMBL is magnitudes larger than the Kaggle dataset. ChEMBL has 13 M compound descriptors, 1.3 M compounds, and 5 k drug targets, compared to the Kaggle dataset with 11 k descriptors, 164 k compounds, and 15 drug targets. On the ChEMBL database, we compared the performance of deep learning to seven target prediction methods, including two commercial predictors, three predictors deployed by pharma, and machine learning methods that we could scale to this dataset. Deep learning outperformed all other methods with respect to the area under ROC curve and was significantly better than all commercial products. Deep learning surpassed the threshold to make virtual compound screening possible and has …",15회,"Multi-task deep networks for drug target prediction
T Unterthiner, A Mayr, G Klambauer, M Steijaert… - Neural Information Processing System, 2014
15회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Genome-wide chromatin remodeling identified at GC-rich long nucleosome-free regions,"Karin Schwarzbauer, Ulrich Bodenhofer, Sepp Hochreiter",2012/11/5,PloS one,7,11,e47924,Public Library of Science,"To gain deeper insights into principles of cell biology, it is essential to understand how cells reorganize their genomes by chromatin remodeling. We analyzed chromatin remodeling on next generation sequencing data from resting and activated T cells to determine a whole-genome chromatin remodeling landscape. We consider chromatin remodeling in terms of nucleosome repositioning which can be observed most robustly in long nucleosome-free regions (LNFRs) that are occupied by nucleosomes in another cell state. We found that LNFR sequences are either AT-rich or GC-rich, where nucleosome repositioning was observed much more prominently in GC-rich LNFRs — a considerable proportion of them outside promoter regions. Using support vector machines with string kernels, we identified a GC-rich DNA sequence pattern indicating loci of nucleosome repositioning in resting T cells. This pattern appears to be also typical for CpG islands. We found out that nucleosome repositioning in GC-rich LNFRs is indeed associated with CpG islands and with binding sites of the CpG-island-binding ZF-CXXC proteins KDM2A and CFP1. That this association occurs prominently inside and also prominently outside of promoter regions hints at a mechanism governing nucleosome repositioning that acts on a whole-genome scale.",15회,"Genome-wide chromatin remodeling identified at GC-rich long nucleosome-free regions
K Schwarzbauer, U Bodenhofer, S Hochreiter - PloS one, 2012
15회 인용 관련 학술자료 전체 17개의 버전",,,,,,,,
Long short-term memory. 1997,"Sepp Hochreiter, Jürgen Schmidhuber",,Neural computation,9,8,,,,15회,"Long short-term memory. 1997
S Hochreiter, J Schmidhuber - Neural computation
15회 인용 관련 학술자료",,,,,,,,
ELU-networks: fast and accurate CNN learning on imagenet,"Martin Heusel, Djork-Arné Clevert, Günter Klambauer, Andreas Mayr, Karin Schwarzbauer, Thomas Unterthiner, Sepp Hochreiter",2015,NiN,8,,35-68,,"We trained a CNN on the ImageNet dataset with a new activation function, called"" exponential linear unit""(ELU)[1], to speed up learning.
Like rectified linear units (ReLUs)[2, 3], leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs also avoid a vanishing gradient via the identity for positive values. However ELUs have improved learning characteristics compared to the other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero. Zero means speed up learning because they bring the gradient closer to the unit natural gradient. Like batch normalization, ELUs push the mean towards zero, but with a significantly smaller computational footprint. While other activation functions like LReLUs and PReLUs also have negative values, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller …",14회,"ELU-networks: fast and accurate CNN learning on imagenet
M Heusel, DA Clevert, G Klambauer, A Mayr… - NiN, 2015
14회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Deep learning for drug target prediction,"Thomas Unterthiner, Andreas Mayr, Günter Klambauer, Marvin Steijaert, Jörg K Wegner, Hugo Ceulemans, Sepp Hochreiter",2014,Work. Represent. Learn. Methods complex outputs,,,,,"An important computational tool in drug design is target prediction where either for a given chemical structure the interacting biomolecules (eg proteins) must be identified. Chemical structures interact with different biomolecules if they have similar 3D structure. Thus, the outputs of the prediction are highly interdependent from each other. Furthermore, we have partially labelled molecules since not all training molecules are measured of being active on each biomolecule. The Merck Kaggle challenge on chemical compound activity was won by Hinton’s group with deep networks. This indicates the high potential of deep learning in drug design and attracted the attention of big pharma. However, the unrealistically small scale of the Kaggle dataset does not allow to assess the value of deep learning in drug target prediction if applied to in-house data of pharmaceutical companies. Even a publicly available drug activity data base like ChEMBL is magnitudes larger than the Kaggle dataset. ChEMBL has 13 M compound descriptors, 1.3 M compounds, and 5 k drug targets, compared to the Kaggle dataset with 11 k descriptors, 164 k compounds, and 15 drug targets. On the ChEMBL database, we compared the performance of deep learning to seven target prediction methods, including two commercial predictors, three predictors deployed by pharma, and machine learning methods that we could scale to this dataset. Deep learning outperformed all other methods with respect to the area under ROC curve and was significantly better than all commercial products. Deep learning surpassed the threshold to make virtual compound screening possible and has …",14회,"Deep learning for drug target prediction
T Unterthiner, A Mayr, G Klambauer, M Steijaert… - Work. Represent. Learn. Methods complex outputs, 2014
14회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
A note on leveraging synergy in multiple meteorological data sets with deep learning for rainfall–runoff modeling,"Frederik Kratzert, Daniel Klotz, Sepp Hochreiter, Grey S Nearing",2021/5/20,Hydrology and Earth System Sciences,25,5,2685-2703,Copernicus GmbH,"A deep learning rainfall–runoff model can take multiple meteorological forcing products as input and learn to combine them in spatially and temporally dynamic ways. This is demonstrated with Long Short-Term Memory networks (LSTMs) trained over basins in the continental US, using the Catchment Attributes and Meteorological data set for Large Sample Studies (CAMELS). Using meteorological input from different data products (North American Land Data Assimilation System, NLDAS, Maurer, and Daymet) in a single LSTM significantly improved simulation accuracy relative to using only individual meteorological products. A sensitivity analysis showed that the LSTM combines precipitation products in different ways, depending on location, and also in different ways for the simulation of different parts of the hydrograph.",13회,"A note on leveraging synergy in multiple meteorological data sets with deep learning for rainfall–runoff modeling
F Kratzert, D Klotz, S Hochreiter, GS Nearing - Hydrology and Earth System Sciences, 2021
13회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Human-level protein localization with convolutional neural networks,"Elisabeth Rumetshofer, Markus Hofmarcher, Clemens Röhrl, Sepp Hochreiter, Günter Klambauer",2018/9/27,,,,,,"Localizing a specific protein in a human cell is essential for understanding cellular functions and biological processes of underlying diseases. A promising, low-cost, and time-efficient biotechnology for localizing proteins is high-throughput fluorescence microscopy imaging (HTI). This imaging technique stains the protein of interest in a cell with fluorescent antibodies and subsequently takes a microscopic image. Together with images of other stained proteins or cell organelles and the annotation by the Human Protein Atlas project, these images provide a rich source of information on the protein location which can be utilized by computational methods. It is yet unclear how precise such methods are and whether they can compete with human experts. We here focus on deep learning image analysis methods and, in particular, on Convolutional Neural Networks (CNNs) since they showed overwhelming success across different imaging tasks. We pro-pose a novel CNN architecture “GapNet-PL” that has been designed to tackle the characteristics of HTI data and uses global averages of filters at different abstraction levels. We present the largest comparison of CNN architectures including GapNet-PL for protein localization in HTI images of human cells. GapNet-PL outperforms all other competing methods and reaches close to perfect localization in all 13 tasks with an average AUC of 98% and F1 score of 78%. On a separate test set the performance of GapNet-PL was compared with three human experts and 25 scholars. GapNet-PL achieved an accuracy of 91%, significantly (p-value 1.1 e− 6) outperforming the best human expert with an accuracy of …",13회,"Human-level protein localization with convolutional neural networks
E Rumetshofer, M Hofmarcher, C Röhrl, S Hochreiter… - International conference on learning representations, 2018
13회 인용 관련 학술자료 전체 3개의 버전",International conference on learning representations,,,,,,,
EVALUATING BENCHMARK PROBLEMS BY RANDOM GUESSING,"Jürgen Schmidhuber, Sepp Hochreiter, Yoshua Bengio",2001,,,,,,"Numerous recent papers focus on standard recurrent networks’ problems with tasks involving long-term dependencies. In this chapter we will solve such tasks by random weight guessing (RG). Although RG cannot be viewed as a reasonable learning algorithm we find that it often outperforms previous,",12회,"Evaluating benchmark problems by random guessing
J Schmidhuber, S Hochreiter, Y Bengio - A Field Guide to Dynamical Recurrent Networks, 2001
12회 인용 관련 학술자료 전체 6개의 버전
EVALUATING LONG-TERM DEPENDENCY BENCHMARK PROBLEMS BY RANDOM GUESSING
J urgen Schmidhuber, C Elvezia, S Hochreiter… - 1997
관련 학술자료 전체 5개의 버전",,,,,,,,
Low-complexity coding and decoding,"Sepp Hochreiter, Jürgen Schmidhuber",1997,"Theoretical aspects of neural computation (TANC 97), Hong Kong",,,297-306,,"We present a novel approach to sensory coding and unsupervised learning. It is called\Low-complexity coding and decoding""(Lococode). Unlike previous methods it explicitly takes into account the information-theoretic complexity of the code generator: lococodes (1) convey information about the input data and (2) can be computed and decoded by low-complexity mappings. To implement Lococode we train autoassociators with Flat Minimum Search, a recent method for discovering neural nets that can be described with few bits of information. Experiments show: unlike codes obtained with standard autoencoders, lococodes are based on familiar feature detectors, never unstructured, usually sparse, sometimes factorial or local (depending on the data). Unlike, eg, independent component analysis (ICA) Lococode does not need to know the number of independent data sources.",12회,"Low-complexity coding and decoding
S Hochreiter, J Schmidhuber - Theoretical aspects of neural computation (TANC 97) …, 1997
12회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Untersuchungen zu dynamischen neuronalen Netzen [in German] Diploma thesis,Sepp Hochreiter,1991,TU Münich,,,,,,12회,"Untersuchungen zu dynamischen neuronalen Netzen [in German] Diploma thesis
S Hochreiter - TU Münich, 1991
12회 인용 관련 학술자료",,,,,,,,
Visual scene understanding for autonomous driving using semantic segmentation,"Markus Hofmarcher, Thomas Unterthiner, José Arjona-Medina, Günter Klambauer, Sepp Hochreiter, Bernhard Nessler",2019,,,,285-296,"Springer, Cham","Deep neural networks are an increasingly important technique for autonomous driving, especially as a visual perception component. Deployment in a real environment necessitates the explainability and inspectability of the algorithms controlling the vehicle. Such insightful explanations are relevant not only for legal issues and insurance matters but also for engineers and developers in order to achieve provable functional quality guarantees. This applies to all scenarios where the results of deep networks control potentially life threatening machines. We suggest the use of a tiered approach, whose main component is a semantic segmentation model, over an end-to-end approach for an autonomous driving system. In order for a system to provide meaningful explanations for its decisions it is necessary to give an explanation about the semantics that it attributes to the complex sensory inputs that it perceives. In the …",11회,"Visual scene understanding for autonomous driving using semantic segmentation
M Hofmarcher, T Unterthiner, J Arjona-Medina… - Explainable AI: Interpreting, Explaining and Visualizing …, 2019
11회 인용 관련 학술자료 전체 4개의 버전",,"Explainable AI: Interpreting, Explaining and Visualizing Deep Learning",,,,,,
An electric field approach to independent component analysis,"Sepp Hochreiter, M Mozer",2000,Proc. Int. Workshop on Independent Component Analysis and Blind Signal Separation (ICA2000),,,45-50,,"We propose a novel algorithm for Independent Component Analysis (ICA) that is based on an electric eld metaphor. As with all ICA techniques, the algorithm searches for a demixing model that produces components whose joint distribution matches the factorial distribution (ie, the product of the marginal distributions). The joint and factorial distributions are represented as positively and negatively charged particles, respectively, and the dynamics of the search are based on the interactions among particles. The algorithm can deal with arbitrary distributions for the sources, nonlinear mixing functions, noisy observations, and an unequal number of source and mixture components. The limitation of the algorithm is that it does not scale with the number of sources. Nonetheless, we demonstrate that the algorithm can solve challenging ICA problems that are beyond the capabilities of other ICA methods.",11회,"An electric field approach to independent component analysis
S Hochreiter, MC Mozer - IN PROC. INT. WORKSHOP ON INDEPENDENT …, 2000
11회 인용 관련 학술자료",,,,,,,,
Modern hopfield networks and attention for immune repertoire classification,"Michael Widrich, Bernhard Schäfl, Hubert Ramsauer, Milena Pavlović, Lukas Gruber, Markus Holzleitner, Johannes Brandstetter, Geir Kjetil Sandve, Victor Greiff, Sepp Hochreiter, Günter Klambauer",2020/7/16,arXiv preprint arXiv:2007.13505,,,,,"A central mechanism in machine learning is to identify, store, and recognize patterns. How to learn, access, and retrieve such patterns is crucial in Hopfield networks and the more recent transformer architectures. We show that the attention mechanism of transformer architectures is actually the update rule of modern Hopfield networks that can store exponentially many patterns. We exploit this high storage capacity of modern Hopfield networks to solve a challenging multiple instance learning (MIL) problem in computational biology: immune repertoire classification. Accurate and interpretable machine learning methods solving this problem could pave the way towards new vaccines and therapies, which is currently a very relevant research topic intensified by the COVID-19 crisis. Immune repertoire classification based on the vast number of immunosequences of an individual is a MIL problem with an unprecedentedly massive number of instances, two orders of magnitude larger than currently considered problems, and with an extremely low witness rate. In this work, we present our novel method DeepRC that integrates transformer-like attention, or equivalently modern Hopfield networks, into deep learning architectures for massive MIL such as immune repertoire classification. We demonstrate that DeepRC outperforms all other methods with respect to predictive performance on large-scale experiments, including simulated and real-world virus infection data, and enables the extraction of sequence motifs that are connected to a given disease class. Source code and datasets: this https URL",10회,"Modern hopfield networks and attention for immune repertoire classification
M Widrich, B Schäfl, H Ramsauer, M Pavlović, L Gruber… - arXiv preprint arXiv:2007.13505, 2020
10회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
A discrete probabilistic memory model for discovering dependencies in time,"Sepp Hochreiter, Michael Mozer",2001,Artificial Neural Networks—ICANN 2001,,,661-668,Springer Berlin/Heidelberg,"Many domains of machine learning involve discovering dependencies and structure over time. In the most complex of domains, long-term temporal dependencies are present. Neural network models such as lstm have been developed to deal with long-term dependencies, but the continuous nature of neural networks is not well suited to discrete symbol processing tasks. Further, the mathematical underpinnings of neural networks are unclear, and gradient descent learning of recurrent neural networks seems particularly susceptible to local optima. We introduce a novel architecture for discovering dependencies in time. The architecture is formed by combining two variants of a hidden Markov model (HMM) - the factorial HMM and the input-output HMM - and adding a further strong constraint that requires the model to behave as a latch-and-store memory (the same constraint exploited in lstm). This model …",10회,"A discrete probabilistic memory model for discovering dependencies in time
S Hochreiter, MC Mozer - International Conference on Artificial Neural Networks, 2001
10회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Source separation as a by-product of regularization,"Sepp Hochreiter, Jürgen Schmidhuber",1999/6/4,Advances in Neural Information Processing Systems 11,11,,459,MIT Press,,10회,"Source separation as a by-product of regularization*
SHJ Schmidhuber - Advances in Neural Information Processing Systems …, 1999
10회 인용 관련 학술자료 전체 14개의 버전",,,,,,,,
Industry-scale application and evaluation of deep learning for drug target prediction,"Noé Sturm, Andreas Mayr, Thanh Le Van, Vladimir Chupakhin, Hugo Ceulemans, Joerg Wegner, Jose-Felipe Golib-Dzib, Nina Jeliazkova, Yves Vandriessche, Stanislav Böhm, Vojtech Cima, Jan Martinovic, Nigel Greene, Tom Vander Aa, Thomas J Ashby, Sepp Hochreiter, Ola Engkvist, Günter Klambauer, Hongming Chen",2020/12,Journal of Cheminformatics,12,,1-13,Springer International Publishing,"Artificial intelligence (AI) is undergoing a revolution thanks to the breakthroughs of machine learning algorithms in computer vision, speech recognition, natural language processing and generative modelling. Recent works on publicly available pharmaceutical data showed that AI methods are highly promising for Drug Target prediction. However, the quality of public data might be different than that of industry data due to different labs reporting measurements, different measurement techniques, fewer samples and less diverse and specialized assays. As part of a European funded project (ExCAPE), that brought together expertise from pharmaceutical industry, machine learning, and high-performance computing, we investigated how well machine learning models obtained from public data can be transferred to internal pharmaceutical industry data. Our results show that machine learning models trained on public …",9회,"Industry-scale application and evaluation of deep learning for drug target prediction
N Sturm, A Mayr, T Le Van, V Chupakhin… - Journal of Cheminformatics, 2020
9회 인용 관련 학술자료 전체 13개의 버전",,,,,,,,
DeepTox: Toxicity prediction using deep learning,"Günter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter",2017/10/20,Toxicol Lett,280,,S69-S69,,"• 2012: ImageNet competition was won by a deep neural network using GPUs. 16% error at 1.2 M images vs. 26% by its closest competitor. 2015: close to human error rate at 4%• 2013: Deep networks won the grand challenge on mitosis detection• 2013: Google researchers obtained a 70% improvement over previous best results on face recognition using 16,000 cores.
• 2011: lowered the error rate of speech recognition on an industry benchmark data set from 24% to about 16%. The speech recognition community has been stuck at 24% for more than a decade. Industrial companies which business is related to information technology became interested.",9회,"DeepTox: Toxicity prediction using deep learning
G Klambauer, T Unterthiner, A Mayr, S Hochreiter - Toxicol Lett, 2017
9회 인용 관련 학술자료",,,,,,,,
On failure modes in molecule generation and optimization,"Philipp Renz, Dries Van Rompaey, Jörg Kurt Wegner, Sepp Hochreiter, Günter Klambauer",2020/10/24,,,,,Elsevier,"There has been a wave of generative models for molecules triggered by advances in the field of Deep Learning. These generative models are often used to optimize chemical compounds towards particular properties or a desired biological activity. The evaluation of generative models remains challenging and suggested performance metrics or scoring functions often do not cover all relevant aspects of drug design projects. In this work, we highlight some unintended failure modes in molecular generation and optimization and how these evade detection by current performance metrics.",8회,"On failure modes in molecule generation and optimization
P Renz, D Van Rompaey, JK Wegner, S Hochreiter… - Drug Discovery Today: Technologies, 2020
8회 인용 관련 학술자료 전체 5개의 버전",,,Drug Discovery Today: Technologies,,,,,
Fréchet ChemblNet Distance: A metric for generative models for molecules,"Kristina Preuer, Philipp Renz, Thomas Unterthiner, Sepp Hochreiter, Günter Klambauer",2018/3,arXiv preprint arXiv:1803.09518,,,,,"The new wave of successful generative models in machine learning has increased the interest in deep learning driven de novo drug design. However, assessing the performance of such generative models is notoriously difficult. Metrics that are typically used to assess the performance of such generative models are the percentage of chemically valid molecules or the similarity to real molecules in terms of particular descriptors, such as the partition coefficient (logP) or druglikeness. However, method comparison is difficult because of the inconsistent use of evaluation metrics, the necessity for multiple metrics, and the fact that some of these measures can easily be tricked by simple rule-based systems. We propose a novel distance measure between two sets of molecules, called Fréchet ChemblNet distance (FCD), that can be used as an evaluation metric for generative models. The FCD is similar to a recently established performance metric for comparing image generation methods, the Fréchet Inception Distance (FID). Whereas the FID uses one of the hidden layers of InceptionNet, the FCD utilizes the penultimate layer of a deep neural network called “ChemblNet”, which was trained to predict drug activities. Thus, the FCD metric takes into account chemically and biologically relevant information about molecules, and also measures the diversity of the set via the distribution of generated molecules. The FCD’s advantage over previous metrics is that it can detect if generated molecules are a) diverse and have similar b) chemical and c) biological properties as real molecules. We further provide an easy-to-use implementation that only requires the …",8회,"Fréchet ChemblNet Distance: A metric for generative models for molecules
K Preuer, P Renz, T Unterthiner, S Hochreiter… - arXiv preprint arXiv:1803.09518, 2018
8회 인용 관련 학술자료",,,,,,,,
Sequence Analysis and Phylogenetics,Sepp Hochreiter,2008,"Institute ofBioinformatics, Johannes Kepler University Linz",,,,," National Center for Biotechnology Information (NCBI-http://www. ncbi. nlm. nih. gov/): GenBank (NIH), DNA sequence data base and BLAST software (with NR); ENTREZ (http://www. ncbi. nlm. nih. gov/Entrez/): biological data and articles, nucleotide sequences from GenBank, EMBL, DDBJ (DNA data base of Japan) as well as SWISS-PROT, PIR, PRF, SEQDB, PDB",8회,"Sequence Analysis and Phylogenetics
S Hochreiter - Institute ofBioinformatics, Johannes Kepler University …, 2008
8회 인용 관련 학술자료",,,,,,,,
Untersuchungen zu dynamischen neuronalen Netzen [Ph. D. dissertation],S Hochreiter,1991,"Technische Universitt MÄunchen, MÄunchen, Germany",,,,,,8회,"Untersuchungen zu dynamischen neuronalen Netzen [Ph. D. dissertation]
S Hochreiter - Technische Universitt MÄunchen, MÄunchen, Germany, 1991
8회 인용 관련 학술자료",,,,,,,,
Untersuchungen zu dynamischen neuronalen netzen.[Master's thesis],S Hochreiter,1991,"Institut Fur Informatik, Technische Universitat, Munchen.[Google Scholar]",,,,,,8회,"Untersuchungen zu dynamischen neuronalen netzen.[Master's thesis]
S Hochreiter - Institut Fur Informatik, Technische Universitat, Munchen …, 1991
8회 인용 관련 학술자료",,,,,,,,
Exploiting the Japanese Toxicogenomics Project for Predictive Modelling of Drug Toxicity,"Djork-Arné Clevert, Martin Heusel, Andreas Mitterecker, Willem Talloen, Hinrich Göhlmann, Jörg Wegner, Andreas Mayr, Günter Klambauer, Sepp Hochreiter",,,,,,,,8회,"Exploiting the Japanese toxicogenomics project for predictive modelling of drug toxicity*
DA Clevert, M Heusel, A Mitterecker, W Talloen… - CAMDA, 2012
8회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
The surprising efficiency of framing geo-spatial time series forecasting as a video prediction task–Insights from the IARAI Traffic4cast Competition at NeurIPS 2019,"David P Kreil, Michael K Kopp, David Jonietz, Moritz Neun, Aleksandra Gruca, Pedro Herruzo, Henry Martin, Ali Soleymani, Sepp Hochreiter",2020/8/19,,,,232-241,PMLR,"Deep Neural Networks models are state-of-the-art solutions in accurately forecasting future video frames in a movie. A successful video prediction model needs to extract and encode semantic features that describe the complex spatio-temporal correlations within image sequences of the real world. The IARAI Traffic4cast Challenge of the NeurIPS Competition Track 2019 for the first time introduced the novel argument that this is also highly relevant for urban traffic. By framing traffic prediction as a movie completion task, the challenge requires models to take advantage of complex geo-spatial and temporal patterns of the underlying process. We here report on the success and insights obtained in a first Traffic Map Movie forecasting challenge. Although short-term traffic prediction is considered hard, this novel approach allowed several research groups to successfully predict future traffic states in a purely data-driven manner from pixel space. We here expand on the original rationale, summarize key findings, and discuss promising future directions of the t4c competition at NeurIPS.",7회,"The surprising efficiency of framing geo-spatial time series forecasting as a video prediction task–Insights from the IARAI Traffic4cast Competition at NeurIPS 2019
DP Kreil, MK Kopp, D Jonietz, M Neun, A Gruca… - NeurIPS 2019 Competition and Demonstration Track, 2020
7회 인용 관련 학술자료 전체 3개의 버전",NeurIPS 2019 Competition and Demonstration Track,,,,,,,
Beyond maximum likelihood and density estimation: A sample-based criterion for unsupervised learning of complex models,"Sepp Hochreiter, Michael C Mozer",2001,,,,535-541,,"The goal of many unsupervised learning procedures is to bring two probability distributions into alignment. Generative models such as Gaussian mixtures and Boltzmann machines can be cast in this light, as can recoding models such as ICA and projection pursuit. We propose a novel sample-based error measure for these classes of models, which applies even in situations where maximum likelihood (ML) and probability density estimation-based formulations cannot be applied, eg, models that are nonlinear or have intractable posteriors. Furthermore, our sample-based error measure avoids the difficulties of approximating a density function. We prove that with an unconstrained model,(1) our approach converges on the correct solution as the number of samples goes to infinity, and (2) the expected solution of our approach in the generative framework is the ML solution. Finally, we evaluate our approach via simulations of linear and nonlinear models on mixture of Gaussians and ICA problems. The experiments show the broad applicability and generality of our approach.",7회,"Beyond maximum likelihood and density estimation: A sample-based criterion for unsupervised learning of complex models
S Hochreiter, MC Mozer - Advances in neural information processing systems, 2001
7회 인용 관련 학술자료 전체 4개의 버전",Advances in neural information processing systems,,,,,,,
Rectified factor networks for biclustering of omics data,"Djork-Arné Clevert, Thomas Unterthiner, Gundula Povysil, Sepp Hochreiter",2017/7/15,Bioinformatics,33,14,i59-i66,Oxford University Press,"Motivation
Biclustering has become a major tool for analyzing large datasets given as matrix of samples times features and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively. Factor Analysis for Bicluster Acquisition (FABIA), one of the most successful biclustering methods, is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated and sample membership is difficult to determine. We propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs …",6회,"Rectified factor networks for biclustering of omics data
DA Clevert, T Unterthiner, G Povysil, S Hochreiter - Bioinformatics, 2017
6회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
"IBD sharing between Africans, Neandertals, and Denisovans","Gundula Povysil, Sepp Hochreiter",2016/12,Genome biology and evolution,8,12,3406-3416,Oxford University Press,"Interbreeding between ancestors of humans and other hominins outside of Africa has been studied intensively, while their common history within Africa still lacks proper attention. However, shedding light on human evolution in this time period about which little is known, is essential for understanding subsequent events outside of Africa. We investigate the genetic relationships of humans, Neandertals, and Denisovans by identifying very short DNA segments in the 1000 Genomes Phase 3 data that these hominins share identical by descent (IBD). By focusing on low frequency and rare variants, we identify very short IBD segments with high confidence. These segments reveal events from a very distant past because shorter IBD segments are presumably older than longer ones. We extracted two types of very old IBD segments that are not only shared among humans, but also with Neandertals and/or Denisovans. The …",6회,"IBD sharing between Africans, Neandertals, and Denisovans
G Povysil, S Hochreiter - Genome biology and evolution, 2016
6회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
"Sharing of very short IBD segments between humans, neandertals, and denisovans","Gundula Povysil, Sepp Hochreiter",2014/1/1,BioRxiv,,,003988,Cold Spring Harbor Laboratory,"We analyze the sharing of very short identity by descent (IBD) segments between humans, Neandertals, and Denisovans to gain new insights into their demographic history. Short IBD segments convey information about events far back in time because the shorter IBD segments are, the older they are assumed to be. The identification of short IBD segments becomes possible through next generation sequencing (NGS), which offers high variant density and reports variants of all frequencies. However, only recently HapFABIA has been proposed as the first method for detecting very short IBD segments in NGS data. HapFABIA utilizes rare variants to identify IBD segments with a low false discovery rate.
We applied HapFABIA to the 1000 Genomes Project whole genome sequencing data to identify IBD segments which are shared within and between populations. Some IBD segments are shared with the reconstructed ancestral genome of humans and other primates. These segments are tagged by rare variants, consequently some rare variants have to be very old. Other IBD segments are also old since they are shared with Neandertals or Denisovans, which explains their shorter lengths compared to segments that are not shared with these ancient genomes. The Denisova genome most prominently matched IBD segments that are shared by Asians. Many of these segments were found exclusively in Asians and they are longer than segments shared between other continental populations and the Denisova genome. Therefore, we could confirm an introgression from Deniosvans into ancestors of Asians after their migration out of Africa. While …",6회,"Sharing of very short IBD segments between humans, neandertals, and denisovans
G Povysil, S Hochreiter - BioRxiv, 2014
6회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Automated microarray classification based on P-SVM gene selection,"Johannes Mohr, Sambu Seo, Klaus Obermayer",2008/12/11,,,,503-507,IEEE,"The analysis of microarray data is a challenging task for statistical and machine learning methods, since the datasets usually contain a very large number of features (genes) and only a small number of examples (subjects). In this work, we describe a technique for gene selection and classification of microarray data based on the recently proposed potential support vector machine (P-SVM) for feature selection and a nu-SVM for classification. The P-SVM expands the decision function in terms of a sparse set of ""support features"". Based on this novel technique for feature selection, we suggest a fully automated method for gene selection, hyper-parameter optimization and microarray classification. Benchmark results are given for the two datasets provided by the ICMLA'08 Automated Micro-Array Classification Challenge.",6회,"Automated microarray classification based on P-SVM gene selection
J Mohr, S Seo, K Obermayer - 2008 Seventh International Conference on Machine …, 2008
6회 인용 관련 학술자료 전체 5개의 버전",2008 Seventh International Conference on Machine Learning and Applications,,,,,,,
Coulomb classifiers: Generalizing support vector machines via an analogy to electrostatic systems,"Sepp Hochreiter, Michael C Mozer, Klaus Obermayer",2002,Advances in neural information processing systems,15,,561-568,,"We introduce a family of classifiers based on a physical analogy to an electrostatic system of charged conductors. The family, called Coulomb classifiers, includes the two best-known support-vector machines (SVMs), the ν–SVM and the C–SVM. In the electrostatics analogy, a training example corresponds to a charged conductor at a given location in space, the classification function corresponds to the electrostatic potential function, and the training objective function corresponds to the Coulomb energy. The electrostatic framework provides not only a novel interpretation of existing algorithms and their interrelationships, but it suggests a variety of new methods for SVMs including kernels that bridge the gap between polynomial and radial-basis functions, objective functions that do not require positive-definite kernels, regularization techniques that allow for the construction of an optimal classifier in Minkowski space. Based on the framework, we propose novel SVMs and perform simulation studies to show that they are comparable or superior to standard SVMs. The experiments include classification tasks on data which are represented in terms of their pairwise proximities, where a Coulomb Classifier outperformed standard SVMs.",6회,"Coulomb classifiers: Generalizing support vector machines via an analogy to electrostatic systems
S Hochreiter, MC Mozer, K Obermayer - Advances in neural information processing systems, 2002
6회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Rainfall–runoff prediction at multiple timescales with a single Long Short-Term Memory network,"Martin Gauch, Frederik Kratzert, Daniel Klotz, Grey Nearing, Jimmy Lin, Sepp Hochreiter",2021/4/19,Hydrology and Earth System Sciences,25,4,2045-2062,Copernicus GmbH,"Long Short-Term Memory (LSTM) networks have been applied to daily discharge prediction with remarkable success. Many practical applications, however, require predictions at more granular timescales. For instance, accurate prediction of short but extreme flood peaks can make a lifesaving difference, yet such peaks may escape the coarse temporal resolution of daily predictions. Naively training an LSTM on hourly data, however, entails very long input sequences that make learning difficult and computationally expensive. In this study, we propose two multi-timescale LSTM (MTS-LSTM) architectures that jointly predict multiple timescales within one model, as they process long-past inputs at a different temporal resolution than more recent inputs. In a benchmark on 516 basins across the continental United States, these models achieved significantly higher Nash–Sutcliffe efficiency (NSE) values than the US National Water Model. Compared to naive prediction with distinct LSTMs per timescale, the multi-timescale architectures are computationally more efficient with no loss in accuracy. Beyond prediction quality, the multi-timescale LSTM can process different input variables at different timescales, which is especially relevant to operational applications where the lead time of meteorological forcings depends on their temporal resolution.",5회,"Rainfall–runoff prediction at multiple timescales with a single Long Short-Term Memory network
M Gauch, F Kratzert, D Klotz, G Nearing, J Lin… - Hydrology and Earth System Sciences, 2021
5회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Uncertainty Estimation with Deep Learning for Rainfall–Runoff Modelling,"Daniel Klotz, Frederik Kratzert, Martin Gauch, Alden Keefe Sampson, Johannes Brandstetter, Günter Klambauer, Sepp Hochreiter, Grey Nearing",2021/4/14,Hydrology and Earth System Sciences Discussions,,,1-32,Copernicus GmbH,"Deep Learning is becoming an increasingly important way to produce accurate hydrological predictions across a wide range of spatial and temporal scales. Uncertainty estimations are critical for actionable hydrological forecasting, and while standardized community benchmarks are becoming an increasingly important part of hydrological model development and research, similar tools for benchmarking uncertainty estimation are lacking. This contributions demonstrates that accurate uncertainty predictions can be obtained with Deep Learning. We establish an uncertainty estimation benchmarking procedure and present four Deep Learning baselines. Three baselines are based on Mixture Density Networks and one is based on Monte Carlo dropout. The results indicate that these approaches constitute strong baselines, especially the former ones. Additionaly, we provide a post-hoc model analysis to put forward some qualitative understanding of the resulting models. This analysis extends the notion of performance and show that learn nuanced behaviors in different situations.",5회,"Uncertainty Estimation with Deep Learning for Rainfall–Runoff Modelling
D Klotz, F Kratzert, M Gauch, A Keefe Sampson… - Hydrology and Earth System Sciences Discussions, 2021
5회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Do internals of neural networks make sense in the context of hydrology?,"Frederik Kratzert, Mathew Herrnegger, Daniel Klotz, Sepp Hochreiter, Günter Klambauer",2018/12,AGU Fall Meeting Abstracts,2018,,H13B-06,,"In recent years, neural networks gained a new wave of popularity in many application domains, such as computer vision or natural language processing. However in applied environmental sciences, like rainfall-runoff modelling in hydrology, neural networks tend to have a rather bad reputation. This can be attributed to their black-box-ness and the difficulty or impossibility to understand network internals leading to a prediction.",5회,"Do internals of neural networks make sense in the context of hydrology?
F Kratzert, M Herrnegger, D Klotz, S Hochreiter… - AGU Fall Meeting Abstracts, 2018
5회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Weighted similarity-based clustering of chemical structures and bioactivity data in early drug discovery,"Nolen J Perualila-Tan, Ziv Shkedy, Willem Talloen, Hinrich WH Göhlmann, QSTAR Consortium, Marijke Van Moerbeke, Adetayo Kasim",2016/6/15,Journal of Bioinformatics and Computational Biology,,,,,"The modern process of discovering candidate molecules in early drug discovery phase includes a wide range of approaches to extract vital information from the intersection of biology and chemistry. A typical strategy in compound selection involves compound clustering based on chemical similarity to obtain representative chemically diverse compounds (not incorporating potency information). In this paper, we propose an integrative clustering approach that makes use of both biological (compound efficacy) and chemical (structural features) data sources for the purpose of discovering a subset of compounds with aligned structural and biological properties. The datasets are integrated at the similarity level by assigning complementary weights to produce a weighted similarity matrix, serving as a generic input in any clustering algorithm. This new analysis work flow is semi-supervised method since, after the …",5회,"Weighted similarity-based clustering of chemical structures and bioactivity data in early drug discovery
NJ Perualila-Tan, Z Shkedy, W Talloen… - Journal of bioinformatics and computational biology, 2016
5회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
"A joint modeling approach for uncovering associations between gene expression, bioactivity and chemical structure in early drug discovery to guide lead selection and genomic …","Nolen J Perualila-Tan, Adetayo Kasim, Willem Talloen, Bie Verbist, Hinrich WH Göhlmann, QSTAR Consortium, Ziv Shkedy",2016/5/25,Statistical applications in genetics and molecular biology,,,,,"The modern drug discovery process involves multiple sources of high-dimensional data. This imposes the challenge of data integration. A typical example is the integration of chemical structure (fingerprint features), phenotypic bioactivity (bioassay read-outs) data for targets of interest, and transcriptomic (gene expression) data in early drug discovery to better understand the chemical and biological mechanisms of candidate drugs, and to facilitate early detection of safety issues prior to later and expensive phases of drug development cycles. In this paper, we discuss a joint model for the transcriptomic and the phenotypic variables conditioned on the chemical structure. This modeling approach can be used to uncover, for a given set of compounds, the association between gene expression and biological activity taking into account the influence of the chemical structure of the compound on both variables. The model …",5회,"A joint modeling approach for uncovering associations between gene expression, bioactivity and chemical structure in early drug discovery to guide lead selection and genomic biomarker development
N Perualila-Tan, A Kasim, W Talloen, B Verbist… - Statistical applications in genetics and molecular …, 2016
5회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Modeling position specificity in sequence kernels by fuzzy equivalence relations,"Ulrich Bodenhofer, Karin Schwarzbauer, Mihaela Ionescu, Sepp Hochreiter",2009,Proc. Joint 13th IFSA World Congress and 6th EUSFLAT Conference,,,1376-1381,,"This paper demonstrates that several known sequence kernels can be expressed in a unified framework in which the position specificity is modeled by fuzzy equivalence relations. In addition to this interpretation, we address the practical issues of positive semidefiniteness, computational complexity, and the extraction of interpretable features from the final support vector machine classifier.",5회,"Modeling Position Specificity in Sequence Kernels by Fuzzy Equivalence Relations.
U Bodenhofer, K Schwarzbauer, M Ionescu… - IFSA/EUSFLAT Conf., 2009
5회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
How to learn programs with artificial recurrent neural networks,"J Schmidhuber, A Graves, FJ Gomez, S Fernandez, S Hochreiter",2009,,,,,Invited by Cambridge University Press,,5회,"How to learn programs with artificial recurrent neural networks
J Schmidhuber, A Graves, FJ Gomez, S Fernandez… - 2009
5회 인용 관련 학술자료",,,,,,,,
Optimal kernels for unsupervised learning,"Sepp Hochreiter, Klaus Obermayer",2005/7/31,,3,,1895-1899,IEEE,"We investigate the optimal kernel for sample-based model selection in unsupervised learning if maximum likelihood approaches are intractable. Given a set of training data and a set of data generated by the model, two kernel density estimators are constructed. A model is selected through gradient descent w.r.t. the model parameters on the integrated squared difference between the density estimators. Firstly we prove that convergence is optimal, i.e. that the cost function has only one global minimum w.r.t. the locations of the model samples, if and only if the kernel in the reparametrized cost function is a Coulomb kernel. As a consequence, Gaussian kernels commonly used for density estimators are suboptimal. Secondly we show that the absolute value of the difference between model and reference density converges at least with 1/t. Finally, we apply the new methods to distribution free ICA and to nonlinear ICA.",5회,"Optimal kernels for unsupervised learning
S Hochreiter, K Obermayer - Proceedings. 2005 IEEE International Joint Conference …, 2005
5회 인용 관련 학술자료 전체 13개의 버전","Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.",,,,,,,
Long short-term memory Neural computation 9,"S Hochreiter, J Schmidhuber",1997,,,,,MIT Press,,5회,"Long short-term memory Neural computation 9
S Hochreiter, J Schmidhuber - 1997
5회 인용 관련 학술자료",,,,,,,,
Flat minimum search finds simple nets,"Sepp Hochreiter, Jürgen Schmidhuber",1994/12/31,,,FKI-200-94,,Inst. für Informatik,"We present a new algorithm for nding low complexity neural networks with high generalization capability. The algorithm searches for a\at"" minimum of the error function. A at minimum is a large connected region in weight-space where the error remains approximately constant. An MDL-based argument shows that at minima correspond to low expected overtting. Although our algorithm requires the computation of second order derivatives, it has backprop's order of complexity. Automatically, it e ectively prunes units, weights, and input lines. Various experiments with feedforward and recurrent nets are described. In an application to stock market prediction, at minimum search outperforms (1) conventional backprop,(2) weight decay,(3)\optimal brain surgeon""/\optimal brain damage"".",5회,"Flat minimum search finds simple nets
S Hochreiter, J Schmidhuber - 1994
5회 인용 관련 학술자료 전체 13개의 버전",,,,,,,,
MC-LSTM: Mass-Conserving LSTM,"Pieter-Jan Hoedt, Frederik Kratzert, Daniel Klotz, Christina Halmich, Markus Holzleitner, Grey Nearing, Sepp Hochreiter, Günter Klambauer",2021/1,arXiv preprint arXiv:2101.05186,,,,,"The success of Convolutional Neural Networks (CNNs) in computer vision is mainly driven by their strong inductive bias, which is strong enough to allow CNNs to solve vision-related tasks with random weights, meaning without learning. Similarly, Long Short-Term Memory (LSTM) has a strong inductive bias towards storing information over time. However, many real-world systems are governed by conservation laws, which lead to the redistribution of particular quantities--eg in physical and economical systems. Our novel Mass-Conserving LSTM (MC-LSTM) adheres to these conservation laws by extending the inductive bias of LSTM to model the redistribution of those stored quantities. MC-LSTMs set a new state-of-the-art for neural arithmetic units at learning arithmetic operations, such as addition tasks, which have a strong conservation law, as the sum is constant over time. Further, MC-LSTM is applied to traffic forecasting, modelling a pendulum, and a large benchmark dataset in hydrology, where it sets a new state-of-the-art for predicting peak flows. In the hydrology example, we show that MC-LSTM states correlate with real-world processes and are therefore interpretable.",4회,"MC-LSTM: Mass-Conserving LSTM
PJ Hoedt, F Kratzert, D Klotz, C Halmich, M Holzleitner… - arXiv preprint arXiv:2101.05186, 2021
4회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Detecting cutaneous basal cell carcinomas in ultra-high resolution and weakly labelled histopathological images,"Susanne Kimeswenger, Elisabeth Rumetshofer, Markus Hofmarcher, Philipp Tschandl, Harald Kittler, Sepp Hochreiter, Wolfram Hötzenecker, Günter Klambauer",2019/11/14,arXiv preprint arXiv:1911.06616,,,,,"Diagnosing basal cell carcinomas (BCC), one of the most common cutaneous malignancies in humans, is a task regularly performed by pathologists and dermato-pathologists. Improving histological diagnosis by providing diagnosis suggestions, ie computer-assisted diagnoses is actively researched to improve safety, quality and efficiency. Increasingly, machine learning methods are applied due to their superior performance. However, typical images obtained by scanning histological sections often have a resolution that is prohibitive for processing with current state-of-the-art neural networks. Furthermore, the data pose a problem of weak labels, since only a tiny fraction of the image is indicative of the disease class, whereas a large fraction of the image is highly similar to the non-disease class. The aim of this study is to evaluate whether it is possible to detect basal cell carcinomas in histological sections using attention-based deep learning models and to overcome the ultra-high resolution and the weak labels of whole slide images. We demonstrate that attention-based models can indeed yield almost perfect classification performance with an AUC of 0.99.",4회,"Detecting cutaneous basal cell carcinomas in ultra-high resolution and weakly labelled histopathological images
S Kimeswenger, E Rumetshofer, M Hofmarcher… - arXiv preprint arXiv:1911.06616, 2019
4회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Repurposed high-throughput images enable biological activity prediction for drug discovery,"Jaak Simm, Günter Klambauer, Adam Arany, Marvin Steijaert, Jörg Kurt Wegner, Emmanuel Gustin, Vladimir Chupakhin, Yolanda T Chong, Jorge Vialard, Peter Buijnsters, Ingrid Velter, Alexander Vapirev, Shantanu Singh, Anne Carpenter, Roel Wuyts, Sepp Hochreiter, Yves Moreau, Hugo Ceulemans",2017/1/1,bioRxiv,,,108399,Cold Spring Harbor Laboratory,"We repurpose a High-Throughput (cell) Imaging (HTI) screen of a glucocorticoid receptor assay to predict target protein activity in multiple other seemingly unrelated assays. In two ongoing drug discovery projects, our repurposing approach increased hit rates by 60- to 250-fold over that of the primary project assays while increasing the chemical structure diversity of the hits. Our results suggest that data from available HTI screens are a rich source of information that can be reused to empower drug discovery efforts.",4회,"Repurposed high-throughput images enable biological activity prediction for drug discovery
J Simm, G Klambauer, A Arany, M Steijaert, JK Wegner… - bioRxiv, 2017
4회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Optimal gradient-based learning using importance weights,"Sepp Hochreiter, Klaus Obermayer",2005/7/31,,1,,114-119,IEEE,"We introduce a novel ""importance weight"" method (IW) to speed up learning of ""difficult"" data sets including unbalanced data, highly non-linear data, or long-term dependencies in sequences. An importance weight is assigned to every training data point and controls its contribution to the total weight update. The importance weights are obtained by solving a quadratic optimization problem and determines the learning informativeness of a data point. For linear classifiers we show, that IW is equivalent to standard support vector learning. We apply IW to feedforward multi-layer perceptrons and to recurrent neural networks (LSTM). Benchmarks with QuickProp and standard gradient descent methods show that IW is usually much faster in terms of epochs as well as in terms of absolute CPU time, and that it provides equal or better prediction results. IW improved gradient descent results on ""real world"" protein datasets. In …",4회,"Optimal gradient-based learning using importance weights
S Hochreiter, K Obermayer - Proceedings. 2005 IEEE International Joint Conference …, 2005
4회 인용 관련 학술자료 전체 8개의 버전","Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.",,,,,,,
Classification of pairwise proximity data with support vectors,"Sepp Hochreiter, Klaus Obermayer",2002,The Learning Workshop. Y. LeCun and Y. Bengio,,,,,"We investigate the problem of learning a classication task on data which are represented in terms of their pairwise proximities. This representation does not refer to an explicit representation of the data items by feature vectors, rather the set of objects is represented by a matrix, which assigns a real number (the similarity measure) to every object pair. This representation is more general than the standard approach of using feature vectors, from which pairwise proximities can always be calculated. We assume that there exists a training set, for which a class label is assigned to every object and for which the proximity matrix has been measured. We now interpret the entries of the matrix as being produced by an unknown kernel operating on (unknown) object feature vectors. Proximity matrices are by denition symmetric. Positive deniteness, however, cannot be assured, and the construction of a classier using the …",4회,"Classification of pairwise proximity data with support vectors
S Hochreiter, K Obermayer - The Learning Workshop. Y. LeCun and Y. Bengio, 2002
4회 인용 관련 학술자료",,,,,,,,
Nonlinear ICA through low-complexity autoencoders,"Sepp Hochreiter, Jürgen Schmidhuber",1999/5/30,,5,,53-56,IEEE,"We train autoencoders by flat minimum search (FMS), a regularizer algorithm for finding low-complexity networks describable by few bits of information. As a by-product, this encourages nonlinear independent component analysis (ICA) and sparse codes of the input data.",4회,"Nonlinear ICA through low-complexity autoencoders
S Hochreiter, J Schmidhuber - 1999 IEEE International Symposium on Circuits and …, 1999
4회 인용 관련 학술자료 전체 11개의 버전",1999 IEEE International Symposium on Circuits and Systems (ISCAS),,,,,,,
Artificial neural networks and pathologists recognize basal cell carcinomas based on different histological patterns,"Susanne Kimeswenger, Philipp Tschandl, Petar Noack, Markus Hofmarcher, Elisabeth Rumetshofer, Harald Kindermann, Rene Silye, Sepp Hochreiter, Martin Kaltenbrunner, Emmanuella Guenova, Guenter Klambauer, Wolfram Hoetzenecker",2021/5,Modern Pathology,34,5,895-903,Nature Publishing Group,"Recent advances in artificial intelligence, particularly in the field of deep learning, have enabled researchers to create compelling algorithms for medical image analysis. Histological slides of basal cell carcinomas (BCCs), the most frequent skin tumor, are accessed by pathologists on a daily basis and are therefore well suited for automated prescreening by neural networks for the identification of cancerous regions and swift tumor classification.",3회,"Artificial neural networks and pathologists recognize basal cell carcinomas based on different histological patterns
S Kimeswenger, P Tschandl, P Noack, M Hofmarcher… - Modern Pathology, 2021
3회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Machine learning–based prediction of transfusion,"Andreas Mitterecker, Axel Hofmann, Kevin M Trentino, Adam Lloyd, Michael F Leahy, Karin Schwarzbauer, Thomas Tschoellitsch, Carl Böck, Sepp Hochreiter, Jens Meier",2020/9,Transfusion,60,9,1977-1986,"John Wiley & Sons, Inc.","Background
The ability to predict transfusions arising during hospital admission might enable economized blood supply management and might furthermore increase patient safety by ensuring a sufficient stock of red blood cells (RBCs) for a specific patient. We therefore investigated the precision of four different machine learning–based prediction algorithms to predict transfusion, massive transfusion, and the number of transfusions in patients admitted to a hospital.
Study Design and Methods
This was a retrospective, observational study in three adult tertiary care hospitals in Western Australia between January 2008 and June 2017. Primary outcome measures for the classification tasks were the area under the curve for the receiver operating characteristics curve, the F1 score, and the average precision of the four machine learning algorithms used: neural networks (NNs), logistic regression (LR), random forests …",3회,"Machine learning–based prediction of transfusion
A Mitterecker, A Hofmann, KM Trentino, A Lloyd… - Transfusion, 2020
3회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
On failure modes of molecule generators and optimizers,"Philipp Renz, Dries Van Rompaey, Jörg Kurt Wegner, Sepp Hochreiter, Günter Klambauer",2020/4/30,,,,,ChemRxiv,"There has been a wave of generative models for molecules triggered by advances in the field of Deep Learning. These generative models are often used to optimize chemical compounds towards particular properties or a desired biological activity. The evaluation of generative models remains challenging and suggested performance metrics or scoring functions often do not cover all relevant aspects of drug design projects. In this work, we highlight some unintended failure modes of generative models and how these evade detection by current performance metrics.",3회,"On failure modes of molecule generators and optimizers
P Renz, D Van Rompaey, JK Wegner, S Hochreiter… - 2020
3회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Using LSTMs for climate change assessment studies on droughts and floods,"Frederik Kratzert, Daniel Klotz, Johannes Brandstetter, Pieter-Jan Hoedt, Grey Nearing, Sepp Hochreiter",2019/11/10,arXiv preprint arXiv:1911.03941,,,,,"Climate change affects occurrences of floods and droughts worldwide. However, predicting climate impacts over individual watersheds is difficult, primarily because accurate hydrological forecasts require models that are calibrated to past data. In this work we present a large-scale LSTM-based modeling approach that--by training on large data sets--learns a diversity of hydrological behaviors. Previous work shows that this model is more accurate than current state-of-the-art models, even when the LSTM-based approach operates out-of-sample and the latter in-sample. In this work, we show how this model can assess the sensitivity of the underlying systems with regard to extreme (high and low) flows in individual watersheds over the continental US.",3회,"Using LSTMs for climate change assessment studies on droughts and floods
F Kratzert, D Klotz, J Brandstetter, PJ Hoedt, G Nearing… - arXiv preprint arXiv:1911.03941, 2019
3회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Increasing the discovery power of-omics studies,"Djork-Arné Clevert, Andreas Mayr, Andreas Mitterecker, Günter Klambauer, Armand Valsesia, Karl Forner, Marianne Tuefferd, Willem Talloen, Jérôme Wojcik, Hinrich Göhlmann, Sepp Hochreiter",2013/4/11,Systems Biomedicine,1,2,84-93,Taylor & Francis,"Motivation: Current clinical and biological studies apply different biotechnologies and subsequently combine the resulting -omics data to test biological hypotheses. The plethora of -omics data and their combination generates a large number of hypotheses and apparently increases the study power. Contrary to these expectations, the wealth of -omics data may even reduce the statistical power of a study because of a large correction factor for multiple testing. Typically, this loss of power in analyzing -omics data are caused by an increased false detection rate (FDR) in measurements, like falsely detected DNA copy number changes, or falsely identified differentially expressed genes. The false detections are random and, therefore, not related to the tested conditions. Thus, a high FDR considerably decreases the discovery power of studies, especially if different -omics data are involved.
Results: On a HapMap data set …",3회,"Increasing the discovery power of-omics studies
DA Clevert, A Mayr, A Mitterecker, G Klambauer… - Systems Biomedicine, 2013
3회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Sphered support vector machine,"S Hochreiter, K Obermayer",2004,,,,,"Technical report, Technische Universität Berlin, Fakultät für Elektrotechnik und Informatik",,3회,"Sphered support vector machine
S Hochreiter, K Obermayer - 2004
3회 인용 관련 학술자료",,,,,,,,
User Manual of the Potential Support Vector Machine,"Tilman Knebel, Sepp Hochreiter",,,,,,,"This is the user manual for the PSVM (see [ncpsvm]) software library which is designed for MICROSOFT Windows as well as for UNIX systems. Compiling the software results in a program which can be used with command line options (eg kernel type, learning/testing, etc.) which does not depend on other software or on a particular software-environment. The PSVM software package also includes a MATLAB interface for convenient working with the PSVM package. In addition lots of sample data and scripts are included. The PSVM software contains a classification, a regression, and a feature selection mode and is based on an efficient SMO optimization technique. The software can directly be applied to dyadic (matrix) data sets or it can be used with kernels like standard SVM software. In contrast to standard SVMs the kernel function does not have to be positive definite, eg the software already implements the indefinite sin-kernel. An important feature of the software is that is allows for n-fold cross validation and for hyperparameter selection. For classification tasks it offers the determination of the significance level and ROC data. In summary the basic features of the software are",3회,"Software Documentation of the Potential Support Vector Machine*
T Knebel, S Hochreiter - Department of Electrical Engineering and Computer …, 2014
3회 인용 관련 학술자료 전체 10개의 버전
User Manual of the Potential Support Vector Machine
T Knebel, S Hochreiter
관련 학술자료 전체 10개의 버전
Potential Support Vector Machine Software Documentation*
T Knebel, S Hochreiter
관련 학술자료",,,,,,,,
Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution,"Vihang P Patil, Markus Hofmarcher, Marius-Constantin Dinu, Matthias Dorfer, Patrick M Blies, Johannes Brandstetter, Jose A Arjona-Medina, Sepp Hochreiter",2020/9/29,arXiv preprint arXiv:2009.14108,,,,,"Reinforcement Learning algorithms require a large number of samples to solve complex tasks with sparse and delayed rewards. Complex tasks can often be hierarchically decomposed into sub-tasks. A step in the Q-function can be associated with solving a sub-task, where the expectation of the return increases. RUDDER has been introduced to identify these steps and then redistribute reward to them, thus immediately giving reward if sub-tasks are solved. Since the problem of delayed rewards is mitigated, learning is considerably sped up. However, for complex tasks, current exploration strategies as deployed in RUDDER struggle with discovering episodes with high rewards. Therefore, we assume that episodes with high rewards are given as demonstrations and do not have to be discovered by exploration. Typically the number of demonstrations is small and RUDDER's LSTM model as a deep learning method does not learn well. Hence, we introduce Align-RUDDER, which is RUDDER with two major modifications. First, Align-RUDDER assumes that episodes with high rewards are given as demonstrations, replacing RUDDER's safe exploration and lessons replay buffer. Second, we replace RUDDER's LSTM model by a profile model that is obtained from multiple sequence alignment of demonstrations. Profile models can be constructed from as few as two demonstrations as known from bioinformatics. Align-RUDDER inherits the concept of reward redistribution, which considerably reduces the delay of rewards, thus speeding up learning. Align-RUDDER outperforms competitors on complex artificial tasks with delayed reward and few …",2회,"Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution
VP Patil, M Hofmarcher, MC Dinu, M Dorfer, PM Blies… - arXiv preprint arXiv:2009.14108, 2020
2회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Quantum optical experiments modeled by long short-term memory,"Thomas Adler, Manuel Erhard, Mario Krenn, Johannes Brandstetter, Johannes Kofler, Sepp Hochreiter",2019/10/30,arXiv preprint arXiv:1910.13804,,,,,"We demonstrate how machine learning is able to model experiments in quantum physics. Quantum entanglement is a cornerstone for upcoming quantum technologies such as quantum computation and quantum cryptography. Of particular interest are complex quantum states with more than two particles and a large number of entangled quantum levels. Given such a multiparticle high-dimensional quantum state, it is usually impossible to reconstruct an experimental setup that produces it. To search for interesting experiments, one thus has to randomly create millions of setups on a computer and calculate the respective output states. In this work, we show that machine learning models can provide significant improvement over random search. We demonstrate that a long short-term memory (LSTM) neural network can successfully learn to model quantum experiments by correctly predicting output state characteristics for given setups without the necessity of computing the states themselves. This approach not only allows for faster search but is also an essential step towards automated design of multiparticle high-dimensional quantum experiments using generative machine learning models.",2회,"Quantum optical experiments modeled by long short-term memory
T Adler, M Erhard, M Krenn, J Brandstetter, J Kofler… - arXiv preprint arXiv:1910.13804, 2019
2회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
A glimpse into the Unobserved: Runoff simulation for ungauged catchments with LSTMs,"Frederik Kratzert, Daniel Klotz, Mathew Herrnegger, Sepp Hochreiter",2018/9/28,,,,,,"Runoff predictions of a river from meteorological inputs is a key task in the field of hydrology. However, current hydrological models require a substantial amount of parameter tuning on basis of historical records. If no historical runoff observations are available it is very challenging to produce good predictions. In this study we explore the capability of LSTMs for simulating the runoff for these ungauged cases. A single LSTM is trained to learn a general hydrological model from hundreds of catchments throughout the contiguous United States of America and evaluated against catchments not used during training. Our results suggest that LSTMs a) are able to learn a general hydrological model and b) in the majority of catchments outperform an established hydrological model, which was especially trained for these catchments.",2회,"A glimpse into the Unobserved: Runoff simulation for ungauged catchments with LSTMs
F Kratzert, D Klotz, M Herrnegger, S Hochreiter - 2018
2회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
First order generative adversarial networks,"Calvin Seward, Thomas Unterthiner, Urs Bergmann, Nikolay Jetchev, Sepp Hochreiter",2018/7/3,,,,4567-4576,PMLR,"GANs excel at learning high dimensional distributions, but they can update generator parameters in directions that do not correspond to the steepest descent direction of the objective. Prominent examples of problematic update directions include those used in both Goodfellow’s original GAN and the WGAN-GP. To formally describe an optimal update direction, we introduce a theoretical framework which allows the derivation of requirements on both the divergence and corresponding method for determining an update direction, with these requirements guaranteeing unbiased mini-batch updates in the direction of steepest descent. We propose a novel divergence which approximates the Wasserstein distance while regularizing the critic’s first order information. Together with an accompanying update direction, this divergence fulfills the requirements for unbiased steepest descent updates. We verify our method, the First Order GAN, with image generation on CelebA, LSUN and CIFAR-10 and set a new state of the art on the One Billion Word language generation task.",2회,"First order generative adversarial networks
C Seward, T Unterthiner, U Bergmann, N Jetchev… - International Conference on Machine Learning, 2018
2회 인용 관련 학술자료 전체 7개의 버전",International Conference on Machine Learning,,,,,,,
Understanding Very Deep Networks via Volume Conservation,"Thomas Unterthiner, Sepp Hochreiter",2016/2/18,,,,,,"Recently, very deep neural networks set new records across many application domains, like Residual Networks at the ImageNet challenge and Highway Networks at language processing tasks. We expect further excellent performance improvements in different fields from these very deep networks. However these networks are still poorly understood, especially since they rely on non-standard architectures. In this contribution we analyze the learning dynamics which are required for successfully training very deep neural networks. For the analysis we use a symplectic network architecture which inherently conserves volume when mapping a representation from one to the next layer. Therefore it avoids the vanishing gradient problem, which in turn allows to effectively train thousands of layers. We consider highway and residual networks as well as the LSTM model, all of which have approximately volume conserving mappings. We identified two important factors for making deep architectures working:(1)(near) volume conserving mappings through or similar (cf.\avoiding the vanishing gradient);(2) Controlling the drift effect, which increases/decreases during propagation toward the output (cf.\avoiding bias shifts);",2회,"Understanding Very Deep Networks via Volume Conservation
T Unterthiner, S Hochreiter - 2016
2회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Theoretical concepts of machine learning,Sepp Hochreiter,2014,"Lecture Notes] Linz, AUT: Institute of Bioinformatics, Johannes Kepler University Linz. Available at:< http://www. bioinf. jku. at/teaching/current/ss vl tcml/ML theoretical. pdf>[Accessed 26/07/2016]",,,,,"This course is part of the curriculum of the master in computer science (in particular the majors “Computational Engineering” and “Intelligent Information Systems”) and part of the master in bioinformatics at the Johannes Kepler University Linz.
Machine learning is currently a major research topic at companies like Google, Microsoft, Amazon, Facebook, AltaVista, Zalando, and many more. Applications are found in computer vision (image recognition), speech recognition, recommender systems, analysis of Big Data, information retrieval. Companies that try to mine the world wide web are offering search engines, social networks, videos, music, information, or connecting people use machine learning techniques. Machine learning methods are used to classify and label web pages, images, videos, and sound recordings in web data. They can find specific objects in images and detect a particular music style if only given the raw data. Therefore Google, Microsoft, Facebook are highly interested in machine learning methods. Machine learning methods attracted the interest of companies offering products via the web. These methods are able to identify groups of similar users, to predict future behavior of customers, and can give recommendation of products in which customers will be interested based previous costumer data.",2회,"Theoretical concepts of machine learning
S Hochreiter - Lecture Notes] Linz, AUT: Institute of Bioinformatics …, 2014
2회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Protein networks tomography: targeting cancer and associated morbidities,Enrico Capobianco,2013/7/1,Systems Biomedicine,1,3,161-178,Taylor & Francis,"Networks represent powerful inference tools for the analysis of complex biological systems. Inference is especially relevant when associations between network nodes are established by focusing on modularity. The problem of identifying first, and validating then, modules in networks has received substantial attention, and many approaches have been proposed. An important goal is functional validation of the identified modules, based on existing database resources. The quality and performance of algorithms can be assessed by evaluating the matching rate between retrieved and well annotated modules, in addition to newly established associations. Due to the variety of algorithms, the concept of module resolution spectrum has become central to this specific research field. In general, coarse-resolution modules reflect global network regulation patterns operating at the gene level or at the protein pathway scale …",2회,"Protein networks tomography: targeting cancer and associated morbidities
E Capobianco - Systems Biomedicine, 2013
2회 인용 관련 학술자료",,,,,,,,
"Bioinformatics Research and Development: First International Conference, BIRD 2007, Berlin, Germany, March 12-14, 2007, Proceedings","Sepp Hochreiter, Roland Wagner",2007/4/4,,4414,,,Springer,"This volume contains the papers which were selected for oral presentation at the first Bioinformatics Research and Development (BIRD) conference held in Berlin, Germany during March 12-14, 2007. BIRD covers a wide range of topics related to bioinformatics like microarray data, genomics, single nucleotide polymorphism, sequence analysis, systems biology, medical applications, proteomics, information systems. The conference was very competitive. From about 140 submissions only 36 were selected by the Program Committee for oral presentation at BIRD and for publication in these proceedings. The acceptance rate was 1/4. The decisions of the Program Committee were guided by the recommendations of several reviewers for each paper. It should be mentioned that these proceedings have companion proceedings published by the Austrian Computer Society where selected poster presentations of the BIRD conference are included. The invited talk titled"" From Flies to Human Disease"" by Josef Penninger, one of the leading researcher in genetic experiments for investigating disease pathogenesis, was very inspiring and gave new insights into future bioinformatics challenges.",2회,"Bioinformatics Research and Development: First International Conference, BIRD 2007, Berlin, Germany, March 12-14, 2007, Proceedings
S Hochreiter, R Wagner - 2007
2회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
P-svm variable selection for discovering dependencies between genetic and brain imaging data,"Johannes Mohr, Imke Puls, Jana Wrase, A Heinz, S Hochreiter, Klaus Obermayer",2006/7/16,,,,5020-5027,IEEE,"The joint analysis of genetic and brain imaging data is the key to understand the genetic underpinnings of brain dysfunctions in several psychiatric diseases known to have a strong genetic component. The goal is to identify associations between genetic and functional or morphometric brain measurements. We here suggest a machine learning method to solve this task, which is based on the recently proposed Potential Support Vector Machine (P-SVM) for variable selection, a subsequent k-NN classification and an estimation of the effect of 'correlations by chance'. We apply it to the detection of associations between candidate single nucleotide polymorphisms (SNPs) and volumetric MRI measurements in alcohol dependent patients and healthy controls.",2회,"P-svm variable selection for discovering dependencies between genetic and brain imaging data
J Mohr, I Puls, J Wrase, A Heinz, S Hochreiter… - The 2006 IEEE International Joint Conference on …, 2006
2회 인용 관련 학술자료 전체 10개의 버전",The 2006 IEEE International Joint Conference on Neural Network Proceedings,,,,,,,
Sequence classification for protein analysis,"Sepp Hochreiter, Klaus Obermayer",,Snowbird Workshop,,,5-8,,,2회,"Sequence classification for protein analysis*
S Hochreiter, K Obermayer - … , Utah. Computational and Biological Learning Society, 2005
2회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Niederschlags-Abfluss-Modellierung mit Long Short-Term Memory (LSTM),"Frederik Kratzert, Martin Gauch, Grey Nearing, Sepp Hochreiter, Daniel Klotz",2021/5/17,Österreichische Wasser-und Abfallwirtschaft,,,1-11,Springer Vienna,Methoden der künstlichen Intelligenz haben sich in den letzten Jahren zu essenziellen Bestandteilen fast aller Bereiche von Wissenschaft und Technik entwickelt. Dies gilt auch für die Hydrologie: Vielschichtige neuronale Netzwerke–auch bekannt als Modelle des Deep Learning–ermöglichen hier Vorhersagen von Niederschlagsabflussmengen in zuvor unerreichter Präzision.,1회,"Niederschlags-Abfluss-Modellierung mit Long Short-Term Memory (LSTM)
F Kratzert, M Gauch, G Nearing, S Hochreiter, D Klotz - Österreichische Wasser-und Abfallwirtschaft, 2021
1회 인용",,,,,,,,
Rainfall–runoff prediction at multiple timescales with a single Long Short-Term Memory network,"Martin Gauch, Frederik Kratzert, Daniel Klotz, Grey Nearing, Jimmy Lin, Sepp Hochreiter",2021/4/19,Hydrology and Earth System Sciences,25,4,2045-2062,Copernicus GmbH,"Long Short-Term Memory (LSTM) networks have been applied to daily discharge prediction with remarkable success. Many practical applications, however, require predictions at more granular timescales. For instance, accurate prediction of short but extreme flood peaks can make a lifesaving difference, yet such peaks may escape the coarse temporal resolution of daily predictions. Naively training an LSTM on hourly data, however, entails very long input sequences that make learning difficult and computationally expensive. In this study, we propose two multi-timescale LSTM (MTS-LSTM) architectures that jointly predict multiple timescales within one model, as they process long-past inputs at a different temporal resolution than more recent inputs. In a benchmark on 516 basins across the continental United States, these models achieved significantly higher Nash–Sutcliffe efficiency (NSE) values than the US National Water Model. Compared to naive prediction with distinct LSTMs per timescale, the multi-timescale architectures are computationally more efficient with no loss in accuracy. Beyond prediction quality, the multi-timescale LSTM can process different input variables at different timescales, which is especially relevant to operational applications where the lead time of meteorological forcings depends on their temporal resolution.",1회,"Rainfall–runoff prediction at multiple timescales with a single Long Short-Term Memory network
M Gauch, F Kratzert, D Klotz, G Nearing, J Lin… - Hydrology and Earth System Sciences, 2021
1회 인용 전체 5개의 버전",,,,,,,,
Convergence proof for actor-critic methods applied to ppo and rudder,"Markus Holzleitner, Lukas Gruber, José Arjona-Medina, Johannes Brandstetter, Sepp Hochreiter",2021,,,,105-130,"Springer, Berlin, Heidelberg","We prove under commonly used assumptions the convergence of actor-critic reinforcement learning algorithms, which simultaneously learn a policy function, the actor, and a value function, the critic. Both functions can be deep neural networks of arbitrary complexity. Our framework allows showing convergence of the well known Proximal Policy Optimization (PPO) and of the recently introduced RUDDER. For the convergence proof we employ recently introduced techniques from the two time-scale stochastic approximation theory.",1회,"Convergence proof for actor-critic methods applied to ppo and rudder
M Holzleitner, L Gruber, J Arjona-Medina… - Transactions on Large-Scale Data-and Knowledge …, 2021
1회 인용 관련 학술자료 전체 2개의 버전",,Transactions on Large-Scale Data-and Knowledge-Centered Systems XLVIII,,,,,,
Cost Optimization at Early Stages of Design Using Deep Reinforcement Learning,"Lorenzo Servadei, Jiapeng Zheng, José Arjona-Medina, Michael Werner, Volkan Esen, Sepp Hochreiter, Wolfgang Ecker, Robert Wille",2020/11/16,,,,37-42,,"With the increase in the complexity of the modern system on Chips (SoCs) and the demand for a lower time-to-market, automation becomes essential in hardware design. This is particularly relevant in complex/time-consuming tasks, as the optimization of design cost for a hardware component. Design cost, in fact, may depend on several objectives, as for the hardware-software trade-off. Given the complexity of this task, the designer often has no means to perform a fast and effective optimization in particular for larger and complex designs. In this paper, we introduce Deep Reinforcement Learning (DRL) for design cost optimization at the early stages of the design process. We first show that DRL is a perfectly suitable solution for the problem at hand. Afterward, by means of a Pointer Network, a neural network specifically applied for combinatorial problems, we benchmark three DRL algorithms towards the selected …",1회,"Cost Optimization at Early Stages of Design Using Deep Reinforcement Learning
L Servadei, J Zheng, J Arjona-Medina, M Werner… - Proceedings of the 2020 ACM/IEEE Workshop on …, 2020
1회 인용 관련 학술자료",,Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning for CAD,,,,,,
Cross-Domain Few-Shot Learning by Representation Fusion,"Thomas Adler, Johannes Brandstetter, Michael Widrich, Andreas Mayr, David Kreil, Michael Kopp, Günter Klambauer, Sepp Hochreiter",2020/10/13,arXiv preprint arXiv:2010.06498,,,,,"In order to quickly adapt to new data, few-shot learning aims at learning from few examples, often by using already acquired knowledge. The new data often differs from the previously seen data due to a domain shift, that is, a change of the input-target distribution. While several methods perform well on small domain shifts like new target classes with similar inputs, larger domain shifts are still challenging. Large domain shifts may result in high-level concepts that are not shared between the original and the new domain. However, low-level concepts like edges in images might still be shared and useful. For cross-domain few-shot learning, we suggest representation fusion to unify different abstraction levels of a deep neural network into one representation. We propose Cross-domain Hebbian Ensemble Few-shot learning (CHEF), which achieves representation fusion by an ensemble of Hebbian learners acting on different layers of a deep neural network that was trained on the original domain. On the few-shot datasets miniImagenet and tieredImagenet, where the domain shift is small, CHEF is competitive with state-of-the-art methods. On cross-domain few-shot benchmark challenges with larger domain shifts, CHEF establishes novel state-of-the-art results in all categories. We further apply CHEF on a real-world cross-domain application in drug discovery. We consider a domain shift from bioactive molecules to environmental chemicals and drugs with twelve associated toxicity prediction tasks. On these tasks, that are highly relevant for computational drug discovery, CHEF significantly outperforms all its competitors. Github: this https URL",1회,"Cross-Domain Few-Shot Learning by Representation Fusion
T Adler, J Brandstetter, M Widrich, A Mayr, D Kreil… - arXiv preprint arXiv:2010.06498, 2020
1회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
DeepRC: Immune repertoire classification with attention-based deep massive multiple instance learning,"Michael Widrich, Bernhard Schäfl, Milena Pavlović, Geir Kjetil Sandve, Sepp Hochreiter, Victor Greiff, Günter Klambauer",2020/1/1,bioRxiv,,,,Cold Spring Harbor Laboratory,"High-throughput immunosequencing allows reconstructing the immune repertoire of an individual, which is an exceptional opportunity for new immunotherapies, immunodiagnostics, and vaccine design. Such immune repertoires are shaped by past and current immune events, for example infection and disease, and thus record an individual9s state of health. Consequently, immune repertoire sequencing data may enable the prediction of health and disease using machine learning. However, finding the connections between an individual9s repertoire and the individual9s disease class, with potentially hundreds of thousands to millions of short sequences per individual, poses a difficult and unique challenge for machine learning methods. In this work, we present our method DeepRC that combines a Deep Learning architecture with attention-based multiple instance learning. To validate that DeepRC accurately predicts an individual9s disease class based on its immune repertoire and determines the associated class-specific sequence motifs, we applied DeepRC in four large-scale experiments encompassing ground-truth simulated as well as real-world virus infection data. We demonstrate that DeepRC outperforms all tested methods with respect to predictive performance and enables the extraction of those sequence motifs that are connected to a given disease class.",1회,"DeepRC: Immune repertoire classification with attention-based deep massive multiple instance learning
M Widrich, B Schäfl, M Pavlović, GK Sandve… - bioRxiv, 2020
1회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Towards the quantification of uncertainty for deep learning based rainfall-runoff models,"Daniel Klotz, Frederik Kratzert, Mathew Herrnegger, Sepp Hochreiter, Günter Klambauer",2019/1/1,Geophys. Res. Abstr,21,,,,"All forms of hydrological endeavors are pervaded by uncertainty. Therefore it is of little surprise that obtaining realistic estimates of prediction uncertainties has become a persistent ambition. m This contribution analyzes the capability of using a specific regularization-mechanism, called dropout, for uncertainty estimation of a neural network based rainfall-runoff models.
The particular form of network under examination is based on the Long Short-Term Memory (LSTM) architecture, which was explicitly designated for time series applications (Hochreiter, citation). Recently, Kratzert el al.(2018a) have shown that LSTM based modeling approaches can be used as data-driven models for describing the rainfall-runoff relationship. The authors envisioned future applications for task like online prediction, where the model would be used in conjunction with a stack of other models. We believe that this envisioned application will only be possible if the networks will earn the trustworthiness from the wider hydrological community by exhibiting properties that go beyond mere performance. One potential avenue for cashing-out on this point is to open the black-box and analyze if the neural network reproduced internally (known) hydrological patterns (such as snow-accumulation and depletion processes, see Kratzert 2018b). A complementary approach, which is extremely important for any environmental model, is to characterize the uncertainty of a given prediction/simulation.",1회,"Towards the quantification of uncertainty for deep learning based rainfall-runoff models
D Klotz, F Kratzert, M Herrnegger, S Hochreiter… - Geophys. Res. Abstr, 2019
1회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Two Time-Scale Update Rule for Generative Adversarial Nets,"Hubert Ramsauer, Martin Heusel, Sepp Hochreiter, Bernhard Nessler, Thomas Unterthiner",2017,,,,6608-6619,,"Generative adversarial networks (GANs) excel in generating images with complex generative models for which maximum likelihood is infeasible. However training GANs is still not proved to converge. We propose a two time-scale update rule (TTUR) for training GANs with different learning rates for the discriminator and the generator. GANs trained with TTUR can be proved to converge under mild assumptions. The TTUR convergence carries over to the Adam stochastic optimiza-tion, which can be described by a second order differential equation. Experiments show that TTUR improves learning for original GANs, Wasserstein GANs, deep convolutional GANs, and boundary equilibrium GANs. TTUR is compared to conventional GAN training on MNIST, CelebA, Billion Word Benchmark, and LSUN bedrooms. TTUR outperforms conventional GAN training both in learning time and performance. time and performance.",1회,"Two Time-Scale Update Rule for Generative Adversarial Nets
H Ramsauer, M Heusel, S Hochreiter, B Nessler… - Advances in Neural Information Processing Systems, 2017
1회 인용 관련 학술자료",Advances in Neural Information Processing Systems,,,,,,,
Machine Learning Techniques for the Analysis of High-Throughput DNA and RNA Sequencing Data.,Günter Klambauer,2014/4,,,,"I-XXII,1-184",,,1회,"Machine Learning Techniques for the Analysis of High-Throughput DNA and RNA Sequencing Data.
G Klambauer - 2014
1회 인용 관련 학술자료",,,,Universität Linz,,,,
δ-Clustering of Monotone Profiles,"Adetayo Kasim, Suzy Sanden, Martin Otava, Sepp Hochreiter, Djork-Arné Clevert, Willem Talloen, Dan Lin",2012,Modeling Dose-Response Microarray Data in Early Drug Development Experiments Using R,,,135-149,Springer Berlin Heidelberg,"In Chaps. and 8, we discussed several testing procedures to detect differentially expressed genes with monotone relationship with respect to dose. The second question of primary interest in dose-response studies is the nature (or the shape of curve) of the dose-response relationship. In the context of dose-response microarray experiments, we wish to group (or classify) genes with similar dose-response relationship. Similar to the previous chapters, the subset of genes with monotone relationship is of interest.",1회,"δ-clustering of monotone profiles
A Kasim, S Van Sanden, M Otava, S Hochreiter… - Modeling Dose-Response Microarray Data in Early …, 2012
1회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
09081 Summary--Similarity-based learning on structures,"Michael Biehl, Barbara Hammer, Sepp Hochreiter, Stefan C Kremer, Thomas Villmann",2009,,,,,Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik,"The seminar centered around different aspects of similarity-based clustering with the special focus on structures. This included theoretical foundations, new algorithms, innovative applications, and future challenges for the field.",1회,"09081 Summary--Similarity-based learning on structures
M Biehl, B Hammer, S Hochreiter, SC Kremer… - Dagstuhl Seminar Proceedings, 2009
1회 인용 관련 학술자료 전체 10개의 버전
09081 Abstracts Collection--Similarity-based learning on structures*
M Biehl, B Hammer, S Hochreiter, SC Kremer… - Dagstuhl Seminar Proceedings, 2009
전체 11개의 버전",Dagstuhl Seminar Proceedings,,,,,,,
09081 Summary--Similarity-based learning on structures,"Michael Biehl, Barbara Hammer, Sepp Hochreiter, Stefan C Kremer, Thomas Villmann",2009,,,,,Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik,"The seminar centered around different aspects of similarity-based clustering with the special focus on structures. This included theoretical foundations, new algorithms, innovative applications, and future challenges for the field.",1회,"09081 Summary--Similarity-based learning on structures
M Biehl, B Hammer, S Hochreiter, SC Kremer… - Dagstuhl Seminar Proceedings, 2009
1회 인용 관련 학술자료 전체 10개의 버전
09081 Abstracts Collection--Similarity-based learning on structures*
M Biehl, B Hammer, S Hochreiter, SC Kremer… - Dagstuhl Seminar Proceedings, 2009
전체 11개의 버전",Dagstuhl Seminar Proceedings,,,,,,,
"Similaritybased learning on structures, 15.02. 09-20.02. 09, volume 09081 of Dagstuhl Seminar Proceedings","M Biehl, B Hammer, S Hochreiter, S Kremer, T Villmann",2009,"Internationales Begegnungs-und Forschungszentrum fuer Informatik (IBFI), Schloss Dagstuhl, Germany",,,,,,1회,"09081 Summary--Similarity-based learning on structures*
M Biehl, B Hammer, S Hochreiter, SC Kremer… - Dagstuhl Seminar Proceedings, 2009
1회 인용 관련 학술자료 전체 10개의 버전
09081 Abstracts Collection--Similarity-based learning on structures*
M Biehl, B Hammer, S Hochreiter, SC Kremer… - Dagstuhl Seminar Proceedings, 2009
전체 11개의 버전",,,,,,,,
Optimality of lstd and its relation to mc,"Steffen Grunewalder, Sepp Hochreiter, Klaus Obermayer",2007/8/12,,,,338-343,IEEE,"In this analytical study we compare the risk of the Monte Carlo (MC) and the least-squares TD (LSTD) estimator. We prove that for the case of acyclic Markov Reward Processes (MRPs) LSTD has minimal risk for any convex loss function in the class of unbiased estimators. When comparing the Monte Carlo estimator, which does not assume a Markov structure, and LSTD, we find that the Monte Carlo estimator is equivalent to LSTD if both estimators have the same amount of information. Theoretical results are supported by an empirical evaluation of the estimators.",1회,"Optimality of lstd and its relation to mc
S Grunewalder, S Hochreiter, K Obermayer - 2007 International Joint Conference on Neural …, 2007
1회 인용 관련 학술자료 전체 11개의 버전",2007 International Joint Conference on Neural Networks,,,,,,,
A note on leveraging synergy in multiple meteorological data sets with deep learning for rainfall–runoff modeling,"Frederik Kratzert, Daniel Klotz, Sepp Hochreiter, Grey S Nearing",2021/5/20,Hydrology and Earth System Sciences,25,5,2685-2703,Copernicus GmbH,"A deep learning rainfall–runoff model can take multiple meteorological forcing products as input and learn to combine them in spatially and temporally dynamic ways. This is demonstrated with Long Short-Term Memory networks (LSTMs) trained over basins in the continental US, using the Catchment Attributes and Meteorological data set for Large Sample Studies (CAMELS). Using meteorological input from different data products (North American Land Data Assimilation System, NLDAS, Maurer, and Daymet) in a single LSTM significantly improved simulation accuracy relative to using only individual meteorological products. A sensitivity analysis showed that the LSTM combines precipitation products in different ways, depending on location, and also in different ways for the simulation of different parts of the hydrograph.",,"A note on leveraging synergy in multiple meteorological data sets with deep learning for rainfall–runoff modeling
F Kratzert, D Klotz, S Hochreiter, GS Nearing - Hydrology and Earth System Sciences, 2021
전체 2개의 버전",,,,,,,,
Learning 3D Granular Flow Simulations,"Andreas Mayr, Sebastian Lehner, Arno Mayrhofer, Christoph Kloss, Sepp Hochreiter, Johannes Brandstetter",2021/5/4,arXiv preprint arXiv:2105.01636,,,,,"Recently, the application of machine learning models has gained momentum in natural sciences and engineering, which is a natural fit due to the abundance of data in these fields. However, the modeling of physical processes from simulation data without first principle solutions remains difficult. Here, we present a Graph Neural Networks approach towards accurate modeling of complex 3D granular flow simulation processes created by the discrete element method LIGGGHTS and concentrate on simulations of physical systems found in real world applications like rotating drums and hoppers. We discuss how to implement Graph Neural Networks that deal with 3D objects, boundary conditions, particle - particle, and particle - boundary interactions such that an accurate modeling of relevant physical quantities is made possible. Finally, we compare the machine learning based trajectories to LIGGGHTS trajectories in terms of particle flows and mixing entropies.",,"Learning 3D Granular Flow Simulations
A Mayr, S Lehner, A Mayrhofer, C Kloss, S Hochreiter… - arXiv preprint arXiv:2105.01636, 2021
전체 3개의 버전",,,,,,,,
The promise of AI for DILI prediction,"Andreu Vall, Yogesh Sabnis, Jiye Shi, Reiner Class, Sepp Hochreiter, Günter Klambauer",2021/4/14,,4,,15,Frontiers,"Drug-induced liver injury (DILI) is a common reason for the withdrawal of a drug from the market. Early assessment of DILI risk is an essential part of drug development, but it is rendered challenging prior to clinical trials by the complex factors that give rise to liver damage. Artificial intelligence (AI) approaches, particularly those building on machine learning, range from random forests to more recent techniques such as deep learning, and provide tools that can analyze chemical compounds and accurately predict some of their properties based purely on their structure. This article reviews existing AI approaches to predicting DILI and elaborates on the challenges that arise from the as yet limited availability of data. Future directions are discussed focusing on rich data modalities, such as 3D spheroids, and the slow but steady increase in drugs annotated with DILI risk labels.",,"The promise of AI for DILI prediction
A Vall, Y Sabnis, J Shi, R Class, S Hochreiter… - Frontiers in Artificial Intelligence, 2021
전체 4개의 버전",,,Frontiers in Artificial Intelligence,,,,,
Modern Hopfield Networks for Few-and Zero-Shot Reaction Prediction,"Philipp Seidl, Philipp Renz, Natalia Dyubankova, Paulo Neves, Jonas Verhoeven, Jörg K Wegner, Sepp Hochreiter, Günter Klambauer",2021/4/7,arXiv preprint arXiv:2104.03279,,,,,"An essential step in the discovery of new drugs and materials is the synthesis of a molecule that exists so far only as an idea to test its biological and physical properties. While computer-aided design of virtual molecules has made large progress, computer-assisted synthesis planning (CASP) to realize physical molecules is still in its infancy and lacks a performance level that would enable large-scale molecule discovery. CASP supports the search for multi-step synthesis routes, which is very challenging due to high branching factors in each synthesis step and the hidden rules that govern the reactions. The central and repeatedly applied step in CASP is reaction prediction, for which machine learning methods yield the best performance. We propose a novel reaction prediction approach that uses a deep learning architecture with modern Hopfield networks (MHNs) that is optimized by contrastive learning. An MHN is an associative memory that can store and retrieve chemical reactions in each layer of a deep learning architecture. We show that our MHN contrastive learning approach enables few- and zero-shot learning for reaction prediction which, in contrast to previous methods, can deal with rare, single, or even no training example(s) for a reaction. On a well established benchmark, our MHN approach pushes the state-of-the-art performance up by a large margin as it improves the predictive top-100 accuracy from to . This advance might pave the way to large-scale molecule discovery.",,"Modern Hopfield Networks for Few-and Zero-Shot Reaction Prediction
P Seidl, P Renz, N Dyubankova, P Neves, J Verhoeven… - arXiv preprint arXiv:2104.03279, 2021
전체 3개의 버전",,,,,,,,
Trusted Artificial Intelligence: Towards Certification of Machine Learning Applications,"Philip Matthias Winter, Sebastian Eder, Johannes Weissenböck, Christoph Schwald, Thomas Doms, Tom Vogt, Sepp Hochreiter, Bernhard Nessler",2021/3/31,arXiv preprint arXiv:2103.16910,,,,,"Artificial Intelligence is one of the fastest growing technologies of the 21st century and accompanies us in our daily lives when interacting with technical applications. However, reliance on such technical systems is crucial for their widespread applicability and acceptance. The societal tools to express reliance are usually formalized by lawful regulations, i.e., standards, norms, accreditations, and certificates. Therefore, the T\""UV AUSTRIA Group in cooperation with the Institute for Machine Learning at the Johannes Kepler University Linz, proposes a certification process and an audit catalog for Machine Learning applications. We are convinced that our approach can serve as the foundation for the certification of applications that use Machine Learning and Deep Learning, the techniques that drive the current revolution in Artificial Intelligence. While certain high-risk areas, such as fully autonomous robots in workspaces shared with humans, are still some time away from certification, we aim to cover low-risk applications with our certification procedure. Our holistic approach attempts to analyze Machine Learning applications from multiple perspectives to evaluate and verify the aspects of secure software development, functional requirements, data quality, data protection, and ethics. Inspired by existing work, we introduce four criticality levels to map the criticality of a Machine Learning application regarding the impact of its decisions on people, environment, and organizations. Currently, the audit catalog can be applied to low-risk applications within the scope of supervised learning as commonly encountered in industry. Guided by field experience …",,"Trusted Artificial Intelligence: Towards Certification of Machine Learning Applications
PM Winter, S Eder, J Weissenböck, C Schwald, T Doms… - arXiv preprint arXiv:2103.16910, 2021
전체 2개의 버전",,,,,,,,
Large-scale river network modeling using Graph Neural Networks,"Frederik Kratzert, Daniel Klotz, Martin Gauch, Christoph Klingler, Grey Nearing, Sepp Hochreiter",2021/3/3,,,EGU21-13375,,Copernicus Meetings,"In the recent past, several studies have demonstrated the ability of deep learning (DL) models, especially based on Long Short-Term Memory (LSTM) networks, for rainfall-runoff modeling. However, almost all of these studies were limited to (multiple) individual catchments or small river networks, consisting of only a few connected catchments.
In this study, we investigate large-scale, spatially distributed rainfall-runoff modeling using DL models. Our setup consists of two independent model components: One model for the runoff-generation process and one for the routing. The former is an LSTM-based model that predicts the discharge contribution of each sub-catchment in a river network. The latter is a Graph Neural Network (GNN) that routes the water along the river network network in hierarchical order. The first part is set up to simulate unimpaired runoff for every sub-catchment. Then, the GNN routes the water …",,"Large-scale river network modeling using Graph Neural Networks
F Kratzert, D Klotz, M Gauch, C Klingler, G Nearing… - 2021
전체 2개의 버전",,,EGU21,,,,,
Uncertainty estimation with LSTM based rainfall-runoff models,"Daniel Klotz, Frederik Kratzert, Martin Gauch, Alden K Sampson, Günter Klambauer, Johannes Brandstetter, Sepp Hochreiter, Grey Nearing",2021/3/3,,,EGU21-13308,,Copernicus Meetings,"Uncertainty is a central part of hydrological inquiry. Deep Learning provides us with new tools for estimating these inherent uncertainties. The currently best performing rainfall-runoff models are based on Long Short-Term Memory (LSTM) networks. However, most LSTM-based modelling studies focus on point estimates.
Building on the success of LSTMs for estimating point predictions, this contribution explores different extensions to directly provide uncertainty estimations. We find that the resulting models provide excellent estimates in our benchmark for daily rainfall-runoff across hundreds basins. We provide an intuitive overview of these strong results, the benchmarking procedure, and the approaches used for obtaining them.",,"Uncertainty estimation with LSTM based rainfall-runoff models
D Klotz, F Kratzert, M Gauch, AK Sampson… - 2021
전체 2개의 버전",,,EGU21,,,,,
Multi-Timescale LSTM for Rainfall–Runoff Forecasting,"Martin Gauch, Frederik Kratzert, Grey Nearing, Jimmy Lin, Sepp Hochreiter, Johannes Brandstetter, Daniel Klotz",2021/3/3,,,EGU21-9714,,Copernicus Meetings,"Rainfall–runoff predictions are generally evaluated on reanalysis datasets such as the DayMet, Maurer, or NLDAS forcings in the CAMELS dataset. While useful for benchmarking, this does not fully reflect real-world applications. There, meteorological information is much coarser, and fine-grained predictions are at best available until the present. For any prediction of future discharge, we must rely on forecasts, which introduce an additional layer of uncertainty. Thus, the model inputs need to switch from past data to forecast data at some point, which raises several questions: How can we design models that support this transition? How can we design tests that evaluate the performance of the model? Aggravating the challenge, the past and future data products may include different variables or have different temporal resolutions.
We demonstrate how to seamlessly integrate past and future meteorological data in one …",,"Multi-Timescale LSTM for Rainfall–Runoff Forecasting
M Gauch, F Kratzert, G Nearing, J Lin, S Hochreiter… - 2021
전체 2개의 버전",,,EGU21,,,,,
Machine Learning based COVID-19 Diagnosis from Blood Tests with Robustness to Domain Shifts,"Theresa Roland, Carl Boeck, Thomas Tschoellitsch, Alexander Maletzky, Sepp Hochreiter, Jens Meier, Guenter Klambauer",2021/1/1,medRxiv,,,,Cold Spring Harbor Laboratory Press,"We investigate machine learning models that identify COVID-19 positive patients and estimate the mortality risk based on routinely acquired blood tests in a hospital setting. However, during pandemics or new outbreaks, disease and testing characteristics change, thus we face domain shifts. Domain shifts can be caused, e.g., by changes in the disease prevalence (spreading or tested population), by refined RT-PCR testing procedures (taking samples, laboratory), or by virus mutations. Therefore, machine learning models for diagnosing COVID-19 or other diseases may not be reliable and degrade in performance over time. To countermand this effect, we propose methods that first identify domain shifts and then reverse their negative effects on the model performance. Frequent re-training and re-assessment, as well as stronger weighting of more recent samples, keeps model performance and credibility at a high level over time. Our diagnosis models are constructed and tested on large-scale data sets, steadily adapt to observed domain shifts, and maintain high ROC AUC values along pandemics.",,"Machine Learning based COVID-19 Diagnosis from Blood Tests with Robustness to Domain Shifts
T Roland, C Boeck, T Tschoellitsch, A Maletzky… - medRxiv, 2021
전체 5개의 버전",,,,,,,,
immuneML: an ecosystem for machine learning analysis of adaptive immune receptor repertoires,"Milena Pavlovic, Lonneke Scheffer, Keshav Motwani, Chakravarthi Kanduri, Radmila Kompova, Nikolay Vazov, Knut Waagan, Fabian LM Bernal, Alexandre Almeida Costa, Brian Corrie, Rahmad Akbar, Ghadi S Al Hajj, Gabriel Balaban, Todd M Brusko, Maria Chernigovskaya, Scott Christley, Lindsay G Cowell, Robert Frank, Ivar Grytten, Sveinung Gundersen, Ingrid Hobæk Haff, Sepp Hochreiter, Eivind Hovig, Ping-Han Hsieh, Gunter Klambauer, Marieke L Kuijjer, Christin Lund-Andersen, Antonio Martini, Thomas Minotto, Johan Pensar, Knut Rand, Enrico Riccardi, Philippe A Robert, Artur Rocha, Andrei Slabodkin, Igor Snapkov, Ludvig M Sollid, Dmytro Titov, Cédric R Weber, Michael Widrich, Gur Yaari, Victor Greiff, Geir Kjetil Sandve",2021/1/1,bioRxiv,,,,Cold Spring Harbor Laboratory,"Adaptive immune receptor repertoires (AIRR) are key targets for biomedical research as they record past and ongoing adaptive immune responses. The capacity of machine learning (ML) to identify complex discriminative sequence patterns renders it an ideal approach for AIRR-based diagnostic and therapeutic discovery. To date, widespread adoption of AIRR ML has been inhibited by a lack of reproducibility, transparency, and interoperability. immuneML (immuneml.uio.no) addresses these concerns by implementing each step of the AIRR ML process in an extensible, open-source software ecosystem that is based on fully specified and shareable workflows. To facilitate widespread user adoption, immuneML is available as a command-line tool and through an intuitive Galaxy web interface, and extensive documentation of workflows is provided. We demonstrate the broad applicability of immuneML by (i) reproducing a large-scale study on immune state prediction, (ii) developing, integrating, and applying a novel method for antigen specificity prediction, and (iii) showcasing streamlined interpretability-focused benchmarking of AIRR ML.",,"immuneML: an ecosystem for machine learning analysis of adaptive immune receptor repertoires
M Pavlovic, L Scheffer, K Motwani, C Kanduri… - bioRxiv, 2021
전체 2개의 버전",,,,,,,,
Examining the uncertainty estimation properties of LSTM based rainfall-runoff models,"Daniel Klotz, Frederik Kratzert, Martin Gauch, Alden Keefe Sampson, Sepp Hochreiter, Grey Stephen Nearing",2020/12/17,AGU Fall Meeting 2020,,,,AGU,,,"Examining the uncertainty estimation properties of LSTM based rainfall-runoff models
D Klotz, F Kratzert, M Gauch, AK Sampson… - AGU Fall Meeting 2020, 2020",,,,,,,,
Towards deep learning based flood forecasting for ungauged basins,"Frederik Kratzert, Daniel Klotz, Guy Shalev, Sella Nevo, Günter Klambauer, Grey Nearing, Sepp Hochreiter",2020/5,EGU General Assembly Conference Abstracts,,,8932,,"As of today, streamflow forecasts are usually made with either conceptual or process-based hydrological models. The problem these models usually have is that they perform best when calibrated for a specific basin, and performance degrades drastically if the models are used in places without historic streamflow measurements. To make things worse, some of the most devastating floods occur in developing and low-income countries, where historic records of streamflow measurements are scarce. Therefore, a central task for enhancing flood forecasts and helping local authorities to manage these areas is to provide high-quality streamflow forecasts in ungauged rivers. Although the IAHS dedicated an entire decade (2003-2012) to advance the problem of Prediction in Ungauged Basins the central goal remains largely a challenge.
In this talk, we will present a novel approach for tackling the problem of prediction in ungauged basins using a data-driven approach. More concretely, we show that the Long Short-Term Memory network (LSTM), which is a special type of a deep learning model, can serve as a generalizable rainfall-runoff simulation model. We will present recent results indicating that the LSTM gives on average better out-of-sample predictions (ungauged prediction) than eg the SAC-SMA in-sample (gauged) or the US National Water Model (Kratzert et al., 2019).",,"Towards deep learning based flood forecasting for ungauged basins
F Kratzert, D Klotz, G Shalev, S Nevo, G Klambauer… - EGU General Assembly Conference Abstracts, 2020
전체 3개의 버전",,,,,,,,
Learning from mistakes: Online updating for deep learning models.,"Daniel Klotz, Frederik Kratzert, Alden K Sampson, Günter Klambauer, Sepp Hochreiter, Grey Nearing",2020/5,EGU General Assembly Conference Abstracts,,,8853,,"Accurate streamflow forecasts are important for many operational purposes, like hydropower operation or flood risk management. It is obvious that for data-driven models best prediction performance would be obtained if recent streamflow observations were used as an additional model input. Therefore, there exists a certain imperative which demands to use forecasting models that use discharge signals whenever available. Forecasting models are, however, not well suited when continuous measurement of discharge can not be guaranteed or for applications in ungauged settings. Regarding the former, missing data can have long lasting repercussions on data-driven models if large data-windows are used for the input. Regarding the latter, data-driven forecast models are not applicable at all. Additionally, we would like to point out that data-driven simulation models need to represent the underlying hydrological …",,"Learning from mistakes: Online updating for deep learning models.
D Klotz, F Kratzert, AK Sampson, G Klambauer… - EGU General Assembly Conference Abstracts, 2020",,,,,,,,
The performance of LSTM models from basin to continental scales,"Frederik Kratzert, Daniel Klotz, Günter Klambauer, Grey Nearing, Sepp Hochreiter",2020/3/9,,,EGU2020-8855,,Copernicus Meetings,"Simulation accuracy among traditional hydrological models usually degrades significantly when going from single basin to regional scale. Hydrological models perform best when calibrated for specific basins, and do worse when a regional calibration scheme is used.
One reason for this is that these models do not (have to) learn hydrological processes from data. Rather, they have a predefined model structure and only a handful of parameters adapt to specific basins. This often yields less-than-optimal parameter values when the loss is not determined by a single basin, but by many through regional calibration.",,"The performance of LSTM models from basin to continental scales
F Kratzert, D Klotz, G Klambauer, G Nearing… - 2020
관련 학술자료 전체 3개의 버전",,,EGU2020,,,,,
The LSC Benchmark Dataset: Technical Appendix and Partial Reanalysis,"Andreas Mayr, Günter Klambauer, Thomas Unterthiner, Sepp Hochreiter",2020/2/12,,,,,,"We recently published the article “Large-scale comparison of machine learning methods for drug target prediction on ChEMBL “, that compared machine learning methods for drug target prediction. Thereby we tried to suggest a pipeline for avoiding three biases, that are often immanent to target prediction performance comparison studies. In the following, we present an overview over the dataset, the pipeline, and discuss some technical details with respect to a large-scale study, such as ours. Furthermore, we provide results of a partial reanalysis of some of the deep learning results by changing the normalization aspect of feature preprocessing.",,"The LSC Benchmark Dataset: Technical Appendix and Partial Reanalysis
A Mayr, G Klambauer, T Unterthiner, S Hochreiter - 2020
관련 학술자료",,,,,,,,
A Deep Learning Architecture for Conservative Dynamical Systems: Application to Rainfall-Runoff Modeling,"Grey Nearing, Frederik Kratzert, Daniel Klotz, Pieter-Jan Hoedt, Günter Klambauer, Sepp Hochreiter, Hoshin Gupta, Sella Nevo, Yossi Matias",2020,,,,,,"The most accurate and generalizable rainfall-runoff models produced by the hydrological sciences community to-date are based on deep learning, and in particular, on Long Short Term Memory networks (LSTMs). Although LSTMs have an explicit state space and gates that mimic input-state-output relationships, these models are not based on physical principles. We propose a deep learning architecture that is based on the LSTM and obeys conservation principles. The model is benchmarked on the mass-conservation problem of simulating streamflow",,"A Deep Learning Architecture for Conservative Dynamical Systems: Application to Rainfall-Runoff Modeling
G Nearing, F Kratzert, D Klotz, PJ Hoedt, G Klambauer… - 2020",,,,,,,,
Large-Scale Rainfall-Runoff Modeling using the Long Short-Term Memory Network,"Frederik Kratzert, Daniel Klotz, Günter Klambauer, Sepp Hochreiter, Grey Stephen Nearing",2019/12/13,AGU Fall Meeting 2019,,,,AGU,,,"Large-Scale Rainfall-Runoff Modeling using the Long Short-Term Memory Network
F Kratzert, D Klotz, G Klambauer, S Hochreiter… - AGU Fall Meeting 2019, 2019
전체 2개의 버전",,,,,,,,
Large-Scale Rainfall-Runoff Modeling using the Long Short-Term Memory Network,"GS Nearing, F Kratzert, D Klotz, G Klambauer, S Hochreiter",2019/12,AGU Fall Meeting Abstracts,2019,,H53B-05,,"An outstanding problem in the hydrological modeling community is how to effectively use large-scale data sets for enhancing rainfall-runoff models. Currently, hydrological models perform best when calibrated for a specific basin, ignoring additional information that could be extracted from other (similar behaving) basins.",,"Large-Scale Rainfall-Runoff Modeling using the Long Short-Term Memory Network
GS Nearing, F Kratzert, D Klotz, G Klambauer… - AGU Fall Meeting Abstracts, 2019",,,,,,,,
Posterior Sampling: Make Reinforcement Learning Sample Efficient Again,"Calvin Seward, Urs Bergmann, Roland Vollgraf, Sepp Hochreiter",2019/9/25,,,,,,"Machine learning thrives on leveraging structure in data, and many breakthroughs (eg\convolutional networks) have been made by designing algorithms which exploit the underlying structure of a distribution. Reinforcement Learning agents interact with worlds that are similarly full of structure. For example, no sequence of actions an agent takes will ever cause the laws of physics to change, therefore an agent which learns to generalize such laws through time and space will have an advantage. Sample efficient reinforcement learning can be accomplished when assuming that the world has structure and designing learning algorithms which exploit this assumption without knowing the actual structure beforehand. Posterior Sampling for Reinforcement Learning (PSRL)\citep {strens2000bayesian} is such a method which assumes structure in the world and exploits it for learning. A PSLR learning agent first samples models of the environment which conform to both prior assumptions on the world's structure and past observations and then interacts with the true environment using a policy guided by the sampled model of the environment. While PSRL delivers theoretical Bayesian regret bounds, there are many open issues which must be addressed before PSRL can be applied to current benchmark continuous reinforcement reinforcement tasks. In this work, we identify these issues and find practical solutions to them leading to a novel algorithm we call Neural-PSRL. We validate the algorithm's effectiveness by achieving state of the art results in the HalfCheetah-v3 and Hopper-v3 domains.",,"Posterior Sampling: Make Reinforcement Learning Sample Efficient Again
C Seward, U Bergmann, R Vollgraf, S Hochreiter - 2019
관련 학술자료",,,,,,,,
A GAN based solver of black-box inverse problems,"Michael Gillhofer, Hubert Ramsauer, Johannes Brandstetter, Bernhard Schäfl, Sepp Hochreiter",2019/9/14,,,,,,"We propose a GAN based approach to solve inverse problems which have non-differential or non-continuous forward relations. In the standard sense, an inverse problem is interpreted as the process of calculating factors that produce observations. We reformulate the inverse problem such that the discriminator is a binary classifier and the generator is used to produce samples in a local region of the input domain of the forward relation. Our GAN based approach solves inverse problems by using adversarial training but without relying on the gradients of the original problem formulation. We prove the efficacy of our approach by applying it to an artificially generated topology optimization problem. We demonstrate that despite not having access to derivatives of f our method leads to similar results than more traditional topology optimization methods.",,"A GAN based solver of black-box inverse problems
M Gillhofer, H Ramsauer, J Brandstetter, B Schäfl… - 2019
관련 학술자료 전체 2개의 버전",,,,,,,,
NeuralHydrology–Interpreting LSTMs in Hydrology,"Sepp Hochreiter, Günter Klambauer",2019/9/10,"Explainable AI: Interpreting, Explaining and Visualizing Deep Learning",11700,,347,Springer Nature,"Despite the huge success of Long Short-Term Memory networks, their applications in environmental sciences are scarce. We argue that one reason is the difficulty to interpret the internals of trained networks. In this study, we look at the application of LSTMs for rainfallrunoff forecasting, one of the central tasks in the field of hydrology, in which the river discharge has to be predicted from meteorological observations. LSTMs are particularly well-suited for this problem since memory cells can represent dynamic reservoirs and storages, which are essential components in state-space modelling approaches of the hydrological system. On basis of two different catchments, one with snow influence and one without, we demonstrate how the trained model can be analyzed and interpreted. In the process, we show that the network internally learns to represent patterns that are consistent with our qualitative understanding of the hydrological system.",,"NeuralHydrology–Interpreting LSTMs in Hydrology
S Hochreiter, G Klambauer - Explainable AI: Interpreting, Explaining and Visualizing …, 2019
관련 학술자료",,,,,,,,
What compound to synthesize next? How machine learning and artificial intelligence impact compound optimization,"Daniel Kuhn, Kristina Preuer, Michael Krug, Guenter Klambauer, Sepp Hochreiter, Friedrich Rippmann",2019/8/25,,258,,,AMER CHEMICAL SOC,,,"What compound to synthesize next? How machine learning and artificial intelligence impact compound optimization
D Kuhn, K Preuer, M Krug, G Klambauer, S Hochreiter… - ABSTRACTS OF PAPERS OF THE AMERICAN …, 2019",ABSTRACTS OF PAPERS OF THE AMERICAN CHEMICAL SOCIETY,,,,,,,
Fréchet ChemNet Distance: A metric for generative models for molecules in drug design—Supporting Information—,"Kristina Preuer, Philipp Renz, Thomas Unterthiner, Sepp Hochreiter, Günter Klambauer",2019/5,Deep Learning in Drug Discovery,,,59,,S1 Determination of necessary data set size of generated molecules to reliable estimate the mean m and covariance C ofthegeneratedsamples........... 3 S2 FCD for real molecules stemming from different databases. The title indicates the used reference set. The bars show the mean FCD of the different real molecule sets and the baseline. The real molecules exhibit a lower FCD compared to the baseline independent of the reference set...................... 4 S3 ArchitectureofChemNet.............................. 6,,"Fréchet ChemNet Distance: A metric for generative models for molecules in drug design—Supporting Information—
K Preuer, P Renz, T Unterthiner, S Hochreiter… - Deep Learning in Drug Discovery, 2019
관련 학술자료 전체 3개의 버전",,,,,,,,
Publication Supplement,"Kristina Preuer, Richard PI Lewis, Sepp Hochreiter, Andreas Bender, Krishna C Bulusu, Günter Klambauer",2019/5,Deep Learning in Drug Discovery,,,44,,"This report gives supplementary information to the manuscript “DeepSynergy: Prediction of anticancer drug synergies with Deep Learning”. It provides more detailed information in the following three sections: data set, methods and results. The first section describes the drugs and cell lines the data set consisted of. The second section informs about the hyperparamter space for the different methods and about the order independence of Deep Synergy. The last section provides further information for the 3 different cross validation strategies.",,"Publication Supplement
K Preuer, RPI Lewis, S Hochreiter, A Bender… - Deep Learning in Drug Discovery, 2019
전체 2개의 버전",,,,,,,,
Supplementary Material: DeepTox: Toxicity Prediction using Deep Learning,"Andreas Mayr, G ünter Klambauer, Thomas Unterthiner, Sepp Hochreiter",2019/3,Deep Learning methods for generative learning and applications in drug discovery,,,65,,"The Supplementary Material contains additional information on the chemical descriptors (Section 1), how the Tox21 challenge dataset can be augmented (Section 2), how probabilistic ensemble predictions (Section 3) are built in the DeepTox pipeline, a performance comparison of toxicophore detecting DNNs with a DNN based on the full descriptor set (Section 4) and the computational resources used (Section 5).",,"Supplementary Material: DeepTox: Toxicity Prediction using Deep Learning
A Mayr, G ünter Klambauer, T Unterthiner, S Hochreiter - Deep Learning methods for generative learning and …, 2019
관련 학술자료 전체 2개의 버전",,,,,,,,
Deep Learning in Drug Discovery/submitted by Kristina Preuer,Kristina Preuer,2019,,,,,,"Machine learning methods have a long tradition in data-driven, computational drug discovery. Drug discovery is a complex multi-stage process which requires expertise and time both being costly factors. Data-driven approaches, such as machine learning and especially Deep Learning, can drastically reduce these costs and the time needed by utilising experimentally gathered data. Furthermore, machine learning methods can improve drug discovery at several different stages. The aim of this thesis is to explore those multiple leverage points for Deep Learning models in order to facilitate the multifaceted process of drug discovery. First, we suggest a method to predict synergetic effects of drug combinations for different cancer types. Secondly, an evaluation metric for computational methods generating novel molecules is proposed. Thirdly, we investigate how Deep Learning models in drug discovery can be interpreted by identifying indicative substructures. These pieces can be combined to create powerful generative models, which both generate promising drug candidates or drug combinations as well as pharmacological knowledge. In this thesis, a Deep Learning approach is presented which expands current activity prediction approaches by two dimensions: drug combinations and disease-specific characteristics. More precisely, the presented deep neural network combines information about two different molecular structures with genetic features describing cancer cells in order to predict biological activity. Therefore, this work creates a broad foundation for data driven activity prediction, because it demonstrates how classical approaches can …",,"Deep Learning in Drug Discovery/submitted by Kristina Preuer
K Preuer - 2019
전체 2개의 버전",,,,Universität Linz,,,,
Using large data sets towards generating a catchment aware hydrological model for global applications,"Frederik Kratzert, Daniel Klotz, Mathew Herrnegger, Sepp Hochreiter, Günter Klambauer",2019/1/1,EGU General Assembly Conference Abstracts,,,13795,,"One reason for the success of deep learning across many applications (eg image classification or machine translation) are large and publicly available data sets. In Hydrology, more specifically in the area of rainfall-runoff modelling, such publicly available data sets are still rare but are increasingly emerging from the community (eg CAMELS [1, 2] and CAMELS-CL [3]). Having such data sets allows to test new data-driven approaches for old but still outstanding hydrological problems.
In this study we build upon the idea of Kratzert et al.[4] using LSTM (Long Short-Term Memory) networks as a regional hydrological model. However, substantial changes are made:(a) We train a single model on hundreds of catchments across the USA, not only for a single HUC (hydrological unit) as in [4](b) We do not only use meteorological time series as inputs but also static catchment characteristics through an adaption of the original LSTM architecture and therefore allow the LSTM to learn a catchment aware hydrological model. Here, we only use catchment characteristics of [2] that do not rely on discharge observation. With this setting we can therefore also investigate, if LSTMs can be used for prediction in ungauged basins. Concretely, we perform 6-fold cross-validation on 531 basins of the CAMELS data set. Out of the 6 splits, 5 are used for training and validation and a single split (approximately 89 basins) as test set for the final evaluation. This mimics an ungauged basin setting by not using any data from the basins in the test set during the entire training period.",,"Using large data sets towards generating a catchment aware hydrological model for global applications
F Kratzert, D Klotz, M Herrnegger, S Hochreiter… - EGU General Assembly Conference Abstracts, 2019
관련 학술자료 전체 3개의 버전",,,,,,,,
panelcn. MOPS: CNV detection in targeted NGS panel data for clinical diagnostics,"Gundula Povysil, A Tzika, J Vogt, V Haunschmid, L Messiaen, J Zschocke, G Klambauer, S Hochreiter, K Wimmer",2018/10/1,,26,,698-698,NATURE PUBLISHING GROUP,"• ROIs with low median RC across all samples excluded• ROIs with high variation of RCs across all samples marked as “low quality”• samples with low median RC across all ROIs excluded from controls, warning for test samples• samples with high variation in ratios between normalized RCs of sample compared to median across all samples excluded from controls, warning for test samples",,"panelcn. MOPS: CNV detection in targeted NGS panel data for clinical diagnostics
G Povysil, A Tzika, J Vogt, V Haunschmid, L Messiaen… - EUROPEAN JOURNAL OF HUMAN GENETICS, 2018
전체 3개의 버전",EUROPEAN JOURNAL OF HUMAN GENETICS,,,,,,,
End-to-end learning of pharmacological assays from high-resolution microscopy images,"Markus Hofmarcher, Elisabeth Rumetshofer, Sepp Hochreiter, Günter Klambauer",2018/9/27,,,,,,"Predicting the outcome of pharmacological assays based on high-resolution microscopy images of treated cells is a crucial task in drug discovery which tremendously increases discovery rates. However, end-to-end learning on these images with convolutional neural networks (CNNs) has not been ventured for this task because it has been considered infeasible and overly complex. On the largest available public dataset, we compare several state-of-the-art CNNs trained in an end-to-end fashion with models based on a cell-centric approach involving segmentation. We found that CNNs operating on full images containing hundreds of cells perform significantly better at assay prediction than networks operating on a single-cell level. Surprisingly, we could predict 29% of the 209 pharmacological assays at high predictive performance (AUC> 0.9). We compared a novel CNN architecture called “GapNet” against four competing CNN architectures and found that it performs on par with the best methods and at the same time has the lowest training time. Our results demonstrate that end-to-end learning on high-resolution imaging data is not only possible but even outperforms cell-centric and segmentation-dependent approaches. Hence, the costly cell segmentation and feature extraction steps are not necessary, in fact they even hamper predictive performance. Our work further suggests that many pharmacological assays could be replaced by high-resolution microscopy imaging together with convolutional neural networks.",,"End-to-end learning of pharmacological assays from high-resolution microscopy images
M Hofmarcher, E Rumetshofer, S Hochreiter… - 2018
관련 학술자료",,,,,,,,
4971 Titles,"Sven-Olaf Lindert, Christian Höfler, Kurt Schlacher, Alexander Humer, Astrid S Pechstein, Martin Meindlhumer, Michael Krommer, Clemens Kastner, Georg Steinbichler, Susanne Kahlen, Michael Jerabek, Thomas Lummerstorfer, Daniel Wöckinger, Wolfgang Amrhein, Stefan Schuster, Johann Reisinger, Marko Hapke, Fabian Fischer, Volkmar Trommer, Stephan J Ginthör, Judith Schlagnitweit, Matthias Bechmann, Norbert Müller, Martin Barna, Mirko Javurek, Peter Wimmer, Christian Marschik, Tim A Osswald, Wolfgang Roland, Hanny Albrecht, Otto Skrabala, Jürgen Miethlinger, Muddasir Shakil, Alois Zoitl, Medina Hamidovic, Uli Marta, Helen Bridle, Damir Hamidovic, Gerold Fink, Robert Wille, Andreas Springer, Werner Haselmayr, Gudrun Gröppel, Tim J von Oertzen, Guillermo Badia, Wolfgang Stockinger, Aicke Hinrichs, Lisa Kaltenböck, Gerhard Larcher, Mario Ullrich, Johannes Fürnkranz, Tomáš Kliegr, Heiko Paulheim, Philipp Renz, Dries Van Rompaey, Jörg Kurt Wegner, Sepp Hochreiter, Günter Klambauer, Sigrid Grepstad, Thomas Vetterlein, Koji Fushimi, Lakshman Neelakantan, Gunther Eggeler, Achim Walter Hassel",2018/6/1,e & i Elektrotechnik und Informationstechnik,135,3,286-293,,UB Linz (ULI).,,"4971 Titles
SO Lindert, C Höfler, K Schlacher, A Humer… - e & i Elektrotechnik und Informationstechnik, 2018",,,,,,,,
Supplementary Material for the Paper “Self-Normalizing Neural Networks”,"Günter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter",2017/11/2,,,,,,"S3 Hyperparameters considered for batch normalized networks in the UCI data sets.. 96 S4 Hyperparameters considered for weight normalized networks in the UCI data sets. 96 S5 Hyperparameters considered for layer normalized networks in the UCI data sets.. 96 S6 Hyperparameters considered for Highway networks in the UCI data sets...... 97 S7 Hyperparameters considered for Residual networks in the UCI data sets...... 97 S8 Comparison of FNN methods on all 121 UCI data sets............... 98 S9 Method comparison on small UCI data sets..................... 101 S10 Method comparison on large UCI data sets..................... 102 S11 Hyperparameters considered for self-normalizing networks in the Tox21 data set. 103 S12 Hyperparameters considered for ReLU networks with MS initialization in the Tox21 dataset........................................ 103
S13 Hyperparameters considered for batch normalized networks in the Tox21 data set. 104 S14 Hyperparameters considered for weight normalized networks in the Tox21 data set. 104 S15 Hyperparameters considered for layer normalized networks in the Tox21 data set. 104 S16 Hyperparameters considered for Highway networks in the Tox21 data set..... 104 S17 Hyperparameters considered for Residual networks in the Tox21 data set...... 105 S18 Hyperparameters considered for self-normalizing networks on the HTRU2 data set. 106 S19 Hyperparameters considered for ReLU networks with Microsoft initialization on theHTRU2dataset.................................. 106 S20 Hyperparameters considered for BatchNorm networks on the HTRU2 data set... 106 S21 Hyperparameters considered for WeightNorm networks on the …",,"Supplementary Material for the Paper “Self-Normalizing Neural Networks”
G Klambauer, T Unterthiner, A Mayr, S Hochreiter - 2017
관련 학술자료",,,,,,,,
Rectified Factor Networks for Biclustering,"Djork-Arné Clevert, Thomas Unterthiner, Sepp Hochreiter",2016/11/2,,,,,,"Biclustering is evolving into one of the major tools for analyzing large datasets given as matrix of samples times features. Biclustering has several noteworthy applications and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively. FABIA is one of the most successful biclustering methods and is used by companies like Bayer, Janssen, or Zalando. FABIA is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated. Sample membership is difficult to determine because vectors do not have exact zero entries and can have both large positive and large negative values. We propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs efficiently construct very sparse, non-linear, high-dimensional representations of the input via their posterior means. RFN learning is a generalized alternating minimization algorithm based on the posterior regularization method which enforces non-negative and normalized posterior means. Each code unit represents a bicluster, where samples for which the code unit is active belong to the bicluster and features that have activating weights to the code unit belong to the bicluster. On 400 benchmark datasets with artificially implanted biclusters, RFN significantly outperformed 13 …",,"Rectified Factor Networks for Biclustering
DA Clevert, T Unterthiner, S Hochreiter - 2016
관련 학술자료 전체 2개의 버전",,,,,,,,
The xMotif algorithm,"Adetayo Kasim, Ziv Shkedy, Sebastian Kaiser, Sepp Hochreiter, Willem Talloen",2016/10/3,,,,75-86,Chapman and Hall/CRC,"The xMotif method, proposed by Murali and Kasif (2003) aims to find conserved gene expression motifs (xMotifs). An xMotif is defined as a subset of rows (genes) that is simultaneously conserved across a subset of the columns (conditions). Hence, xMotif can be seen as a bicluster. Note that although the xMotif method was developed for a gene expression application, it can be applied to any N× M data matrix for which the identification of local patterns is of interest. The analysis presented in this chapter was conducted using the BiclustGUI package, which is a GUI consisting of several R packages for biclustering. An elaborate description of the package is given in Chapter 20.
ABSTRACT",,"The xMotif algorithm
A Kasim, Z Shkedy, S Kaiser, S Hochreiter, W Talloen - Applied Biclustering Methods for Big and High …, 2016",,Applied Biclustering Methods for Big and High-Dimensional Data Using R,,,,,,
Ranking of Biclusters in Drug Discovery Experiments,"Adetayo Kasim, Ziv Shkedy, Sebastian Kaiser, Sepp Hochreiter, Willem Talloen",2016/10/3,,,,249-264,Chapman and Hall/CRC,"In Chapter 14, biclustering is presented as a gene module enrichment technique where we search for a bicluster containing the primary genes of interest. Ideally, we would like to examine all biclusters that were discovered by an algorithm. However, in many cases, a large number of biclusters are reported in a bicluster solution. This implies that a procedure to prioritize biclusters, irrespective of biclustering algorithm is needed. Clearly, one open question is how to determine which biclusters are most informative and rank them on the basis of their importance. In many studies, biclusters are empirically evaluated based on different statistical measures (Koyutürk et al., 2004) or",,"Ranking of Biclusters in Drug Discovery Experiments
A Kasim, Z Shkedy, S Kaiser, S Hochreiter, W Talloen - Applied Biclustering Methods for Big and High …, 2016",,Applied Biclustering Methods for Big and High-Dimensional Data Using R,,,,,,
Biclustering for Cloud Computing,"Adetayo Kasim, Ziv Shkedy, Sebastian Kaiser, Sepp Hochreiter, Willem Talloen",2016/10/3,,,,389-398,Chapman and Hall/CRC,"Over the last few years, cloud computing has become a popular option for data analysis for several reasons. Modern day technologies can produce, capture and store a large amount of data. However, the data analysis framework or the computational power has not developed at the same speed to analyse all these data. Currently, there is an increase in interest to use High Performance Computing (HPC) tools (eg using computer clusters, parallelization of data analysis programs, etc.) to handle big data structures. These HPC tools can be used in a physically available computer cluster. However, powerful hardwares are expensive to buy and maintain. In general, there are two different scenarios: one needs one machine with a certain amount of storage, memory, etc., or a cluster of multiple machines with certain specifications is required to perform the data analysis. Performing the analysis using cloud computing is …",,"Biclustering for Cloud Computing
A Kasim, Z Shkedy, S Kaiser, S Hochreiter, W Talloen - Applied Biclustering Methods for Big and High …, 2016",,Applied Biclustering Methods for Big and High-Dimensional Data Using R,,,,,,
Bimax Algorithm,"Adetayo Kasim, Ziv Shkedy, Sebastian Kaiser, Sepp Hochreiter, Willem Talloen",2016/10/3,,,,87-98,Chapman and Hall/CRC,"Bimax (binary inclusion-maximal biclustering algorithm) is a biclustering algorithm introduced by Prelic et al.(2006) as a reference biclustering method for a comparison with different biclustering methods. They advocate its use as a preprocessing step, to identify potentially relevant biclusters that can be used as input for other methods. The main benefit of Bimax, according to Prelic et al.(2006), is the relatively small computation time, while still providing biologically relevant biclusters using a simple data model. Similar to Chapter 4 the analysis is conducted using the BiclustGUI package. In this chapter we focus on the script window.
ABSTRACT",,"Bimax Algorithm
A Kasim, Z Shkedy, S Kaiser, S Hochreiter, W Talloen - Applied Biclustering Methods for Big and High …, 2016",,Applied Biclustering Methods for Big and High-Dimensional Data Using R,,,,,,
Enrichment of Gene Expression Modules Using Multiple Factor Analysis and Biclustering,"Adetayo Kasim, Ziv Shkedy, Sebastian Kaiser, Sepp Hochreiter, Willem Talloen",2016/10/3,,,,229-248,Chapman and Hall/CRC,"Up to this chapter in the book, we have discussed the setting in which we search for local patterns in a single data matrix X given by",,"Enrichment of Gene Expression Modules Using Multiple Factor Analysis and Biclustering
A Kasim, Z Shkedy, S Kaiser, S Hochreiter, W Talloen - Applied Biclustering Methods for Big and High …, 2016",,Applied Biclustering Methods for Big and High-Dimensional Data Using R,,,,,,
The BiclustGUI Package,"Adetayo Kasim, Ziv Shkedy, Sebastian Kaiser, Sepp Hochreiter, Willem Talloen",2016/10/3,,,,347-374,Chapman and Hall/CRC,"Ewoud De Troyer, Martin Otava, Jitao David Zhang, Setia Pramana, Tatsiana Khamiakova, Sebastian Kaiser, Martin Sill, Aedin Culhane, Daniel Gusenleitner, Pierre Gestraud, Gabor Csardi, Mengsteab Aregay, Sepp Hochreiter, Gunter Klambauer, Djork-Arne Clevert, Tobias Verbeke, Nolen Joy Perualila, Adetayo Kasim and Ziv Shkedy",,"The BiclustGUI Package
A Kasim, Z Shkedy, S Kaiser, S Hochreiter, W Talloen - Applied Biclustering Methods for Big and High …, 2016",,Applied Biclustering Methods for Big and High-Dimensional Data Using R,,,,,,
Spectral Biclustering,"Adetayo Kasim, Ziv Shkedy, Sebastian Kaiser, Sepp Hochreiter, Willem Talloen",2016/10/3,,,,115-124,Chapman and Hall/CRC,The spectral biclustering algorithm was proposed by Kluger et al.(2003) as a method to identify subsets of features and conditions with checkerboard structure. A checkerboard structure can be described as a combination of constantbiclusters in a single data matrix. Figure 7.1 shows an example of a data matrix with 9 biclusters in a checkerboard structure. According to Madeira and Oliveira (2004) the algorithm is designed to identify non-overlapping biclusters and other types of biclusters apart from constant clusters that might not be detected by the algorithm. It is a multiplicative algorithm based on a singular value decomposition (SVD) of the data matrix and requires a normalisation step in order to uncover the underlying checkerboard structures. Figure 7.1 illustrates the multiplicative structure of the signal in the normalized data matrix. Each element in the de-noised data matrix is assumed to be a multiplication of …,,"Spectral Biclustering
A Kasim, Z Shkedy, S Kaiser, S Hochreiter, W Talloen - Applied Biclustering Methods for Big and High …, 2016",,Applied Biclustering Methods for Big and High-Dimensional Data Using R,,,,,,
FABIA,Sepp Hochreiter,2016/10/3,,,,125-144,Chapman and Hall/CRC,"FABIA (factor analysis for bicluster acquisition; Hochreiter et al., 2010) evolved into one of the most successful biclustering methods. It has been applied to genomics, where it identified in gene expression data task-relevant biological modules (Xiong et al., 2014). For example in drug design, first chemical compounds are added to cell lines and then the change in gene expression is measured. The goal is to identify biological modules that are altered by chemical compounds to assess their biological effects (see Chapter 12-Chapter 15 for more details). In another drug design application, FABIA was used to extract biclusters from a data matrix that contains bioactivity measurements across compounds. An entry in the data matrix is the activity level of a compound for a specific bioassay. Biclusters correspond to compounds that are active on similar bioassays, that is compounds that interact with similar proteins, eg, by …",,"FABIA
S Hochreiter - Applied Biclustering Methods for Big and High …, 2016",,Applied Biclustering Methods for Big and High-Dimensional Data Using R,,,,,,
Pattern Discovery in High-Dimensional Problems Using Biclustering Methods for Binary Data,"Adetayo Kasim, Ziv Shkedy, Sebastian Kaiser, Sepp Hochreiter, Willem Talloen",2016/10/3,,,,303-322,Chapman and Hall/CRC,"Analysis of high-dimensional data typically produces vast amount of results. In this chapter, we demonstrate the use of biclustering methods to discover patterns in order to interpret the results and to summarize or integrate them with other sources of information.
ABSTRACT",,"Pattern Discovery in High-Dimensional Problems Using Biclustering Methods for Binary Data
A Kasim, Z Shkedy, S Kaiser, S Hochreiter, W Talloen - Applied Biclustering Methods for Big and High …, 2016",,Applied Biclustering Methods for Big and High-Dimensional Data Using R,,,,,,
HapFABIA: Biclustering for Detecting Identity by Descent,"Adetayo Kasim, Ziv Shkedy, Sebastian Kaiser, Sepp Hochreiter, Willem Talloen",2016/10/3,,,,265-286,Chapman and Hall/CRC,"In this chapter an application of biclustering in genetics is demonstrated. Using FABIA from Chapter 8, the HapFABIA method finds biclusters in genotyping data and, thereby, identifies DNA regions that are shared between individuals. DNA regions are shared between different human populations, between humans and Denisovans, and between humans and Neandertals. This chapter is based on previous publications: Hochreiter et al.(2010); Hochreiter (2013); Povysil and Hochreiter (2014). FABIA and HapFABIA use variational approaches to biclustering (Hochreiter et al., 2010, 2006; Klambauer et al., 2012, 2013). The FABIA learning procedure is a variational expectation maximization (EM), which maximizes the posterior of the parameters (Hochreiter et al., 2010; Talloen et al., 2010; Hochreiter et al., 2006; Talloen et al., 2007; Clevert et al., 2011; Klambauer et al., 2012, 2013). In the next section we ex-",,"HapFABIA: Biclustering for Detecting Identity by Descent
A Kasim, Z Shkedy, S Kaiser, S Hochreiter, W Talloen - Applied Biclustering Methods for Big and High …, 2016",,Applied Biclustering Methods for Big and High-Dimensional Data Using R,,,,,,
The Plaid Model,"Ziv Shkedy, Ewoud De Troyer, Adetayo Kasim, Sepp Hochreiter, Heather Turner",2016/10/3,,,,99-114,Chapman and Hall/CRC,"The plaid model is an additive biclustering method (Lazzeroni and Owen, 2002; Turner et al., 2005) that defines the expression level of the ith gene under the jth condition as a sum of biclusters (layers) in the expression matrix. Let Y be N× M data matrix for which the rows represent genes and the columns conditions. For K biclusters, the gene expression level is expressed as a linear model of the form",,"The Plaid Model
Z Shkedy, E De Troyer, A Kasim, S Hochreiter… - Applied Biclustering Methods for Big and High …, 2016",,Applied Biclustering Methods for Big and High-Dimensional Data Using R,,,,,,
"Verbist B, Klambauer G, Vervoort L, Talloen W, Shkedy Z, Thas O, Bender A","HWH Göhlmann, S Hochreiter, T Bigirumurame",2015,,,,,,"The pharmaceutical industry is faced with steadily declining R&D efficiency which results in fewer drugs reaching the market despite increased investment. A major cause for this low efficiency is the failure of drug candidates in late-stage development owing to safety issues or previously undiscovered side-effects. We analyzed to what extent gene expression data can help to de-risk drug development in early phases by detecting the biological effects of compounds across disease areas, targets and scaffolds. For eight drug discovery projects within a global pharmaceutical company, gene expression data were informative and able to support go/no-go decisions. Our studies show that gene expression profiling can detect adverse effects of compounds, and is a valuable tool in early-stage drug discovery decision making.",,"Verbist B, Klambauer G, Vervoort L, Talloen W, Shkedy Z, Thas O, Bender A
HWH Göhlmann, S Hochreiter, T Bigirumurame - 2015
관련 학술자료",,,,,,,,
"Dagstuhl Reports, Vol. 3, Issue 5 ISSN 2192-5283","Sebastian Maneth, Helmut Seidl, Andreas Kerren, Helen C Purchase, Matthew O Ward, Diego Calvanese, Sven Hartmann, Ernest Teniente, Andreas Bender, Hinrich Göhlmann, Sepp Hochreiter, Ziv Shkedy",2013/10,,,,,,"The aim of this Dagstuhl Seminar was to bring together researchers from various research areas related to the theory and application of tree transducers. Recently, interest in tree transducers has been revived due to surprising new applications in areas such as XML databases, security verification, programming language theory, and linguistics. This seminar therefore aimed to inspire the exchange of theoretical results and information regarding the practical requirements related to tree transducers.",,"Dagstuhl Reports, Vol. 3, Issue 5 ISSN 2192-5283
S Maneth, H Seidl, A Kerren, HC Purchase, MO Ward… - 2013
전체 5개의 버전",,,,,,,,
Package ‘hapFabia’,"Sepp Hochreiter, Maintainer Sepp Hochreiter",2013/6/19,,,,,,"Description A package to identify very short IBD segments in large sequencing data by FABIA biclustering. Two haplotypes are identical by descent (IBD) if they share a segment that both inherited from a common ancestor. Current IBD methods reliably detect long IBD segments because many minor alleles in the segment are concordant between the two haplotypes. However, many cohort studies contain unrelated individuals which share only short IBD segments. This package provides software to identify short IBD segments in sequencing data. Knowledge of short IBD segments are relevant for phasing of genotyping data, association studies, and for population genetics, where they shed light on the evolutionary history of humans. The package supports VCF formats, is based on sparse matrix operations, and provides visualization of haplotype clusters in different formats.",,"Package ‘hapFabia’
S Hochreiter, MS Hochreiter - 2013
관련 학술자료 전체 7개의 버전",,,,,,,,
Package ‘fabia’,"Sepp Hochreiter, Maintainer Sepp Hochreiter",2013/6/19,,,,,,"Description Biclustering by``Factor Analysis for Bicluster Acquisition''(FABIA). FABIA is a model-based technique for biclustering, that is clustering rows and columns simultaneously. Biclusters are found by factor analysis where both the factors and the loading matrix are sparse. FABIA is a multiplicative model that extracts linear dependencies between samples and feature patterns. It captures realistic non-Gaussian data distributions with heavy tails as observed in gene expression measurements. FABIA utilizes well understood model selection techniques like the EM algorithm and variational approaches and is embedded into a Bayesian framework. FABIA ranks biclusters according to their information content and separates spurious biclusters from true biclusters. The code is written in C.",,"Package ‘fabia’
S Hochreiter, MS Hochreiter - 2013
관련 학술자료 전체 7개의 버전",,,,,,,,
Computational Methods Aiding Early-Stage Drug Design (Dagstuhl Seminar 13212),"Andreas Bender, Hinrich Göhlmann, Sepp Hochreiter, Ziv Shkedy",2013,,3,5,,Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik,"This report documents the program and the outcomes of Dagstuhl Seminar 13212"" Computational Methods Aiding Early-Stage Drug Design"". The aim of the seminar was to bring scientists working on various aspects of drug discovery, genomic technologies and computational science (eg, bioinformatics, chemoinformatics, machine learning, and statistics) together to explore how high dimensional data sets created by genomic technologies can be integrated to identify functional manifestations of drug actions on living cells early in the drug discovery process.",,"Computational Methods Aiding Early-Stage Drug Design (Dagstuhl Seminar 13212)
A Bender, H Göhlmann, S Hochreiter, Z Shkedy - Dagstuhl Reports, 2013
관련 학술자료 전체 10개의 버전",Dagstuhl Reports,,,,,,,
Package ‘fabiaData’,"Sepp Hochreiter, Maintainer Sepp Hochreiter",2012/8/15,,,,,,"Description Supplying gene expression data sets for the demos of the biclustering method``Factor Analysis for Bicluster Acquisition''(FABIA). The following three data sets are provided: A) breast cancer (van't Veer, Nature, 2002), B) multiple tissues (Su, PNAS, 2002), and C) diffuse large-B-cell lymphoma (Rosenwald, N Engl J Med, 2002).",,"Package ‘fabiaData’
S Hochreiter, MS Hochreiter…
관련 학술자료 전체 6개의 버전",,,,,,,,
ı-Clustering of Monotone Profiles,"Adetayo Kasim, Suzy Van Sanden, Martin Otava, Sepp Hochreiter, Djork-Arne Clevert, Willem Talloen, Dan Lin",2012/4/30,Modeling Dose-Response Microarray Data in Early Drug Development Experiments Using R: Order Restricted Analysis of Microarray Data,,,135,Springer,"In Chaps. 7 and 8, we discussed several testing procedures to detect differentially expressed genes with monotone relationship with respect to dose. The second question of primary interest in dose-response studies is the nature (or the shape of curve) of the dose-response relationship. In the context of dose-response microarray experiments, we wish to group (or classify) genes with similar dose-response relationship. Similar to the previous chapters, the subset of genes with monotone relationship is of interest.",,"ı-Clustering of Monotone Profiles
A Kasim, S Van Sanden, M Otava, S Hochreiter… - Modeling Dose-Response Microarray Data in Early …, 2012
관련 학술자료",,,,,,,,
Marginal Independence of INI Filtering and Test Statistics,Sepp Hochreiter,2010/12/15,,,,,,"In the following we show that for permutation invariant test statistics and for the t-test statistic T, the I/NI call filter applied to null hypotheses is independent of the statistic. The result is given in Theorem 1 at the end of this section. The theorem guarantees type I error rate control if first filtering by I/NI calls, then using these statistics, and finally applying correction for multiple testing. To proof this theorem, first we need some results on summarization with Robust Multi-array Average (RMA) for Gaussian noise and for correlated probes in the probe sets. These results are given in the following lemmas.",,"Marginal Independence of INI Filtering and Test Statistics
S Hochreiter - 2010
전체 6개의 버전",,,,,,,,
Complex networks govern coiled coil oligomerization: A multi-method approach,"CC Mahrenholz, IG Abfalter, U Bodenhofer, S Hochreiter, R Volkmer",2010/9/1,,16,,108-108,JOHN WILEY & SONS LTD,,,"Complex networks govern coiled coil oligomerization: A multi-method approach
CC Mahrenholz, IG Abfalter, U Bodenhofer… - JOURNAL OF PEPTIDE SCIENCE, 2010",JOURNAL OF PEPTIDE SCIENCE,,,,,,,
Detection of nonlinear effects in gene expression pathways,"Andreas Mayr, Djork-Arne Clevert, Sepp Hochreiter",2010/7/28,Nature Precedings,,,1-1,Nature Publishing Group,"One of the main topics in systems biology is to model genetic pathways. Genes of a pathway, which show linear dependencies of their expression values, are easy to identify to belong to the pathway. However, if feedback loops or signal cascades are present, gene expression values of pathway genes can be nonlinearly dependent on the expression values of other genes in the pathway. In this situation such genes are hard to detect as belonging to the pathway because nonlinearity and noise must be distinguished. We propose an algorithm to infer nonlinear network elements in pathways from microarray data. Our model assumes, that gene expression values, belonging to one pathway, are mainly driven by one single latent factor. We expect that there are two groups of genes in a pathway: genes belonging to the first group are linearly dependent on the hidden factor, genes from the other group show a nonlinear …",,"Detection of nonlinear effects in gene expression pathways
A Mayr, DA Clevert, S Hochreiter - Nature Precedings, 2010
전체 5개의 버전",,,,,,,,
Identifying Copy Number Variations based on Next Generation Sequencing Data by a Mixture of Poisson Model,"Karin Schwarzbauer, Günter Klambauer, Andreas Mayr, Sepp Hochreiter",2010/7/28,Nature Precedings,,,1-1,Nature Publishing Group,"Next generation sequencing (NGS) technologies have profoundly impacted biological research and are becoming more and more popular due to cost effectiveness and their speed. NGS can be utilized to identify DNA structural variants, namely copy number variations (CNVs) which showed association with diseases like HIV, diabetes II, or cancer. There have been first approaches to detect CNVs in NGS data, where most of them detect a CNV by a significant difference of read counts within neighboring windows at the chromosome. However these methods suffer from systematical variations of the underlying read count distributions along the chromosome due to biological and technical noise. In contrast to these global methods, we locally model the read count distribution characteristics by a mixture of Poissons which allows to incorporate a linear dependence between copy numbers and read counts. Model …",,"Identifying Copy Number Variations based on Next Generation Sequencing Data by a Mixture of Poisson Model
K Schwarzbauer, G Klambauer, A Mayr, S Hochreiter - Nature Precedings, 2010
전체 6개의 버전",,,,,,,,
Decoding Sequence Classification Models for Acquiring New Biological Insights,"Ulrich Bodenhofer, Andreas Kothmeier, Ingrid Abfalter, Carsten Mahrenholz, Sepp Hochreiter",2010/7/27,Nature Precedings,,,1-1,Nature Publishing Group,"Classifying biological sequences is one of the most important tasks in computational biology. In the last decade, support vector machines (SVMs) in combination with sequence kernels have emerged as a de-facto standard. These methods are theoretically well-founded, reliable, and provide high-accuracy solutions at low computational cost. However, obtaining a highly accurate classifier is rarely the end of the story in many practical situations. Instead, one often aims to acquire biological knowledge about the principles underlying a given classification task. SVMs with traditional sequence kernels do not offer a straightforward way of accessing this knowledge. In this contribution, we propose a new approach to analyzing biological sequences on the basis of support vector machines with sequence kernels. We first extract explicit pattern weights from a given SVM. When classifying a sequence, we then compute a …",,"Decoding Sequence Classification Models for Acquiring New Biological Insights
U Bodenhofer, A Kothmeier, I Abfalter, C Mahrenholz… - Nature Precedings, 2010
관련 학술자료 전체 8개의 버전",,,,,,,,
A normalization technique for next generation sequencing experiments,"Günter Klambauer, Karin Schwarzbauer, Andreas Mayr, Sepp Hochreiter",2010/7/27,Nature Precedings,,,1-1,Nature Publishing Group,"Next generation sequencing (NGS) are these days one of the key technologies in biology. NGS'cost effectiveness and capability of finding the smallest variations in the genome makes them increasingly popular. For studies aiming at genome assembly, differences in read count statistics do not affect the outcome. However, these differences bias the outcome if the goal is to identify structural DNA characteristics like copy number variations (CNVs). Thus a normalization step must removed such random read count variations subsequently read counts from different experiments are comparable. Especially after normalization the commonly used assumption of Poisson read count distribution in windows on the chromosomes is more justified. Strong deviations of read counts from the estimated mean Poisson distribution indicate CNVs.",,"A normalization technique for next generation sequencing experiments
G Klambauer, K Schwarzbauer, A Mayr, S Hochreiter - Nature Precedings, 2010
전체 10개의 버전",,,,,,,,
PrOCoil–Advances in predicting two-and three-stranded coiled coils,"Carsten C Mahrenholz, Ingrid G Abfalter, Ulrich Bodenhofer, Rudolf Volkmer, Sepp Hochreiter",2010/7/16,,,713,,Nature Publishing Group,"* Overview*∣ Coiled coils are usually described as consisting of two up to seven α-helices that are wrapped around each other. They can associate as either homomeric or heteromeric structures and bind in parallel or antiparallel topologies. Another characteristic of all coiled coils is the periodic recurrence of a sequence [abcdefg] n called heptad repeat, where n denotes the heptad number. In these repeats, a and d are hydrophobic amino acids at core positions crucial for the tertiary structure. In contrast, the polar positions b, c, and f are hydrophilic and e and g are charged residues. Due to their ability to oligomerize, coiled coils are involved in a variety of important cellular functions, either on their own or as part of larger protein complexes. Hence, they are in the focus of current research, for instance, as potential oncogenes and in the context of viral fusion proteins. Since structure and occurrence are well known, it …",,"PrOCoil-Advances in predicting two-and three-stranded coiled coils
C Mahrenholz, I Abfalter, U Bodenhofer, R Volkmer… - Nature Precedings, 2010
전체 7개의 버전",,,,,,,,
Analysis of Robust Soft Learning Vector Quantization and an application to Facial Expression Recognition,"Gert-Jan de Vries, Michael Biehl",2009,,,,,IBFI-Schloss Dagstuhl,"Learning Vector Quantization (LVQ) is a popular method for multiclass classification. Several variants of LVQ have been developed recently, of which Robust Soft Learning Vector Quantization (RSLVQ) is a promising one. Although LVQ methods have an intuitive design with clear updating rules, their dynamics are not yet well understood. In simulations within a controlled environment RSLVQ performed very close to optimal. This controlled environment enabled us to perform a mathematical analysis as a first step in obtaining a better theoretical understanding of the learning dynamics. In this talk I will discuss the theoretical analysis and its results. Moreover, I will focus on the practical application of RSLVQ to a real world dataset containing extracted features from facial expression data.",,"Analysis of Robust Soft Learning Vector Quantization and an application to Facial Expression Recognition
GJ de Vries, M Biehl - Dagstuhl Seminar Proceedings, 2009
관련 학술자료 전체 6개의 버전",Dagstuhl Seminar Proceedings,,,,,,,
An adaptive model for learning molecular endpoints,"Ian Walsh, Alessandro Vullo, Gianluca Pollastri",2009,,,,,IBFI-Schloss Dagstuhl,"I will describe a recursive neural network that deals with undirected graphs, and its application to predicting property labels or activity values of small molecules. The model is entirely general, in that it can process any undirected graph with a finite number of nodes by factorising it into a number of directed graphs with the same skeleton. The model's only input in the applications I will present is the graph representing the chemical structure of the molecule. In spite of its simplicity, the model outperforms or matches the state of the art in three of the four tasks, and in the fourth is outperformed only by a method resorting to a very problem-specific feature.",,"An adaptive model for learning molecular endpoints
I Walsh, A Vullo, G Pollastri - Dagstuhl Seminar Proceedings, 2009
관련 학술자료 전체 5개의 버전",Dagstuhl Seminar Proceedings,,,,,,,
Estimating Time Delay in Gravitationally Lensed Fluxes,"Peter Tino, Juan C Cuevas-Tello, Somak Raychaudhury",2009,,,,,IBFI-Schloss Dagstuhl,"We study the problem of estimating the time delay between two signals representing delayed, irregularly sampled and noisy versions of the same underlying pattern. We propose a kernel-based technique in the context of an astronomical problem, namely estimating the time delay between two gravitationally lensed signals from a distant quasar. We test the algorithm on several artificial data sets, and also on real astronomical observations. By carrying out a statistical analysis of the results we present a detailed comparison of our method with the most popular methods for time delay estimation in astrophysics. Our method yields more accurate and more stable time delay estimates. Our methodology can be readily applied to current state-of-the-art optical monitoring data in astronomy, but can also be applied in other disciplines involving similar time series data.",,"Estimating Time Delay in Gravitationally Lensed Fluxes
P Tino, JC Cuevas-Tello, S Raychaudhury - Dagstuhl Seminar Proceedings, 2009
관련 학술자료 전체 7개의 버전",Dagstuhl Seminar Proceedings,,,,,,,
algorithm for the potential support vector machine Knebel Tilman; Hochreiter Sepp; Obermayer Klaus,SMO An,2008,Neural computation,20,1,271-87,,,,,,,,,,,,
Remote Homology detection with LSTM,Martin Heusel,2007/5/12,,,,,,"High-throughput techniques for annotating protein sequences with structural and functional features play an important role in the postgenomics. In this thesis a recurrent neural network called “Long Short Term Memory”(LSTM) is used for finding properties of a protein family called Proteasome, ranking amino acid properties for classifying performance, finding signal patterns in protein sequences, differentating within a protein fold class and finally using a trained LSTM to detect possibly unknown proteasome family members in a large unlabeled database. At least the LSTM is adapted to remote homology detection and is compared with state-of-the-art and newly developed methods.",,"Remote Homology detection with LSTM
M Heusel - 2007
관련 학술자료",,,,,,,,
Monaural Speech Separation by Support Vector Machines: Bridging the Divide Between Supervised and Unsupervised Learning Methods,"Sepp Hochreiter, Michael Mozer",2007,Blind Speech Separation,,,411-428,Springer Netherlands,"We address the problem of identifying multiple independent speech sources from a single signal that is a mixture of the sources. Because the problem is ill-posed, standard independent component analysis (ICA) approaches which try to invert the mixing matrix fail. We show how the unsupervised problem can be transformed into a supervised regression task which is then solved by supportvector regression (SVR). It turns out that the linear SVR approach is equivalent to the sparse-decomposition method proposed by [1, 2]. However, we can extend the method to nonlinear ICA by applying the “kernel trick.” Beyond the kernel trick, the SVM perspective provides a new interpretation of the sparse-decomposition method’s hyperparameter which is related to the input noise. The limitation of the SVM perspective is that, for the nonlinear case, it can recover only whether or not a mixture component is present; it cannot …",,"Monaural Speech Separation by Support Vector Machines: Bridging the Divide Between Supervised and Unsupervised Learning Methods
S Hochreiter, MC Mozer - Blind Speech Separation, 2007
관련 학술자료 전체 9개의 버전",,,,,,,,
Learning Quadratic Forms by Density Estimation and its Applications to Image Coding,"Hauke Bartsch, Sepp Hochreiter, Klaus Obermayer",2003/2/23,,,,,,We develop a novel method for source separation and apply it to natural images. It is a specialization of independent factor analysis (IFA) but overcomes generic IFA problems and finds many independent sources in few observations. A fast and robust EM learning algorithm produces an over-complete basis. Compared to standard approaches our method generates superior codes in terms of population sparseness and dispersity. The algorithm learns features which possess properties that are observed in simple as well as complex cells found in V1.,,"Learning Quadratic Forms by Density Estimation and its Applications to Image Coding
H Bartsch, S Hochreiter, K Obermayer - 2003
관련 학술자료 전체 9개의 버전",,,,,,,,
Coulomb Classifiers: Reinterpreting SVMs as Electrostatic Systems; CU-CS-921-01,"Sepp Hochreiter, Michael C Mozer",2001/5/1,,,,,,"Q q s""! e $#%'& () 10e h 2 e 35 44 7 28 y 945 q@ 8') BV 4C44) 3D) E3'3 h FQ 2 y 5 F G"" I 7 2 6 e) 35 7B) Py 7QS R e"" B 7 AF S 2 h 2 y V 5P)'3 W 0e@ X"" 4Y 2 Py 74 bac d 4') h C Bq",,"Coulomb Classifiers: Reinterpreting SVMs as Electrostatic Systems; CU-CS-921-01
S Hochreiter, MC Mozer - 2001",,,,,,,,
EVALUATING LONG-TERM DEPENDENCY,"Jiurgen Schmidhuber, Corso Elvezia, Sepp Hochreiter",1997/10/31,,,,,,"Numerous recent papers focus on standard recurrent nets' problems with tasks involving long-term dependencies. We solve such tasks by random weight guessing (RG). Although RG cannot be viewed as a reasonable learning algorithm we find that it often outperforms previous, more complex methods on widely used benchmark problems. One reason for RG's success is that the solutions to many of these benchmarks are dense in weight space. An analysis of cases in which RG works well versus those in which it does not can serve to improve the quality of benchmarks for novel recurrent net algorithms.",,"EVALUATING LONG-TERM DEPENDENCY
J Schmidhuber, C Elvezia, S Hochreiter - 1997
관련 학술자료",,,,,,,,
LOCOCODE,"Jürgen Schmidhuber, Sepp Hochreiter",1997,,,,,"TUM, Techn. Univ. München, Inst. für Informatik",,,"LOCOCODE
J Schmidhuber, S Hochreiter - 1997",,,,,,,,
GUESSING CAN OUTPERFORM MANY LONG TIME LAG ALGORITHMS,"J urgen Schmidhuber, Corso Elvezia, Sepp Hochreiter",1996/5/6,,,,,,"Numerous recent papers focus on standard recurrent nets' problems with long time lags between relevant signals. Some propose rather sophisticated, alternative methods. We show: many problems used to test previous methods can be solved more quickly by random weight guessing.
Introduction. The main problem of gradient-based, recurrent nets (see, eg, overviews by Williams, 1989; Pearlmutter, 1995) is this: error signals\owing backwards in time"" tend to either blow up or vanish (for the rst, detailed, theoretical analysis see Hochreiter, 1991| the vanishing error case was later also treated by Bengio et al., 1994). That's why standard recurrent nets cannot deal with long time lags between relevant input/error signals. Rather sophisticated, alternative methods were proposed. For instance, Bengio et al.(1994) investigate simulated annealing, multi-grid random search, time-weighted pseudo-Newton optimization, and discrete error propagation. Bengio and Frasconi (1994) also propose an EM approach for propagating targets. Quite a few papers use Bengio et al.'s\2-sequence problem""(and\latch problem"") to show the proposed algorithms's superiority, eg, Bengio et al.(1994), Bengio and Frasconi (1994), El Hihi and Bengio (1995), Lin et al.(1995). For the same purpose, some papers also use the socalled\parity problem"", eg, Bengio et al.(1994), Bengio and Frasconi (1994). Some of Tomita's grammars (1982) are also often used as benchmark problems for recurrent nets (see, eg, Bengio and Frasconi, 1995; Watrous and Kuhn, 1992; Pollack, 1991; Miller and Giles, 1993; Manolios and Fanelli, 1994). This paper exempli es: such problems can be …",,"GUESSING CAN OUTPERFORM MANY LONG TIME LAG ALGORITHMS
J urgen Schmidhuber, C Elvezia, S Hochreiter - 1996
관련 학술자료 전체 12개의 버전",,,,,,,,
Convergence Proof for Actor-Critic Methods Applied to PPO and RUDDER,"Johannes Brandstetter, Sepp Hochreiter",,Transactions on Large-Scale Data-and Knowledge-Centered Systems XLVIII: Special Issue In Memory of Univ. Prof. Dr. Roland Wagner,,,105,Springer Nature,"We prove under commonly used assumptions the convergence of actor-critic reinforcement learning algorithms, which simultaneously learn a policy function, the actor, and a value function, the critic. Both functions can be deep neural networks of arbitrary complexity. Our framework allows showing convergence of the well known Proximal Policy Optimization (PPO) and of the recently introduced RUDDER. For the convergence proof we employ recently introduced techniques from the two time-scale stochastic approximation theory. Previous convergence proofs assume linear function approximation, cannot treat episodic examples, or do not consider that policies become greedy. The latter is relevant since optimal policies are typically deterministic. Our results are valid for actor-critic methods that use episodic samples and that have a policy that becomes more greedy during learning.",,"Convergence Proof for Actor-Critic Methods Applied to PPO and RUDDER
J Brandstetter, S Hochreiter - Transactions on Large-Scale Data-and Knowledge …",,,,,,,,
biclustGUI Shiny App,"Ewoud De Troyer, Rudradev Sengupta, Jitao David Martin Otava, Sebastian Kaiser Zhang, Aedin Culhane, Daniel Gusenleitner, Pierre Gestraud, Gabor Csardi, Sepp Hochreiter, Gunter Klambauer, Djork-Arne Clevert, Nolen Joy Perualila, Adetayo Kasim, Ziv Shkedy",,,,,,,"Ewoud De Troyer, Rudradev Sengupta, Martin Otava, Jitao David Zhang, Sebastian Kaiser, Aedin Culhane, Daniel Gusenleitner, Pierre Gestraud, Gabor Csardi, Sepp Hochreiter, Gunter Klambauer, Djork-Arne Clevert, Nolen Joy Perualila, Adetayo Kasim and Ziv Shkedy",,"biclustGUI Shiny App
E De Troyer, R Sengupta, JD Martin Otava, SK Zhang…",,,,,,,,
A Machine Learner’s Guide to Streamflow Prediction,"Martin Gauch, Daniel Klotz, Frederik Kratzert, Grey Nearing, Sepp Hochreiter, Jimmy Lin",,,,,,,"Although often subconsciously, many people deal with water-related issues on a daily basis. For instance, many regions rely on hydropower plants to produce their electricity, and, at the extreme, floods and droughts pose one of the big environmental threats of climate change. At the same time, many machine learning researchers have started to look beyond their field and wish to contribute to environmental issues of our time. The modeling of streamflow—the amount of water that flows through a river cross-section at a given time—is a natural starting point to such contributions: It encompasses a variety of tasks that will be familiar to machine learning researchers, but it is also a vital component of flood and drought prediction (among other applications). Moreover, researchers can draw upon large open datasets, sensory networks, and remote sensing data to train their models. As a getting-started resource, this guide provides a brief introduction to streamflow modeling for machine learning researchers and highlights a number of possible research directions where machine learning could advance the domain.",,"A Machine Learner’s Guide to Streamflow Prediction
M Gauch, D Klotz, F Kratzert, G Nearing, S Hochreiter…
관련 학술자료",,,,,,,,
Characterising activation functions by their backward dynamics around forward fixed points,"Pieter-Jan Hoedt, Sepp Hochreiter, Günter Klambauer",,,,,,,"The forward dynamics in neural networks for various activation functions has been studied extensively in the context of initialisation and normalisation strategies, by mean field theory, edge of chaos theory, and fixed point analysis. However, the study of the backward dynamics appears to be largely disconnected to the insights obtained from the forward analysis. We argue that many of the ideas from the forward analysis could and should be applied to backward dynamics. We show that the ideas of mean field theory and fixed point analysis apply to the backward pass and allow to characterise activation functions.
Introduction. The importance of how the variance of data is propagated through the forward pass of a deep neural network (DNN) has been acknowledged already well before the hype of deep learning (DL) took off (LeCun et al., 1998). Glorot et al.(2010) derive an initialisation strategy which aims at preserving variance propagated through a tanh network. He et al.(2015) build upon this idea to find a proper initialisation scheme for networks with ReLUs, neglecting the backward analysis. Normalisation techniques (Ioffe et al., 2015; Salimans et al., 2016; Ba et al., 2016) aim at controlling the mean and variance of the propagated data. As an alternative, Klambauer et al.(2017) introduced SELUs with corresponding initialisation scheme to create self-normalising neural networks (SNNs). This combination of initialisation and activation function gives rise to a stable fixed point in mean and variance propagation. Poole et al.(2016), Schoenholz et al.(2017), and Yang et al.(2017) analyse the fixed points in covariance and correlation propagation …",,"Characterising activation functions by their backward dynamics around forward fixed points
PJ Hoedt, S Hochreiter, G Klambauer
관련 학술자료",,,,,,,,
SUPPLEMENT A: Modern Hopfield Networks and Attention for Immune Repertoire Classification,"Michael Widrich, Bernhard Schäfl, Milena Pavlovic, Geir Kjetil Sandve, Sepp Hochreiter, Victor Greiff, Günter Klambauer",,,,,,,"This document is a supplement to the paper"" Modern Hopfield Networks and Attention for Immune Repertoire Classification"". All datasets and code will be fully released at https://github. com/ml-jku/DeepRC. The CMV dataset is publicly available at https://clients. adaptivebiotech. com/pub/Emerson-2017-NatGen.",,"SUPPLEMENT A: Modern Hopfield Networks and Attention for Immune Repertoire Classification
M Widrich, B Schäfl, M Pavlovic, GK Sandve…
관련 학술자료",,,,,,,,
Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields Download PDF,"Thomas Unterthiner Thomas, Bernhard Nessler, Calvin Seward Calvin, Günter Klambauer, Martin Heusel, Hubert Ramsauer, Sepp Hochreiter",,,,,,,"Generative adversarial networks (GANs) evolved into one of the most successful unsupervised techniques for generating realistic images. Even though it has recently been shown that GAN training converges, GAN models often end up in local Nash equilibria that are associated with mode collapse or otherwise fail to model the target distribution. We introduce Coulomb GANs, which pose the GAN learning problem as a potential field of charged particles, where generated samples are attracted to training set samples but repel each other. The discriminator learns a potential field while the generator decreases the energy by moving its samples along the vector (force) field determined by the gradient of the potential field. Through decreasing the energy, the GAN model learns to generate samples according to the whole target distribution and does not only cover some of its modes. We prove that Coulomb GANs …",,"Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields Download PDF
TU Thomas, B Nessler, CS Calvin, G Klambauer…",,,,,,,,
Gene Selection on Micro Array Data through Support Vector Machines,"Sepp Hochreiter, Klaus Obermayer",,,,,,,"Introduction. Gene expression data sets typically consist of about 100 tissue samples each of which is described by the expression values of few 10,000 genes. Machine learning techniques require more examples (tissue samples) than features (genes) to guarantee sufficient generalization capability [5]. Therefore the selection of relevant genes is mandatory for processing micro array data. The quality of the final results strongly depend on the feature selection algorithms [1]. We present a new feature selection method where the selected feature vectors correspond to support vectors. Our approach is tested on three gene expression data sets where the outcome of a cancer therapy must be predicted. For all three cancer types (brain tumor, lymphoma, and breast cancer) we were able to considerably improve the prediction results compared to the results of standard methods published in NATURE and NATURE MEDICINE. The improvement of the results is important because for a negative therapy outcome prediction two policies are possible: an alternative treatment or a closer observation of the patient. Positive prediction can indicate a lower dosis of medication and, therefore, lower risk of side effects of the treatment. Basic Idea. We consider the classification task for datasets which are described by matrices. Rows and columns of these matrices correspond to objects where row and column objects may be from different sets and column objects are labeled. Data matrix entries express relationships between row and column objects and are produced by an unknown kernel. This kernel represents a dot product in some (unknown) feature space …",,"Gene Selection on Micro Array Data through Support Vector Machines
S Hochreiter, K Obermayer
관련 학술자료 전체 2개의 버전",,,,,,,,
Uncertainty Estimation Methods to Support Decision-Making in Early Phases of Drug Discovery,"Philipp Renz, Sepp Hochreiter, Günter Klambauer",,,,,,,"It takes about a decade to develop a new drug by a process in which a large number of decisions have to be made. Those decisions are critical for the success or failure of a multi-million dollar drug discovery project, which could save many lives or increase life quality. Decisions in early phases of drug discovery, such as the selection of certain series of chemical compounds, are particularly impactful on the success rate. Machine learning models are increasingly used to inform the decision making process by predicting desired effects, undesired effects, such as toxicity, molecular properties, or which wet-lab test to perform next. Thus, accurately quantifying the uncertainties of the models’ outputs is critical, for example, in order to calculate expected utilities, to estimate the risk and the potential gain. In this work, we review, assess and compare recent uncertainty estimation methods with respect to their use in drug discovery projects. We test both, which methods give well calibrated prediction and which ones perform well at misclassification detection. For the latter, we find the entropy of the predictive distribution performs best. Finally, we discuss the problem of defining out-of-distribution samples for prediction tasks on chemical compounds.",,"Uncertainty Estimation Methods to Support Decision-Making in Early Phases of Drug Discovery
P Renz, S Hochreiter, G Klambauer
관련 학술자료 전체 2개의 버전",,,,,,,,
Publication Supplement,Sepp Hochreiter,,,,,,,"FABIA models each IBD segment in genotype data X by an outer product z λT of two vectors λ and z, where the vector λ indicates tagSNVs by non-zero values and the vector z indicates individuals that possess the IBD segment. FABIA can represent a homozygous region of an IBD segment by z= 2, that is, two occurrences of an IBD segment in one diploid individual. If we assume genotyping errors which are accounted for by a noise term Υ, the FABIA model for genotype data X is",,"Publication Supplement
S Hochreiter
관련 학술자료",,,,,,,,
Coulomb Classifiers: Reinterpreting SVMs as Electrostatic Systems; CU-CS-921-01,"Michael C Mozer, Sepp Hochreiter",,,,,,,Skip to Content …,,"Coulomb Classifiers: Reinterpreting SVMs as Electrostatic Systems; CU-CS-921-01
MC Mozer, S Hochreiter
전체 2개의 버전",,,,,,,,
Prediction in Ungauged Basins with Long Short-Term,"Frederik Kratzert, Daniel Klotz, Mathew Herrnegger, Alden K Sampson, Sepp Hochreiter, Grey S Nearing",,,,,,,"Abstract 15 Long Short-Term Memory (LSTM) networks offer unprecedented accuracy for predic-16 tion in ungauged basins. We trained and tested an LSTM on the CAMELS basins (ap-17 proximately 30 years of daily rainfall/runoff data from 531 catchments in the US of sizes 18 ranging from 4 km2 to 2,000 km2) using k-fold validation, so that predictions were made 19 in basins that supplied no training data. This effectively ‘ungauged’model was bench-20 marked over a 15-year validation period against the Sacramento Soil Moisture Account-21 ing (SAC-SMA) model and also against the NOAA National Water Model reanalysis. 22 SAC-SMA was calibrated separately for each basin using 15 years of daily data (ie, this 23 is a ‘gauged’model). The out-of-sample LSTM had higher median Nash-Sutcliffe Effi-24 ciencies across the 531 basins (0.69) than either the calibrated SAC-SMA (0.64) or the 25 National Water Model (0.58). We outline several future research directions that would 26 help develop this technology into a comprehensive regional hydrology model. 27",,"Prediction in Ungauged Basins with Long Short-Term
F Kratzert, D Klotz, M Herrnegger, AK Sampson…
관련 학술자료 전체 3개의 버전",,,,,,,,
LSTM-Designed Quantum Experiments,"Thomas Adler, Manuel Erhard, Mario Krenn, Johannes Brandstetter, Johannes Kofler, Sepp Hochreiter",,,,,,,"We demonstrate how machine learning helps to design experiments in quantum physics. Quantum entanglement is a cornerstone for upcoming quantum technologies such as quantum computation and quantum cryptography. Of particular interest are complex quantum states with more than two particles and a large number of entangled quantum levels. Given such a multiparticle high-dimensional quantum state, it is usually impossible to reconstruct an experimental setup that produces it. To search for interesting experiments, one thus has to randomly create millions of setups on a computer and calculate the respective output states. In this work, we show that machine learning models can provide significant improvement over random search. We demonstrate that a long short-term memory (LSTM) neural network can successfully learn to model quantum experiments by correctly predicting output state characteristics for given setups without the necessity of computing the states themselves. This approach not only allows for faster search but is also an essential step towards automated design of multiparticle high-dimensional quantum experiments using generative machine learning models.",,"LSTM-Designed Quantum Experiments
T Adler, M Erhard, M Krenn, J Brandstetter, J Kofler…
관련 학술자료",,,,,,,,
New insights into coiled coil formation by means of support vector machines,"Ingrid G Abfalter, Carsten C Mahrenholz, Ulrich Bodenhofer, Sepp Hochreiter",,,,,,,"Coiled coil proteins consist of two up to seven α-helices that are wrapped around each other. They can associate as either homomeric or heteromeric structures and bind in parallel or antiparallel topologies.[1]. One of the important functions of these proteins is playing an integral role in the infectious mechanism of viruses like bird flu, swine flu or HIV, as they enter host cells using coiled coil fusion proteins. Such fusion proteins are highly conserved, hence, they are considered a very attractive target for the development of anti-viral drugs [2].
While structure and occurrence of coiled coils are well known, the rules for oligomeric formation, the key to biological function and a prerequisite for rational drug design, are poorly understood. In order to be able to comprehend and manipulate coiled-coil formation, we determine specific properties that influence the oligomerization of coiled coil proteins, ie how many α-helices …",,"New insights into coiled coil formation by means of support vector machines
IG Abfalter, CC Mahrenholz, U Bodenhofer…
관련 학술자료 전체 5개의 버전",,,,,,,,
δ-Biclustering and FLOC Algorithm,"Adetayo Kasim, Sepp Hochreiter, Ziv Shkedy",,,,,,,"Cheng and Church (2000) introduced biclustering as simultaneous clustering of both features and samples in order to find underlying patterns. The patterns are characterised by biclusters with mean squared residual score smaller than a pre-specified threshold (δ). Yang et al.(2003) proposed FLOC (Flexible Overlapping biClustering), an alternative algorithm to find δ-biclusters without the interference of random data used to mask a found bicluster or missing values in the approach of Cheng and Church (2000).
ABSTRACT",,"δ-Biclustering and FLOC Algorithm
A Kasim, S Hochreiter, Z Shkedy",,,,,,,,
Sparse Factor Analysis for Detecting Copy Number Variations (CNVs),"Andreas Mitterecker, Djork-Arne Clevert, Andreas Mayr, An De Bondt, Willem Talloen, Marianne Tuefferd, Hinrich Göhlmann, Sepp Hochreiter",,,,,,,"Recently, CN. FARMS has been proposed for analyzing copy number variations (CNVs) with oligo genotyping arrays like the Affymetrix SNP6 chips. CN. FARMS extracts a common hidden factor of neighbouring reporters on the DNA, where the factor represents the local copy numbers. If an individual has more copies of a DNA-subsequence compared to a reference, then reporters on this subsequence have higher intensity than those of the reference. CN. FARMS assigns to each copy number estimate a confidence value (signal likelihood) which is large if reporters agree to each other across the samples. Standard factor analysis assumes a Gaussian factor distribution which, however, is a wrong assumption for CNVs. Redon et al. 2006 discovered that most CNVs affect less than three individuals out of the 269 HapMap samples. Thus, CNV analysis requires the assumption of the hidden factor being sparsely distributed.
To account for a sparse hidden variable, we assume either a Laplace or a multimodal distribution. Because the posterior cannot be computed analytically, we use for the Laplace prior both a variational and an approximated EM approach. For the multimodal distribution we use a lower bound on the likelihood and represent the prior by a mixture of Gaussians. The sparse CN. FARMS methods were applied to Affymetrix SNP6 chips on the HapMap data set. We noticed that many previously reported CNVs are likely to be false positives and also found novel CNVs.",,"Sparse Factor Analysis for Detecting Copy Number Variations (CNVs)
A Mitterecker, DA Clevert, A Mayr, A De Bondt…
전체 8개의 버전",,,,,,,,
FARMS: a probabilistic latent variable model for summarizing Affymetrix array data at probe level,"Djork-Arné Clevert, Sepp Hochreiter",,,,,,,"Page 1. FARMS: a probabilistic latent variable model for summarizing Affymetrix array data at probe level Djork-Arné Clevert, Sepp Hochreiter Institute of Bioinformatics, Johannes Kepler University Linz Willem Talloen, An De Bond, Hinrich Göhlmann Johnson & Johnson Pharmaceutical Research & Development, a division of Janssen Pharmaceutica nv, Beerse, Belgium Page 2. ● Introduction ● Microarray technology ● Model & assumption ● Data sets & experiments ● Results ● FARMS I/NI-Calls ● Results ● Conclusion 2 Overview Page 3. ● Microarrays measure simultaneously cellular concentrations of thousands of mRNAs ● mRNA concentration ~ activity of a gene ● Activity of a gene = expression level ● Basis for the functional genome analysis 3 Microarrays Page 4. 4 Affymetrix technology RNA Probe B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B 10 20 30 40 50 60 In Vitro Transskription …",,"FARMS: a probabilistic latent variable model for summarizing Affymetrix array data at probe level
DA Clevert, S Hochreiter
전체 10개의 버전",,,,,,,,
I/NI-calls: a novel unsupervised feature selection criterion,"Djork-Arné Clevert, Willem Talloen, Hinrich WH Göhlmann, Sepp Hochreiter",,,,,,,"Results: We have applied this technique on 30 different data sets including recent publications from top journals (like Nature, Science and PNAS), covering six of the most commonly used gene chips. We found that our method excluded the non-informative probe sets without loss of sensitivity and specificity. The exclusion rates are about 98% while never losing a spiked-in gene in spiked-in data sets. As this objective technique results in uninformative feature reduction, it offers a critical solution to the curse of high-dimensionality in the analysis of microarray data.",,"I/NI-calls: a novel unsupervised feature selection criterion
DA Clevert, W Talloen, HWH Göhlmann, S Hochreiter
전체 12개의 버전",,,,,,,,
Detecting rare copy number variations (CNVs) with sparse coding,"Andreas Mitterecker, Djork-Arné Clevert, Andreas Mayr, An De Bondt, Willem Talloen, Hinrich Göhlmann, Sepp Hochreiter",,,,,,,Results: We have applied the Laplacian cn. FARMS model on the HapMap dataset to detect CNVs. We could verify most of published copy number variable regions and found new ones. However some known CNVs seem to be false positives.,,"Detecting rare copy number variations (CNVs) with sparse coding
A Mitterecker, DA Clevert, A Mayr, A De Bondt…
관련 학술자료 전체 7개의 버전",,,,,,,,
Publication Supplement,"Carsten C Mahrenholz, Ingrid G Abfalter, Ulrich Bodenhofer, Rudolf Volkmer, Sepp Hochreiter",,,,,,,"Figure S1 provides details about the circular-dichroism analysis of GCN4 mutants in TBS (154 mM NaF, 10 mM tris (hydroxymethyl) aminomethane, pH 8.0, room temperature). Spectra were recorded on a Jasco (Tokyo, Japan) J-720 spectropolarimeter at total peptide concentrations of 75 µM and corrected by subtracting the buffer baseline. All Variants show clear α-helical tendency with minima at 208 and 222.",,"Publication Supplement
CC Mahrenholz, IG Abfalter, U Bodenhofer, R Volkmer…
관련 학술자료",,,,,,,,
Lstm can solve hard long time lag problems,SHJ Schmidhuber,,Advances in Neural Information Processing Systems,9,,473,,,,,,,,,,,,
Lstm can solve hard long time lag problems,SHJ Schmidhuber,,Advances in Neural Information Processing Systems,9,,473,,,,,,,,,,,,
Aiding Drug Design with Deep Neural Networks,"Thomas Unterthiner, Andreas Mayr, Günter Klambauer, Marvin Steijaert, Jörg K Wegner, Hugo Ceulemans, Sepp Hochreiter",,,,,,,"An important computational tool in drug design is target prediction where either for a given chemical structure the interacting biomolecules (eg proteins) must be identified. Chemical structures interact with different biomolecules if they have similar 3D structure. Thus, the outputs of the prediction are highly interdependent from each other. Furthermore, we have partially labelled molecules since not all training molecules are measured of being active on each biomolecule. The Merck Kaggle challenge on chemical compound activity was won by Hinton’s group with deep networks. This indicates the high potential of deep learning in drug design and attracted the attention of big pharma. However, the unrealistically small scale of the Kaggle dataset does not allow to assess the value of deep learning in drug target prediction if applied to in-house data of pharmaceutical companies. Even a publicly available drug activity data base like ChEMBL is magnitudes larger than the Kaggle dataset. ChEMBL has 13 M compound descriptors, 1.3 M compounds, and 5 k drug targets, compared to the Kaggle dataset with 11 k descriptors, 164 k compounds, and 15 drug targets. On the ChEMBL database, we compared the performance of deep learning to seven target prediction methods, including two commercial predictors, three predictors deployed by pharma, and machine learning methods that we could scale to this dataset. Deep learning outperformed all other methods with respect to the area under ROC curve and was significantly better than all commercial products. Deep learning surpassed the threshold to make virtual compound screening possible and has …",,"Aiding Drug Design with Deep Neural Networks
T Unterthiner, A Mayr, G Klambauer, M Steijaert…
관련 학술자료 전체 5개의 버전",,,,,,,,
Rectified Factor Networks and Dropout,"Djork-Arné Clevert, Thomas Unterthiner, Sepp Hochreiter",,,,,,,"The success of deep learning techniques is based on their robust, effective and abstract representations of the input. In particular, sparse representations that are obtained from rectified linear units and dropout increased classification performance at various tasks. Deep architectures are often constructed by unsupervised pretraining and stacking of either restricted Boltzmann machines (RBMs) or autoencoders. We propose rectified factor networks (RFNs) for pretraining of deep networks. In contrast to RBMs and autoencoders, RFNs (1) estimate the noise of each input component,(2) aim at decorrelating the hidden units (factors),(3) estimate the precision of hidden units by the posterior variance. In the E-step of an EM algorithm, RFN learning (i) enforces non-negative posterior means,(ii) allows dropout of hidden units, and (iii) normalizes the signal part of the hidden units. In the M-step, RFN learning applies gradient descent along the Newton direction to allow rectifying, dropout, and fast GPU implementations. RFN learning can be considered as a variational EM algorithm with unknown prior which is estimated during maximizing the likelihood. Using a fixed point analysis, we show RFNs explain the data variance like factor analysis. RFNs produce sparse and non-linear input representations for new data by a linear mapping and subsequent rectification, therefore can be readily used for pretraining of deep networks. It is tailored to making full use of large hidden layers with respect to both using all of them to code the input and computational complexity. We tested and compared RFNs for unsupervised pretraining of deep learning on nine different …",,"Rectified Factor Networks and Dropout
DA Clevert, T Unterthiner, S Hochreiter
관련 학술자료 전체 4개의 버전",,,,,,,,
Basic Methods of Data Analysis,Sepp Hochreiter,,,,,,,"This course is part of the curriculum of the master in computer science (in particular the majors “Computational Engineering” and “Intelligent Information Systems”) and part of the master in bioinformatics at the Johannes Kepler University Linz.
Machine learning is currently a major research topic at companies like Google, Microsoft, Amazon, Facebook, AltaVista, Zalando, and many more. Applications are found in computer vision (image recognition), speech recognition, recommender systems, analysis of Big Data, information retrieval. Companies which have their domain in the world wide web like companies offering search engines, social networks, videos, information, or connecting people with specific interest use machine learning techniques to analyze their data. Machine learning methods are used to annotate web pages, images, videos, and sound recordings in web data. They can find specific objects in images and detect a particular music style if only given the raw data. Therefore Google, Microsoft, Facebook are highly interested in machine learning methods. Machine learning methods attracted the interest of companies offering products via the web. These methods are able to identify groups of similar users, to predict future behavior of customers, and can give recommendation of products in which customers will be interested based previous costumer data.",,"Basic Methods of Data Analysis
S Hochreiter
관련 학술자료 전체 7개의 버전",,,,,,,,
Bioinformatics Research and Development,Sepp Hochreiter Roland Wagner,,,,,,,"This volume contains the papers which were selected for oral presentation at the first Bioinformatics Research and Development (BIRD) conference held in Berlin, Germany during March 12-14, 2007. BIRD covers a wide range of topics related to bioinformatics like microarray data, genomics, single nucleotide polymorphism, sequence analysis, systems biology, medical applications, proteomics, information systems.
The conference was very competitive. From about 140 submissions only 36 were selected by the Program Committee for oral presentation at BIRD and for publication in these proceedings. The acceptance rate was 1/4. The decisions of the Program Committee were guided by the recommendations of several reviewers for each paper. It should be mentioned that these proceedings have companion proceedings published by the Austrian Computer Society where selected poster presentations of the BIRD …",,"Bioinformatics Research and Development
SHR Wagner",,,,,,,,
Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term D ependencies* Sepp Hochreiter Fakult at f ur Informatik,"Yoshua Bengio, Paolo Frasconi, J urgen Schmidhuber, Corso Elvezia",,,,,,,"1 Introduction Recurrent networks (crossreference Chapter 12) can, in principle, use their feedback connections to store representations of recent input events in the form of activations. The most widely used algorithms for learning what to put in short-term memory, however, take too much time to be feasible or do not work well at all, especially when minimal time lags between inputs and corresponding teacher signals are long.¡ lthough theoretically fascinating, they do not provide clear£¢¥¤ a § ¦ t©¦ a advantages over, say, backprop in feedforward networks with limited time windows (see crossreference Chapters 11 and 12). ith conventional algorithms based on the computation of the complete gradient, such as£ ack-! ropagation Through Time""(# $ TT, eg,¥% 22, 2'&, 2 (0)) or1 Real-Time Recurrent $2 earning'(RTR32, eg,¥% 21"")) error signals4 6fl owing backwards in time"" tend to either (1) blow up or (2) vanish87 the temporal evolution of the backpropagated error e@ 9 ponentially depends on the siBA e of the weightsC% 11,(0). Case (1) may lead to oscillating weights, while in case (2) learning to bridge long time lags takes a prohibitive amount of time, or does not work at all. D n what follows, we give a theoretical analysis of this problem by studying the asymptotic behavior of error gradients as a function of time lags. ED n F ection 2, we consider the case of standard R3G3G s and derive the main result using the approachIfi rst proposed inP% 11""). ED n F ectionRQ, we consider the more general case of adaptive dynamical systems, which include, besides standard RSGTG s, other recurrent architectures based on diBff erent connectivities and …",,"Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term D ependencies* Sepp Hochreiter Fakult at f ur Informatik
Y Bengio, P Frasconi, J urgen Schmidhuber, C Elvezia",,,,,,,,
Unsupervised Methods,Sepp Hochreiter,,,,,,,"Page 1. Machine Learning Unsupervised Methods Part 1 Sepp Hochreiter Institute of Bioinformatics Johannes Kepler University, Linz, Austria Page 2. Machine Learning: Unsupervised Methods Sepp Hochreiter Course 3 ECTS 2 SWS VO (class) 1.5 ECTS 1 SWS UE (exercise) Basic Course of Master Bioinformatics Basic Course of Master Computer Science: Computational Engineering / Int. Syst. Class: Mo 15:30-17:00 (HS 19) Exercise: Mon 13:45-14:30 (MT 226) – group 2 Mon 14:30-15:15 (MT 226) – group 1+ group 3 EXAMS: VO: 3 written intermediate exams UE: weekly homework (evaluated) Page 3. Machine Learning: Unsupervised Methods Sepp Hochreiter Other Courses Lecture Lecturer 365,077 Machine Learning: Unsupervised Techniques VL Hochreiter Mon 15:30-17:00/HS 19 365,078 Machine Learning: Unsupervised Techniques – G2 UE Kofler Mon 13:45-14:30/MT 226 …",,"Unsupervised Methods
S Hochreiter
관련 학술자료 전체 6개의 버전",,,,,,,,
FABIA: Factor Analysis for Bicluster Acquisition—supplementary material—,"Sepp Hochreiter, Ulrich Bodenhofer, Martin Heusel, Andreas Mayr, Andreas Mitterecker, Adetayo Kasim, Tatsiana Khamiakova, Suzy Van, Dan Lin Sanden, Willem Talloen, Luc Bijnens, Hinrich WH Göhlmann, Ziv Shkedy, Djork-Arné Clevert",,,,,,,"S1 Factor analysis model with two factors and four observations............ 5 S2 Prelic data sets with noise variance 1, 0.4, 0.2 per row. The skewness is on average 0.64 and the excess kurtosis is on average 0.15................... 20 S3 Examples of Qubic data sets. A noise-free one (left) and a noisy one (right).... 21 S4 Results on the most complex data set from Li et al.(2009) using the quality measure in Li et al.(2009)................................ 22 S5 The first three data sets of our experiments. Left: noisy data. Right: noise free data. 23 S6 Three data sets with the same parameters (noise, size, overlap, etc.) as in our experiments, but with biclusters arranged in blocks for better visualization..... 24 S7 Our experimental data sets. The skewness is on average 0.0 and the excess kurtosis isonaverage0. 65.................................. 25
S8 Data densities of the gene expression data sets. Left: breast cancer data set, skewness is 0.45 and excess kurtosis is 0.93; Middle: multiple tissues data set, skewness is 0.15 and excess kurtosis is 1.3; Right: DLBCL data set, skewness is-0.05 and excesskurtosisis0. 35................................ 28 S9 Density of gene expression data sets plotted together. Breast cancer: solid blue; multiple tissue types: dashed red; DLBCL: dashed black.............. 29 S10 GO analysis for biological process (BP) on FABIA bicluster 1 obtained for the breast cancer data set. The GO hierarchy is shown. The darker the circles, the higher is the significance (the lower the p-value).................. 31 S11 STRING protein network derived from genes contained in FABIA bicluster 1 of the breast cancer data set. Connections are labeled as described on p. 29...... 32 S12 GO analysis for …",,"FABIA: Factor Analysis for Bicluster Acquisition—supplementary material—
S Hochreiter, U Bodenhofer, M Heusel, A Mayr…
관련 학술자료",,,,,,,,
Basic Methods of Data Analysis Part,Sepp Hochreiter,,,,,,,5 Linear Models 5.1 Linear Regression 5.1.1 Linear Model 5.1.2 Assumptions 5.1.3 Least Squares Parameter Estimation 5.1.4 Evaluation 5.1.5 Conf. Intervals 5.1.6 Tests 5.1.7 Examples 5.2 ANOVA 5.2.1 One Factor 5.2.2 Two Factors 5.2.3 Examples 5.3 ANCOVA 5.3.1 The Model 5.3.2 Examples 5.4 Mixed Effects Mo. 5.4.1 Approx. Estim. 5.4.2 Full Estimator 5.5 Generalized Linear Models 5.5.1 Logistic Reg. 5.5.2 Multinomial Logistic Regression 5.5.3 Poisson Reg. 5.5.4 Examples 5.6 Regularization 5.6.1 Partial Least Squares Regression 5.6.2 Ridge Reg. 5.6.3 LASSO 5.6.4 Elastic Net 5.6.5 Examples … We have considered linear regression for bivariate variables … Goal: fitting a linear function (a line) to data points … Objective: sum of the squared deviations between data and the line … → multiple linear regression: vector x (considered here) … 5 Linear Models 5.1 Linear Regression 5.1.1 Linear Model 5.1.2 Assumptions …,,"Basic Methods of Data Analysis Part
S Hochreiter
관련 학술자료 전체 6개의 버전",,,,,,,,
Bioinformatics II Theoretical Bioinformatics and Machine Learning Part 4,Sepp Hochreiter,,,,,,,"4 Support Vector Machines 4.1 SVM / Bioinf. 4.2 Linear Separable 4.3 Linear SVM 4.4 Nonlin. Separable 4.5 Average Bounds 4.6 nu-SVM 4.7 Non-Linear SVM 4.8 Example 4.9 Multiclass SVM 4.10 Regression 4.11 One Class SVM 4.12 Least Square 4.13 PSVM 4.14 Optimiz./SMO 4.14.1 Optimization 4.14.2 SMO 4.15 Desig. Kernels 4.15.1 String 4.15.2 Spectrum 4.15.3 Mismatch 4.15.4 Motif Kernel 4.15.5 Pairwise Kernel 4.15.6 Local Alignment 4.15.7 Smith-Waterm. 4.15.8 Fisher Kernel 4.15.9 Profile / PSSM 4.15.10 Chemical prop. 4.15.11 Local DNA 4.15.12 Salzberg DNA 4.15.13 Shifted Weigh. 4.16 Kernel PCA 4.17 Kernel Discr. Ana. 4.18 Software  … • SVM is based on principle of structural risk minimization (SRM) … • Since the mid 90s (Cortes and Vapnik … SVMs became the most popular supervised technique … • Popularity: - bounds on the future error, the risk … 4 Support Vector Machines 4.1 SVM / Bioinf. 4.2 Linear …",,"Bioinformatics II Theoretical Bioinformatics and Machine Learning Part 4
S Hochreiter
관련 학술자료 전체 4개의 버전",,,,,,,,
Identification of non reliable probes on customized Affymetrix Mouse430_2 platform,"Noura Chelbat, Adetayo Kassim2 Ulrich Bodenhofer, W Talloen, Sepp Hochreiter, Ziv Shkedy",,,,,,,"Results
The discrimination between non reliable-bad probes from reliable-good probes was computed through two alternative methods obtaining accuracies of wrongly performing probes in the range of 60–70% for both approaches",,"Identification of non reliable probes on customized Affymetrix Mouse430_2 platform
N Chelbat, AKU Bodenhofer, W Talloen, S Hochreiter…
관련 학술자료 전체 5개의 버전",,,,,,,,
Publication Supplement,"Günter Klambauer, Karin Schwarzbauer, Andreas Mayr, Djork-Arné Clevert, Andreas Mitterecker, Ulrich Bodenhofer, Sepp Hochreiter",,,,,,,"S1 The performance in terms of area under ROC curve (AUCroc) for three different library sizes and different choices of the hyperparameter G. The displayed values are the means over 800 data sets, that is 100 data sets for each of the eight different settings for the number of replicates in the conditions............... 33",,"Publication Supplement
G Klambauer, K Schwarzbauer, A Mayr, DA Clevert…
관련 학술자료 전체 12개의 버전",,,,,,,,
Bioinformatics III,Sepp Hochreiter,,,,,,,"This course is part of the curriculum of the master of science in bioinformatics at the Johannes Kepler University Linz. Machine learning has a major application in biology and medicine and many fields of research in bioinformatics are based on machine learning. For example one of the most prominent bioinformatics textbooks “Bioinformatics: The Machine Learning Approach” by P. Baldi and S. Brunak (MIT Press, ISBN 0-262-02506-X) sees the foundation of bioinformatics in machine learning.
Machine learning methods, for example neural networks used for the secondary and 3D structure prediction of proteins, have proven their value as essential bioinformatics tools. Modern measurement techniques in both biology and medicine create a huge demand for new machine learning approaches. One such technique is the measurement of mRNA concentrations with microarrays, where the data is first preprocessed, then genes of interest are identified, and finally predictions made. In other examples DNA data is integrated with other complementary measurements in order to detect alternative splicing, nucleosome positions, gene regulation, etc. All of these tasks are performed by machine learning algorithms. Alongside neural networks the most prominent machine learning techniques relate to support vector machines, kernel approaches, projection method and belief networks. These methods provide noise reduction, feature selection, structure extraction, classification/regression, and assist modeling. In the biomedical context, machine learning algorithms predict cancer treatment outcomes based on gene expression profiles, they classify novel …",,"Bioinformatics III
S Hochreiter
관련 학술자료 전체 12개의 버전
Bioinformatics I*
S Hochreiter
관련 학술자료 전체 15개의 버전",,,,,,,,
Software Manual,Sepp Hochreiter,,,,,,,"The fabia package is part of the Bioconductor (http://www. bioconductor. org) project. The package allows to extract biclusters from data sets based on a generative model according to the FABIA method (Hochreiter et al., 2010). It has been designed especially for microarray data sets, but can be used for other kinds of data sets as well.",,"Software Manual
S Hochreiter
관련 학술자료 전체 17개의 버전",,,,,,,,
Gaussian processes for machine learning,"Carl Edward Rasmussen, Christopher K. I. Williams",2006,,,,,MIT Press,We give a basic introduction to Gaussian Process regression models. We focus on understanding the role of the stochastic process and how it is used to define a distribution over functions. We present the simple equations for incorporating training data and examine how to learn the hyperparameters using the marginal likelihood. We explain the practical advantages of Gaussian Process and end with conclusions and a look at the current trends in GP work.,23544회,"Gaussian processes in machine learning
CE Rasmussen - Summer school on machine learning, 2003
21737회 인용 관련 학술자료 전체 43개의 버전
Gaussian processes formachine learning*
C KI Williams - 2006
1322회 인용 관련 학술자료 전체 5개의 버전
Gaussian processes for machine learning, vol. 1
CE Rasmussen, CK Williams - 2006
436회 인용 관련 학술자료
Gaussian processes for machine learning, vol. 2*
CK Williams, CE Rasmussen - MIT press Cambridge, MA, 2006
239회 인용 관련 학술자료
Gaussian processes for machine learning, ser. Adaptive computation and machine learning
C Rasmussen, C Williams - Cambridge, MA, UsA: MIT Press, 2006
118회 인용 관련 학술자료
Gaussian processes for machine learning the MIT press
CE Rasmussen, C Williams - Cambridge, MA, 2006
114회 인용 관련 학술자료
Gaussian processes for machine learning. 2006*
CE Rasmussen, CKI Williams - Cited on, 2014
90회 인용 관련 학술자료
Gaussian Processes for Machine Learning Cambridge*
CE Rasmussen, CKI Williams - MA: the MIT Press.[Google Scholar], 2006
55회 인용 관련 학술자료",,,,,,,,
Gaussian process for machine learning,"Carl Edward Rasmussen, Christopher KI Williams",2006,,,,,MIT press,We give a basic introduction to Gaussian Process regression models. We focus on understanding the role of the stochastic process and how it is used to define a distribution over functions. We present the simple equations for incorporating training data and examine how to learn the hyperparameters using the marginal likelihood. We explain the practical advantages of Gaussian Process and end with conclusions and a look at the current trends in GP work.,22094회,"Gaussian processes in machine learning
CE Rasmussen - Summer school on machine learning, 2003
21737회 인용 관련 학술자료 전체 43개의 버전
Gaussian processes for machine learning, vol. 1*
CE Rasmussen, CK Williams - 2006
436회 인용 관련 학술자료
Gaussian processes for machine learning the MIT press*
CE Rasmussen, C Williams - Cambridge, MA, 2006
114회 인용 관련 학술자료
Gaussian Process for Machine Learning. Adaptive Computation and Machine Learning
CE Rasmussen, CKI Williams - 2006
43회 인용 관련 학술자료
Gaussian processes for machine learning, ser*
CE Rasmussen, CKI Williams - Lecture Notes in Computer Science. Springer Berlin …, 2006
33회 인용 관련 학술자료",,,,,,,,
The PASCAL Visual Object Classes (VOC) challenge,"Mark Everingham, Luc Van Gool, Christopher K. I. Williams, John Winn, Andrew Zisserman",2010,Int J Computer Vision,88,2,303-338,,"Abstract The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection. This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (eg the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.",11238회,"The pascal visual object classes (voc) challenge
M Everingham, L Van Gool, CKI Williams, J Winn… - International journal of computer vision, 2010
11238회 인용 관련 학술자료 전체 25개의 버전",,,,,,,,
The pascal visual object classes challenge: A retrospective,"Mark Everingham, SM Ali Eslami, Luc Van Gool, Christopher KI Williams, John Winn, Andrew Zisserman",2015/1,International journal of computer vision,111,1,98-136,Springer US,"The Pascal Visual Object Classes (VOC) challenge consists of two components: (i) a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii) an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008–2012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the VOC datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the VOC datasets we …",3602회,"The pascal visual object classes challenge: A retrospective
M Everingham, SMA Eslami, L Van Gool, CKI Williams… - International journal of computer vision, 2015
3602회 인용 관련 학술자료 전체 33개의 버전",,,,,,,,
The PASCAL visual object classes challenge 2007 (VOC2007) results,"Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, Andrew Zisserman",2007/10,,1,5,,,"This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006). Details of the challenge, data, and evaluation are presented. Participants in the challenge submitted descriptions of their methods, and these have been included verbatim. This document should be considered preliminary, and subject to change.",2749회,"The PASCAL visual object classes challenge 2007 (VOC2007) results
M Everingham, L Van Gool, CKI Williams, J Winn… - 2007
2749회 인용 관련 학술자료 전체 20개의 버전",,,,,,,,
Using the Nyström method to speed up kernel machines,"Christopher Williams, Matthias Seeger",2001,,,CONF,682-688,,"¢¡¡¤£¦¥ § ©""! $# &% &%'% &#(¦) 0 1! 32 (% 5 4769 8&Ä@ CB (D¦ 6&@ E ÄFGFIHQP&RG¥ § TSUVBQ6X WYb adcf ehgE i i5pC Yb a cI% r qsFut FHPRG¥ § SvB¥ § P@ Gw P xy BDI¥ § © w¦¥ § T@£ b H6¥ § £¦ 6'g w6&£ d# 6% G%¢¥ § @ bd'VQ Vde GV dfg Ih V 1 V© iVj j kmlen"" oqp@£ r 8&@ e 6 SPAB¥ § sVB 6&£¥ § T@ sH $¥ § 6'Bg P xt g¦ w'% ux B $ DG6C 6&¥ § v6&@ G£¦ 6v8 (PwSxF Pw¥ § TB $¥ § Pv@ y¥ § w s¥ § Äe 6w# w¥ § @ GB $ DG6 ÄFGFIHQP&RG¥ § TSUVBQ¥ § zPw@ i irp {Y| a1c7¥ § } HQ6VvB g HQ6V£ 8g6 BD¦ 6y 8'PvS9F B (VB¥ § Pw@ 8 (PwBw Px S@ g w6&HQ@ I6 S96gB $ DGP¦£ w% PABQ6q B $ D VB BQDG¥ § zw S Vt BQH $¥ § R¥ § © w@ GPAB w¥ § @ w H£ 6 BQPs B $ DG6 ac B (6'HQSC% t PV q6s6'H&# w 8 (PwSxF B $¥ § @ BQDI6 6'¥ § z 6'@£¦ 6&8'PwSxF Pw¥ § B¥ § Pv@¥ § w x &2 PwF 6'H (vB (¥ § TPw@ 1% D¦ 6&H $6 r HQ6U Sx6'BQDGP¦£ w BQPE 8'PvSxF B $6 B $ DG6 GHwBy y 6&¥ § 6&@ s 6w Ä@ G£ 6&¥ § 6&@ s6V8 $ B (PwHw Px W# e BB (D¦ 6&¥ § THU s6&H 6x H@¦@ G¥ § @ B $¥ § Sx6w ÄH $6 w¥ § @ I¥ § d8'Ä@ uB ge 6 PU 1 V2 Pw@ g¥ § xf 7%",2351회,"Using the Nyström method to speed up kernel machines
C Williams, M Seeger - 2001
2351회 인용 관련 학술자료 전체 7개의 버전",,,Proceedings of the 14th annual conference on neural information processing systems,,,,,
GTM: The generative topographic mapping,"Christopher M Bishop, Markus Svensén, Christopher KI Williams",1998/1/1,Neural computation,10,1,215-234,MIT Press,"Latent variable models represent the probability density of data in a space of several dimensions in terms of a smaller number of latent, or hidden, variables. A familiar example is factor analysis, which is based on a linear transformation between the latent space and the data space. In this article, we introduce a form of nonlinear latent variable model called the generative topographic mapping, for which the parameters of the model can be determined using the expectation-maximization algorithm. GTM provides a principled alternative to the widely used self-organizing map (SOM) of Kohonen (1982) and overcomes most of the significant limitations of the SOM. We demonstrate the performance of the GTM algorithm on a toy problem and on simulated data from flow diagnostics for a multiphase oil pipeline.",1730회,"GTM: The generative topographic mapping
CM Bishop, M Svensén, CKI Williams - Neural computation, 1998
1730회 인용 관련 학술자료 전체 25개의 버전",,,,,,,,
Gaussian processes for regression,"Christopher KI Williams, Carl Edward Rasmussen",1996,,,,,MIT,"The Bayesian analysis of neural networks is difficult because a simple prior over weights implies a complex prior distribution over functions. In this paper we investigate the use of Gaussian process priors over functions, which permit the predictive Bayesian analysis for fixed values of hyperparameters to be carried out exactly using matrix operations. Two methods, using optimization and averaging (via Hybrid Monte Carlo) over hyperparameters have been tested on a number of challenging problems and have produced excellent results.",1289회,"Gaussian processes for regression
CKI Williams, CE Rasmussen - 1996
1289회 인용 관련 학술자료 전체 39개의 버전",,,,,,,,
Multi-task Gaussian process prediction,"Chris Williams, Edwin V Bonilla, Kian M Chai",2007,Advances in neural information processing systems,,,153-160,,"Evgeniou et al (2005) induce correlations between tasks based on a correlated prior over linear regression parameters Conti & O’Hagan (2007): emulating multi-output simulators Use of task descriptors so that Kf lm
= kf (tl, tm), eg Yu et al (2007), Bonilla et al (2007). Semiparametric latent factor model (SLFM) of Teh et al (2005) has P latent processes each with its own covariance function. Noiseless outputs are obtained by linear mixing of these latent functions. Our model is similar, but simpler, in that all of the P latent processes share the same covariance function; this reduces the number of free parameters to be fitted and should help to minimize overfitting",965회,"Multi-task Gaussian process prediction
C Williams, EV Bonilla, KM Chai - Advances in neural information processing systems, 2007
965회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
Bayesian classification with Gaussian processes,"Christopher KI Williams, David Barber",1998/12,IEEE Transactions on Pattern Analysis and Machine Intelligence,20,12,1342-1351,IEEE,"We consider the problem of assigning an input vector to one of m classes by predicting P(c|x) for c=1,...,m. For a two-class problem, the probability of class one given x is estimated by /spl sigma/(y(x)), where /spl sigma/(y)=1/(1+e/sup -y/). A Gaussian process prior is placed on y(x), and is combined with the training data to obtain predictions for new x points. We provide a Bayesian treatment, integrating over uncertainty in y and in the parameters that control the Gaussian process prior the necessary integration over y is carried out using Laplace's approximation. The method is generalized to multiclass problems (m>2) using the softmax function. We demonstrate the effectiveness of the method on a number of datasets.",868회,"Bayesian classification with Gaussian processes
CKI Williams, D Barber - IEEE Transactions on Pattern Analysis and Machine …, 1998
868회 인용 관련 학술자료 전체 21개의 버전",,,,,,,,
Prediction with Gaussian processes: From linear regression to linear prediction and beyond,Christopher KI Williams,1998,,,,599-621,"Springer, Dordrecht","The main aim of this paper is to provide a tutorial on regression with Gaussian processes. We start from Bayesian linear regression, and show how by a change of viewpoint one can see this method as a Gaussian process predictor based on priors over functions, rather than on priors over parameters. This leads in to a more general discussion of Gaussian processes in section 4. Section 5 deals with further issues, including hierarchical modelling and the setting of the parameters that control the Gaussian process, the covariance functions for neural network models and the use of Gaussian processes in classification problems.",791회,"Prediction with Gaussian processes: From linear regression to linear prediction and beyond
CKI Williams - Learning in graphical models, 1998
791회 인용 관련 학술자료 전체 15개의 버전",,Learning in graphical models,,,,,,
Fast forward selection to speed up sparse Gaussian process regression,"Matthias Seeger, Christopher Williams, Neil Lawrence",2003,,,CONF,,,"³v3 µ x vy vWrl¶· v"" b Vlx bv¢ y µ¶ wx yv lx vWvW V¶ wµbµbx ¹fsu·¶ ws lr3 w º»¶ wvy s¶ r ¼½¶£ yy su¶ wr3 µ x V¾"" vy y x vq lx vy ys lr¦ f"" v¶ w bx surb!¶! rb wtwvWe bvW bx s ys ¾ wxH twvWx¶ ly lx¿»¶ xr À y vWe v¾Á su wreÂÄ Ã¦ bxÅ·(vq b V Æ s y vy Ç y vqrh s¶ eueu¶ lyC¶ ly¶ wy (¶ r vÈh bs tw¶ we vWrl (wrbv3¿ G bs ¾r y vqeuvW¾"" y4 bv É y bµ µ£ lx rÊË µ¶ vqx ry¶ w Ì x¶ wr V l· Íf lv""¢ s ¾q¶ wrË wb µivqx wx· Î x¶ wr V w· Î y vqeuvW¾"" su wrÏ lr¶ wx Ì ¾q bx twv Ðb surb r¶ wy ÑfyWÂ Ò lx v su· µ£ lx r¶ rh eu wf s euvW¶ wy C¶¤ y V ¾"" suvqrh eu Q y¶ w beuv $¶ µbµbx ¹Vs·¶ su wr wn bvÅ eu w Ì·¶ wx ls r¶ we $ eus Ñlvqeus bf V ½ bv x¶ ws rVÇ surb b¶ wr¶ bf¿ G bs ¾r Ó ¾W¶ rÔ ivÍ wµV s· s yv Ì¶ w wÕ y¶ ½ e¶ x wvG rf b· Q£ vWxÖ¢ f fµ£ vWx µ¶ wx¶ w· v"" vWx y¶ w V l·¶ w Ç s ¾q¶ we eu wÂ ³4v¢ VvW·(lr y xr¶ wv bvÍ· V Vvqe» y vWe v¾Á s lr ¾W¶ µ¶ w bs eus suvWy w Q bv¶ eu w lx sb·× s rT¶ Ø xr¶ rb lv w vq¹fµivqx su·(vWrh yWÂÏ ÙÚrÛ e surbv¿ Gs bvÅ VvWtwvqeu wµ·(vWrh whwx¦· v"" b V¢ f¦¿% vQ µ x vy vWrl¤¶ Í y su· µbe v tfsuvq¿ T lr y µ¶ xry vÓ¶ µ µbx ¹Vsu·¶ w su wr£ y¢ wx ¼½¡ Ü· V VvWeuy¶ r£ bvqsux! br£ Vvqx e fsurb¶ wy yb· µV su wr y!¶ r¢ ybw¿ Ý x vqe¶ wÇ s lr y% w bvWxG·(vq b V byWÂ",505회,"Fast forward selection to speed up sparse Gaussian process regression
M Seeger, C Williams, N Lawrence - 2003
505회 인용 관련 학술자료 전체 7개의 버전",,,Artificial Intelligence and Statistics 9,,,,,
Using machine learning to focus iterative optimization,"Felix Agakov, Edwin Bonilla, John Cavazos, Björn Franke, Grigori Fursin, Michael FP O'Boyle, John Thomson, Marc Toussaint, Christopher KI Williams",2006/3/26,,,,11 pp.-305,IEEE,"Iterative compiler optimization has been shown to outperform static approaches. This, however, is at the cost of large numbers of evaluations of the program. This paper develops a new methodology to reduce this number and hence speed up iterative optimization. It uses predictive modelling from the domain of machine learning to automatically focus search on those areas likely to give greatest performance. This approach is independent of search algorithm, search space or compiler infrastructure and scales gracefully with the compiler optimization space size. Off-line, a training set of programs is iteratively evaluated and the shape of the spaces and program features are modelled. These models are learnt and used to focus the iterative optimization of a new program. We evaluate two learnt models, an independent and Markov model, and evaluate their worth on two embedded platforms, the Texas Instrument …",475회,"Using machine learning to focus iterative optimization
F Agakov, E Bonilla, J Cavazos, B Franke, G Fursin… - International Symposium on Code Generation and …, 2006
475회 인용 관련 학술자료 전체 25개의 버전",International Symposium on Code Generation and Optimization (CGO'06),,,,,,,
Regression with input-dependent noise: A Gaussian process treatment,"Paul W Goldberg, Christopher KI Williams, Christopher M Bishop",1997,Advances in neural information processing systems,10,,493-499,,"Gaussian processes provide natural non-parametric prior distributions over regression functions. In this paper we consider regression problems where there is noise on the output, and the variance of the noise depends on the inputs. If we assume that the noise is a smooth function of the inputs, then it is natural to model the noise variance using a second Gaussian process, in addition to the Gaussian process governing the noise-free output value. We show that prior uncertainty about the parameters controlling both processes can be handled and that the posterior distribution of the noise rate can be sampled from using Markov chain Monte Carlo methods. Our results on a synthetic data set give a posterior noise variance that well-approximates the true variance.",329회,"Regression with input-dependent noise: A Gaussian process treatment
PW Goldberg, CKI Williams, CM Bishop - Advances in neural information processing systems, 1997
329회 인용 관련 학술자료 전체 14개의 버전",,,,,,,,
The 2005 pascal visual object classes challenge,"Mark Everingham, Andrew Zisserman, Christopher KI Williams, Luc Van Gool, Moray Allan, Christopher M Bishop, Olivier Chapelle, Navneet Dalal, Thomas Deselaers, Gyuri Dorkó, Stefan Duffner, Jan Eichhorn, Jason DR Farquhar, Mario Fritz, Christophe Garcia, Tom Griffiths, Frederic Jurie, Daniel Keysers, Markus Koskela, Jorma Laaksonen, Diane Larlus, Bastian Leibe, Hongying Meng, Hermann Ney, Bernt Schiele, Cordelia Schmid, Edgar Seemann, John Shawe-Taylor, Amos Storkey, Sandor Szedmak, Bill Triggs, Ilkay Ulusoy, Ville Viitaniemi, Jianguo Zhang",2005/4/11,,,,117-176,"Springer, Berlin, Heidelberg","The PASCAL Visual Object Classes Challenge ran from February to March 2005. The goal of the challenge was to recognize objects from a number of visual object classes in realistic scenes (i.e. not pre-segmented objects). Four object classes were selected: motorbikes, bicycles, cars and people. Twelve teams entered the challenge. In this chapter we provide details of the datasets, algorithms used by the teams, evaluation criteria, and results achieved.",305회,"The 2005 pascal visual object classes challenge
M Everingham, A Zisserman, CKI Williams, L Van Gool… - Machine Learning Challenges Workshop, 2005
305회 인용 관련 학술자료 전체 36개의 버전",Machine Learning Challenges Workshop,,,,,,,
Resin infusion under flexible tooling (RIFT): a review,"Christopher Williams, John Summerscales, Stephen Grove",1996/1/1,,27,7,517-524,Elsevier,"Increasing legislation to limit styrene emissions (mainly from polyester resin systems) into the work place has been the key factor in promoting new technology in the manufacture of fibre reinforced plastics composites. Styrene emissions can be reduced by the development of: resin systems with low styrene emission; improved ventilation and air filtering systems; closed moulding techniques. It is the final area on which this paper concentrates.
RIFT is a variant of vacuum-driven RTM in which one of the solid tool faces is replaced by a flexible polymeric film. The process is known by several acronyms—in this paper it is referred to as RIFT (Resin Infusion under Flexible Tooling). Potentially a very clean and economical composites manufacturing method, the process draws resin into a dry reinforcement on an evacuated vacuum bagged tool using only the partial vacuum to drive the resin. It reduces worker contact with …",275회,"Resin infusion under flexible tooling (RIFT): a review
C Williams, J Summerscales, S Grove - Composites Part A: Applied Science and …, 1996
275회 인용 관련 학술자료 전체 7개의 버전",,,Composites Part A: Applied Science and Manufacturing,,,,,
Dataset issues in object recognition,"Jean Ponce, Tamara L Berg, Mark Everingham, David A Forsyth, Martial Hebert, Svetlana Lazebnik, Marcin Marszalek, Cordelia Schmid, Bryan C Russell, Antonio Torralba, Christopher KI Williams, Jianguo Zhang, Andrew Zisserman",2006,,,,29-48,"Springer, Berlin, Heidelberg","Appropriate datasets are required at all stages of object recognition research, including learning visual models of object and scene categories, detecting and localizing instances of these models in images, and evaluating the performance of recognition algorithms. Current datasets are lacking in several respects, and this paper discusses some of the lessons learned from existing efforts, as well as innovative ways to obtain very large and diverse annotated datasets. It also suggests a few criteria for gathering future datasets.",270회,"Dataset issues in object recognition
J Ponce, TL Berg, M Everingham, DA Forsyth, M Hebert… - Toward category-level object recognition, 2006
270회 인용 관련 학술자료 전체 44개의 버전",,Toward category-level object recognition,,,,,,
Milepost gcc: Machine learning enabled self-tuning compiler,"Grigori Fursin, Yuriy Kashnikov, Abdul Wahid Memon, Zbigniew Chamski, Olivier Temam, Mircea Namolaru, Elad Yom-Tov, Bilha Mendelson, Ayal Zaks, Eric Courtois, Francois Bodin, Phil Barnard, Elton Ashton, Edwin Bonilla, John Thomson, Christopher KI Williams, Michael O’Boyle",2011/6,International journal of parallel programming,39,3,296-327,Springer US,"Tuning compiler optimizations for rapidly evolving hardware makes porting and extending an optimizing compiler for each new platform extremely challenging. Iterative optimization is a popular approach to adapting programs to a new architecture automatically using feedback-directed compilation. However, the large number of evaluations required for each program has prevented iterative compilation from widespread take-up in production compilers. Machine learning has been proposed to tune optimizations across programs systematically but is currently limited to a few transformations, long training phases and critically lacks publicly released, stable tools. Our approach is to develop a modular, extensible, self-tuning optimization infrastructure to automatically learn the best optimizations across multiple programs and architectures based on the correlation between program features, run-time behavior and …",246회,"Milepost gcc: Machine learning enabled self-tuning compiler
G Fursin, Y Kashnikov, AW Memon, Z Chamski… - International journal of parallel programming, 2011
246회 인용 관련 학술자료 전체 24개의 버전",,,,,,,,
Using generative models for handwritten digit recognition,"Michael Revow, Christopher KI Williams, Geoffrey E Hinton",1996/6,IEEE transactions on pattern analysis and machine intelligence,18,6,592-606,IEEE,"We describe a method of recognizing handwritten digits by fitting generative models that are built from deformable B-splines with Gaussian ""ink generators"" spaced along the length of the spline. The splines are adjusted using a novel elastic matching procedure based on the expectation maximization algorithm that maximizes the likelihood of the model generating the data. This approach has many advantages: 1) the system not only produces a classification of the digit but also a rich description of the instantiation parameters which can yield information such as the writing style; 2) the generative models can perform recognition driven segmentation; 3) the method involves a relatively small number of parameters and hence training is relatively easy and fast; and 4) unlike many other recognition schemes, it does not rely on some form of pre-normalization of input images, but can handle arbitrary scalings, translations …",237회,"Using generative models for handwritten digit recognition
M Revow, CKI Williams, GE Hinton - IEEE transactions on pattern analysis and machine …, 1996
237회 인용 관련 학술자료 전체 45개의 버전",,,,,,,,
The shape boltzmann machine: a strong model of object shape,"SM Ali Eslami, Nicolas Heess, Christopher KI Williams, John Winn",2014/4/1,International Journal of Computer Vision,107,2,155-176,Springer US,"A good model of object shape is essential in applications such as segmentation, detection, inpainting and graphics. For example, when performing segmentation, local constraints on the shapes can help where object boundaries are noisy or unclear, and global constraints can resolve ambiguities where background clutter looks similar to parts of the objects. In general, the stronger the model of shape, the more performance is improved. In this paper, we use a type of deep Boltzmann machine (Salakhutdinov and Hinton, International Conference on Artificial Intelligence and Statistics, 2009) that we call a Shape Boltzmann Machine (SBM) for the task of modeling foreground/background (binary) and parts-based (categorical) shape images. We show that the SBM characterizes a strong model of shape, in that samples from the model look realistic and it can generalize to generate samples that differ from …",234회,"The shape boltzmann machine: a strong model of object shape
SMA Eslami, N Heess, CKI Williams, J Winn - International Journal of Computer Vision, 2014
234회 인용 관련 학술자료 전체 33개의 버전
The Shape Boltzmann Machine*
SMA Eslami, N Heess, CKI Williams, J Winn
관련 학술자료 전체 17개의 버전",,,,,,,,
Developments of the generative topographic mapping,"Christopher M Bishop, Markus Svensén, Christopher KI Williams",1998/11/6,Neurocomputing,21,1-3,203-224,Elsevier,"The generative topographic mapping (GTM) model was introduced by Bishop et al. (1998, Neural Comput. 10(1), 215–234) as a probabilistic re-formulation of the self-organizing map (SOM). It offers a number of advantages compared with the standard SOM, and has already been used in a variety of applications. In this paper we report on several extensions of the GTM, including an incremental version of the EM algorithm for estimating the model parameters, the use of local subspace models, extensions to mixed discrete and continuous data, semi-linear models which permit the use of high-dimensional manifolds whilst avoiding computational intractability, Bayesian inference applied to hyper-parameters, and an alternative framework for the GTM based on Gaussian processes. All of these developments directly exploit the probabilistic structure of the GTM, thereby allowing the underlying modelling assumptions to …",234회,"Developments of the generative topographic mapping
CM Bishop, M Svensén, CKI Williams - Neurocomputing, 1998
234회 인용 관련 학술자료 전체 13개의 버전",,,,,,,,
GTM: A principled alternative to the self-organizing map,"Christopher M Bishop, Markus Svensén, Christopher KI Williams",1996/7/16,,,,165-170,"Springer, Berlin, Heidelberg","The Self-Organizing Map (SOM) algorithm has been extensively studied and has been applied with considerable success to a wide variety of problems. However, the algorithm is derived from heuristic ideas and this leads to a number of significant limitations. In this paper, we consider the problem of modelling the probability density of data in a space of several dimensions in terms of a smaller number of latent, or hidden, variables. We introduce a novel form of latent variable model, which we call the GTM algorithm (for Generative Topographic Map), which allows general non-linear transformations from latent space to data space, and which is trained using the EM (expectation-maximization) algorithm. Our approach overcomes the limitations of the SOM, while introducing no significant disadvantages. We demonstrate the performance of the GTM algorithm on simulated data from flow diagnostics for a multi …",233회,"GTM: A principled alternative to the self-organizing map
CM Bishop, M Svensén, CKI Williams - International Conference on Artificial Neural Networks, 1996
233회 인용 관련 학술자료 전체 20개의 버전",International Conference on Artificial Neural Networks,,,,,,,
Computing with infinite networks,Christopher KI Williams,1997,Advances in neural information processing systems,,,295-301,MORGAN KAUFMANN PUBLISHERS,"For neural networks with a wide class of weight-priors, it can be shown that in the limit of an infinite number of hidden units the prior over functions tends to a Gaussian process. In this paper an-alytic forms are derived for the covariance function of the Gaussian processes corresponding to networks with sigmoidal and Gaussian hidden units. This allows predictions to be made efficiently using networks with an infinite number of hidden units, and shows that, somewhat paradoxically, it may be easier to compute with infinite networks than finite ones.",226회,"Computing with infinite networks
CKI Williams - Advances in neural information processing systems, 1997
226회 인용 관련 학술자료 전체 7개의 버전
Computing with infinite networks*
MC Mozer, MI Jordan, T Petsche - Advances in Neural Information Processing Systems 9, 1997
2회 인용 관련 학술자료",,,,,,,,
Harmonising chorales by probabilistic inference,"Moray Allan, Christopher KI Williams",2005,Advances in neural information processing systems,17,,25-32,MIT Press,"We describe how we used a data set of chorale harmonisations composed by Johann Sebastian Bach to train Hidden Markov Models. Using a probabilistic framework allows us to create a harmonisation system which learns from examples, and which can compose new harmonisations. We make a quantitative comparison of our system's harmonisation performance against simpler models, and provide example harmonisations.",218회,"Harmonising chorales by probabilistic inference
M Allan, CKI Williams - Advances in neural information processing systems, 2005
218회 인용 관련 학술자료 전체 21개의 버전",,,,,,,,
The effect of the input density distribution on kernel-based classifiers,"Christopher Williams, Matthias Seeger",2000,,,,,,"The eigenfunction expansion of a kernel function K (x, y) as used in support vector machines or Gaussian process predictors is studied when the input data is drawn from a distribution p (x). In this case it is shown that the eigenfunctions fig obey the equation K (x, y) p (x) i (x) dx= ii (y). This has a number of consequences including (i) the eigenvalues/vectors of the n × n Gram matrix K obtained by evaluating the kernel at all pairs of training points K (xi, xj) converge to the eigenvalues and eigenfunctions of the integral equation above as n! 1 and (ii) the dependence of the eigenfunctions on p (x) may be useful for the class-discrimination task. We show that on a number of datasets using the RBF kernel the eigenvalue spectrum of the Gram matrix decays rapidly, and discuss how this property might be used to speed up kernel-based predictors.",217회,"The effect of the input density distribution on kernel-based classifiers
C Williams, M Seeger - Proceedings of the 17th international conference on …, 2000
217회 인용 관련 학술자료 전체 5개의 버전",Proceedings of the 17th international conference on machine learning,,,,,,,
The pascal visual object classes challenge 2007 results,"Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, Andrew Zisserman",2007,,122,,,,,199회,"The pascal visual object classes challenge 2007 results
M Everingham, L Van Gool, CKI Williams, J Winn… - 2007
199회 인용 관련 학술자료",,,,,,,,
Computation with infinite neural networks,Christopher KI Williams,1998/7/1,Neural Computation,10,5,1203-1216,MIT Press,"For neural networks with a wide class of weight priors, it can be shown that in the limit of an infinite number of hidden units, the prior over functions tends to a gaussian process. In this article, analytic forms are derived for the covariance function of the gaussian processes corresponding to networks with sigmoidal and gaussian hidden units. This allows predictions to be made efficiently using networks with an infinite number of hidden units and shows, somewhat paradoxically, that it may be easier to carry out Bayesian prediction with infinite networks rather than finite ones.",199회,"Computation with infinite neural networks
CKI Williams - Neural Computation, 1998
199회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
On a connection between kernel PCA and metric multidimensional scaling,Christopher KI Williams,2002/1,Machine Learning,46,1,11-19,Kluwer Academic Publishers,"In this note we show that the kernel PCA algorithm of Schölkopf, Smola, and Müller (Neural Computation, 10, 1299–1319.) can be interpreted as a form of metric multidimensional scaling (MDS) when the kernel function k(x, y) is isotropic, i.e. it depends only on ‖x − y‖. This leads to a metric MDS algorithm where the desired configuration of points is found via the solution of an eigenproblem rather than through the iterative optimization of the stress objective function. The question of kernel choice is also discussed.",188회,"On a connection between kernel PCA and metric multidimensional scaling
CKI Williams - Machine Learning, 2002
188회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
On the eigenspectrum of the Gram matrix and the generalization error of kernel-PCA,"John Shawe-Taylor, Christopher KI Williams, Nello Cristianini, Jaz Kandola",2005/6/27,IEEE Transactions on Information Theory,51,7,2510-2522,IEEE,"In this paper, the relationships between the eigenvalues of the m/spl times/m Gram matrix K for a kernel /spl kappa/(/spl middot/,/spl middot/) corresponding to a sample x/sub 1/,...,x/sub m/ drawn from a density p(x) and the eigenvalues of the corresponding continuous eigenproblem is analyzed. The differences between the two spectra are bounded and a performance bound on kernel principal component analysis (PCA) is provided showing that good performance can be expected even in very-high-dimensional feature spaces provided the sample eigenvalues fall sufficiently quickly.",180회,"On the eigenspectrum of the Gram matrix and the generalization error of kernel-PCA
J Shawe-Taylor, CKI Williams, N Cristianini, J Kandola - IEEE Transactions on Information Theory, 2005
180회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
Dictionary of computer vision and image processing,"Robert B Fisher, Toby P Breckon, Kenneth Dawson-Howe, Andrew Fitzgibbon, Craig Robertson, Emanuele Trucco, Christopher KI Williams",2013/11/8,,,,,John Wiley & Sons,"Written by leading researchers, the 2nd Edition of the Dictionary of Computer Vision & Image Processing is a comprehensive and reliable resource which now provides explanations of over 3500 of the most commonly used terms across image processing, computer vision and related fields including machine vision. It offers clear and concise definitions with short examples or mathematical precision where necessary for clarity that ultimately makes it a very usable reference for new entrants to these fields at senior undergraduate and graduate level, through to early career researchers to help build up knowledge of key concepts. As the book is a useful source for recent terminology and concepts, experienced professionals will also find it a valuable resource for keeping up to date with the latest advances. New features of the 2nd Edition: Contains more than 1000 new terms, notably an increased focus on image processing and machine vision terms; Includes the addition of reference links across the majority of terms pointing readers to further information about the concept under discussion so that they can continue to expand their understanding; Now available as an eBook with enhanced content: approximately 50 videos to further illustrate specific terms; active cross-linking between terms so that readers can easily navigate from one related term to another and build up a full picture of the topic in question; and hyperlinked references to fully embed the text in the current literature.",170회,"Dictionary of computer vision and image processing
RB Fisher, TP Breckon, K Dawson-Howe, A Fitzgibbon… - 2013
170회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Approximation methods for Gaussian process regression,"Joaquin Quinonero-Candela, Carl Edward Rasmussen, Christopher KI Williams",2007/8,,,,203-223,MIT Press,"A wealth of computationally efficient approximation methods for Gaussian process regression have been recently proposed. We give a unifying overview of sparse approximations, following Quiñonero-Candela and Rasmussen (2005), and a brief review of approximate matrix-vector multiplication methods.",167회,"Approximation methods for Gaussian process regression
J Quinonero-Candela, CE Rasmussen, CKI Williams - Large-scale kernel machines, 2007
167회 인용 관련 학술자료 전체 17개의 버전",,Large-scale kernel machines,,,,,,
Adaptive elastic models for hand-printed character recognition,"Geoffrey E Hinton, Christopher KI Williams, Michael D Revow",1991/12/2,NIPS,4,,512-519,,"Hand-printed digits can be modeled as splines that are governed by about 8 control points. For each known digit, the control points have preferred"" home"" locations, and deformations of the digit are generated by moving the control points away from their home locations. Images of digits can be produced by placing Gaussian ink generators uniformly along the spline. Real images can be recognized by finding the digit model most likely to have generated the data. For each digit model we use an elastic matching algorithm to minimize an energy function that includes both the deformation energy of the digit model and the log probability that the model would generate the inked pixels in the image. The model with the lowest total energy wins. If a uniform noise process is included in the model of image generation, some of the inked pixels can be rejected as noise as a digit model is fitting a poorly segmented image. The digit models learn by modifying the home locations of the control points.",165회,"Adaptive elastic models for hand-printed character recognition
GE Hinton, CKI Williams, MD Revow - NIPS, 1991
165회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
MILEPOST GCC: machine learning based research compiler,"Grigori Fursin, Cupertino Miranda, Olivier Temam, Mircea Namolaru, Elad Yom-Tov, Ayal Zaks, Bilha Mendelson, Edwin Bonilla, John Thomson, Hugh Leather, Chris Williams, Michael O'Boyle, Phil Barnard, Elton Ashton, Eric Courtois, Francois Bodin",2008/6/17,,,,,,"Tuning hardwired compiler optimizations for rapidly evolving hardware makes porting an optimizing compiler for each new platform extremely challenging. Our radical approach is to develop a modular, extensible, self-optimizing compiler that automatically learns the best optimization heuristics based on the behavior of the platform. In this paper we describe MILEPOST GCC, a machine-learning-based compiler that automatically adjusts its optimization heuristics to improve the execution time, code size, or compilation time of specific programs on different architectures. Our preliminary experimental results show that it is possible to considerably reduce execution time of the MiBench benchmark suite on a range of platforms entirely automatically.",143회,"MILEPOST GCC: machine learning based research compiler
G Fursin, C Miranda, O Temam, M Namolaru… - GCC summit, 2008
143회 인용 관련 학술자료 전체 23개의 버전",GCC summit,,,,,,,
A framework for evaluating approximation methods for Gaussian process regression,"Krzysztof Chalupka, Christopher KI Williams, Iain Murray",2013,Journal of Machine Learning Research,14,,333-350,Microtome Publishing,"Gaussian process (GP) predictors are an important component of many Bayesian approaches to machine learning. However, even a straightforward implementation of Gaussian process regression (GPR) requires O (n2) space and O (n3) time for a data set of n examples. Several approximation methods have been proposed, but there is a lack of understanding of the relative merits of the different approximations, and in what situations they are most useful. We recommend assessing the quality of the predictions obtained as a function of the compute time taken, and comparing to standard baselines (eg, Subset of Data and FITC). We empirically investigate four different approximation algorithms on four different prediction problems, and make our code available to encourage future comparisons.",136회,"A framework for evaluating approximation methods for Gaussian process regression
K Chalupka, CKI Williams, I Murray - Journal of Machine Learning Research, 2013
136회 인용 관련 학술자료 전체 15개의 버전",,,,,,,,
A framework for the quantitative evaluation of disentangled representations,"Cian Eastwood, Christopher KI Williams",2018/2/15,,,,,,"Recent AI research has emphasised the importance of learning disentangled representations of the explanatory factors behind data. Despite the growing interest in models which can learn such representations, visual inspection remains the standard evaluation metric. While various desiderata have been implied in recent definitions, it is currently unclear what exactly makes one disentangled representation better than another. In this work we propose a framework for the quantitative evaluation of disentangled representations when the ground-truth latent structure is available. Three criteria are explicitly defined and quantified to elucidate the quality of learnt representations and thus compare models on an equal basis. To illustrate the appropriateness of the framework, we employ it to compare quantitatively the representations learned by recent state-of-the-art models.",132회,"A framework for the quantitative evaluation of disentangled representations
C Eastwood, CKI Williams - International Conference on Learning Representations, 2018
132회 인용 관련 학술자료 전체 5개의 버전",International Conference on Learning Representations,,,,,,,
Combining belief networks and neural networks for scene segmentation,"Xiaojuan Feng, Christopher KI Williams, Stephen N Felderhof",2002/8/7,IEEE Transactions on Pattern Analysis and Machine Intelligence,24,4,467-483,IEEE,"We are concerned with the problem of image segmentation, in which each pixel is assigned to one of a predefined finite number of labels. In Bayesian image analysis, this requires fusing together local predictions for the class labels with a prior model of label images. Following the work of Bouman and Shapiro (1994), we consider the use of tree-structured belief networks (TSBNs) as prior models. The parameters in the TSBN are trained using a maximum-likelihood objective function with the EM algorithm and the resulting model is evaluated by calculating how efficiently it codes label images. A number of authors have used Gaussian mixture models to connect the label field to the image data. We compare this approach to the scaled-likelihood method of Smyth (1994) and Morgan and Bourlard (1995), where local predictions of pixel classification from neural networks are fused with the TSBN prior. Our results show …",132회,"Combining belief networks and neural networks for scene segmentation
X Feng, CKI Williams, SN Felderhof - IEEE Transactions on Pattern Analysis and Machine …, 2002
132회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Kernel multi-task learning using task-specific features,"Edwin V Bonilla, Felix V Agakov, Christopher KI Williams",2007/3/11,,,,43-50,PMLR,"In this paper we are concerned with multitask learning when task-specific features are available. We describe two ways of achieving this using Gaussian process predictors: in the first method, the data from all tasks is combined into one dataset, making use of the task-specific features. In the second method we train specific predictors for each reference task, and then combine their predictions using a gating network. We demonstrate these methods on a compiler performance prediction problem, where a task is defined as predicting the speed-up obtained when applying a sequence of code transformations to a given program.",131회,"Kernel multi-task learning using task-specific features
EV Bonilla, FV Agakov, CKI Williams - Artificial Intelligence and Statistics, 2007
131회 인용 관련 학술자료 전체 18개의 버전",Artificial Intelligence and Statistics,,,,,,,
The pascal visual object classes challenge 2007 (voc 2007) results (2007),"Mark Everingham, L Van Gool, Christopher KI Williams, John Winn, Andrew Zisserman",2008,,,,,,,121회,"The pascal visual object classes challenge 2007 (voc 2007) results (2007)
M Everingham, L Van Gool, CKI Williams, J Winn… - 2008
121회 인용 관련 학술자료",,,,,,,,
Factorial switching linear dynamical systems applied to physiological condition monitoring,"John A Quinn, Christopher KI Williams, Neil McIntosh",2008/8/1,IEEE Transactions on Pattern Analysis and Machine Intelligence,31,9,1537-1551,IEEE,"Condition monitoring often involves the analysis of systems with hidden factors that switch between different modes of operation in some way. Given a sequence of observations, the task is to infer the filtering distribution of the switch setting at each time step. In this paper, we present factorial switching linear dynamical systems as a general framework for handling such problems. We show how domain knowledge and learning can be successfully combined in this framework, and introduce a new factor (the ldquoX-factorrdquo) for dealing with unmodeled variation. We demonstrate the flexibility of this type of model by applying it to the problem of monitoring the condition of a premature baby receiving intensive care. The state of health of a baby cannot be observed directly, but different underlying factors are associated with particular patterns of physiological measurements and artifacts. We have explicit knowledge of …",116회,"Factorial switching linear dynamical systems applied to physiological condition monitoring
JA Quinn, CKI Williams, N McIntosh - IEEE Transactions on Pattern Analysis and Machine …, 2008
116회 인용 관련 학술자료 전체 22개의 버전",,,,,,,,
Gaussian regression and optimal finite dimensional linear models,"Huaiyu Zhu, Christopher KI Williams, Richard Rohwer, Michal Morciniec",1997/7/3,,,,,Aston University,"The problem of regression under Gaussian assumptions is treated generally. The relationship between Bayesian prediction, regularization and smoothing is elucidated. The ideal regression is the posterior mean and its computation scales as O(n3), where n is the sample size. We show that the optimal m-dimensional linear model under a given prior is spanned by the first m eigenfunctions of a covariance operator, which is a trace-class operator. This is an infinite dimensional analogue of principal component analysis. The importance of Hilbert space methods to practical statistics is also discussed.",114회,"Gaussian regression and optimal finite dimensional linear models
H Zhu, CKI Williams, R Rohwer, M Morciniec - 1997
114회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
Multi-task gaussian process learning of robot inverse dynamics,"Kian Ming Chai, Stefan Klanke, Chris Williams, Sethu Vijayakumar",2008,,,,,,"The inverse dynamics problem for a robotic manipulator is to compute the torques needed at the joints to drive it along a given trajectory; it is beneficial to be able to learn this function for adaptive control. A robotic manipulator will often need to be controlled while holding different loads in its end effector, giving rise to a multi-task learning problem. By placing independent Gaussian process priors over the latent functions of the inverse dynamics, we obtain a multi-task Gaussian process prior for handling multiple loads, where the inter-task similarity depends on the underlying inertial parameters. Experiments demonstrate that this multi-task formulation is effective in sharing information among the various loads, and generally improves performance over either learning only on single tasks or pooling the data over all tasks.",113회,"Multi-task gaussian process learning of robot inverse dynamics
KM Chai, S Klanke, C Williams, S Vijayakumar - 2008
113회 인용 관련 학술자료 전체 18개의 버전",,,,,,,,
Learning to segment images using dynamic feature binding,"Michael C Mozer, Richard S Zemel, Marlene Behrmann, Christopher KI Williams",1992/9,Neural Computation,4,5,650-665,MIT Press,"Despite the fact that complex visual scenes contain multiple, overlapping objects, people perform object recognition with ease and accuracy. One operation that facilitates recognition is an early segmentation process in which features of objects are grouped and labeled according to which object they belong. Current computational systems that perform this operation are based on predefined grouping heuristics. We describe a system called MAGIC that learns how to group features based on a set of presegmented examples. In many cases, MAGIC discovers grouping heuristics similar to those previously proposed, but it also has the capability of finding nonintuitive structural regularities in images. Grouping is performed by a relaxation network that attempts to dynamically bind related features. Features transmit a complex-valued signal (amplitude and phase) to one another; binding can thus be represented by phase …",111회,"Learning to segment images using dynamic feature binding
MC Mozer, RS Zemel, M Behrmann, CKI Williams - Neural Computation, 1992
111회 인용 관련 학술자료 전체 23개의 버전",,,,,,,,
Gaussian processes for Bayesian classification via hybrid Monte Carlo,"David Barber, Christopher KI Williams",1997,Advances in neural information processing systems,,,340-346,MORGAN KAUFMANN PUBLISHERS,"The full Bayesian method for applying neural networks to a pre-diction problem is to set up the prior/hyperprior structure for the net and then perform the necessary integrals. However, these integrals are not tractable analytically, and Markov Chain Monte Carlo (MCMC) methods are slow, especially if the parameter space is high-dimensional. Using Gaussian processes we can approximate the weight space integral analytically, so that only a small number of hyperparameters need be integrated over by MCMC methods.",107회,"Gaussian processes for Bayesian classification via hybrid Monte Carlo
D Barber, CKI Williams - Advances in neural information processing systems, 1997
107회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
The pascal visual object classes challenge 2012 (voc2012) results (2012),"M Everingham, L Van Gool, CKI Williams, J Winn, A Zisserman",2011,URL http://www. pascal-network. org/challenges/VOC/voc2011/workshop/index. html,,,,,,104회,"The pascal visual object classes challenge 2012 (voc2012) results (2012)
M Everingham, L Van Gool, CKI Williams, J Winn… - URL http://www. pascal-network. org/challenges/VOC …, 2011
104회 인용 관련 학술자료",,,,,,,,
On a connection between kernel PCA and metric multidimensional scaling,Christopher KI Williams,2001,,,,675-681,,"In this paper we show that the kernel peA algorithm of Sch6lkopf et al (1998) can be interpreted as a form of metric multidimensional scaling (MDS) when the kernel function k (x, y) is isotropic, ie it depends only on Ilx-yll. This leads to a metric MDS algorithm where the desired configuration of points is found via the solution of an eigenproblem rather than through the iterative optimization of the stress objective function. The question of kernel choice is also discussed.",104회,"On a connection between kernel PCA and metric multidimensional scaling
CKI Williams - Advances in neural information processing systems, 2001
104회 인용 관련 학술자료 전체 7개의 버전",Advances in neural information processing systems,,,,,,,
Magnification factors for the GTM algorithm,"Christopher M Bishop, Markus Svensén, Christopher KI Williams",1997/1/1,,,,64-69,IET Digital Library,"The generative topographic mapping (GTM) algorithm of C.M. Bishop et al. (1996) has been introduced as a principled alternative to the self-organizing map (SOM). As well as avoiding a number of deficiencies in the SOM, the GTM algorithm has the key property that the smoothness properties of the model are decoupled from the reference vectors, and are described by a continuous mapping from a lower-dimensional latent space into the data space. Magnification factors, which are approximated by the difference between code-book vectors in SOMs, can therefore be evaluated for the GTM model as continuous functions of the latent variables using the techniques of differential geometry. They play an important role in data visualization by highlighting the boundaries between data clusters, and are illustrated here for both a toy data set, and a problem involving the identification of crab species from morphological data.",102회,"Magnification factors for the GTM algorithm
CM Bishop, M Svensén, CKI Williams - 1997
63회 인용 관련 학술자료 전체 16개의 버전
Magnification factors for the SOM and GTM algorithms*
CM Bishop, M Svens' en, CKI Williams - Proceedings 1997 Workshop on Self-Organizing Maps, 1997
48회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
On the number of modes of a Gaussian mixture,"Miguel A Carreira-Perpinán, Christopher KI Williams",2003/6/10,,,,625-640,"Springer, Berlin, Heidelberg","We consider a problem intimately related to the creation of maxima under Gaussian blurring: the number of modes of a Gaussian mixture in D dimensions. To our knowledge, a general answer to this question is not known. We conjecture that if the components of the mixture have the same covariance matrix (or the same covariance matrix up to a scaling factor), then the number of modes cannot exceed the number of components. We demonstrate that the number of modes can exceed the number of components when the components are allowed to have arbitrary and different covariance matrices.
We will review related results from scale-space theory, statistics and machine learning, including a proof of the conjecture in 1D. We present a convergent, EM-like algorithm for mode finding and compare results of searching for all modes starting from the centers of the mixture components with a brute-force …",99회,"On the number of modes of a Gaussian mixture
MA Carreira-Perpinán, CKI Williams - International Conference on Scale-Space Theories in …, 2003
99회 인용 관련 학술자료 전체 24개의 버전",International Conference on Scale-Space Theories in Computer Vision,,,,,,,
Lending direction to neural networks,"Richard S Zemel, Christopher KI Williams, Michael C Mozer",1995/1/1,Neural Networks,8,4,503-512,Pergamon,"We present a general formulation for a network of stochastic directional units. This formulation is an extension of the Boltzmann machine in which the units are not binary, but take on values on a cyclic range, between 0 and 2π radians. This measure is appropriate to many domains, representing cyclic or angular values (e.g., wind direction, days of the week, phases of the moon). The state of each unit in a directional-unit Boltzmann machine (DUBM) is described by a complex variable, where the phase component specifies a direction; the weights are also complex variables. We associate a quadratic energy function, and corresponding probability, with each DUBM configuration. The probability distribution for the state of a given unit conditioned on the state of the rest of the network is a circular version of the Gaussian probability distribution, known as the von Mises distribution. In a mean-field approximation to a …",95회,"Lending direction to neural networks
RS Zemel, CKI Williams, MC Mozer - Neural Networks, 1995
95회 인용 관련 학술자료 전체 40개의 버전",,,,,,,,
Greedy learning of multiple objects in images using robust statistics and factorial learning,"Christopher KI Williams, Michalis K Titsias",2004/5/1,Neural Computation,16,5,1039-1062,MIT Press,"We consider data that are images containing views of multiple objects. Our task is to learn about each of the objects present in the images. This task can be approached as a factorial learning problem, where each image must be explained by instantiating a model for each of the objects present with the correct instantiation parameters. A major problem with learning a factorial model is that as the number of objects increases, there is a combinatorial explosion of the number of configurations that need to be considered. We develop a method to extract object models sequentially from the data by making use of a robust statistical method, thus avoiding the combinatorial explosion, and present results showing successful extraction of objects from real images.",91회,"Greedy learning of multiple objects in images using robust statistics and factorial learning
CKI Williams, MK Titsias - Neural Computation, 2004
91회 인용 관련 학술자료 전체 17개의 버전",,,,,,,,
Pascal visual object classes challenge results,"Mark Everingham, Luc Van Gool, Chris Williams, J Winn, A Zisserman",2005/4/5,Available from www. pascal-network. org,1,6,7,,"The goal of this challenge is to recognize objects from a number of visual object classes in images of realistic scenes. It is fundamentally a supervised learning learning problem in that a training set of labelled images is provided. The object classes are: motorbikes, bicycles, people and cars. Twelve participants entered the challenge. A full description of the challenge including software and image sets is available on the web page http://www. pascal-network. org/challenges/VOC/voc/index. html.",87회,"Pascal visual object classes challenge results
M Everingham, L Van Gool, C Williams, J Winn… - Available from www. pascal-network. org, 2005
87회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
A MCMC approach to hierarchical mixture modelling,Christopher KI Williams,2000,,,,680-686,,"There are many hierarchical clustering algorithms available, but these lack a firm statistical basis. Here we set up a hierarchical probabilistic mixture model, where data is generated in a hierarchical tree-structured manner. Markov chain Monte Carlo (MCMC) methods are demonstrated which can be used to sample from the posterior distribution over trees containing variable numbers of hidden units.",83회,"A MCMC approach to hierarchical mixture modelling
CKI Williams - Advances in Neural Information Processing Systems, 2000
83회 인용 관련 학술자료 전체 9개의 버전",Advances in Neural Information Processing Systems,,,,,,,
Visual boundary prediction: A deep neural prediction network and quality dissection,"Jyri Kivinen, Chris Williams, Nicolas Heess",2014/4/2,,,,512-521,PMLR,"This paper investigates visual boundary detection, ie prediction of the presence of a boundary at a given image location. We develop a novel neurally-inspired deep architecture for the task. Notable aspects of our work are (i) the use of “covariance features”[Ranzato and Hinton, 2010] which depend on the\emphsquared response of a filter to the input image, and (ii) the integration of image information from multiple scales and semantic levels via multiple streams of interlinked, layered, and non-linear “deep” processing. Our results on the Berkeley Segmentation Data Set 500 (BSDS500) show comparable or better performance to the top-performing methods [Arbelaez et al., 2011, Ren and Bo, 2012, Lim et al., 2013, Dollár and Zitnick, 2013] with effective inference times. We also propose novel quantitative assessment techniques for improved method understanding and comparison. We carefully dissect the performance of our architecture, feature-types used and training methods, providing clear signals for model understanding and development.",81회,"Visual boundary prediction: A deep neural prediction network and quality dissection
J Kivinen, C Williams, N Heess - Artificial Intelligence and Statistics, 2014
81회 인용 관련 학술자료 전체 11개의 버전",Artificial Intelligence and Statistics,,,,,,,
The pascal visual object classes challenge 2009 (VOC2009),"Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, Andrew Zisserman",2009,Summary presentation at the 2009 PASCAL VOC workshop,10,,,,,79회,"The pascal visual object classes challenge 2009 (VOC2009)
M Everingham, L Van Gool, CKI Williams, J Winn… - Summary presentation at the 2009 PASCAL VOC …, 2009
79회 인용 관련 학술자료",,,,,,,,
The shape variational autoencoder: A deep generative model of part‐segmented 3D objects,"Charlie Nash, Christopher KI Williams",2017/8,Computer Graphics Forum,36,5,1-12,,"We introduce a generative model of part‐segmented 3D objects: the shape variational auto‐encoder (ShapeVAE). The ShapeVAE describes a joint distribution over the existence of object parts, the locations of a dense set of surface points, and over surface normals associated with these points. Our model makes use of a deep encoder‐decoder architecture that leverages the part‐decomposability of 3D objects to embed high‐dimensional shape representations and sample novel instances. Given an input collection of part‐segmented objects with dense point correspondences the ShapeVAE is capable of synthesizing novel, realistic shapes, and by performing conditional inference enables imputation of missing parts or surface normals. In addition, by generating both points and surface normals, our model allows for the use of powerful surface‐reconstruction methods for mesh synthesis. We provide a quantitative …",75회,"The shape variational autoencoder: A deep generative model of part‐segmented 3D objects
C Nash, CKI Williams - Computer Graphics Forum, 2017
75회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
A generative model for parts-based object segmentation,"S Eslami, Christopher Williams",2012,Advances in Neural Information Processing Systems,25,,100-107,,"The Shape Boltzmann Machine (SBM)[1] has recently been introduced as a stateof-the-art model of foreground/background object shape. We extend the SBM to account for the foreground object’s parts. Our new model, the Multinomial SBM (MSBM), can capture both local and global statistics of part shapes accurately. We combine the MSBM with an appearance model to form a fully generative model of images of objects. Parts-based object segmentations are obtained simply by performing probabilistic inference in the model. We apply the model to two challenging datasets which exhibit significant shape and appearance variability, and find that it obtains results that are comparable to the state-of-the-art.
There has been significant focus in computer vision on object recognition and detection eg [2], but a strong desire remains to obtain richer descriptions of objects than just their bounding boxes. One such description is a parts-based object segmentation, in which an image is partitioned into multiple sets of pixels, each belonging to either a part of the object of interest, or its background.",71회,"A generative model for parts-based object segmentation
S Eslami, C Williams - Advances in Neural Information Processing Systems, 2012
71회 인용 관련 학술자료 전체 31개의 버전",,,,,,,,
Autoregressive hidden Markov models for the early detection of neonatal sepsis,"Ioan Stanculescu, Christopher KI Williams, Yvonne Freer",2013/12/11,IEEE journal of biomedical and health informatics,18,5,1560-1570,IEEE,Late onset neonatal sepsis is one of the major clinical concerns when premature babies receive intensive care. Current practice relies on slow laboratory testing of blood cultures for diagnosis. A valuable research question is whether sepsis can be reliably detected before the blood sample is taken. This paper investigates the extent to which physiological events observed in the patient's monitoring traces could be used for the early detection of neonatal sepsis. We model the distribution of these events with an autoregressive hidden Markov model (AR-HMM). Both learning and inference carefully use domain knowledge to extract the baby's true physiology from the monitoring data. Our model can produce real-time predictions about the onset of the infection and also handles missing data. We evaluate the effectiveness of the AR-HMM for sepsis detection on a dataset collected from the Neonatal Intensive Care Unit at …,70회,"Autoregressive hidden Markov models for the early detection of neonatal sepsis
I Stanculescu, CKI Williams, Y Freer - IEEE journal of biomedical and health informatics, 2013
70회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
Mean field networks that learn to discriminate temporally distorted strings,"Christopher KI Williams, Geoffrey E Hinton",1991/1/1,,,,18-22,Morgan Kaufmann,"Neural networks can be used to discriminate between very similar phonemes and they can handle the variability in time of occurrence by using a time-delay architecture followed by a temporal integration (Lang, Hinton and Waibel, 1990). So far, however, neural networks have been less successful at handling longer duration events that require something equivalent to “time warping” in order to match stored knowledge to the data. We present a type of mean field network (MFN) with tied weights that is capable of approximating the recognizer for a hidden markov model (HMM). In the process of settling to a stable state, the MFN finds a blend of likely ways of generating the input string given its internal model of the probabilities of transitions between hidden states and the probabilities of input symbols given a hidden state. This blend is a heuristic approximation to the full set of path probabilities that is implicitly …",63회,"Mean field networks that learn to discriminate temporally distorted strings
CKI Williams, GE Hinton - Connectionist Models, 1991
63회 인용 관련 학술자료 전체 9개의 버전",,Connectionist Models,,,,,,
Image modeling with position-encoding dynamic trees,"AJ Storkey, CKI Williams",2003/7,"Pattern Analysis and Machine Intelligence, IEEE Transactions on",25,7,859-871,IEEE,"This paper describes the position-encoding dynamic tree (PEDT). The PEDT is a probabilistic model for images that improves on the dynamic tree by allowing the positions of objects to play a part in the model. This increases the flexibility of the model over the dynamic tree and allows the positions of objects to be located and manipulated. This paper motivates and defines this form of probabilistic model using the belief network formalism. A structured variational approach for inference and learning in the PEDT is developed, and the resulting variational updates are obtained, along with additional implementation considerations that ensure the computational cost scales linearly in the number of nodes of the belief network. The PEDT model is demonstrated and compared with the dynamic tree and fixed tree. The structured variational learning method is compared with mean field approaches.",61회,"Image modeling with position-encoding dynamic trees
AJ Slorkey, CKL Williams - IEEE Transactions on Pattern Analysis and Machine …, 2003
61회 인용 관련 학술자료 전체 19개의 버전",,,,,,,,
"Gaussian processes for machine learning, vol. 2, no. 3","CK Williams, Carl Edward Rasmussen",2006,,,,4,"Cambridge, MA, USA: MIT Press",,57회,"Gaussian processes for machine learning, vol. 2, no. 3
CK Williams, CE Rasmussen - 2006
57회 인용 관련 학술자료",,,,,,,,
Products of Gaussians and probabilistic minor component analysis,"Christopher KI Williams, Felix V Agakov",2002/5/1,Neural Computation,14,5,1169-1182,MIT Press,"Recently, Hinton introduced the products of experts architecture for density estimation, where individual expert probabilities are multiplied and renormalized. We consider products of gaussian “pancakes” equally elongated in all directions except one and prove that the maximum likelihood solution for the model gives rise to a minor component analysis solution. We also discuss the covariance structure of sums and products of gaussian pancakes or one-factor probabilistic principal component analysis models.",57회,"Products of Gaussians and probabilistic minor component analysis
CKI Williams, FV Agakov - Neural Computation, 2002
57회 인용 관련 학술자료 전체 15개의 버전",,,,,,,,
Learning kernel classifiers,Christopher K I Williams,2003/6/1,,98,462,489-490,Taylor & Francis,"Over the last 5 years or so, a major area of research activity in the machinelearning research community has been that of kernel machines. The best-known example of these is the support vector machine (SVM), derived from the work of Vladimir Vapnik and coworkers. Although some statisticians are active members of this research community, many are not, thus I start this review by outlining some of the basic ideas of kernel machines, and relating them to more familiar ideas from the statistical literature, before going on to consider the specifi c merits of the two books.
The basic idea behind kernel methods is that we start with an input pattern x and rerepresent it in a feature space as Á. x/. A simple example of this would be a polynomial feature space in which a two-dimensional input pattern x D. x1; x2/T would be represented under a quadratic polynomial transformation as Á. x/D. x2 1; x2 2; p2x1x2/T. The key idea …",56회,"Learning kernel classifiers
CKI Williams - 2003
56회 인용 관련 학술자료 전체 8개의 버전",,,Journal of the American Statistical Association,,,,,
Upper and lower bounds on the learning curve for Gaussian processes,"Christopher KI Williams, Francesco Vivarelli",2000/7,Machine Learning,40,1,77-102,Kluwer Academic Publishers,"In this paper we introduce and illustrate non-trivial upper and lower bounds on the learning curves for one-dimensional Guassian Processes. The analysis is carried out emphasising the effects induced on the bounds by the smoothness of the random process described by the Modified Bessel and the Squared Exponential covariance functions. We present an explanation of the early, linearly-decreasing behavior of the learning curves and the bounds as well as a study of the asymptotic behavior of the curves. The effects of the noise level and the lengthscale on the tightness of the bounds are also discussed.",56회,"Upper and lower bounds on the learning curve for Gaussian processes
CKI Williams, F Vivarelli - Machine Learning, 2000
56회 인용 관련 학술자료 전체 17개의 버전",,,,,,,,
Transformation equivariant boltzmann machines,"Jyri J Kivinen, Christopher KI Williams",2011/6/14,,,,1-9,"Springer, Berlin, Heidelberg","We develop a novel modeling framework for Boltzmann machines, augmenting each hidden unit with a latent transformation assignment variable which describes the selection of the transformed view of the canonical connection weights associated with the unit. This enables the inferences of the model to transform in response to transformed input data in a stable and predictable way, and avoids learning multiple features differing only with respect to the set of transformations. Extending prior work on translation equivariant (convolutional) models, we develop translation and rotation equivariant restricted Boltzmann machines (RBMs) and deep belief nets (DBNs), and demonstrate their effectiveness in learning frequently occurring statistical structure from artificial and natural images.",55회,"Transformation equivariant boltzmann machines
JJ Kivinen, CKI Williams - International Conference on Artificial Neural Networks, 2011
55회 인용 관련 학술자료 전체 9개의 버전",International Conference on Artificial Neural Networks,,,,,,,
Known unknowns: Novelty detection in condition monitoring,"John A Quinn, Christopher KI Williams",2007/6/6,,,,1-6,"Springer, Berlin, Heidelberg","In time-series analysis it is often assumed that observed data can be modelled as being derived from a number of regimes of dynamics, as e.g. in a Switching Kalman Filter (SKF) [8,2]. However, it may not be possible to model all of the regimes, and in this case it can be useful to represent explicitly a ‘novel’ regime. We apply this idea to the Factorial Switching Kalman Filter (FSKF) by introducing an extra factor (the ‘X-factor’) to account for the unmodelled variation. We apply our method to physiological monitoring data from premature infants receiving intensive care, and demonstrate that the model is effective in detecting abnormal sequences of observations that are not modelled by the known regimes.",54회,"Known unknowns: Novelty detection in condition monitoring
JA Quinn, CKI Williams - Iberian Conference on Pattern Recognition and Image …, 2007
54회 인용 관련 학술자료 전체 12개의 버전",Iberian Conference on Pattern Recognition and Image Analysis,,,,,,,
Factorial switching Kalman filters for condition monitoring in neonatal intensive care,"Christopher Williams, John Quinn, Neil McIntosh",2006/1,,,,,MIT Press,"The observed physiological dynamics of an infant receiving intensive care are affected by many possible factors, including interventions to the baby, the operation of the monitoring equipment and the state of health. The Factorial Switching Kalman Filter can be used to infer the presence of such factors from a sequence of observations, and to estimate the true values where these observations have been corrupted. We apply this model to clinical time series data and show it to be effective in identifying a number of artifactual and physiological patterns.",54회,"Factorial switching Kalman filters for condition monitoring in neonatal intensive care
C Williams, J Quinn, N McIntosh - 2006
54회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
Greedy learning of binary latent trees,"Stefan Harmeling, Chris Williams",2010/3,"Pattern Analysis and Machine Intelligence, IEEE Transactions on",,99,1-1,IEEE,"Inferring latent structures from observations helps to model and possibly also understand underlying data generating processes. A rich class of latent structures is the latent trees, i.e., tree-structured distributions involving latent variables where the visible variables are leaves. These are also called hierarchical latent class (HLC) models. Zhang and Kočka [CHECK END OF SENTENCE] proposed a search algorithm for learning such models in the spirit of Bayesian network structure learning. While such an approach can find good solutions, it can be computationally expensive. As an alternative, we investigate two greedy procedures: The BIN-G algorithm determines both the structure of the tree and the cardinality of the latent variables in a bottom-up fashion. The BIN-A algorithm first determines the tree structure using agglomerative hierarchical clustering, and then determines the cardinality of the latent variables as …",53회,"Greedy learning of binary latent trees
S Harmeling, CKI Williams - IEEE Transactions on Pattern Analysis and Machine …, 2010
53회 인용 관련 학술자료 전체 19개의 버전",,,,,,,,
DTs: dynamic trees,"Christopher KI Williams, Nicholas J Adams",1999/7/20,Advances in neural information processing systems,,,634-640,MIT; 1998,"In this paper we introduce a new class of image models, which we call dynamic trees or DTs. A dynamic tree model specifies a prior over a large number of trees, each one of which is a tree-structured belief net (TSBN). Experiments show that DTs are capable of generating images that are less blocky, and the models have better translation invariance properties than a fixed,"" balanced"" TSBN. We also show that Simulated Annealing is effective at finding trees which have high posterior probability.",50회,"DTs: dynamic trees
CKI Williams, NJ Adams - Advances in neural information processing systems, 1999
50회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Observations on the Nyström method for Gaussian process prediction,"Christopher KI Williams, Carl Edward Rasmussen, A Scwaighofer, Volker Tresp",2002/1,,,,,University of Edinburgh,"A number of methods for speeding up Gaussian Process (GP) prediction have been proposed, including the Nyström method of Williams and Seeger (2001). In this paper we focus on two issues (1) the relationship of the Nyström method to the Subset of Regressors method (Poggio and Girosi 1990; Luo and Wahba, 1997) and (2) understanding in what circumstances the Nyström approximation would be expected to provide a good approximation to exact GP regression.",49회,"Observations on the Nyström method for Gaussian process prediction
CKI Williams, CE Rasmussen, A Scwaighofer, V Tresp - 2002
49회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Multiple texture Boltzmann machines,"Jyri Kivinen, Christopher Williams",2012/3/21,,,,638-646,PMLR,"We assess the generative power of the mPoT-model of [10] with tiled-convolutional weight sharing as a model for visual textures by specifically training on this task, evaluating model performance on texture synthesis and inpainting tasks using quantitative metrics. We also analyze the relative importance of the mean and covariance parts of the mPoT model by comparing its performance to those of its subcomponents, tiled-convolutional versions of the PoT/FoE and Gaussian-Bernoulli restricted Boltzmann machine (GB-RBM). Our results suggest that while state-of-the-art or better performance can be achieved using the mPoT, similar performance can be achieved with the mean-only model. We then develop a model for multiple textures based on the GB-RBM, using a shared set of weights but texture-specific hidden unit biases. We show comparable performance of the multiple texture model to individually trained texture models.",47회,"Multiple texture Boltzmann machines
J Kivinen, C Williams - Artificial Intelligence and Statistics, 2012
47회 인용 관련 학술자료 전체 11개의 버전",Artificial Intelligence and Statistics,,,,,,,
Discovering hidden features with Gaussian processes regression,"Francesco Vivarelli, Christopher KI Williams",1999,,,,613-619,,"In Gaussian process regression the covariance between the outputs at input locations x and x is usually assumed to depend on the distance (x− x) T W (x− x), where W is a positive definite matrix. W is often taken to be diagonal, but if we allow W to be a general positive definite matrix which can be tuned on the basis of training data, then an eigen-analysis of W shows that we are effectively creating hidden features, where the dimensionality of the hidden-feature space is determined by the data. We demonstrate the superiority of predictions using the general matrix over those based on a diagonal matrix on two test problems.",47회,"Discovering hidden features with Gaussian processes regression
F Vivarelli, CKI Williams - Advances in Neural Information Processing Systems, 1999
47회 인용 관련 학술자료 전체 5개의 버전",Advances in Neural Information Processing Systems,,,,,,,
Biblical scholarship and the church: A sixteenth-century crisis of authority,"Allan K Jenkins, Patrick Preston",2016/4/15,,,,,Routledge,"Conflicting claims to authority in relation to the translation and interpretation of the Bible have been a recurrent source of tension within the Christian church, and were a key issue in the Reformation debate. This book traces how the authority of the Septuagint and later that of the Vulgate was called into question by the return to the original languages of scripture, and how linguistic scholarship was seen to pose a challenge to the authority of the teaching and tradition of the church. It shows how issues that remained unresolved in the early church re-emerged in first half of the sixteenth century with the publication of Erasmus’ Greek-Latin New Testament of 1516. After examining the differences between Erasmus and his critics, the authors contrast the situation in England, where Reformation issues were dominant, and Italy, where the authority of Rome was never in question. Focusing particularly on the dispute between Thomas More and William Tyndale in England, and between Ambrosius Catharinus and Cardinal Cajetan in Italy, this book brings together perspectives from biblical studies and church history and provides access to texts not previously translated into English.",44회,"Biblical scholarship and the church: A sixteenth-century crisis of authority
AK Jenkins, P Preston - 2016
44회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
EM optimization of latent-variable density models,"Christopher Bishop, Markus Svensén, Christopher Williams",1995,Advances in neural information processing systems,8,,465-471,,"There is currently considerable interest in developing general nonlinear density models based on latent, or hidden, variables. Such models have the ability to discover the presence of a relatively small number of underlying'causes' which, acting in combination, give rise to the apparent complexity of the observed data set. Unfortunately, to train such models generally requires large computational effort. In this paper we introduce a novel latent variable algorithm which retains the general non-linear capabilities of previous models but which uses a training procedure based on the EM algorithm. We demonstrate the performance of the model on a toy problem and on data from flow diagnostics for a multi-phase oil pipeline.",44회,"EM optimization of latent-variable density models
C Bishop, M Svensén, C Williams - Advances in neural information processing systems, 1995
44회 인용 관련 학술자료 전체 15개의 버전",,,,,,,,
Using the equivalent kernel to understand Gaussian process regression,"Peter Sollich, Christopher Williams",2005,,,,1313-1320,,"The equivalent kernel [1] is a way of understanding how Gaussian process regression works for large sample sizes based on a continuum limit. In this paper we show (1) how to approximate the equivalent kernel of the widely-used squared exponential (or Gaussian) kernel and related kernels, and (2) how analysis using the equivalent kernel helps to understand the learning curves for Gaussian processes.",43회,"Using the equivalent kernel to understand Gaussian process regression
P Sollich, C Williams - Advances in Neural Information Processing Systems, 2005
43회 인용 관련 학술자료 전체 15개의 버전",Advances in Neural Information Processing Systems,,,,,,,
Finite-dimensional approximation of Gaussian processes,"Giancarlo Ferrari Trecate, Christopher KI Williams, Manfred Opper",1999/7/20,Proceedings of the 1998 conference on Advances in neural information processing systems II,,,218-224,,"Gaussian process (GP) prediction suffers from O (n3) scaling with the data set size n. By using a finite-dimensional basis to approximate the GP predictor, the computational complexity can be reduced. We derive optimal finite-dimensional predictors under a number of assumptions, and show the superiority of these predictors over the Projected Bayes Regression method (which is asymptotically optimal). We also show how to calculate the minimal model size for a given n. The calculations are backed up by numerical experiments.",43회,"Finite-dimensional approximation of Gaussian processes
GF Trecate, CKI Williams, M Opper - Proceedings of the 1998 conference on Advances in …, 1999
43회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
On the relationship between Bayesian error bars and the input data density,"CKI Williams, C Qazaz, Christopher M Bishop, H Zhu",1995/1/1,,,,160-165,IET Digital Library,"We investigate the dependence of Bayesian error bars on the distribution of data in input space. For generalized linear regression models we derive an upper bound on the error bars which shows that, in the neighbourhood of the data points, the error bars are substantially reduced from their prior values. For regions of high data density we also show that the contribution to the output variance due to the uncertainty in the weights can exhibit an approximate inverse proportionality to the probability density. Empirical results support these conclusions.",41회,"On the relationship between Bayesian error bars and the input data density
CKI Williams, C Qazaz, CM Bishop, H Zhu - 1995
41회 인용 관련 학술자료 전체 18개의 버전",,,,,,,,
Gaussian processes for machine learning (Internet ed.). Adaptive computation and machine learning,"C Rasmussen, C Williams",2006,,,,266,"Cambridge, Massachusetts: MIT Press",,39회,"Gaussian processes for machine learning (Internet ed.). Adaptive computation and machine learning
C Rasmussen, C Williams - 2006
20회 인용 관련 학술자료
Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning) The MIT Press
CE Rasmussen, CKI Williams - Cambridge, MA, USA, 2005
19회 인용 관련 학술자료",,,,,,,,
Regression with Gaussian processes,Christopher KI Williams,1997,,,,378-382,"Springer, Boston, MA","The Bayesian analysis of neural networks is difficult because the prior over functions has a complex form, leading to implementations that either make approximations or use Monte Carlo integration techniques. In this paper I investigate the use of Gaussian process priors over functions, which permit the predictive Bayesian analysis to be carried out exactly using matrix operations. The method has been tested on two challenging problems and has produced excellent results.",38회,"Regression with Gaussian processes
CKI Williams - Mathematics of Neural Networks, 1997
38회 인용 관련 학술자료 전체 16개의 버전",,Mathematics of Neural Networks,,,,,,
Learning Generative Texture Models with extended Fields-of-Experts.,"Nicolas Heess, Christopher KI Williams, Geoffrey E Hinton",2009/9/7,,,,1-11,,"We evaluate the ability of the popular Field-of-Experts (FoE) to model structure in images. As a test case we focus on modeling synthetic and natural textures. We find that even for modeling single textures, the FoE provides insufficient flexibility to learn good generative models–it does not perform any better than the much simpler Gaussian FoE. We propose an extended version of the FoE (allowing for bimodal potentials) and demonstrate that this novel formulation, when trained with a better approximation of the likelihood gradient, gives rise to a more powerful generative model of specific visual structure that produces significantly better results for the texture task.",37회,"Learning Generative Texture Models with extended Fields-of-Experts.
N Heess, CKI Williams, GE Hinton - BMVC, 2009
37회 인용 관련 학술자료 전체 19개의 버전",BMVC,,,,,,,
"Safety and efficacy of fluoxetine on functional outcome after acute stroke (AFFINITY): a randomised, double-blind, placebo-controlled trial","Graeme J Hankey, Maree L Hackett, Osvaldo P Almeida, Leon Flicker, Gillian E Mead, Martin S Dennis, Christopher Etherton-Beer, Andrew H Ford, Laurent Billot, Stephen Jan, Thomas Lung, Veronica Murray, Erik Lundström, Craig S Anderson, Robert Herbert, Gregory Carter, Geoffrey A Donnan, Huy-Thang Nguyen, John Gommans, Qilong Yi, Qiang Li, Severine Bompoint, Sarah Barrett, Anne Claxton, Julia O'Dea, Michelle Tang, Clare Williams, Shenae Peterson, Christie Drummond, Uyen-Ha Hong, Linh-Thi My Le, Tram-Thi Bich Ngo, Yen-Bao Mai, Huyen-Thanh Han, Nhu-Quynh Truong, Huong-Thi Nguyen, Hai-Thanh Ngo, Thi Binh Nguyen, Oanh-Thi Kieu Ha, Richard I Lindley, Peter New, Andrew Lee, Thanh-Trung Tran, Loan-Tran Truc Mai Le, Sang-Van Nguyen, Thuy-Anh Diem Nguyen, Tam-Nhat Dang, Hanh-Thi Truc Phan, Loan-Thi Ngoc Vo, Mai-Hue Nguyen, Hanh-Cao Dang, Hong-Thi Tran, Linh-Thi Cam Dam, Trinh-Thi Kim Ngo, Thai-Nguyen Thanh Pham, Binh-Nguyen Pham, Nha-Thi Thanh Dao, Huong-Thi Bich Nguyen, Linh-Thi Cam Le, Chi-Minh Do, Huy-Quoc Huynh, Giau-Thi Kim Tran, Oanh-Thi Le, Ly-Thi Khanh Tran, Chinh-Dinh Duong, Duong-Van Kieu, Na Le, Hoa-Ngoc Nguyen, Binh-Van Le, Long-Thanh Nguyen, Long-Van Nguyen, Tuan-Quoc Dinh, Tan-Van Vo, Tram-Ngoc Bui, Uyen-Thi To Hoang, Hien-Thi Bich Nguyen, Ha-Thi Thu Nguyen, Nga-Thuy Lam, Khanh-Kim Le, Phuong-Thanh Trinh, Hop-Quang Huynh, Thao-Thi Thu Nguyen, Huyen-Ngoc Lu, Tham-Hong Pham, Sam-Hoanh Nguyen, Ninh-Hong Le, Giang-Truong Nguyen, Bich-Thi Doan, Sung-Phuoc Pham, Duong-Huu Luong, Ha-Van Mai, Thuc-Van Tran, Phuong-Thi Do, Hoai-Thi Le, Chi-Van Nguyen, Phuong-Doan Nguyen, Ton-Duy Mai, Phuong-Viet Dao, Dung-Tien Nguyen, Dai-Quoc Khuong, Trung-Xuan Vuong, Lan-Tuong Vu, Ngoc-Duc Ngo, Hanh-Hong Dang, Phuong-Thai Truong, Ngan-Thi Le, Hoa-Van Hoang, Chung-Quang Do, Minh-Thao Nguyen, Anh-Hai Dam, Quynh-Nhu Le, Ngoc-Hoang Nguyen, Tuyen-Van Nguyen, Toan-Dinh Le, Ha-Thi Hai Dinh, Cuong-Van Pham, Khanh-Thi Ngoc Thach, Linh-Hai Nguyen, Loan-Thi Nguyen, Vien-Chi Le, Phuong-Hong Tran, Tai-Anh Nguyen, Tuan-Van Le, Luyen-Van Truong, Tue-Chau Bui, Ngoc-Xuan Huynh, Lap-Van Dinh, An-Gia Pham, Trang-Thi Huyen Le, Vy-Tuong Nguyen, Yen-Hai Nguyen, Thang-Ba Nguyen, Huy Thai, Quyen-Thi Ngoc Pham, Khoa-Duy Dao, Quoc-Nguyen Bao Pham, Thuong-Thi Huyen Dang, Huong-Huynh To Dinh, Trang-Mai Tong, Thuy-Thi Vu, Si-Tri Le, Tai-Ngoc Tran, Phuong-Hoai Tran, Ngoc-Thuy Nhu Dinh, Binh-Thanh Nguyen, Vinh-Phuong Do, Anh-Ngoc Nguyen, Binh-Thi Thanh Nguyen, David Blacker, Lindsey Bunce",2020/8/1,The Lancet Neurology,19,8,651-660,Elsevier,"Background
Trials of fluoxetine for recovery after stroke report conflicting results. The Assessment oF FluoxetINe In sTroke recoverY (AFFINITY) trial aimed to show if daily oral fluoxetine for 6 months after stroke improves functional outcome in an ethnically diverse population.
Methods
AFFINITY was a randomised, parallel-group, double-blind, placebo-controlled trial done in 43 hospital stroke units in Australia (n=29), New Zealand (four), and Vietnam (ten). Eligible patients were adults (aged ≥18 years) with a clinical diagnosis of acute stroke in the previous 2–15 days, brain imaging consistent with ischaemic or haemorrhagic stroke, and a persisting neurological deficit that produced a modified Rankin Scale (mRS) score of 1 or more. Patients were randomly assigned 1:1 via a web-based system using a minimisation algorithm to once daily, oral fluoxetine 20 mg capsules or matching placebo for 6 months. Patients …",35회,"Safety and efficacy of fluoxetine on functional outcome after acute stroke (AFFINITY): a randomised, double-blind, placebo-controlled trial
GJ Hankey, ML Hackett, OP Almeida, L Flicker… - The Lancet Neurology, 2020
35회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
Vision-as-inverse-graphics: Obtaining a rich 3d explanation of a scene from a single image,"Lukasz Romaszko, Christopher KI Williams, Pol Moreno, Pushmeet Kohli",2017,,,,851-859,,"We develop an inverse graphics approach to the problem of scene understanding, obtaining a rich representation that includes descriptions of the objects in the scene and their spatial layout, as well as global latent variables like the camera parameters and lighting. The framework's stages include object detection, the prediction of the camera and lighting variables, and prediction of object-specific variables (shape, appearance and pose). This acts like the encoder of an autoencoder, with graphics rendering as the decoder. Importantly the scene representation is interpretable and is of variable dimension to match the detected number of objects plus the global variables. For the prediction of the camera latent variables we introduce a novel architecture termed Probabilistic HoughNets (PHNs), which provides a principled approach to combining information from multiple detections. We demonstrate the quality of the reconstructions obtained quantitatively on synthetic data, and qualitatively on real scenes.",35회,"Vision-as-inverse-graphics: Obtaining a rich 3d explanation of a scene from a single image
L Romaszko, CKI Williams, P Moreno, P Kohli - Proceedings of the IEEE International Conference on …, 2017
35회 인용 관련 학술자료 전체 7개의 버전",Proceedings of the IEEE International Conference on Computer Vision Workshops,,,,,,,
Regression,"Carl Edward Rasmussen, Christopher KI Williams",2005,,,,7-31,MIT press,"This chapter contains sections titled: Weight-space View, Function-space View, Varying the Hyperparameters, Decision Theory for Regression, An Example Application, Smoothing, Weight Functions and Equivalent Kernels, Incorporating Explicit Basis Functions, History and Related Work, Exercises",35회,"Regression
CE Rasmussen, CKI Williams - 2005
35회 인용 관련 학술자료",,,,,,,,
An analysis of contrastive divergence learning in gaussian boltzmann machines,"Christopher KI Williams, Felix V Agakov",2002/5/17,Institute for Adaptive and Neural Computation,,,,,"The Boltzmann machine (BM) learning rule for random field models with latent variables can be problematic to use in practice. These problems have (at least partially) been attributed to the negative phase in BM learning where a Gibbs sampling chain should be run to equilibrium. Hinton (1999, 2000) has introduced an alternative called contrastive divergence (CD) learning where the chain is run for only 1 step. In this paper we analyse the mean and variance of the parameter update obtained after i steps of Gibbs sampling for a simple Gaussian BM. For this model our analysis shows that CD learning produces (as expected) a biased estimate of the true parameter update. We also show that the variance does usually increase with i and quantify this behaviour.",34회,"An analysis of contrastive divergence learning in gaussian boltzmann machines
CKI Williams, FV Agakov - Institute for Adaptive and Neural Computation, 2002
34회 인용 관련 학술자료 전체 14개의 버전",,,,,,,,
A Hierarchical Switching Linear Dynamical System Applied to the Detection of Sepsis in Neonatal Condition Monitoring.,"Ioan Stanculescu, Christopher KI Williams, Yvonne Freer",2014/7/23,UAI,14,,752-761,,"In this paper we develop a Hierarchical Switching Linear Dynamical System (HSLDS) for the detection of sepsis in neonates in an intensive care unit. The Factorial Switching LDS (FSLDS) of Quinn et al.(2009) is able to describe the observed vital signs data in terms of a number of discrete factors, which have either physiological or artifactual origin. In this paper we demonstrate that by adding a higher-level discrete variable with semantics sepsis/non-sepsis we can detect changes in the physiological factors that signal the presence of sepsis. We demonstrate that the performance of our model for the detection of sepsis is not statistically different from the auto-regressive HMM of Stanculescu et al.(2013), despite the fact that their model is given “ground truth” annotations of the physiological factors, while our HSLDS must infer them from the raw vital signs data.",33회,"A Hierarchical Switching Linear Dynamical System Applied to the Detection of Sepsis in Neonatal Condition Monitoring.
I Stanculescu, CKI Williams, Y Freer - UAI, 2014
33회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
The stability of kernel principal components analysis and its relation to the process eigenspectrum,"John Shawe-Taylor, Christopher KI Williams",2003,Advances in neural information processing systems,,,383-390,MIT; 1998,"In this paper we analyze the relationships between the eigenvalues of the mxm Gram matrix K for a kernel k (:,-) corresponding to a sample x1,..., Xm drawn from a density p (x) and the eigenvalues of the corresponding continuous eigenproblem. We bound the differences between the two spectra and provide a performance bound on kernel PCA.",33회,"The stability of kernel principal components analysis and its relation to the process eigenspectrum
J Shawe-Taylor, CKI Williams - Advances in neural information processing systems, 2003
33회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Extreme Components Analysis.,"Max Welling, Felix V Agakov, Christopher KI Williams",2003/1/1,,,,137-144,,"Principal components analysis (PCA) is one of the most widely used techniques in machine learning and data mining. Minor components analysis (MCA) is less well known, but can also play an important role in the presence of constraints on the data distribution. In this paper we present a probabilistic model for “extreme components analysis”(XCA) which at the maximum likelihood solution extracts an optimal combination of principal and minor components. For a given number of components, the log-likelihood of the XCA model is guaranteed to be larger or equal than that of the probabilistic models for PCA and MCA. We describe an efficient algorithm to solve for the globally optimal solution. For log-convex spectra we prove that the solution consists of principal components only, while for log-concave spectra the solution consists of minor components. In general, the solution admits a combination of both. In experiments we explore the properties of XCA on some synthetic and real-world datasets.",33회,"Extreme Components Analysis.
M Welling, FV Agakov, CKI Williams - NIPS, 2003
33회 인용 관련 학술자료 전체 17개의 버전",NIPS,,,,,,,
Cleaning sky survey data bases using hough transform and renewal string approaches,"AJ Storkey, NC Hambly, CKI Williams, Robert G Mann",2004/1/1,Monthly Notices of the Royal Astronomical Society,347,1,36-51,Blackwell Science Ltd,"Large astronomical data bases obtained from sky surveys such as the SuperCOSMOS Sky Survey (SSS) invariably suffer from spurious records coming from the artefactual effects of the telescope, satellites and junk objects in orbit around the Earth and physical defects on the photographic plate or CCD. Though relatively small in number, these spurious records present a significant problem in many situations, where they can become a large proportion of the records potentially of interest to a given astronomer. Accurate and robust techniques are needed for locating and flagging such spurious objects, and we are undertaking a programme investigating the use of machine learning techniques in this context. In this paper we focus on the four most common causes of unwanted records in the SSS: satellite or aeroplane tracks, scratches, fibres and other linear phenomena introduced to the plate, circular haloes …",32회,"Cleaning sky survey data bases using hough transform and renewal string approaches
AJ Storkey, NC Hambly, CKI Williams, RG Mann - Monthly Notices of the Royal Astronomical Society, 2004
32회 인용 관련 학술자료 전체 21개의 버전",,,,,,,,
Dynamic trees for image modelling,"Nicholas J Adams, Christopher KI Williams",2003/9/1,Image and Vision Computing,21,10,865-877,Elsevier,"This paper introduces a new class of image model which we call dynamic trees or DTs. A dynamic tree model specifies a prior over structures of trees, each of which is a forest of one or more tree-structured belief networks (TSBN). In the literature standard tree-structured belief network models have been found to produce ‘blocky’ segmentations when naturally occurring boundaries within an image did not coincide with those of the subtrees in the rigid fixed structure of the network. Dynamic trees have a flexible architecture which allows the structure to vary to create configurations where the subtree and image boundaries align, and experimentation with the model has shown significant improvements.
For large models the number of tree configurations quickly becomes intractable to enumerate over, presenting a problem for exact inference. Techniques such as Gibbs sampling over trees and search using simulated …",32회,"Dynamic trees for image modelling
NJ Adams, CKI Williams - Image and Vision Computing, 2003
32회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Gaussian processes,CKI Williams,2002/3/1,"handbook of Brain Theory and Neural Networks,",,,,,"Much of the work in the field of artificial neural networks concerns the problem of supervised learning. Here we may be interested in regression problems (by which we mean the prediction of some real-valued variable (s)), or classification problems (predicting a class label) given the values of some input variables. Due to factors such as measurement noise, it is necessary to take a statistical view of the learning problem. Given (possibly noisy) observations of a function at n points, it is necessary to impose extra assumptions about the function if there is to be hope of predicting its value elsewhere. Here we take a Bayesian approach, placing a prior probability distribution over possible functions and then letting the observed data"" sculpt"" this prior into a posterior using the available data. The Bayesian approach can provide solutions to several problems such as local optima in weight space, the setting of regularization parameters, overfitting and model selection (see MacKay 1992, Neal 1996 and BAYESIAN METHODS FOR SUPERVISED NEURAL NETWORKS). One can place a prior distribution P (w) on the weights w of a neural network to induce a prior over functions P (y (x; w)) but the computations required to make predictions are not easy due to the non-linearities in the system, and one needs to resort to analytic approximations or Monte Carlo methods. Gaussian processes are a way of specifying a prior directly over function space; it is often simpler to do this than to work with priors over parameters. Gaussian processes (GPs) are probably the simplest kind of function space prior that one can consider, being a generalization of …",31회,"Gaussian processes
CKI Williams - handbook of Brain Theory and Neural Networks,, 2002
31회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Comparing Bayesian neural network algorithms for classifying segmented outdoor images,"Francesco Vivarelli, Christopher KI Williams",2001/5/1,Neural Networks,14,4-5,427-437,Pergamon,"In this paper we investigate the Bayesian training of neural networks for region labelling of segmented outdoor scenes; the data are drawn from the Sowerby Image Database of British Aerospace. Neural networks are trained with two Bayesian methods, (i) the evidence framework of MacKay, 1992a, MacKay, 1992b and (ii) a Markov Chain Monte Carlo method due to Neal (1996). The performance of the two methods is compared to evaluating the empirical learning curves of neural networks trained with the two methods. We also investigate the use of the Automatic Relevance Determination method for input feature selection.",30회,"Comparing Bayesian neural network algorithms for classifying segmented outdoor images
F Vivarelli, CKI Williams - Neural Networks, 2001
30회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Understanding gaussian process regression using the equivalent kernel,"Peter Sollich, Christopher KI Williams",2004/9/7,,,,211-228,"Springer, Berlin, Heidelberg","The equivalent kernel [1] is a way of understanding how Gaussian process regression works for large sample sizes based on a continuum limit. In this paper we show how to approximate the equivalent kernel of the widely-used squared exponential (or Gaussian) kernel and related kernels. This is easiest for uniform input densities, but we also discuss the generalization to the non-uniform case. We show further that the equivalent kernel can be used to understand the learning curves for Gaussian processes, and investigate how kernel smoothing using the equivalent kernel compares to full Gaussian process regression.",28회,"Understanding gaussian process regression using the equivalent kernel
P Sollich, CKI Williams - International Workshop on Deterministic and Statistical …, 2004
28회 인용 관련 학술자료 전체 16개의 버전",International Workshop on Deterministic and Statistical Methods in Machine Learning,,,,,,,
Endoscopic sensing of alveolar pH,"Debaditya Choudhury, Michael George Tanner, Sarah McAughtrie, Fei Yu, Beth Mills, TR Choudhary, Sohan Seth, TH Craven, JM Stone, IK Mati, CJ Campbell, Mark Bradley, CKI Williams, Kevin Dhaliwal, TA Birks, Robert R Thomson",2017/1/1,Biomedical optics express,8,1,243-259,Optical Society of America,"Previously unobtainable measurements of alveolar pH were obtained using an endoscope-deployable optrode. The pH sensing was achieved using functionalized gold nanoshell sensors and surface enhanced Raman spectroscopy (SERS). The optrode consisted of an asymmetric dual-core optical fiber designed for spatially separating the optical pump delivery and signal collection, in order to circumvent the unwanted Raman signal generated within the fiber. Using this approach, we demonstrate a ~100-fold increase in SERS signal-to-fiber background ratio, and demonstrate multiple site pH sensing with a measurement accuracy of ± 0.07 pH units in the respiratory acini of an ex vivo ovine lung model. We also demonstrate that alveolar pH changes in response to ventilation.",27회,"Endoscopic sensing of alveolar pH
D Choudhury, MG Tanner, S McAughtrie, F Yu, B Mills… - Biomedical optics express, 2017
27회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Overcoming occlusion with inverse graphics,"Pol Moreno, Christopher KI Williams, Charlie Nash, Pushmeet Kohli",2016/10/8,,,,170-185,"Springer, Cham","Scene understanding tasks such as the prediction of object pose, shape, appearance and illumination are hampered by the occlusions often found in images. We propose a vision-as-inverse-graphics approach to handle these occlusions by making use of a graphics renderer in combination with a robust generative model (GM). Since searching over scene factors to obtain the best match for an image is very inefficient, we make use of a recognition model (RM) trained on synthetic data to initialize the search. This paper addresses two issues: (i) We study how the inferences are affected by the degree of occlusion of the foreground object, and show that a robust GM which includes an outlier model to account for occlusions works significantly better than a non-robust model. (ii) We characterize the performance of the RM and the gains that can be made by refining the search using the GM, using a new dataset …",27회,"Overcoming occlusion with inverse graphics
P Moreno, CKI Williams, C Nash, P Kohli - European Conference on Computer Vision, 2016
27회 인용 관련 학술자료 전체 5개의 버전",European Conference on Computer Vision,,,,,,,
A regularized discriminative model for the prediction of protein–peptide interactions,"Wolfgang P Lehrach, Dirk Husmeier, Christopher KI Williams",2006/3/1,Bioinformatics,22,5,532-540,Oxford University Press,"Motivation: Short well-defined domains known as peptide recognition modules (PRMs) regulate many important protein–protein interactions involved in the formation of macromolecular complexes and biochemical pathways. Since high-throughput experiments like yeast two-hybrid and phage display are expensive and intrinsically noisy, it would be desirable to more specifically target or partially bypass them with complementary in silico approaches. In the present paper, we present a probabilistic discriminative approach to predicting PRM-mediated protein–protein interactions from sequence data. The model is motivated by the discriminative model of Segal and Sharan as an alternative to the generative approach of Reiss and Schwikowski. In our evaluation, we focus on predicting the interaction network. As proposed by Williams, we overcome the problem of susceptibility to over-fitting by adopting a …",26회,"A regularized discriminative model for the prediction of protein–peptide interactions
WP Lehrach, D Husmeier, CKI Williams - Bioinformatics, 2006
26회 인용 관련 학술자료 전체 13개의 버전",,,,,,,,
Combining deformable models and neural networks for handprinted digit recognition,Christopher KI Williams,1994/11,,,,,,"This thesis describes a system which uses deformable models to classify handwritten digits, as found in ZIP codes. It achieves recognition rates comparable to the state of the art. Obtaining this level of performance has required working with large databases and the investigation of several variations on the basic system, and has required more person-years of research activity than mine alone. Prof. Geo rey Hinton has been an enthusiastic supervisor of the work, and I have also collaborated closely with Dr. Michael Revow on parts of the work described in this thesis. I am responsible for the research on half of the contributions itemized in section 6.2. 1, and have been involved collaboratively on the other half. iv",26회,"Combining deformable models and neural networks for handprinted digit recognition
CKI Williams - 1994
26회 인용 관련 학술자료 전체 27개의 버전",,,,"University of Toronto, Department of Computer Science",,,,
An isotropic Gaussian mixture can have more modes than components,"Miguel Á Carreira-Perpiñán, Christopher KI Williams",2003/12/1,Institute for Adaptive and Neural Computation,4,2,,,"Carreira-Perpinan and Williams (2003) conjectured that a homoscedastic Gaussian mixture of M components in d 1 dimensions has at most M modes. Prof. JJ Duistermaat (personal communication, 2003) provided the counterexample of a 3–component mixture in d= 2 where the Gaussians are located at the vertices of an equilateral triangle; for a certain range of variances modes are present near to the vertices and also at the centre of the triangle. In this paper we illustrate the nature of the counterexample and compute the range of variances for which there are more than 3 maxima. We also extend the construction to the regular simplex with M vertices and show that for M",24회,"An isotropic Gaussian mixture can have more modes than components
MÁ Carreira-Perpiñán, CKI Williams - Institute for Adaptive and Neural Computation, 2003
24회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
Modelling frontal discontinuities in wind fields,"Dan Cornford, Ian T Nabney, Christopher KI Williams",2002/1/1,Journal of nonparametric statistics,14,1-2,43-58,Taylor & Francis Group,"A Bayesian procedure for the retrieval of wind vectors over the ocean using satellite-borne scatterometers requires realistic prior near-surface wind field models over the oceans. We have implemented carefully chosen vector Gaussian Process models; however, in some cases these models are too smooth to reproduce real atmospheric features, such as fronts. At the scale of the scatterometer observations, fronts appear as discontinuities in wind direction. Due to the nature of the retrieval problem a simple discontinuity model is not feasible, and hence we have developed a constrained discontinuity vector Gaussian Process model which ensures realistic fronts. We describe the generative model and show how to compute the data likelihood given the model. We show the results of inference using the model with Markov Chain Monte Carlo methods on both synthetic and real data.",24회,"Modelling frontal discontinuities in wind fields
D Cornford, IT Nabney, CKI Williams - Journal of nonparametric statistics, 2002
24회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
Guilt in the classroom,Christopher Williams,1998/1/1,,,,233-243,Academic Press,"Publisher Summary
Traditionally, guilt is viewed as a source of psychopathology. This chapter summarizes ways in which guilt may be adaptive in the classroom environment. It reviews empirical data indicating that guilt shows adaptive relationships with a wide range of behaviors inside and outside the classroom. Relationships appear to be robust across age level and, indeed, similar findings appear in childhood and adulthood. Guilt is a social emotion. Greater guilt is positively correlated with healthy interpersonal relationships and with caring, considerate, honest, and trustworthy behavior. Guilt is inversely related to aggressive, acting-out behavior. Moreover, greater guilt is related to volunteerism and eschewal of racist attitudes, suggesting that individuals higher on guilt are more tolerant and accepting of others with backgrounds different from their own and more conscious of inequities. The relationship of guilt to …",22회,"Guilt in the classroom
C Williams - Guilt and children, 1998
22회 인용 관련 학술자료 전체 3개의 버전",,Guilt and children,,,,,,
Instantiating deformable models with a neural net,"Christopher KI Williams, Michael Revow, Geoffrey E Hinton",1997/10/1,Computer vision and image understanding,68,1,120-126,Academic Press,"Deformable models are an attractive approach to recognizing objects which have considerable within-class variability such as handwritten characters. However, there are severe search problems associated with fitting the models to data which could be reduced if a better starting point for the search were available. We show that by training a neural network to predict how a deformable model should be instantiated from an input image, such improved starting points can be obtained. This method has been implemented for a system that recognizes handwritten digits using deformable models, and the results show that the search time can be significantly reduced without compromising recognition performance.",21회,"Instantiating deformable models with a neural net
CKI Williams, M Revow, GE Hinton - Computer vision and image understanding, 1997
21회 인용 관련 학술자료 전체 20개의 버전",,,,,,,,
Letters of,Raymond Williams,2009/5,"Williams (Assistant Fish Division Administrator, Oregon Department of Fish and Wildlife) to G. Griffin (Protected Resources Division, NMFS Northwest Region) dated",12,,,,"New Left Books 1979. 390pp. Hardback£ 12, 75. In form (it's well over 400 pages long) this is an unusual book, being the well-edited reproduction of a series of interviews of taped discussions between the'subject'—Raymond Williams—and three members of the editorial committee of New Left Review. It is a form which has been used in recent years in the more directly political statements of such writers as Regis Debray and Santiago Carillo and, indeed, in articles in Marxism Today; but this is a more ambitious enterprise, in the sense that, though quite complex theoretical issues are included, a good deal of the genuine flexibility and mutual enrichment of good discussion gets across. I don't think the danger of such a form—the imposing of a suspiciously'rigged'pattern by the'interrogators'—is altogether avoided; but in general the dialogue form has encouraged a more direct, unaffected and open kind of talk and language than either the average article in NLR or Williams himself have often managed to achieve individually. That the discipline of clear communication imposed on both sides of the dialogue-form should have so successful and desirable an outcome is in itself a suggestive and encouraging fact.
One doesn't want, however, to overdo the question of form, important as it is. Themain thing about this interesting, and in many ways impressive book is that it helps us come to terms with the still developing contribution to socialist thinking of an impressive man. If it also helps him, that constitutes a bonus from which we shall all gain. For many years, and especially since the publication of Culture and Society in 1958, Raymond Williams has been …",20회,"Letters of
R Williams - Williams (Assistant Fish Division Administrator, Oregon …, 2009
19회 인용 관련 학술자료
Letter from*
R WILLIAM - 1772
1회 인용 관련 학술자료
etters L*
R Williams - 1982
전체 3개의 버전",,,,,,,,
How to pretend that correlated variables are independent by using difference observations,Christopher KI Williams,2005/1/1,,17,1,1-6,MIT Press,"In many areas of data modeling, observations at different locations (e.g., time frames or pixel locations) are augmented by differences of nearby observations (e.g., δ features in speech recognition, Gabor jets in image analysis). These augmented observations are then often modeled as being independent. How can this make sense? We provide two interpretations, showing (1) that the likelihood of data generated from an autoregressive process can be computed in terms of “independent” augmented observations and (2) that the augmented observations can be given a coherent treatment in terms of the products of experts model (Hinton, 1999).",20회,"How to pretend that correlated variables are independent by using difference observations
CKI Williams - Neural computation, 2005
20회 인용 관련 학술자료 전체 13개의 버전",,,Neural computation,,,,,
Localisation microscopy with quantum dots using non-negative matrix factorisation,"Ondřej Mandula, Ivana Šumanovac Šestak, Rainer Heintzmann, Christopher KI Williams",2014/10/6,Optics express,22,20,24594-24605,Optical Society of America,"We propose non-negative matrix factorisation with iterative restarts (iNMF) to model a noisy dataset of highly overlapping fluorophores with intermittent intensities. We can recover high-resolution images of individual sources from the optimised model, despite their high mutual overlap in the original data. Each source can have an arbitrary, unknown shape of the PSF and blinking behaviour. This allows us to use quantum dots as bright and stable fluorophores for localisation microscopy. We compare the iNMF results to CSSTORM, 3B and bSOFI. iNMF shows superior performance in the challenging task of super-resolution imaging using quantum dots. We can also retrieve axial localisation of the sources from the shape of the recovered PSF.",19회,"Localisation microscopy with quantum dots using non-negative matrix factorisation
O Mandula, IŠ Šestak, R Heintzmann, CKI Williams - Optics express, 2014
19회 인용 관련 학술자료 전체 13개의 버전",,,,,,,,
MFDTs: Mean field dynamic trees,"Nicholas J Adams, Amos J Storkey, Zoubin Ghahramani, Christopher KI Williams",2000/9/3,,3,,147-150,IEEE,"Tree structured belief networks are attractive for image segmentation tasks. However, networks with fixed architectures are not very suitable as they lead to blocky artefacts, and led to the introduction of dynamic trees (DTs). The Dynamic trees architecture provide a prior distribution over tree structures, and simulated annealing (SA) was used to search for structures with high posterior probability. In this paper we introduce a mean field approach to inference in DTs. We find that the mean field method captures the posterior better than just using the maximum a posteriori solution found by SA.",19회,"MFDTs: Mean field dynamic trees
NJ Adams, AJ Storkey, Z Ghahramani, CKI Williams - Proceedings 15th International Conference on Pattern …, 2000
19회 인용 관련 학술자료 전체 11개의 버전",Proceedings 15th International Conference on Pattern Recognition. ICPR-2000,,,,,,,
Bayesian inference for wind field retrieval,"Ian T Nabney, Dan Cornford, Christopher KI Williams",2000/1/1,Neurocomputing,30,1-4,3-11,Elsevier,"In many problems in spatial statistics it is necessary to infer a global problem solution by combining local models. A principled approach to this problem is to develop a global probabilistic model for the relationships between local variables and to use this as the prior in a Bayesian inference procedure. We use a Gaussian process with hyper-parameters estimated from numerical weather prediction models, which yields meteorologically convincing wind fields. We use neural networks to make local estimates of wind vector probabilities. The resulting inference problem cannot be solved analytically, but Markov Chain Monte Carlo methods allow us to retrieve accurate wind fields.",19회,"Bayesian inference for wind field retrieval
IT Nabney, D Cornford, CKI Williams - Neurocomputing, 2000
19회 인용 관련 학술자료 전체 15개의 버전",,,,,,,,
The Social Art Cinema: A Moment in the History of British Film and Television Culture,Christopher Williams,1996,Cinema: the Beginnings and the Future,,,190-200,U of Westminster P,"British cinema has fbur repr, rtations and a problem. The first reputation is for a kind of built-in mediocrity, a supposed lack of interest in visual style or formal elaboration which can also be perceived as emotional inhibition. Satyajit Ray's argr-rment was that the medium compels its user'to face facts, to probe, to revea, l, to get close to people and things; while the British nature inclines to the opposite; to stay aloof, to cloak harsh tmths with innuendoes'.'Ray thought British film-makers lacked the creative imagination to produce visible filmic equivalents of the conflicts, clashes or tensions which may or may not (he was not sure) have existed in British culture. The argument has been advanced in broadly sirnilar terms by many other writers. though with str-uctr-rral or intellectual terms replacing Ray's' natural'one.
The seconcl reputation is for realism. Many British films from different periods have engaged substantially with …",19회,"The Social Art Cinema: A Moment in the History of British Film and Television Culture
C Williams - Cinema: the Beginnings and the Future, 1996
19회 인용 관련 학술자료",,,,,,,,
Directional-unit boltzmann machines,"Richard S Zemel, Christopher KI Williams, Michael Mozer",1993,Advances in Neural Information Processing Systems,,,172-172,MORGAN KAUFMANN PUBLISHERS,"We present a general formulation for a network of stochastic directional units. This formulation is an extension of the Boltzmann machine in which the units are not binary, but take on values in a cyclic range, between 0 and 271'radians. The state of each unit in a Directional-Unit Boltzmann Machine (DUBM) is described by a complex variable, where the phase component specifies a direction; the weights are also complex variables. We associate a quadratic energy function, and corresponding probability, with each DUBM configuration. The conditional distribution of a unit's stochastic state is a circular version of the Gaussian probability distribution, known as the von Mises distribution. In a mean-field approximation to a stochastic DUBM, the phase component of a unit's state represents its mean direction, and the magnitude component specifies the degree of certainty associated with this direction. This combination of a value and a certainty provides additional representational power in a unit. We describe a learning algorithm and simulations that demonstrate a mean-field DUBM'S ability to learn interesting mappings.
Many kinds of information can naturally be represented in terms of angular, or directional, variables. A circular range forms a suitable representation for explicitly directional information, such as wind direction, as well as for information where the underlying range is periodic, such as days of the week or months of the year. In computer vision, tangent fields and optic flow fields are represented as fields of oriented line segments, each of which can be described by a magnitude and direction. Directions can also be used to represent a set …",19회,"Directional-unit boltzmann machines
RS Zemel, CKI Williams, M Mozer - Advances in Neural Information Processing Systems, 1993
19회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Factored Shapes and Appearances for Parts-based Object Understanding.,"Seyed Mohammadali Eslami, Christopher KI Williams",2011/9/2,,,,1-12,,"Page 1. Factored Shapes and Appearances for Parts-based Object Understanding SM Ali Eslami Christopher KI Williams British Machine Vision Conference September 2, 2011 Page 2. Page 3. Classification Page 4. Localisation Page 5. Segmentation Page 6. This talk's focus (Panoramio/nicho593) Segment this 6 Page 7. 7 Page 8. 7 Page 9. Outline 1. The segmentation task 2. The FSA model 3. Experimental results 4. Discussion 8 Page 10. The segmentation task The image X The segmentation S 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 9 Page 11. The segmentation task 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 The image X The segmentation S The generative approach ► Construct a joint model of X and S parameterised by θ: p(X,S|θ) ► Learn θ given dataset Dtrain: arg maxθ p(Dtrain|θ) ► Return probable segmentation Stest given Xtest and θ: p(Stest|Xtest,θ) 10 Page 12. The segmentation task 0 0 1 1 …",18회,"Factored Shapes and Appearances for Parts-based Object Understanding.
SM Eslami, CKI Williams - BMVC, 2011
18회 인용 관련 학술자료 전체 36개의 버전",BMVC,,,,,,,
Model selection and adaptation of hyperparameters,"Carl Edward Rasmussen, Christopher KI Williams",2005,,,,105-128,MIT Press,"This chapter contains sections titled: The Model Selection Problem, Bayesian Model Selection, Cross-validation, Model Selection for GP Regression, Model Selection for GP Classification, Exercises",18회,"Model selection and adaptation of hyperparameters
CE Rasmussen, CKI Williams - 2005
18회 인용 관련 학술자료",,,,,,,,
Products of gaussians,"Christopher KI Williams, Felix V Agakov, Stephen N Felderhof",2001/1/1,,,,1017-1024,,"Ъ виан Р вигв ДН Е з вижг й и Шжг й из г мд жиз ДШг Е бг а в л з к ж а в к й а джг а зи бг аз гж и ж гб в иг джгк в гк ж аа бг а г и и К Й агл л гвз ж Шг бг аз в л мд жи з йзз вК аи гй и джг й и г йзз вз з азг йзз вИ йзЙ з в з з бда зижй ийж и джг й и в к ж ж зижй ийж К Я м б в ДНЕ Шжг й из г йзз в д в з л к ж з иг джг а зи Х вгж гбдгв виз в анз зИ ДОЕ джг й из г НЙ игж ШШ бг аз в ДПЕ джг й из г мд жиз гвзижй и гв гж в ЪДНЕ джг ззК
Ъ виан Р вигв ДН Е з вижг й и Шжг й из г мд жиз ДШг Е бг а в л з к ж а в к й а джг а зи бг аз гж и ж гб в иг джгк в гк ж аа бг а г и и К Св и з д д ж л гвз ж Шг бг аз в л мд жи з йзз вК Си з зн иг з и и в и з з и джг й и бг а л аа азг йзз вК Ргл к жИ йзз в з з бда зижй ийж И и джг й и в к ж ж зижй ийж К Эз в йзз в мд жиз з ииж и к з и д жб из и гжгй в анз з г и джг й и ж и ийж И л в Ц йаи л и ги ж бг азИ К К бг аз Ќв гк ж з ж и ж в гб к ж а зК агл л м б в и ж з з г и джг й из г йзз вз гвзижй и гв ДНЕ Шжг Й й из г йзз в д в з ДШг ШЕ л к ж з иг джг а зи Х вгж гбдгЙ в виз в анз з ДХ ЕИ джгк в гбда б ви жн ж зйаи иг джг а зи Шж в д а гбдгв виз в анз з ДШШ Е г и в н Ь дд в в з гд ДН Е ДОЕ Шжг Й й из г НЙ игж ШШ бг аз ДПЕ джг й из г мд жиз гвзижй и гв гж в ЪДНЕ джг ззК",18회,"Products of gaussians
CKI Williams, FV Agakov, SN Felderhof - NIPS, 2001
18회 인용 관련 학술자료 전체 6개의 버전",NIPS,,,,,,,
Fast unsupervised greedy learning of multiple objects and parts from video,"Michalis K Titsias, Christopher KI Williams",2004/6/27,,,,179-179,IEEE,"Williams and Titsias (2004) have shown how to carry out unsupervised greedy learning of multiple objects from images (GLOMO), building on the work of Jojic and Frey (2001). In this paper we show that the earlier work on GLOMO can be greatly speeded up for video sequence data by carrying out approximate tracking of the multiple objects in the scene. Our method is applied to raw image sequence data and extracts the objects one at a time. First, the moving background is learned, and moving objects are found at later stages. The algorithm recursively updates an appearance model of the tracked object so that possible occlusion of the object is taken into account which makes tracking stable. We apply this method to learn multiple objects in image sequences as well as articulated parts of the human body.",16회,"Fast unsupervised greedy learning of multiple objects and parts from video
MK Titsias, CKI Williams - 2004 Conference on Computer Vision and Pattern …, 2004
16회 인용 관련 학술자료 전체 7개의 버전",2004 Conference on Computer Vision and Pattern Recognition Workshop,,,,,,,
Learning about multiple objects in images: Factorial learning without factorial search,"Christopher KI Williams, Michalis K Titsias",2003,Advances in neural information processing systems,,,1415-1424,MIT; 1998,"We consider data which are images containing views of multiple objects. Our task is to learn about each of the objects present in the images. This task can be approached as a factorial learning problem, where each image must be explained by instantiating a model for each of the objects present with the correct instantiation parameters. A major problem with learning a factorial model is that as the number of objects increases, there is a combinatorial explosion of the number of configurations that need to be considered. We develop a method to extract object models sequentially from the data by making use of a robust statistical method, thus avoiding the combinatorial explosion, and present results showing successful extraction of objects from real images.",16회,"Learning about multiple objects in images: Factorial learning without factorial search
CKI Williams, MK Titsias - Advances in neural information processing systems, 2003
16회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Covariance functions,"Carl Edward Rasmussen, Christopher KI Williams",2005,,,,79-104,MIT Press,"This chapter contains sections titled: Preliminaries, Examples of Covariance Functions, Eigenfunction Analysis of Kernels, Kernels for Non-vectorial Inputs, Exercises",15회,"Covariance functions
CE Rasmussen, CKI Williams - 2005
15회 인용 관련 학술자료",,,,,,,,
Adding constrained discontinuities to gaussian process models of wind fields,"Dan Cornford, Ian T Nabney, Christopher KI Williams",1999,,,,861-867,,"Gaussian Processes provide good prior models for spatial data, but can be too smooth. In many physical situations there are discontinuities along bounding surfaces, for example fronts in near-surface wind fields. We describe a modelling method for such a constrained discontinuity and demonstrate how to infer the model parameters in wind fields with MCMC sampling.",15회,"Adding constrained discontinuities to gaussian process models of wind fields
D Cornford, IT Nabney, CKI Williams - Advances in Neural Information Processing Systems, 1999
15회 인용 관련 학술자료 전체 18개의 버전",Advances in Neural Information Processing Systems,,,,,,,
Using Bayesian neural networks to classify segmented images,"Francesco Vivarelli, Christopher KI Williams",1997/7/7,,,,268-273,IET,"We present results that compare the performance of neural networks trained with two Bayesian methods, (i) the evidence framework of D.J.C. MacKay (1992) and (ii) a Markov chain Monte Carlo method due to R.M. Neal (1996) on a task of classifying segmented outdoor images. We also investigate the use of the automatic relevance determination method for input feature selection.",15회,"Using Bayesian neural networks to classify segmented images
F Vivarelli, CKI Williams - Fifth International Conference on Artificial Neural …, 1997
15회 인용 관련 학술자료 전체 13개의 버전",Fifth International Conference on Artificial Neural Networks (Conf. Publ. No. 440),,,,,,,
Data de-duplication for serial-access storage media,,2014/3/4,,,,,,"Data storage and retrieval methods and apparatus are provided for facilitating data de-duplication for serial-access storage media such as tape. During data storage, input data is divided into a succession of chunks and, for each chunk, a corresponding data item is written to the storage media. The data item comprises the chunk data itself where it is the first occurrence of that data, and otherwise comprises a chunk-data identifier identifying that chunk of subject data. To facilitate reconstruction of the original data on read-back from the storage media a cache (50) is used together with a database (35R), stored on the media, that includes for each duplicated chunk, the location of the corresponding chunk of subject data.",14회,"Data de-duplication for serial-access storage media
C Williams, G Trezise, JP Buckingham, NT Hutchon… - US Patent 8,667,235, 2014
14회 인용 관련 학술자료 전체 4개의 버전",,,,,"Christopher Williams, Gregory Trezise, Jonathan Peter Buckingham, Neil Thomas Hutchon, Darren Edward Kent, Andrew Hana, Peter Walsh, Rafel Jibry, Robert Morling",US,13259739,8667235
Object localisation using the generative template of features,"Moray Allan, Christopher KI Williams",2009/7/1,Computer Vision and Image Understanding,113,7,824-838,Academic Press,"We introduce the Generative Template of Features (GTF), a parts-based model for visual object category detection. The GTF consists of a number of parts, and for each part there is a corresponding spatial location distribution and a distribution over ‘visual words’ (clusters of invariant features). The performance of the GTF is evaluated for object localisation, and it is shown that such a relatively simple model can give state-of-the-art performance. We also demonstrate how a Hough-transform-like method for object localisation can be derived from the GTF model.",14회,"Object localisation using the generative template of features
M Allan, CKI Williams - Computer Vision and Image Understanding, 2009
14회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
"Influence of hand grenade weight, shape and diameter on performance and subjective handling properties in relations to ergonomic design considerations","Cheng-Kang Yuan, Cheng-Lang Kuo",2006/3/1,Applied ergonomics,37,2,113-118,Elsevier,"Three hand-grenade design factors, namely shape (ball, oval, can), diameter (55, 60, and 65 mm) and weight (300, 400, and 500 g), were assessed. The objective criteria were (1) throwing distance from the grenade stop point to throwing point, and (2) error distance from the grenade stop point to the target. The subjective criteria were (3) the overall rating of handling (to hold and control) properties and (4) the rating of perceived exertions of throwing strength. Twenty ROC Army soldiers threw a Mark II practice grenade to familiarize them with the throwing procedure, and then, while standing, threw 21 experimental, mockup grenades at a target indicated by a flagpole 40 m away from the throwing point. Grenade weight had the greatest effect on both subjective and objective criteria. The 300 g grenade had the greatest throwing distance (38.6±6.5 m) and had the greatest accuracy (6.9±3.9 m). Grenade shape was …",14회,"Influence of hand grenade weight, shape and diameter on performance and subjective handling properties in relations to ergonomic design considerations
CK Yuan, CL Kuo - Applied ergonomics, 2006
14회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
On a connection between object localization with a generative template of features and pose-space prediction methods,"Christopher KI Williams, Moray Allan",2006/1,"School Informatics, Univ. of Edinburg, Edinburg, UK, Tech. Rep. EDI-INF-RR-0719",,,,,"We address the task of localizing objects from a given object class in an image. The image is represented as a collection of “visual words” at interest points. The generative template of features (GTF) model defines a distribution over visual words and their spatial locations for each part of the object (Sudderth et al., 2005; Fergus et al., 2005). We show how to derive pose-space prediction methods (such as the Hough transform) from the GTF.",14회,"On a connection between object localization with a generative template of features and pose-space prediction methods
CKI Williams, M Allan - School Informatics, Univ. of Edinburg, Edinburg, UK …, 2006
14회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
THE DEFINITION OF CURVED GEOMETRY FOR WIDESPAN,Chris JK Williams,2000,Widespan roof structures,,,41,Thomas Telford Services Limited,"If an enclosure is to be constructed of curved lines and surfaces rather than straight lines and flat planes, the questions arise as to how the geometry is first to be chosen and then how it can be defined with sufficient accuracy for the structure to be built and clad. There are clearly many ways that the geometry can be chosen and defined, but they fall into three broad categories and the methods used on any one project may fall into more than one of these categories. The categories are:",14회,"THE DEFINITION OF CURVED GEOMETRY FOR WIDESPAN
CJK Williams - Widespan roof structures, 2000
14회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Hand-printed digit recognition using deformable models,"Christopher KI Williams, Michael D Revow, Geoffrey E Hinton",1993,Spatial Vision in Humans and Robots,,,1-23,Cambridge Univ. Press,"Hand-printed characters can take on a great variety of shapes, especially when they are produced by a diverse population of writers. This variability makes the use of rigid templates impractical for hand-printed character recognition. It has long been realized (e. g. Ullmann, 1972; Burr, 1981b) that this limitation can be overcome by using elastically deformable models, and recent work (eg Yuille, 1990; Grenander et al., 1990) has provided a general framework for the problem. For images of single digits this framework implies that the best interpretation of an image is the model that minimizes an energy function that includes both the deformation energy of the digit model and the data misfit between the model and the image. An alternative approach to digit recognition is based on statistical pattern recognition techniques; an example is the use of a feedforward neural network for ZIP code digit recognition by le Cun et al.(1990). This method",14회,"Hand-printed digit recognition using deformable models
CKI Williams, MD Revow, GE Hinton - Spatial Vision in Humans and Robots, 1993
14회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
An evaluation of change point detection algorithms,"Gerrit JJ van den Burg, Christopher KI Williams",2020/3/13,arXiv preprint arXiv:2003.06222,,,,,"Change point detection is an important part of time series analysis, as the presence of a change point indicates an abrupt and significant change in the data generating process. While many algorithms for change point detection exist, little attention has been paid to evaluating their performance on real-world time series. Algorithms are typically evaluated on simulated data and a small number of commonly-used series with unreliable ground truth. Clearly this does not provide sufficient insight into the comparative performance of these algorithms. Therefore, instead of developing yet another change point detection method, we consider it vastly more important to properly evaluate existing algorithms on real-world data. To achieve this, we present the first data set specifically designed for the evaluation of change point detection algorithms, consisting of 37 time series from various domains. Each time series was annotated by five expert human annotators to provide ground truth on the presence and location of change points. We analyze the consistency of the human annotators, and describe evaluation metrics that can be used to measure algorithm performance in the presence of multiple ground truth annotations. Subsequently, we present a benchmark study where 13 existing algorithms are evaluated on each of the time series in the data set. This study shows that binary segmentation (Scott and Knott, 1974) and Bayesian online change point detection (Adams and MacKay, 2007) are among the best performing methods. Our aim is that this data set will serve as a proving ground in the development of novel change point detection algorithms.",13회,"An evaluation of change point detection algorithms
GJJ van den Burg, CKI Williams - arXiv preprint arXiv:2003.06222, 2020
13회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Developing the agile implementation playbook for integrating evidence-based health care services into clinical practice,"Malaz A Boustani, Marjolein A Van der Marck, Nadia Adams, Jose M Azar, Richard J Holden, Horst C Vollmar, Sophia Wang, Christopher Williams, Catherine Alder, Shelley Suarez, Babar Khan, Ben Zarzaur, Nicole R Fowler, Ashley Overley, Craig A Solid, Alfonso Gatmaitan",2019/4,Academic Medicine,94,4,556,Wolters Kluwer Health,"Problem Despite the more than $32 billion the National Institutes of Health has invested annually, evidence-based health care services are not reliably implemented, sustained, or distributed in health care delivery organizations, resulting in suboptimal care and patient harm. New organizational approaches and frameworks that reflect the complex nature of health care systems are needed to achieve this goal.",13회,"Developing the agile implementation playbook for integrating evidence-based health care services into clinical practice
MA Boustani, MA Van der Marck, N Adams, JM Azar… - Academic Medicine, 2019
13회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Assessing the utility of autofluorescence-based pulmonary optical endomicroscopy to predict the malignant potential of solitary pulmonary nodules in humans,"Sohan Seth, Ahsan R Akram, Paul McCool, Jody Westerfeld, David Wilson, Stephen McLaughlin, Kevin Dhaliwal, Christopher KI Williams",2016/8/23,Scientific reports,6,1,1-10,Nature Publishing Group,"Solitary pulmonary nodules are common, often incidental findings on chest CT scans. The investigation of pulmonary nodules is time-consuming and often leads to protracted follow-up with ongoing radiological surveillance, however, clinical calculators that assess the risk of the nodule being malignant exist to help in the stratification of patients. Furthermore recent advances in interventional pulmonology include the ability to both navigate to nodules and also to perform autofluorescence endomicroscopy. In this study we assessed the efficacy of incorporating additional information from label-free fibre-based optical endomicrosopy of the nodule on assessing risk of malignancy. Using image analysis and machine learning approaches, we find that this information does not yield any gain in predictive performance in a cohort of patients. Further advances with pulmonary endomicroscopy will require the addition of …",13회,"Assessing the utility of autofluorescence-based pulmonary optical endomicroscopy to predict the malignant potential of solitary pulmonary nodules in humans
S Seth, AR Akram, P McCool, J Westerfeld, D Wilson… - Scientific reports, 2016
13회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
Clinical attributes and surgical outcomes of angiocentric gliomas,"Leonel Ampie, Winward Choy, Joseph D DiDomenico, Jonathan B Lamano, Christopher Kazu Williams, Kartik Kesavabhotla, Qinwen Mao, Orin Bloch",2016/6/1,,28,,117-122,Churchill Livingstone,"Angiocentric gliomas (AG) are exceedingly rare low-grade neoplasms which often present in the form of intractable epilepsy within younger patients. The current study extensively reviews all reported cases which were pathologically verified as AG in the literature to analyze clinical attributes and surgical outcomes of this neoplasm. There were 88 patients with AG reported in the literature consisting mostly of pediatric cases. The sex distribution consisted of 45 males and 36 females with the remaining seven cases not documenting sex. The average age of initial diagnosis was 16 years with almost half of all diagnosed patients being within the first decade of life. In cases where extent of resection was reported, gross total resection (GTR) was achieved in 54 patients, subtotal resection (STR) in 16, and biopsy only in three. Post-operative complications were transient and only occurred in three patients with no reports of …",13회,"Clinical attributes and surgical outcomes of angiocentric gliomas
L Ampie, W Choy, JD DiDomenico, JB Lamano… - Journal of Clinical Neuroscience, 2016
13회 인용 관련 학술자료 전체 9개의 버전",,,Journal of Clinical Neuroscience,,,,,
A framework for evaluating approximation methods for gaussian process regression,"Krzysztof Chalupka, Christopher KI Williams, Iain Murray",2012/5/29,arXiv preprint arXiv:1205.6326,,,,,"Gaussian process (GP) predictors are an important component of many Bayesian approaches to machine learning. However, even a straightforward implementation of Gaussian process regression (GPR) requires O (n^ 2) space and O (n^ 3) time for a dataset of n examples. Several approximation methods have been proposed, but there is a lack of understanding of the relative merits of the different approximations, and in what situations they are most useful. We recommend assessing the quality of the predictions obtained as a function of the compute time taken, and comparing to standard baselines (eg, Subset of Data and FITC). We empirically investigate four different approximation algorithms on four different prediction problems, and make our code available to encourage future comparisons.",13회,"A framework for evaluating approximation methods for gaussian process regression
K Chalupka, CKI Williams, I Murray - arXiv preprint arXiv:1205.6326, 2012
13회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
The Richard Burton Diaries,Christopher Williams,2012,,,,,Yale University Press,"The volume published for the first time the surviving diaries of Richard Burton. The diaries were written between 1939 and 1983 - throughout his career and the year of his celebrated marriages to Elizabeth Taylor. Diary entries appear in their original sequence, with annotations to clarify the people, places, books and events mentioned.",13회,"The Richard Burton Diaries
C Williams - 2012
13회 인용 관련 학술자료",,,,,,,,
Combining neural networks and belief networks for image segmentation,"Christopher KI Williams, Xiaojuan Feng",1998/9/2,,,,393-401,IEEE,"We are concerned with segmenting an image into a number of predefined classes. We show how to fuse together local predictions for the class labels with a prior model of segmentations using the scaled-likelihood method. The prior model is based on a tree-structured belief network. Both the neural network and belief network were trained on a set of training images, and then the combined system was used to make predictions on a set of test images. We show that the combined neural network/belief network classifier gives improved prediction accuracy on 9 out of the 11 classes.",13회,"Combining neural networks and belief networks for image segmentation
CKI Williams, X Feng - Neural Networks for Signal Processing VIII …, 1998
13회 인용 관련 학술자료 전체 5개의 버전",Neural Networks for Signal Processing VIII. Proceedings of the 1998 IEEE Signal Processing Society Workshop (Cat. No. 98TH8378),,,,,,,
Unsupervised learning of object models,"Christopher KI Williams, Richard S Zemel, Michael C Mozer",1993,AAAI Fall 1993 Symposium on Machine Learning in Computer Vision,,,20-24,,"Given a set of images, each of which contains one instance of a small but unknown set of objects imaged from a random viewpoint, we show how to perform unsupervised learning to discover the object classes. To group the data into objects we use a mixture model which is trained with the EM algorithm. We have investigated characterizing the the probability distribution for the features of each object either in terms of an object model or by a Gaussian distribution. We compare the performance of these two approaches on a dataset containing six di erent stick-animals, and on a dataset consisting of seven hand gestures.",13회,"Unsupervised learning of object models
CKI Williams, RS Zemel, MC Mozer - AAAI Fall 1993 Symposium on Machine Learning in …, 1993
13회 인용 관련 학술자료 전체 25개의 버전",,,,,,,,
Inverting supervised representations with autoregressive neural density models,"Charlie Nash, Nate Kushman, Christopher KI Williams",2019/4/11,,,,1620-1629,PMLR,"We present a method for feature interpretation that makes use of recent advances in autoregressive density estimation models to invert model representations. We train generative inversion models to express a distribution over input features conditioned on intermediate model representations. Insights into the invariances learned by supervised models can be gained by viewing samples from these inversion models. In addition, we can use these inversion models to estimate the mutual information between a model’s inputs and its intermediate representations, thus quantifying the amount of information preserved by the network at different stages. Using this method we examine the types of information preserved at different layers of convolutional neural networks, and explore the invariances induced by different architectural choices. Finally we show that the mutual information between inputs and network layers initially increases and then decreases over the course of training, supporting recent work by Shwartz-Ziv and Tishby (2017) on the information bottleneck theory of deep learning.",12회,"Inverting supervised representations with autoregressive neural density models
C Nash, N Kushman, CKI Williams - The 22nd International Conference on Artificial …, 2019
12회 인용 관련 학술자료 전체 5개의 버전",The 22nd International Conference on Artificial Intelligence and Statistics,,,,,,,
The PASCAL visual object classes challenge workshop 2009,"Mark Everingham, Luc van Gool, CKI Williams, John Winn, Andrew Zisserman, RGAA Conformité",2009,"Proceedings of the International Conference on Computer Vision, Kyoto, Japan",,,,,"This workshop will present and discuss the results of the PASCAL Visual Object Classes Challenge (VOC2008). As in previous years' challenges there are two main competitions, one testing image classification ("" does the image contain an instance of this class?""), and one testing object detection ("" provide a bounding box for each instance of the class, if any""). In addition there are two'taster'competitions: the first evaluates the object layout in more detail ("" detect the hands, feet etc for a person""), the second evaluates object segmentation at the pixel level.
A new database has been prepared consisting of 20 classes with around 25000 annotated instances in total. The images are obtained from flickr. The classes include people, cats, dogs, cars, motorbikes, bottles and sofas. The annotation includes a rectangular bounding box and flags to indicate pose and level of difficulty.",12회,"The PASCAL visual object classes challenge workshop 2009
M Everingham, L van Gool, CKI Williams, J Winn… - Proceedings of the International Conference on …, 2009
12회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Predictive search distributions,"Edwin V Bonilla, Christopher KI Williams, Felix V Agakov, John Cavazos, John Thomson, Michael FP O'Boyle",2006/6/25,,,,121-128,,"Estimation of Distribution Algorithms (EDAs) are a popular approach to learn a probability distribution over the"" good"" solutions to a combinatorial optimization problem. Here we consider the case where there is a collection of such optimization problems with learned distributions, and where each problem can be characterized by some vector of features. Now we can define a machine learning problem to predict the distribution of good solutions q (s| x) for a new problem with features x, where s denotes a solution. This predictive distribution is then used to focus the search. We demonstrate the utility of our method on a compiler optimization task where the goal is to find a sequence of code transformations to make the code run fastest. Results on a set of 12 different benchmarks on two distinct architectures show that our approach consistently leads to significant improvements in performance.",12회,"Predictive search distributions
EV Bonilla, CKI Williams, FV Agakov, J Cavazos… - Proceedings of the 23rd International Conference on …, 2006
12회 인용 관련 학술자료 전체 4개의 버전",,Proceedings of the 23rd International Conference on Machine learning,,,,,,
An upper bound on the Bayesian error bars for generalized linear regression,"Cazhaow S Qazaz, Christopher KI Williams, Christopher M Bishop",1997,,,,295-299,"Springer, Boston, MA","In the Bayesian framework, predictions for a regression problem are expressed in terms of a distribution of output values. The mode of this distribution corresponds to the most probable output, while the uncertainty associated with the predictions can conveniently be expressed in terms of error bars given by the standard deviation of the output distribution. In this paper we consider the evaluation of error bars in the context of the class of generalized linear regression models. We provide insights into the dependence of the error bars on the location of the data points and we derive an upper bound on the true error bars in terms of the contributions from individual data points which are themselves easily evaluated.",12회,"An upper bound on the Bayesian error bars for generalized linear regression
CS Qazaz, CKI Williams, CM Bishop - Mathematics of Neural Networks, 1997
12회 인용 관련 학술자료 전체 11개의 버전",,Mathematics of Neural Networks,,,,,,
A new method of spike modelling and interval analysis,"Duncan J MacGregor, CKI Williams, G Leng",2009/1/15,Journal of neuroscience methods,176,1,45-56,Elsevier,"Here we develop a new model of spike firing, based on the leaky integrate and fire model, modified to simulate afterpotentials. We also develop new analysis techniques, applying these to recorded and model generated data in order to make a comparative analysis and develop the model as a hypothesis for the functional components of the neuron. The model is based in this first instance on hypothalamic oxytocin neurons. We demonstrate how model parameters and cell properties relate to features observed in inter-spike intervals histograms, and the limits of these in being able to detect patterning features in spike recordings. A new technique, spike train analysis, is able to detect previously unobserved patterning, showing a dependence of spike intervals on previous firing activity. This effect is reproduced in the model by adding the small amplitude but long lasting after hyper-polarising potential (AHP). A fit …",11회,"A new method of spike modelling and interval analysis
DJ MacGregor, CKI Williams, G Leng - Journal of neuroscience methods, 2009
11회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
The impact of using related individuals for haplotype reconstruction in population studies,"Michael T Schouten, Christopher KI Williams, Chris S Haley",2005/11/1,Genetics,171,3,1321-1330,Oxford University Press,"Recent studies have highlighted the dangers of using haplotypes reconstructed directly from population data for a fine-scale mapping analysis. Family data may help resolve ambiguity, yet can be costly to obtain. This study is concerned with the following question: How much family data (if any) should be used to facilitate haplotype reconstruction in a population study? We conduct a simulation study to evaluate how changes in family information can affect the accuracy of haplotype frequency estimates and phase reconstruction. To reconstruct haplotypes, we introduce an EM-based algorithm that can efficiently accommodate unrelated individuals, parent-child trios, and arbitrarily large half-sib pedigrees. Simulations are conducted for a diverse set of haplotype frequency distributions, all of which have been previously published in empirical studies. A wide variety of important results regarding the effectiveness of …",11회,"The impact of using related individuals for haplotype reconstruction in population studies
MT Schouten, CKI Williams, CS Haley - Genetics, 2005
11회 인용 관련 학술자료 전체 14개의 버전",,,,,,,,
Tuberculosis exposure risk in emergency medicine residents,"Andrew W Asimos, Jay S Kaufman, Carol H Lee, Cleopas M Williams, Wallace A Carter, William K Chiang",1999/10,Academic emergency medicine,6,10,1044-1049,Blackwell Publishing Ltd,"Objectives: To assess purified protein derivative (PPD) test surveillance and respiratory protection practices of emergency medicine (EM) residents, along with the prevalence of PPD test conversion and the development of active tuberculosis (TB) in EM residents. Methods: The study instrument was an anonymous, self‐reporting, multiple‐choice survey administered to U.S. and Canadian EM residents. It was distributed for voluntary completion in conjunction with the American Board of Emergency Medicine's annual in‐service examination, which was administered February 25, 1998. Results: A total of 89.3% (n = 2,985) of residents eligible to complete the survey completed at least part of it. The majority of residents are PPD‐tested once a year. The prevalence of PPD test conversions in EM residents was between 1.4% (36/2,575) and 2.0% (52/2,575). Of the residents who PPD test‐converted, the ED was most …",11회,"Tuberculosis exposure risk in emergency medicine residents
AW Asimos, JS Kaufman, CH Lee, CM Williams… - Academic emergency medicine, 1999
11회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Tree-structured belief networks as models of images,"Christopher KI Williams, Xiaojuan Feng",1999/1/1,,,,31-36,IET Digital Library,In this paper we deal with the use the tree-structured belief network (TSBN) as a prior model in segmenting a natural image into a number of predefined classes. The TSBN was trained using the EM algorithm based on a set of training label images. The average log likelihood (or bit rate) of a test set of images shows that the learned TSBN is a better model for images than models based on independent blocks of varying sizes. We also analyze the relative advantages obtained by modelling correlations at different length scales in the tree.,11회,"Tree-structured belief networks as models of images
CKI Williams, X Feng - 1999
11회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Using a neural net to instantiate a deformable model,"Christopher KI Williams, Michael Revow, Geoffrey E Hinton",1995,Advances in neural information processing systems,,,965-972,MORGAN KAUFMANN PUBLISHERS,"Deformable models are an attractive approach to recognizing nonrigid objects which have considerable within class variability. However, there are severe search problems associated with fitting the models to data. We show that by using neural networks to provide better starting points, the search time can be significantly reduced. The method is demonstrated on a character recognition task.
In previous work we have developed an approach to handwritten character recognition based on the use of deformable models (Hinton, Williams and Revow, 1992a; Revow, Williams and Hinton, 1993). We have obtained good performance with this method, but a major problem is that the search procedure for fitting each model to an image is very computationally intensive, because there is no efficient algorithm (like dynamic programming) for this task. In this paper we demonstrate that it is possible to"" compile down"" some of the knowledge gained while fitting models to data to obtain better starting points that significantly reduce the search time.",11회,"Using a neural net to instantiate a deformable model
CKI Williams, M Revow, GE Hinton - Advances in neural information processing systems, 1995
11회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Form finding and cutting patterns for air-supported structures,Christopher Williams,1980,,,,99-120,Institution of Structural Engineers,"Williams, C. (1980). Form finding and cutting patterns for air-supported structures. In Air-supported structures: the state of the art (pp. 99-120). London: Institution of Structural Engineers … Form finding and cutting patterns for air-supported structures. / Williams, Christopher … Air-supported structures: the state of the art. London : Institution of Structural Engineers, 1980. p. 99-120 … Williams, C 1980, Form finding and cutting patterns for air-supported structures. in Air-supported structures: the state of the art. Institution of Structural Engineers, London, pp. 99-120.",11회,"Form finding and cutting patterns for air-supported structures
C Williams - Air-supported structures: the state of the art, 1980
11회 인용 관련 학술자료",,Air-supported structures: the state of the art,,,,,,
Flexible screening panel,,1969/12/16,,,,,,"A screening panel for a screen of the DSM (Dutch State Mines) type is a unitary flexible slab of urethane rubber, or the like, comprising interconnecting screening bars and support bars, the latter extending at an angle with respect to the screening bars. Screening bars are parallel to each other, and so are support bars. Screening bars and Support bars lie in the same plane and have identical cross-section in form of truncated pyramids whose bases together constitute a screening surface. The panel has a clamping strengthening flap extending laterally from at least one edge thereof.
This invention relates to the screening art, and is concerned with the provision of an improved fixed fine screen of the type disclosed in US Patent No. 2,916,142, Fontein, dated Dec. 8, 1959. Said type of fine screen is characterized by an inclined Screening deck-flat, or curved-composed of parallel spaced rod-like members which are …",11회,"Flexible screening panel
CJ Williams - US Patent 3,483,976, 1969
11회 인용 관련 학술자료 전체 2개의 버전",,,,,Charles J Williams,US,,3483976
Automating the calibration of a neonatal condition monitoring system,"Christopher KI Williams, Ioan Stanculescu",2011/7/2,,,,240-249,"Springer, Berlin, Heidelberg","Condition monitoring of premature babies in intensive care can be carried out using a Factorial Switching Linear Dynamical System (FSLDS) [15]. A crucial part of training the FSLDS is the manual calibration stage, where an interval of normality must be identified for each baby that is monitored. In this paper we replace this manual step by using a classifier to predict whether an interval is normal or not. We show that the monitoring results obtained using automated calibration are almost as good as those using manual calibration.",10회,"Automating the calibration of a neonatal condition monitoring system
CKI Williams, I Stanculescu - Conference on Artificial Intelligence in Medicine in …, 2011
10회 인용 관련 학술자료 전체 12개의 버전",Conference on Artificial Intelligence in Medicine in Europe,,,,,,,
NIGERIA'S (UNHOLY) WEDLOCK WITH CORRUPTION: CAN DEATH PUT THEM ASUNDER?,Femi Adegbulu,2010/8/1,Journal of International Social Research,3,12,,,"Corruption as it is, it has been argued, is more evil than what it amounts to, and more hydra-headed than ordinary legislation could cope with. It has pervaded every sector of the Nigerian life. Law enforcement agents and agencies take bribes brazenly, but this seems to be the least form of corruption. 419 has gone digital and it surfaces in every area of human interest. More and more billionaires emerge from people who, previously had been without any visible means of livelihood. Institutions of learning are not spared of this cankerworm as unwholesome practices hitherto alien to the ivory tower are now common place. The courts are no longer the last hope of the common man, but the bastion of corruption, greed and avarice as judges award justice to the highest bidder. The hoi-polloi have been eclipsed and cowed into hapless complacency. What should be done to rescue the soul of Nigeria from this perilous …",10회,"NIGERIA'S (UNHOLY) WEDLOCK WITH CORRUPTION: CAN DEATH PUT THEM ASUNDER?
F Adegbulu - Journal of International Social Research, 2010
10회 인용 관련 학술자료",,,,,,,,
Numerical simulation of wave energy converters using Eulerian and Lagrangian CFD methods,"J Westphalen, DM Greaves, Alison Hunt-Raby, Christopher JK Williams, Paul H Taylor, ZZ Hu, DM Causon, CG Mingham, PK Stansby, BD Rogers, P Omidvar",2010/1/1,,,,,International Society of Offshore and Polar Engineers,"During the last years many concepts of wave energy converters (WEC) have been proposed. All are designed to generate energy at competitive economic rates in average sea states and also to survive extreme wave conditions. Due to the complexity of most offshore wave energy devices and their motion response in different sea states, physical tank tests are common practice for WEC design. Full scale tests are also necessary, but are expensive and only considered once the design has been optimised. Computational Fluid Dynamics (CFD) is now recognised as an important complement to traditional physical testing techniques in offshore engineering. Once properly calibrated and validated to the problem, CFD offers a high density of test data and results in a reasonable timescale to assist with design changes and improvements to the device.
Within the EPSRC funded research project “Extreme Wave Loading …",10회,"Numerical simulation of wave energy converters using Eulerian and Lagrangian CFD methods
J Westphalen, DM Greaves, A Hunt-Raby… - The Twentieth International Offshore and Polar …, 2010
10회 인용 관련 학술자료 전체 4개의 버전",The Twentieth International Offshore and Polar Engineering Conference,,,,,,,
Data storage cartridge with sensor,,2003/4/10,,,,,,There is disclosed a medium cartridge comprising: a casing; a data storage medium for storing data; and at least one shock sensor for sensing a shock condition experienced by said medium cartridge.,10회,"Data storage cartridge with sensor
S Holmes, C Williams, A Hodkinson - US Patent App. 10/251,983, 2003
10회 인용 관련 학술자료 전체 2개의 버전",,,,,"Stephen Holmes, Christopher Williams, Allan Hodkinson",US,10251983,
Observations on the Nyström method for Gaussian processes,"Christopher KI Williams, Carl Edward Rasmussen, Anton Schwaighofer, Volker Tresp",2002,,,,,,"A number of methods for speeding up Gaussian Process (GP) prediction have been proposed, including the Nyström method of Williams and Seeger (2001). In this paper we focus on two issues (1) the relationship of the Nyström method to the Subset of Regressors method (Poggio and Girosi, 1990; Luo and Wahba, 1997) and (2) understanding in what circumstances the Nyström approximation would be expected to provide a good approximation to exact GP regression.",10회,"Observations on the Nyström method for Gaussian processes
CKI Williams, CE Rasmussen, A Schwaighofer, V Tresp - 2002
10회 인용 관련 학술자료
Н йзз в джг зз ж ж зз гв в и Цнзиж гб дджгм б и гв*
О ДмЃ мЃЕ, З ДмЃЕДУ, ДОЕ ДмЃЕ, ДУ иЬ
전체 6개의 버전",,,,,,,,
"Greater guilt is related to prosocial, academic and socioemotional competence","J Bybee, C Williams, R Merisca",1994,"Poster presented at the annual convention of the American Psychological Association, Los Angeles, CA",,,,,,10회,"Greater guilt is related to prosocial, academic and socioemotional competence
J Bybee, C Williams, R Merisca - Poster presented at the annual convention of the …, 1994
10회 인용 관련 학술자료",,,,,,,,
Using mixtures of deformable models to capture variations in hand printed digits,"Michael Revow, Christopher KI Williams, Geoffrey E Hinton",1993,,,,,,"Deformable models are an attractive way for characterizing handwritten digits since they have relatively few parameters, are able to capture many topological variations, and incorporate much prior knowledge. We have described a system [8] that uses learned digit models consisting of splines whose shape is governed by a small number of control points. Images can be classified by separately fitting each digit model to the image, and using a simple neural network to decide which model fits best. We use an elastic matching algorithm to minimize an energy function that includes both the deformation energy of the digit model and the log probability that the model would generate the inked pixels in the image. The use of multiple models for each digit can characterize the population of handwritten digits better. We show how multiple models may be used without increasing the time required for elastic matching.",10회,"Using mixtures of deformable models to capture variations in hand printed digits
M Revow, CKI Williams, GE Hinton - 1993
10회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Meshfree peridynamic computer modelling of concrete in three dimensions using randomly positioned particles,CJKW Williams,2012/6,"Proceedings of Second Interna-120. Newman, J., Choo, BS: Advanced Concrete Technology",4,,229-237,,,9회,"Meshfree peridynamic computer modelling of concrete in three dimensions using randomly positioned particles
C Williams - Proceedings of Second Interna-120. Newman, J., Choo …, 2012
9회 인용 관련 학술자료",,,,,,,,
The PASCAL VOC2007,"Mark Everingham, Luc Van Gool, Chris KI Williams, John Winn, Andrew Zisserman",2007,"development kit. Technical report, University of Leeds",,,,,,9회,"The PASCAL VOC2007
M Everingham, L Van Gool, CKI Williams, J Winn… - development kit. Technical report, University of Leeds, 2007
9회 인용 관련 학술자료",,,,,,,,
Fast learning of sprites using invariant features,"Moray Allan, Michalis K Titsias, Christopher KI Williams",2005,,,,,,"A popular framework for the interpretation of image sequences is the layers or sprite model of eg Wang and Adelson (1994), Irani et al.(1994). Jojic and Frey (2001) provide a generative probabilistic model framework for this task, but their algorithm is slow as it needs to search over discretized transformations (eg translations, or affines) for each layer. In this paper we show that by using invariant features (eg Lowe’s SIFT features) and clustering their motions we can reduce or eliminate the search and thus learn the sprites much faster. We demonstrate our algorithm on two image sequences. 1",9회,"Fast learning of sprites using invariant features
M Allan, MK Titsias, CKI Williams - In Proc. BMVC, 2005
9회 인용 관련 학술자료 전체 3개의 버전",In Proc. BMVC,,,,,,,
Human structure interaction: the development of an analytical model of the human body,"C Williams, MY Rafiq, A Carter",1999/4,"International Conference: Vibration, Noice and Structural Dynamics’ 99",,,32-39,,,9회,"Human structure interaction: the development of an analytical model of the human body
C Williams, MY Rafiq, A Carter - … Conference: Vibration, Noice and Structural Dynamics' …, 1999
9회 인용 관련 학술자료",,,,,,,,
The rise and fall of the British press,Mick Temple,2017/9/11,,,,,Routledge,"The Rise and Fall of the British Press takes an artful look at the past, present and immediate future of the printed newspaper. Temple offers a thought-provoking account of the evolution of Britain’s news consumption across the centuries, situating it within significant social, cultural and political currents of the time. Chapters cover: The impact of key technological developments; from the birth of print and the introduction of television, to the rise of the internet and digital media; The ever-shifting power play between political parties and the press; The notion of the ‘public sphere’and how newspapers have influenced it over the decades; The role of news media during some of Europe’s most significant historical events, such as the French Revolution, the First and Second World Wars and the Suez crisis; The aftermath of the Leveson inquiry and the question of increased media regulation; The successes and failures of important media players, including Baron Beaverbrook and Lord Northcliffe in the nineteenth century, and Rupert Murdoch and Mark Zuckerberg in the twentieth and twenty-first centuries. Throughout the book, parallels are drawn between current issues impacting on the press and society and those from previous decades, further illuminating the role, both historic and ongoing, of the news media in Britain. Temple concludes the book by looking to the future of print journalism, calling for a reassessment of its role in the twenty-first century, redefining what journalism should be and reasserting its value in society today. This far-reaching analysis will be an invaluable resource for both students and researchers of journalism and media studies.",8회,"The rise and fall of the British press
M Temple - 2017
8회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Prevalence of nasal colonization by methicillin-resistant Staphylococcus aureus in persons using a homeless shelter in Kansas City,"Megan Ottomeyer, Charles D Graham, Avery D Legg, Elizabeth S Cooper, Chad D Law, Mariam Molani, Karine Matevossian, Jerry Marlin, Charlott Williams, Ramon Newman, Jason A Wasserman, Larry W Segars, Tracey AH Taylor",2016/10/25,Frontiers in public health,4,,234,Frontiers,"Nasal colonization of methicillin-resistant Staphylococcus aureus (MRSA) plays an important role in the epidemiology and pathogenesis of disease. Situations of close-quarter contact in groups are generally regarded as a risk factor for community acquired MRSA strains due to transmission via fomites and person to person contact. With these criteria for risk, homeless individuals using shelter facilities, including showers and toilets, should be considered high risk for colonization and infection. The aim of this study was to determine the prevalence of nasal colonization of MRSA in a homeless population compared to established rates of colonization within the public and a control group of subjects from a neighboring medical school campus, and to analyze phylogenetic diversity among the MRSA strains. Nasal samples were taken from the study population of 332 adult participants, and analyzed. In addition, participants were surveyed about various lifestyle factors in order to elucidate potential patterns of behavior associated with MRSA colonization. Homeless and control groups both had higher prevalence of MRSA (9.8% and 10.6% respectively) when compared to the general population reported by previous studies (1.8%). However, the control group had a similar MRSA rate compared to healthcare workers (4.6%) while the homeless population had an increased prevalence. Risk factors identified in this study included male gender, age over 50 years and use of antibiotics within the past 3 months. Phylogenetic relationships between 9 of the positive samples from the homeless population were analyzed, showing 8 of the 9 samples had a high …",8회,"Prevalence of nasal colonization by methicillin-resistant Staphylococcus aureus in persons using a homeless shelter in Kansas City
M Ottomeyer, CD Graham, AD Legg, ES Cooper… - Frontiers in public health, 2016
8회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
Retrieving data recorded at different bit densities,,1998/4/7,,,,,,"A Digital Data Storage (DDS) data storage mechanism for reading DDS tapes containing data at either 61 kbpi or 122 kbpi has two circuits for recovering data from signals induced in a magnetic head by magnetic patterns on the tape. One circuit incorporates a clipping amplifier, a phase-locked loop (PLL), and a latch to sample the two-level signal obtained at 61 kbpi, at times defined by clock pulses from the PLL. The second circuit incorporates a PR-1 partial-response maximum-likelihood (PRML) detector to decode the three-level signal obtained at 122 kbpi. The cosine frequency response characteristic of the PR-1 channel facilitates use of the same rotary head drum and magnetic head gap for reading tapes at either bit density.",8회,"Retrieving data recorded at different bit densities
JP Hardwick, CH Williams - US Patent 5,737,141, 1998
8회 인용 관련 학술자료 전체 2개의 버전",,,,,"John Patrick Hardwick, Christopher Huw Williams",US,08646241,5737141
An investigation into the integration of neural networks with the structured genetic algorithm to aid conceptual design,"MY Rafiq, C Williams",1998,,,,295-307,"Springer, Berlin, Heidelberg","Genetic Algorithms (GAs) and structured Genetic Algorithms (sGAs) are powerful tools for modelling some of the activities related to the conceptual stage of the design process. Artificial Neural Networks (ANNs) are Artificial Intelligence (AI) tools which can learn and generalise from examples and experience to produce meaningful solutions to problems even when input data is fuzzy, discontinuous or is incomplete. Human creativity, intuition and expertise can be combined and incorporated when training ANNs. Research has shown that the ANN can be a powerful tool for modelling some of the activities of the conceptual stage of the design process. The current paper investigates possibilities of integrating the sGA and the ANN in the context of a decision support tool to assist designers.",8회,"An investigation into the integration of neural networks with the structured genetic algorithm to aid conceptual design
MY Rafiq, C Williams - Artificial Intelligence in Structural Engineering, 1998
8회 인용 관련 학술자료 전체 4개의 버전",,Artificial Intelligence in Structural Engineering,,,,,,
Robust variational autoencoders for outlier detection and repair of mixed-type data,"Simao Eduardo, Alfredo Nazábal, Christopher KI Williams, Charles Sutton",2020/6/3,,,,4056-4066,PMLR,"We focus on the problem of unsupervised cell outlier detection and repair inmixed-type tabular data. Traditional methods are concerned only with detecting which rows in the dataset areoutliers. However, identifying which cells are corrupted in aspecific row is an important problem in practice, and the very first steptowards repairing them. We introduce the Robust VariationalAutoencoder (RVAE), a deep generative model that learns the jointdistribution of the clean data while identifying the outlier cells, allowing their imputation (repair). RVAE explicitly learns the probability of each cell being an outlier, balancing differentlikelihood models in the row outlier score, making the method suitablefor outlier detection in mixed-type datasets. We show experimentallythat not only RVAE performs better than several state-of-the-art methods incell outlier detection and repair for tabular data, but also that is robust against theinitial hyper-parameter selection.",7회,"Robust variational autoencoders for outlier detection and repair of mixed-type data
S Eduardo, A Nazábal, CKI Williams, C Sutton - International Conference on Artificial Intelligence and …, 2020
7회 인용 관련 학술자료 전체 6개의 버전",International Conference on Artificial Intelligence and Statistics,,,,,,,
Autoencoders and probabilistic inference with missing data: An exact solution for the factor analysis case,"Christopher KI Williams, Charlie Nash, Alfredo Nazábal",2018/1/11,arXiv preprint arXiv:1801.03851,,,,,"Latent variable models can be used to probabilistically"" fill-in"" missing data entries. The variational autoencoder architecture (Kingma and Welling, 2014; Rezende et al., 2014) includes a"" recognition"" or"" encoder"" network that infers the latent variables given the data variables. However, it is not clear how to handle missing data variables in this network. The factor analysis (FA) model is a basic autoencoder, using linear encoder and decoder networks. We show how to calculate exactly the latent posterior distribution for the factor analysis (FA) model in the presence of missing data, and note that this solution implies that a different encoder network is required for each pattern of missingness. We also discuss various approximations to the exact solution. Experiments compare the effectiveness of various approaches to filling in the missing data.",7회,"Autoencoders and probabilistic inference with missing data: An exact solution for the factor analysis case
CKI Williams, C Nash, A Nazábal - arXiv preprint arXiv:1801.03851, 2018
7회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Estimating bacterial and cellular load in fcfm imaging,"Sohan Seth, Ahsan R Akram, Kevin Dhaliwal, Christopher KI Williams",2018/1,Journal of Imaging,4,1,11,Multidisciplinary Digital Publishing Institute,"We address the task of estimating bacterial and cellular load in the human distal lung with fibered confocal fluorescence microscopy (FCFM). In pulmonary FCFM some cells can display autofluorescence, and they appear as disc like objects in the FCFM images, whereas bacteria, although not autofluorescent, appear as bright blinking dots when exposed to a targeted smartprobe. Estimating bacterial and cellular load becomes a challenging task due to the presence of background from autofluorescent human lung tissues, ie, elastin, and imaging artifacts from motion etc. We create a database of annotated images for both these tasks where bacteria and cells were annotated, and use these databases for supervised learning. We extract image patches around each pixel as features, and train a classifier to predict if a bacterium or cell is present at that pixel. We apply our approach on two datasets for detecting bacteria and cells respectively. For the bacteria dataset, we show that the estimated bacterial load increases after introducing the targeted smartprobe in the presence of bacteria. For the cell dataset, we show that the estimated cellular load agrees with a clinician’s assessment. View Full-Text",7회,"Estimating bacterial and cellular load in fcfm imaging
S Seth, AR Akram, K Dhaliwal, CKI Williams - Journal of Imaging, 2018
7회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Shell Design Considerations for 3D Printing with Drones,"Paul Shepherd, Chris Williams",2017/9/28,Proceedings of IASS Annual Symposia,2017,23,1-10,International Association for Shell and Spatial Structures (IASS),"Many researchers (e.g. Baarsen et. al. [2], Bos et. al. [3] , Galiaard et. al. [5], Perkins & Skitmore [11]) have reported on the potential innovations available when additive manufacturing (3D printing) is applied to the building design process, be it at the scale of an individual building component (Galiaard et. al. [5]) or the building itself (Baarsen et. al. [2]). However, by the very fact that the printing takes place inside the volume of the 3D printer, the finished product, even if printed at ‘architectural scale’ (Yasui et. al. [13]), must be smaller than the machine used to create it. To overcome this limitation, the authors are involved in a project to develop autonomous flying drones capable of 3D printing in the classic sense, by extruding liquid through a nozzle which then sets solid (www.aerial-abm.com). The initial focus is on using a foaming two-part polycarbonate composite, which possesses excellent properties in terms of …",7회,"Shell Design Considerations for 3D Printing with Drones
P Shepherd, C Williams - Proceedings of IASS Annual Symposia, 2017
7회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
Discriminative switching linear dynamical systems applied to physiological condition monitoring,"Konstantinos Georgatzis, Christopher KI Williams",2015/4/24,arXiv preprint arXiv:1504.06494,,,,,"We present a Discriminative Switching Linear Dynamical System (DSLDS) applied to patient monitoring in Intensive Care Units (ICUs). Our approach is based on identifying the state-of-health of a patient given their observed vital signs using a discriminative classifier, and then inferring their underlying physiological values conditioned on this status. The work builds on the Factorial Switching Linear Dynamical System (FSLDS)(Quinn et al., 2009) which has been previously used in a similar setting. The FSLDS is a generative model, whereas the DSLDS is a discriminative model. We demonstrate on two real-world datasets that the DSLDS is able to outperform the FSLDS in most cases of interest, and that an -mixture of the two models achieves higher performance than either of the two models separately.",7회,"Discriminative switching linear dynamical systems applied to physiological condition monitoring
K Georgatzis, CKI Williams - arXiv preprint arXiv:1504.06494, 2015
7회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
Renewal Strings for Cleaning Astronomical Databases,"Amos J Storkey, Nigel C Hambly, Christopher KI Williams, Robert G Mann",2014/8/7,arXiv preprint arXiv:1408.1489,,,,,"Large astronomical databases obtained from sky surveys such as the SuperCOSMOS Sky Surveys (SSS) invariably suffer from a small number of spurious records coming from artefactual effects of the telescope, satellites and junk objects in orbit around earth and physical defects on the photographic plate or CCD. Though relatively small in number these spurious records present a significant problem in many situations where they can become a large proportion of the records potentially of interest to a given astronomer. In this paper we focus on the four most common causes of unwanted records in the SSS: satellite or aeroplane tracks, scratches fibres and other linear phenomena introduced to the plate, circular halos around bright stars due to internal reflections within the telescope and diffraction spikes near to bright stars. Accurate and robust techniques are needed for locating and flagging such spurious objects. We have developed renewal strings, a probabilistic technique combining the Hough transform, renewal processes and hidden Markov models which have proven highly effective in this context. The methods are applied to the SSS data to develop a dataset of spurious object detections, along with confidence measures, which can allow this unwanted data to be removed from consideration. These methods are general and can be adapted to any future astronomical survey data.",7회,"Renewal Strings for Cleaning Astronomical Databases
AJ Storkey, NC Hambly, CKI Williams, RG Mann - arXiv preprint arXiv:1408.1489, 2014
7회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
Characterization of a hollow core fibre-coupled near field terahertz probe,"M Misra, Y Pan, CR Williams, SA Maier, SR Andrews",2013/5/21,Journal of Applied Physics,113,19,193104,American Institute of Physics,We describe the design and performance of a freely positionable THz near field probe based on a hollow core photonic crystal fibre-coupled photoconducting dipole antenna with an integrated sub-wavelength aperture. Experimental studies of the spatial resolution are compared with detailed finite element electromagnetic simulations and imaging artefacts that are a particular feature of this type of device are discussed. We illustrate the potential applications with descriptions of time domain near field studies of surface waves on a metamaterial and multimode propagation in a parallel plate waveguide.,7회,"Characterization of a hollow core fibre-coupled near field terahertz probe
M Misra, Y Pan, CR Williams, SA Maier, SR Andrews - Journal of Applied Physics, 2013
7회 인용 관련 학술자료 전체 9개의 버전",,,,,,,,
PASCAL 2008 Results,"Mark Everingham, Luc van Gool, Chris Williams, John Winn, Andrew Zisserman",2008,,,,,,,7회,"PASCAL 2008 Results
M Everingham, L van Gool, C Williams, J Winn… - 2008
7회 인용 관련 학술자료",,,,,,,,
"Pattern Recognition and Image Analysis: Third Iberian Conference, IbPRIA 2007, Girona, Spain, June 6-8, 2007, Proceedings, Part I","Joan Martí, José M Benedí, Ana M Mendonça, Joan Serrat",2007/7/4,,4477,,,Springer Science & Business Media,"Part of a two-volume set, this book constitutes the refereed proceedings of the Third Iberian Conference on Pattern Recognition and Image Analysis, IbPRIA 2007, held in Girona, Spain in June 2007. It covers pattern recognition, human language technology, special architectures and industrial applications, motion analysis, image analysis, biomedical applications, shape and texture analysis, 3D, and image coding and processing.",7회,"Pattern Recognition and Image Analysis: Third Iberian Conference, IbPRIA 2007, Girona, Spain, June 6-8, 2007, Proceedings, Part I
J Martí, JM Benedí, AM Mendonça, J Serrat - 2007
7회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Dynamic positional trees for structural image analysis,"Amos J Storkey, Christopher KI Williams",2001/1/4,,,,286-292,PMLR,"Dynamic positional trees are a significant extension of dynamic trees, incorporating movable nodes. This addition makes sequence tracking viable within the model, but requires a new formulation to incorporate the prior over positions. The model is implemented using a structured variational procedure, and is illustrated on synthetic raytraced images and image sequences.",7회,"Dynamic positional trees for structural image analysis
AJ Storkey, CKI Williams - International Workshop on Artificial Intelligence and …, 2001
7회 인용 관련 학술자료 전체 2개의 버전",International Workshop on Artificial Intelligence and Statistics,,,,,,,
Use your label: making sense of nutrition information,"Carol Williams, Mike Rayner, Mark Myatt, A Boaz",1998,,,,,"Great Britain, Ministry of Agriculture, Fisheries and Food",,7회,"Use your label: making sense of nutrition information
C Williams, M Rayner, M Myatt, A Boaz - 1998
7회 인용 관련 학술자료",,,,,,,,
Interventions to reduce social isolation and loneliness during COVID-19 physical distancing measures: A rapid systematic review,"Christopher YK Williams, Adam T Townson, Milan Kapur, Alice F Ferreira, Rebecca Nunn, Julieta Galante, Veronica Phillips, Sarah Gentry, Juliet A Usher-Smith",2021/2/17,,16,2,e0247139,Public Library of Science,"Background A significant proportion of the worldwide population is at risk of social isolation and loneliness as a result of the COVID-19 pandemic. We aimed to identify effective interventions to reduce social isolation and loneliness that are compatible with COVID-19 shielding and social distancing measures. Methods and findings In this rapid systematic review, we searched six electronic databases (Medline, Embase, Web of Science, PsycINFO, Cochrane Database of Systematic Reviews and SCOPUS) from inception to April 2020 for systematic reviews appraising interventions for loneliness and/or social isolation. Primary studies from those reviews were eligible if they included: 1) participants in a non-hospital setting; 2) interventions to reduce social isolation and/or loneliness that would be feasible during COVID-19 shielding measures; 3) a relevant control group; and 4) quantitative measures of social isolation, social support or loneliness. At least two authors independently screened studies, extracted data, and assessed risk of bias using the Downs and Black checklist. Study registration: PROSPERO CRD42020178654. We identified 45 RCTs and 13 non-randomised controlled trials; none were conducted during the COVID-19 pandemic. The nature, type, and potential effectiveness of interventions varied greatly. Effective interventions for loneliness include psychological therapies such as mindfulness, lessons on friendship, robotic pets, and social facilitation software. Few interventions improved social isolation. Overall, 37 of 58 studies were of “Fair” quality, as measured by the Downs & Black checklist. The main study limitations identified …",6회,"Interventions to reduce social isolation and loneliness during COVID-19 physical distancing measures: A rapid systematic review
CYK Williams, AT Townson, M Kapur, AF Ferreira… - PloS one, 2021
6회 인용 전체 15개의 버전",,,PloS one,,,,,
Predicting patient state-of-health using sliding window and recurrent classifiers,"Adam McCarthy, Christopher KI Williams",2016/12/2,arXiv preprint arXiv:1612.00662,,,,,"Bedside monitors in Intensive Care Units (ICUs) frequently sound incorrectly, slowing response times and desensitising nurses to alarms (Chambrin, 2001), causing true alarms to be missed (Hug et al., 2011). We compare sliding window predictors with recurrent predictors to classify patient state-of-health from ICU multivariate time series; we report slightly improved performance for the RNN for three out of four targets.",6회,"Predicting patient state-of-health using sliding window and recurrent classifiers
A McCarthy, CKI Williams - arXiv preprint arXiv:1612.00662, 2016
6회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Visual object classes challenge 2012 (voc2012),"Mark Everingham, Luc van Gool, Chris Williams, John Winn, Andrew Zisserman",2012,Retrieved from Pascal,2,,,,,6회,"Visual object classes challenge 2012 (voc2012)
M Everingham, L van Gool, C Williams, J Winn… - Retrieved from Pascal, 2012
6회 인용 관련 학술자료",,,,,,,,
Success rates of underhand and overhand free-throws as novel skills.,"Robert C Schneider, Christopher Williams",2010/6/1,Journal of Physical Education & Sport/Citius Altius Fortius,27,2,,,"In the pursuit of scoring as many points as possible during basketball competitions, most effective freethrow shooting techniques were explored. This study sought to determine whether the underhand or overhand basketball free-throw shooting style was naturally more prone to success than the other. Total participants (N= 29) were 15 male and 14 female undergraduate students, who were at least 18 years of age (average age was 23.98) with no prior basketball shooting experience. Through a counterbalanced design, each participant shot 25 underhand free-throws on one day and 25 overhand free-throws on a different day. No significant differences between the number of successful overhand and underhand shots were observed for attempts 1-13 when compared to attempts 14-25. Males averaged. 57 more successful attempts overhand than underhand. Females averaged. 33 less successful attempts overhand than underhand. Overall, as a group, the performance of both underhand and overhand shooting was positively correlated (. 28), representing a trend suggesting that if a participant shot well underhand they also shot well overhand, indicating that it is unlikely that either the overhand or underhand shooting style is more naturally more prone to success than the other; hence, free-throw shooting success may be more dependent on repetition than style.",6회,"Success rates of underhand and overhand free-throws as novel skills.
RC Schneider, C Williams - Journal of Physical Education & Sport/Citius Altius …, 2010
6회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Improved numberical methods for computing likelihoods in the stochastic integrate-and-fire model,"L Paninski, Adrian M Haith, Jonathan W Pillow, Christopher KI Williams",2005,,,,,,"A classic and recurring problem in theoretical neuroscience is to estimate the interspike interval (ISI) probability density: the probability that a white noise-driven integrate-and-fire-type neuronal model that has fired at time t= 0 will not fire again until time t= T. This problem appears in a number of contexts, including firing rate computations, statistical model fitting, and decoding. In particular, Paninski et al.(Neural Comp. 2004) recently introduced likelihood-based methods for fitting stochastic integrate-and-fire models to spike train data; these techniques rely on the numerical computation of these ISI densities. Computing this likelihood is equivalent to computing a Markov first passage time density, the probability that the model voltage (a Markov process) crosses threshold for the first time at time t= T, given that the voltage was reset to some fixed subthreshold value at time t= 0. Here we detail an improved numerical method for computing this likelihood, based on a technique of Plesser-Tanaka (Physics Letters A, 1997), and related to methods introduced by DiNardo, Ricciardi, and colleagues. We begin by noting that the ISI density uniquely solves a certain singular linear Volterra integral equation, then provide details on approximating this integral equation by a lower-triangular matrix equation, which may be solved efficiently on a computer. In addition, the gradient of this solution with respect to the model parameters may be computed efficiently via straightforward matrix perturbation techniques. This semi-analytic computation of the gradient greatly speeds numerical optimization of the model parameters in a maximum-likelihood setting and therefore …",6회,"Improved numberical methods for computing likelihoods in the stochastic integrate-and-fire model
L Paninski, AM Haith, JW Pillow, CKI Williams - Computational and Systems Neuroscience (COSYNE) …, 2005
6회 인용 관련 학술자료",Computational and Systems Neuroscience (COSYNE) 2005,,,,,,,
Classification,"Carl Edward Rasmussen, Christopher KI Williams",2005,,,,33-77,MIT Press,"This chapter contains sections titled: Classification Problems, Linear Models for Classification, Gaussian Process Classification, The Laplace Approximation for the Binary GP Classifier, Multi-class Laplace Approximation, Expectation Propagation, Experiments, Discussion, Appendix: Moment Derivations, Exercises",6회,"Classification
CE Rasmussen, CKI Williams - 2005
6회 인용 관련 학술자료",,,,,,,,
Robust variational autoencoders for outlier detection in mixed-type data,"Simão Eduardo, Alfredo Nazábal, Christopher KI Williams, Charles Sutton",2019,arXiv preprint arXiv:1907.06671,,,,,,5회,"Robust variational autoencoders for outlier detection in mixed-type data
S Eduardo, A Nazábal, CKI Williams, C Sutton - arXiv preprint arXiv:1907.06671, 2019
5회 인용 관련 학술자료",,,,,,,,
13 Neural Maps: Their Function and Development,"James A Bednar, Christopher KI Williams",2016/11/4,From Neuron to Cognition via Computational Neuroscience,,,,MIT press,"In this chapter, we first define a neural map as a sheet of neurons systematically related to another population of neurons, including the special but common case of a topographic map as a spatially organized mapping of this type. We further define a feature map as a topographic mapping of some underlying features or patterns in the input data, beyond the strict anatomical arrangement of the input region. Next, we review the main biological findings about the properties of these maps in adult animals, which will be expanded in more detail when discussing specific models of development and function later. We use well-established examples from the visual system but highlight similarities and differences with maps in other sensory modalities and in motor regions. The remaining sections present models and analyses addressing a series of key questions about neural maps:",5회,"13 Neural Maps: Their Function and Development
JA Bednar, CKI Williams - From Neuron to Cognition via Computational …, 2016
5회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Flexible design and construction strategies for self-help housing in Botswana,"K Jobe, CJK Williams",2016/6/28,The Open Construction and Building Technology Journal,10,1,,,"In an effort to coordinate the housing schemes from different departments, Government of the Republic of Botswana took a decision to establish Single Housing Authority (SiHA) through a Presidential Cabinet Directive CAB20 (B) 2010 in July 2010. Previously, these schemes were designed and built by the local councils, with the help of the local builders and house owners. A review of the architect designed and contractor-led housing projects under this scheme, demonstrate the shortcomings of a standardized housing design approach and the need to develop a flexible design strategies that can respond to the inevitable changes associated with low-income housing. A qualitative case study research of Self-Help Housing Agency (SHHA)’s built houses was conducted in Mochudi (Botswana) to explore potential strategies of improving the current self-help housing design processes. Using case study examples from Mochudi, a systematic and flexible design framework is suggested as an economically viable approach to improve the quality of self-help housing design processes that reduce costly changes which are associated with the current government-funded housing schemes.",5회,"Flexible design and construction strategies for self-help housing in Botswana
K Jobe, CJK Williams - The Open Construction and Building Technology …, 2016
5회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
An empirical study of one of the simplest causal prediction algorithms,"Joris M Mooij, Jerome Cremers",2015/7/16,UAI 2015 Workshop on Advances in Causal Inference,,1504,30-39,,"We study one of the simplest causal prediction algorithms that uses only conditional independences estimated from purely observational data. A specific pattern of four conditional independence relations amongst a quadruple of random variables already implies that one of these variables causes another one without any confounding. As a consequence, it is possible to predict what would happen under an intervention on that variable without actually performing the intervention. Although the method is asymptotically consistent and works well in settings with only few (latent) variables, we find that its prediction accuracy can be worse than simple (inconsistent) baselines when many (latent) variables are present. Our findings illustrate that violations of strong faithfulness become increasingly likely in the presence of many latent variables, and this can significantly deterioriate the accuracy of constraint-based causal prediction algorithms that assume faithfulness.",5회,"An empirical study of one of the simplest causal prediction algorithms
JM Mooij, J Cremers - UAI 2015 Workshop on Advances in Causal Inference, 2015
5회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
Assessing the significance of performance differences on the pascal voc challenges via bootstrapping,"Mark Everingham, SM Eslami, Luc Van Gool, Christopher KI Williams, John Winn, Andrew Zisserman",2013,Technical note,,,1-4,,"In the PASCAL VOC challenges, entrants in a particular competition are evaluated in terms of a specified metric. It can happen that some entrants will have similar scores, and it is of interest to assess the significance of these differences. For example, we might be interested to know if the highest-scoring entry is significantly better than some of the others. In this note we discuss the use of bootstrap sampling to address this question. We first came across the idea of bootstrapping precisionrecall curves in the blog comment by O’Connor (2010), although bootstrapping of ROC curves has been discussed by many authors, eg Hall et al (2004); Bertail et al (2009).",5회,"Assessing the significance of performance differences on the pascal voc challenges via bootstrapping
M Everingham, SM Eslami, L Van Gool, CKI Williams… - Technical note, 2013
5회 인용 관련 학술자료 전체 20개의 버전",,,,,,,,
Kick-starting GPLVM optimization via a connection to metric MDS,"Sebastian Bitzer, Christopher KI Williams",2010/12,,,,,,"The Gaussian Process Latent Variable Model (GPLVM) is an attractive model for dimensionality reduction, but the optimization of the GPLVM likelihood with respect to the latent point locations is difficult, and prone to local optima. Here we start from the insight that in the GPLVM, we should have that, where is the kernel function evaluated at latent points and, and is the corresponding estimate from the data. For an isotropic covariance function this relationship can be inverted to yield an estimate of the interpoint distances in the latent space, and these can be fed into a multidimensional scaling (MDS) algorithm. This yields an initial estimate of the latent locations, which can be subsequently optimized in the usual GPLVM fashion. We compare two variants of this approach to the standard PCA initialization and to the ISOMAP algorithm, and show that our initialization converges to the best GPLVM likelihoods on all six tested motion capture data sets.",5회,"Kick-starting GPLVM optimization via a connection to metric MDS
S Bitzer, CKI Williams - NIPS 2010 Workshop on Challenges of Data …, 2010
5회 인용 관련 학술자료 전체 15개의 버전",NIPS 2010 Workshop on Challenges of Data Visualization,,,,,,,
A note on noise-free Gaussian process prediction with separable covariance functions and grid designs,"Christopher KI Williams, Kian Ming A Chai, Edwin V Bonilla",2007/12,,,,,"Technical report, University of Edinburgh","Consider a random function f with a separable (or tensor product) covariance function, ie where x is broken into D groups (x1, x2,..., xD) and the covariance function has the form k (x, x)=∏ D i= 1 ki (xi, xi). We also require that observations of f are made on a D-dimensional grid. We show how conditional independences for the Gaussian process prediction for f (x∗)(corresponding to an off-grid test input x∗) depend on how x∗ matches the observation grids. This generalizes results on autokrigeability (see, eg Wackernagel 1998, ch. 25) to D> 2.",5회,"A note on noise-free Gaussian process prediction with separable covariance functions and grid designs
CKI Williams, KMA Chai, EV Bonilla - 2007
5회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
GPML Toolbox,"Carl Edward Rasmussen, Hannes Nickisch",2006,"ebrary, Dec",,,,,"The GPML toolbox is an Octave 3.2. x and Matlab 7. x implementation of inference and prediction in Gaussian process (GP) models. It implements algorithms discussed in Rasmussen & Williams: Gaussian Processes for Machine Learning, the MIT press, 2006 and Nickisch &",5회,"GPML Toolbox
CE Rasmussen, H Nickisch - ebrary, Dec, 2006
5회 인용 관련 학술자료",,,,,,,,
The generation of bone-like forms using analytic functions of a complex variable,"EAO Nsugbe, CJK Williams",2001/1/1,Engineering structures,23,1,22-28,Elsevier,This paper describes the use of analytic functions of a complex variable to generate two dimensional mappings which can then be used to generate bone-like three dimensional wall forms and arch forms.,5회,"The generation of bone-like forms using analytic functions of a complex variable
EAO Nsugbe, CJK Williams - Engineering structures, 2001
5회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Training Bayesian networks for image segmentation,"Xiaojuan Feng, Christopher KI Williams",1998/9/24,,3457,,82-92,International Society for Optics and Photonics,"We are concerned with the problem of image segmentation in which each pixel is assigned to one of a predefined finite number of classes. In Bayesian image analysis, this requires fusing together local predictions for the class labels with a prior model of segmentations. Markov Random Fields (MRFs) have been used to incorporate some of this prior knowledge, but this not entirely satisfactory as inference in MRFs is NP-hard. The multiscale quadtree model of Bouman and Shapiro (1994) is an attractive alternative, as this is a tree-structured belief network in which inference can be carried out in linear time (Pearl 1988). It is an hierarchical model where the bottom-level nodes are pixels, and higher levels correspond to downsampled versions of the image. The conditional-probability tables (CPTs) in the belief network encode the knowledge of how the levels interact. In this paper we discuss two methods of learning …",5회,"Training Bayesian networks for image segmentation
X Feng, CKI Williams - Mathematical Modeling and Estimation Techniques in …, 1998
5회 인용 관련 학술자료 전체 12개의 버전",Mathematical Modeling and Estimation Techniques in Computer Vision,,,,,,,
Combining two methods of recognizing hand-printed digits,"G Hinton, C Williams, M Revow",1992,Art. Neural Systems,2,,53-60,,"Hand-printed digits can be recognized quite well by a feedforward neural network that uses equality constraints between weights to achieve limited translation^ invariance. However, the net has no explicit model of what a digit looks like and this can lead it to make confident errors. An alternative approach, which incorporates much more prior knowledge, is to use explicit deformable models of the digits and to recognize a digit by finding which model fits best. We describe a system that uses learned digit models which consist of splines whose shape is governed by 8 control points. The elastic models are good at capturing shape knowledge, and the elastic matching process is good at rejecting parts of the image that are best explained as noise. However, the elastic matching is slow and can get trapped in local optima if the initial configuration of thè elastic model is far from the actual data. So we are developing a …",5회,"Combining two methods of recognizing hand-printed digits
G Hinton, C Williams, M Revow - Art. Neural Systems, 1992
5회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Mathematical methods in flexible spacecraft dynamics,"CJ Williams, EB Crellin, SA Gotts",1976,,,,,na,,5회,"Mathematical methods in flexible spacecraft dynamics
CJ Williams, EB Crellin, SA Gotts - 1976
5회 인용 관련 학술자료",,,,,,,,
Method of making a fine screen,,1971/1/19,,,,,,"A METHOD FOR MAKING SCREENING PANELS FROM HARDENABLE SYNTHETIC ORGANIC RESINOUS MATERIAL BY INTRODUCING THE LIQUID RESINOUS MATERIAL INTO A MOLD HAVING A PLURALITY OF INTERCONNECTING GROOVES PROVIDING TRUNCATED PEAKS THEREBETWEEN IN AN AMOUNT IN EXCESS OF THAT REQUIRED TO FILL THE GROOVES, PLACING A RESILIENT COVERING SHEET OVER THE FILLED MOLD AND THEN A RIGID PLANE COVER ON THE RESILIENT SHEET. THE COVER AND SHEET ARE SECURED TO THE MOLD SO THAT THE TRUNCATED PEAKS PRESS INTO THE RESILIENT SHEET THUS REMOVING EXCESS RESINOUS MATERIAL FROM THE TOPS OF THE PEAKS AND EXUDING EXCESS RESINOUS MATERIAL FROM THE MOLD. THE RESINOUS MATERIAL IS THEN ALLOWED TO SET AND AFTER DISASSEMBLING THE COVER …",5회,"Method of making a fine screen
CJ Williams - US Patent 3,557,276, 1971
5회 인용 관련 학술자료 전체 2개의 버전",,,,,Charles J Williams,US,,3557276
"Paediatric multisystem inflammatory syndrome temporally associated with SARS-CoV-2 (PIMS-TS): Prospective, national surveillance, United Kingdom and Ireland, 2020","Jessica Flood, Joseph Shingleton, Emma Bennett, Brodie Walker, Zahin Amin-Chowdhury, Godwin Oligbu, Jacob Avis, Richard M Lynn, Peter Davis, Tara Bharucha, Clare E Pain, Deepthi Jyothish, Elizabeth Whittaker, Buvana Dwarakanathan, Rachael Wood, Christopher Williams, Olivia Swann, Malcolm G Semple, Mary E Ramsay, Christine E Jones, Athimalaipet V Ramanan, Nick Gent, Shamez N Ladhani",2021/4/1,The Lancet Regional Health-Europe,3,,100075,Elsevier,"Background
Paediatric Multisystem Inflammatory Syndrome temporally associated with SARS-CoV-2 (PIMS-TS), first identified in April 2020, shares features of both Kawasaki disease (KD) and toxic shock syndrome (TSS). The surveillance describes the epidemiology and clinical characteristics of PIMS-TS in the United Kingdom and Ireland.
Methods
Public Health England initiated prospective national surveillance of PIMS-TS through the British Paediatric Surveillance Unit. Paediatricians were contacted monthly to report PIMS-TS, KD and TSS cases electronically and complete a detailed clinical questionnaire. Cases with symptom onset between 01 March and 15 June 2020 were included.
Findings
There were 216 cases with features of PIMS-TS alone, 13 with features of both PIMS-TS and KD, 28 with features of PIMS-TS and TSS and 11 with features of PIMS-TS, KD and TSS, with differences in age, ethnicity …",4회,"Paediatric multisystem inflammatory syndrome temporally associated with SARS-CoV-2 (PIMS-TS): Prospective, national surveillance, United Kingdom and Ireland, 2020
J Flood, J Shingleton, E Bennett, B Walker… - The Lancet Regional Health-Europe, 2021
4회 인용 전체 10개의 버전",,,,,,,,
"Data engineering for data analytics: a classification of the issues, and case studies","Alfredo Nazabal, Christopher KI Williams, Giovanni Colavizza, Camila Rangel Smith, Angus Williams",2020/4/27,arXiv preprint arXiv:2004.12929,,,,,"Consider the situation where a data analyst wishes to carry out an analysis on a given dataset. It is widely recognized that most of the analyst's time will be taken up with\emph {data engineering} tasks such as acquiring, understanding, cleaning and preparing the data. In this paper we provide a description and classification of such tasks into high-levels groups, namely data organization, data quality and feature engineering. We also make available four datasets and example analyses that exhibit a wide variety of these problems, to help encourage the development of tools and techniques to help reduce this burden and push forward research towards the automation or semi-automation of the data engineering process.",4회,"Data engineering for data analytics: a classification of the issues, and case studies
A Nazabal, CKI Williams, G Colavizza, CR Smith… - arXiv preprint arXiv:2004.12929, 2020
4회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Discontinuous Maxwell–Rankine stress functions for space frames,"Allan McRobie, Chris Williams",2018/3,International Journal of Space Structures,33,1,35-47,SAGE Publications,This article shows how bending and torsional moments in three-dimensional frames can be represented via a discontinuous Maxwell–Rankine stress function. The associated Rankine reciprocal contains polygonal faces whose areas represent forces. These faces are orthogonal to the member forces (which may include shear forces) and need not be orthogonal to the beams.,4회,"Discontinuous Maxwell–Rankine stress functions for space frames
A McRobie, C Williams - International Journal of Space Structures, 2018
4회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
A stress function for 3D frames,"FA McRobie, CJK Williams",2017/6/15,International Journal of Solids and Structures,117,,104-110,Pergamon,"This paper generalises Rankine diagrams for 3D trusses to be applicable to 3D frames. Rankine diagrams are a graphical representation of a state of self-stress in a 3D truss, with the area of reciprocal polygons representing the axial force in their corresponding original bars. Rankine diagrams are a polyhedral version of the continuous Maxwell–Rankine stress function. In this paper we present a new stress function. It is piecewise linear and discontinuous and it allows the analysis of 3D frames, giving all six stress resultants of axial and shear forces and bending and torsional moments in any member. A succinct statement of the stress function is given in terms of 4D Clifford Algebra.",4회,"A stress function for 3D frames
FA McRobie, CJK Williams - International Journal of Solids and Structures, 2017
4회 인용 관련 학술자료 전체 7개의 버전",,,,,,,,
Input-output non-linear dynamical systems applied to physiological condition monitoring,"Konstantinos Georgatzis, Chris Williams, Christopher Hawthorne",2016/12/10,,,,1-16,PMLR,We present a non-linear dynamical system for modelling the effect of drug infusions on the vital signs of patients admitted in Intensive Care Units (ICUs). More specifically we are interested in modelling the effect of a widely used anaesthetic drug (Propofol) on a patient’s monitored depth of anaesthesia and haemodynamics. We compare our approach with one from the Pharmacokinetics/Pharmacodynamics (PK/PD) literature and show that we can provide significant improvements in performance without requiring the incorporation of expert physiological knowledge in our system.,4회,"Input-output non-linear dynamical systems applied to physiological condition monitoring
K Georgatzis, C Williams, C Hawthorne - Machine Learning for Healthcare Conference, 2016
4회 인용 관련 학술자료 전체 11개의 버전",Machine Learning for Healthcare Conference,,,,,,,
Detecting artifactual events in vital signs monitoring data,"Partha Lal, Christopher KI Williams, Konstantinos Georgatzis, Christopher Hawthorne, Paul McMonagle, Ian Piper, Martin Shaw",2015/9/23,,,,,"Technical report, University of Edinburgh and University of Glasgow","The presence of artifact in intensive care monitoring data is a major problem. For example, maintaining blood pressure in critically ill patients is a key management goal, and yet it is the physiological variable most prone to error. In addition to real-time monitoring, artifact detection is necessary for the proper audit or trial of therapies.
In this study we collect and annotate data from 27 intensive care unit (ICU) patients from the Southern General Hospital in Glasgow. Two models are compared for the detection, removal and cleaning of artifact in the vital signs data, namely the Factorial Switching Linear Dynamical System (FSLDS) and the Discriminative Switching Linear Dynamical System (DSLDS). We also consider a combination of the two, called the α-mixture (as described in sec. 7.3). Three types of artifactual events are considered: blood sample, damped trace (in the arterial line), and suction events. The area under ROC curve (AUC) scores for the detection of these events are: blood sample 0.95, damped trace: 0.79, suction 0.64 (α-mixture), with similar results for the FSLDS and DSLDS. The system is able run in realtime, and we discuss issues that had to be addressed to achieve this.",4회,"Detecting artifactual events in vital signs monitoring data
P Lal, CKI Williams, K Georgatzis, C Hawthorne… - 2015
4회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
"Nature Photon. 2, 175 (2008)","CR Williams, SR Andrews, SA Maier, AI Fernández-Domínguez, L Martín-Moreno, FJ García-Vidal",2007,,,,,,,4회,"Nature Photon. 2, 175 (2008)
CR Williams, SR Andrews, SA Maier… - 2007
4회 인용 관련 학술자료",,,,,,,,
Sequential learning of layered models from video,"Michalis K Titsias, Christopher KI Williams",2006,,,,577-595,"Springer, Berlin, Heidelberg","A popular framework for the interpretation of image sequences is the layers or sprite model, see e.g. [15], [6] . Jojic and Frey [8] provide a generative probabilistic model framework for this task, but their algorithm is slow as it needs to search over discretized transformations (e.g. translations, or affines) for each layer simultaneously. Exact computation with this model scales exponentially with the number of objects, so Jojic and Frey used an approximate variational algorithm to speed up inference. Williams and Titsias [16] proposed an alternative sequential algorithm for the extraction of objects one at a time using a robust statistical method, thus avoiding the combinatorial explosion.
In this chapter we elaborate on our sequential algorithm in the following ways: Firstly, we describe a method to speed up the computation of the transformations based on approximate tracking of the multiple objects in the …",4회,"Sequential learning of layered models from video
MK Titsias, CKI Williams - Toward Category-Level Object Recognition, 2006
4회 인용 관련 학술자료 전체 11개의 버전",,Toward Category-Level Object Recognition,,,,,,
"An expectation maximisation algorithm for one-to-many record linkage, illustrated on the problem of matching far infra-red astronomical sources to optical counterparts","Amos J Storkey, Christopher KI Williams, Emma Taylor, Robert G Mann, Blackford Hill",2005/8,University of Edinburgh Informatics Research Report (EDI-INF-RR-0318).< http://www. inf. ed. ac. uk/publications/report/0318. html,,,,,"The problem of record linkage is often seen simply in terms of making links between data points that might be generated from the same source. However, in many cases the grounds for linking items is itself not certain. In fact it is often desirable to learn, in an unsupervised manner, what form linked objects take in different databases. One simple case of this is the “one to many” linkage problem, where each object in one dataset is potentially linked to one of many objects in another dataset, and where the candidate matches are mutually exclusive. We show how the Expectation Maximisation algorithm can be used for this matching problem, both to calculate the probability of a match, and to learn something about the characteristics that matched objects have. The approach is derived for the specific astronomical problem of linking far infra-red observations to optical counterparts, but is generally applicable. This report outlines the theory of this record linkage procedure, but does not discuss its application or any implementational details.",4회,"An expectation maximisation algorithm for one-to-many record linkage, illustrated on the problem of matching far infra-red astronomical sources to optical counterparts
AJ Storkey, CKI Williams, E Taylor, RG Mann, B Hill - University of Edinburgh Informatics Research Report …, 2005
4회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
The stability of kernel principal components analysis and its relation to the process eigenspectrum,"Christopher Williams, John S Shawe-taylor",2003,,,,383-390,MIT Press,"In this paper we analyze the relationships between the eigenvaluesof the mxm Gram matrix K for a kernel k (·,.) corresponding to asample Xl,..., Xm drawn from a density p (x) and the eigenvaluesof the corresponding continuous eigenproblem. We bound the differencesbetween the two spectra and provide a performance boundon kernel PCA.",4회,"The stability of kernel principal components analysis and its relation to the process eigenspectrum
C Williams, JS Shawe-taylor - Advances in Neural Information Processing Systems …, 2003
4회 인용 관련 학술자료",,Advances in Neural Information Processing Systems 15 (NIPS 2002),,,,,,
Dynamic trees: Learning to model outdoor scenes,"Nicholas J Adams, Christopher KI Williams",2002/5/28,,,,82-96,"Springer, Berlin, Heidelberg","This paper considers the dynamic tree (DT) model, first introduced in [1]. A dynamic tree specifies a prior over structures of trees, each of which is a forest of one or more tree-structured belief networks (TSBN). In the literature standard tree-structured belief network models have been found to produce “blocky” segmentations when naturally occurring boundaries within an image did not coincide with those of the subtrees in the fixed structure of the network. Dynamic trees have a flexible architecture which allows the structure to vary to create configurations where the subtree and image boundaries align, and experimentation with the model has shown significant improvements.
Here we derive an EM-style update based upon mean field inference for learning the parameters of the dynamic tree model and apply it to a database of images of outdoor scenes where all of its parameters are learned. DTs are …",4회,"Dynamic trees: Learning to model outdoor scenes
NJ Adams, CKI Williams - European Conference on Computer Vision, 2002
4회 인용 관련 학술자료 전체 11개의 버전",European Conference on Computer Vision,,,,,,,
The structural design of fabric structures to resist wind loading,CJK Williams,1997,RESEARCH PAPER-HEALTH AND SAFETY EXECUTIVE LONDON,38,,74-82,HEALTH & SAFETY EXECUTIVE,,4회,"The structural design of fabric structures to resist wind loading
CJK Williams - … PAPER-HEALTH AND SAFETY EXECUTIVE LONDON, 1997
4회 인용 관련 학술자료",,,,,,,,
Detecting and reconstructing vascular trees in retinal images,"Piotr Jasiobedzki, Christopher KI Williams, Feng Lu",1994/5/11,,2167,,815-825,International Society for Optics and Photonics,"Reconstruction of the vascular tree in retinal (ocular fundus) images is important, because it yields information such as the shape and size of individual vessels, their branching pattern and arterio-venous crossings, thereby providing information on the condition of the retina. The vascular tree is also helpful in the registration of retinal images. In this paper we describe an automated technique for detecting and reconstructing vascular trees, based on a robust detection of vessel candidates (ribbonlike features), their labelling using a neural network (NN), and a final reconstruction of the vessel tree using these labels. The NN uses vessel models automatically built during a training phase and does not rely on any explicit user specified models or sets of features.",4회,"Detecting and reconstructing vascular trees in retinal images
P Jasiobedzki, CKI Williams, F Lu - Medical Imaging 1994: Image Processing, 1994
4회 인용 관련 학술자료 전체 2개의 버전",Medical Imaging 1994: Image Processing,,,,,,,
Travelling waves and standing waves on fabric structures,CJK Williams,1990/11/6,Structural Engineer,68,21/6,,,"Synopsis the fluid. At the particular instant of time at which the ‘snapshot’in Fig The classical theory of travelling and standing waves is applied 1 was taken, the line joining A and B was horizontal and the line joining to the case of wind blowing across a fabric structure. Results A and C was vertical. The anticlockwise angular velocity of the line joining are obtained which are of practical importance for the design A and B is equal to of fabric structures. vertical velocity of B-vertical velocity of A-(v+* v)-V",4회,"Travelling waves and standing waves on fabric structures
CJK Williams - Structural Engineer, 1990
4회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
INFLUENCE OF TRAINING ON MAXIMUM OXYGEN-UPTAKE AND ENDURANCE CAPACITY DURING SINGLE LEG EXERCISE,"PK Bland, C Williams",1982/1/1,,327,JUN,P57-P57,CAMBRIDGE UNIV PRESS,,4회,"INFLUENCE OF TRAINING ON MAXIMUM OXYGEN-UPTAKE AND ENDURANCE CAPACITY DURING SINGLE LEG EXERCISE
PK Bland, C Williams - JOURNAL OF PHYSIOLOGY-LONDON, 1982
4회 인용 관련 학술자료",JOURNAL OF PHYSIOLOGY-LONDON,,,,,,,
Classroom-Based Motivational Interviewing for Improving College Students’ Academic Performance: A Randomized Trial,"Gerald G Strait, Christopher Williams, Christopher Peters",2019/4,Teaching of Psychology,46,2,164-167,SAGE Publications,"In this study, we used a randomized control trial (N = 84) to evaluate the effects of a classroom-based motivational interviewing intervention on undergraduate psychology students’ test performance. Results indicated that students in the treatment group (n = 38) demonstrated significant increases in their exam grades following the intervention (d = .34). However, these changes were not significantly different from students in a control group (n = 43) who received a handout on study tips.",3회,"Classroom-Based Motivational Interviewing for Improving College Students’ Academic Performance: A Randomized Trial
GG Strait, C Williams, C Peters - Teaching of Psychology, 2019
3회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Estimating Bacterial Load in FCFM Imaging,"Sohan Seth, Ahsan R Akram, Kevin Dhaliwal, Christopher KI Williams",2017/7/11,,,,909-921,"Springer, Cham","We address the task of detecting bacteria and estimating bacterial load in the human distal lung with fibered confocal fluorescence microscopy (FCFM) and a targeted smartprobe. Bacteria appear as bright dots in the image when exposed to a smartprobe, but they are often difficult to detect due to the presence of background autofluorescence inherent to human lungs. In this study, we create a database of annotated image frames where a clinician has labelled bacteria, and use this database for supervised learning to build a suitable bacterial load estimation software.",3회,"Estimating Bacterial Load in FCFM Imaging
S Seth, AR Akram, K Dhaliwal, CKI Williams - Annual Conference on Medical Image Understanding …, 2017
3회 인용 관련 학술자료 전체 4개의 버전",Annual Conference on Medical Image Understanding and Analysis,,,,,,,
Artefact in physiological data collected from patients with brain injury: Quantifying the problem and providing a solution using a factorial switching linear dynamical systems …,"Konstantinos Georgatzis, Partha Lal, Christopher Hawthorne, Martin Shaw, Ian Piper, Claire Tarbert, Rob Donald, Christopher KI Williams",2016,,,,301-305,"Springer, Cham","Introduction: High-resolution, artefact-free and accurately annotated physiological data are desirable in patients with brain injury both to inform clinical decision-making and for intelligent analysis of the data in applications such as predictive modelling. We have quantified the quality of annotation surrounding artefactual events and propose a factorial switching linear dynamical systems (FSLDS) approach to automatically detect artefact in physiological data collected in the neurological intensive care unit (NICU). Methods: Retrospective analysis of the BrainIT data set to discover potential hypotensive events corrupted by artefact and identify the annotation of associated clinical interventions. Training of an FSLDS model on clinician-annotated artefactual events in five patients with severe traumatic brain injury. Results: In a subset of 187 patients in the BrainIT database, 26.5 % of potential hypotensive events …",3회,"Artefact in physiological data collected from patients with brain injury: Quantifying the problem and providing a solution using a factorial switching linear dynamical systems approach
K Georgatzis, P Lal, C Hawthorne, M Shaw, I Piper… - Intracranial Pressure and Brain Monitoring XV, 2016
3회 인용 관련 학술자료 전체 6개의 버전",,Intracranial Pressure and Brain Monitoring XV,,,,,,
The use of dynamic relaxation to solve the differential equation describing the shape of the tallest possible building,Dragos I Naicu,2015/10/19,,,,34-45,CIMNE,"The problem of finding the tallest possible column that can be constructed from a given volume of material without buckling under its own weight was finally solved by Keller and Niordson in 1966. The cross-sectional size of the column reduces with height so that there is less weight near the top and more bending stiffness near the base. Their theory can also be applied to tall buildings if the weight is adjusted to include floors, live load, cladding and finishes. In this paper we simplify the Keller and Niordson derivation and extend the theory to materials with non-linear elasticity, effectively limiting the stress in the vertical structure of the building. The result is one highly non-linear ordinary differential equation which we solve using dynamic relaxation.",3회,"The use of dynamic relaxation to solve the differential equation describing the shape of the tallest possible building
DI Naicu - Textiles composites and inflatable structures VII …, 2015
3회 인용 관련 학술자료 전체 7개의 버전","Textiles composites and inflatable structures VII: proceedings of the VII International Conference on Textile Composites and Inflatable Structures, Barcelona, Spain. 19-21 October, 2015",,,,,,,
Tree-Cut for Probabilistic Image Segmentation,"Shell X Hu, Christopher KI Williams, Sinisa Todorovic",2015/6/11,arXiv preprint arXiv:1506.03852,,,,,"This paper presents a new probabilistic generative model for image segmentation, ie the task of partitioning an image into homogeneous regions. Our model is grounded on a mid-level image representation, called a region tree, in which regions are recursively split into subregions until superpixels are reached. Given the region tree, image segmentation is formalized as sampling cuts in the tree from the model. Inference for the cuts is exact, and formulated using dynamic programming. Our tree-cut model can be tuned to sample segmentations at a particular scale of interest out of many possible multiscale image segmentations. This generalizes the common notion that there should be only one correct segmentation per image. Also, it allows moving beyond the standard single-scale evaluation, where the segmentation result for an image is averaged against the corresponding set of coarse and fine human annotations, to conduct a scale-specific evaluation. Our quantitative results are comparable to those of the leading gPb-owt-ucm method, with the notable advantage that we additionally produce a distribution over all possible tree-consistent segmentations of the image.",3회,"Tree-Cut for Probabilistic Image Segmentation
SX Hu, CKI Williams, S Todorovic - arXiv preprint arXiv:1506.03852, 2015
3회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
CFD modelling of fall pipe rock dumping using PICIN,"Qiang Chen, David M Kelly, Jeremy Spearman, Aggelos Dimakopoulos, Jun Zang, CHRIS JK WILLIAMS",2015,,,,,,"In this paper fall pipe rock dumping is investigated in 2D using the PICIN CFD model. PICIN employs the hybrid Eulerian-Lagrangian full particle Particle-In-Cell framework for incompressible free surface flow augmented with a full two-way fluid-solid interaction model. The PICIN model is first compared against a benchmark case of two circular particles falling in a water-filled tube. The results agree well with the numerical predictions of Patankar (2001). When applied to cases of randomly shaped rocks falling in pipe, the PICIN model seems to capture the physical processes and mechanisms that lead to clustering of the rocks.",3회,"CFD modelling of fall pipe rock dumping using PICIN
Q Chen, DM Kelly, J Spearman, A Dimakopoulos… - The Proceedings of the Coastal Sediments 2015, 2015
3회 인용 관련 학술자료 전체 5개의 버전",,The Proceedings of the Coastal Sediments 2015,,,,,,
Self-examination behaviors for syphilis symptoms among HIV-infected men,"Melanie M Taylor, Brandy Peterson, John Post, Carol Williams, Thanes Vanig, Michelle Winscott",2010/10,Journal of acquired immune deficiency syndromes (1999),55,2,284,NIH Public Access,"METHODS
The 2 Phoenix-area clinics that reported the highest number of syphilis cases in 2007 were chosen for this education program that commenced in January 2008 and lasted 12 months. Clinic A is a publically funded HIV clinic with a patient population of approximately 1500 clients. Clinic B is a private clinic that provides care to approximately 1200 HIV patients.",3회,"Self-examination behaviors for syphilis symptoms among HIV-infected men
MM Taylor, B Peterson, J Post, C Williams, T Vanig… - Journal of acquired immune deficiency syndromes …, 2010
3회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
British Museum Great Court,"Paul Shepherd, Christopher JK Williams",2010/10,,,,122-125,Thames & Hudson,"Shepherd, P., & Williams, CJK (2010). British Museum Great Court. In J. Burry, & M. Burry (Eds.), The New Mathematics of Architecture (pp. 122-125). New York: Thames & Hudson … British Museum Great Court. / Shepherd, Paul; Williams, Christopher JK … The New Mathematics of Architecture. ed. / Jane Burry; Mark Burry. New York : Thames & Hudson, 2010. p. 122-125 … Shepherd, P & Williams, CJK 2010, British Museum Great Court. in J Burry & M Burry (eds), The New Mathematics of Architecture. Thames & Hudson, New York, pp. 122-125.",3회,"British Museum Great Court
P Shepherd, CJK Williams - The New Mathematics of Architecture, 2010
3회 인용 관련 학술자료",,The New Mathematics of Architecture,,,,,,
Physiological monitoring with factorial switching linear dynamical systems,"J Quinn, C Williams",2010,Probabilistic Methods for Time-Series Analysis,,,,,"A common way to handle nonlinearity in complex time series data is to try splitting the data up into a number of simpler segments. Sometimes we have domain knowledge to support this piecewise modelling approach, for example in condition monitoring applications. In such problems, the evolution of some observed data is governed by a number of hidden factors that switch between different modes of operation. In real-world data, eg from medicine, robotic control or finance, we might be interested in factors which represent pathologies, mechanical failure modes, or economic conditions respectively. Given just the monitoring data, we are interested in recovering the state of the factors that gave rise to it. A good model for this type of problem is the Switching Linear Dynamical System (SLDS), which has been discussed in previous chapters. A latent “switch” variable in this type of model selects between different linear-Gaussian state spaces. In this chapter we consider a generalisation, the Factorial Switching Linear Dynamical System (FSLDS), where instead of a single switch setting there are multiple discrete factors that collectively determine the dynamics. In practice there may be a very large number of possible factors, and we may only have explicit knowledge of commonly occurring ones.
We illustrate how the FSLDS can be used in the physiological monitoring of premature babies in intensive care. This application is a useful introduction because it has complex observed data, a diverse range of factors affecting the observations, and the challenge of many “unknown” factors. It also provides an opportunity to demonstrate the ways in which …",3회,"Physiological monitoring with factorial switching linear dynamical systems
J Quinn, C Williams - Probabilistic Methods for Time-Series Analysis, 2010
3회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
A Tutorial Introduction to Stochastic Differential Equations: Continuous-time Gaussian Markov Processes,CKI Williams,2006/12,"NIPS workshop on Dynamical Systems, Stochastic Processes and Bayesian Inference",,,,,"Page 1. A Tutorial Introduction to Stochastic Differential Equations: Continuous-time Gaussian Markov Processes Chris Williams Institute for Adaptive and Neural Computation School of Informatics, University of Edinburgh, UK December 2006 1 Page 2. AR Processes: Discrete-time Gaussian Markov Processes A discrete-time autoregressive (AR) process of order p: Xt = p ∑ k=1 akXt−k + b0Zt, where Zt ∼ N(0,1) and all Zt's are iid. AR(2) example: . . . . Linear combinations of Gaussians are Gaussian 2 Page 3. From discrete to continuous time In continuous time, have not only the function value but also p of its derivatives at time t apX(p)(t) + ap−1X(p−1)(t) + ... a0X(t) = b0Z(t), where Z(t) is a white Gaussian noise process with covariance …",3회,"A Tutorial Introduction to Stochastic Differential Equations: Continuous-time Gaussian Markov Processes
CKI Williams - NIPS workshop on Dynamical Systems, Stochastic …, 2006
3회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Position encoding dynamic trees for image sequence analysis,"SN Felderhof, AJ Storkey, CKI Williams",2002,,,,,University of Edinburgh,,3회,"Position encoding dynamic trees for image sequence analysis
SN Felderhof, AJ Storkey, CKI Williams - 2002
3회 인용 관련 학술자료",,,Technical report,,,,,
Products and sums of tree-structured gaussian processes,"Christopher KI Williams, Stephen N Felderhof",2001,,,,,,"Recently Hinton (1999) has introduced the Products of Experts (PoE) model. In this paper we consider a PoE model in which each expert is a Gaussian, giving rise to a product model that is also Gaussian. However, if we constrain each expert to be a tree-structured Gaussian process (TSGP) the product of these then has a more complex structure than the individual trees. By way of comparison we also consider the framework within which the resultant process is constructed from the sum of tree-structured Gaussian processes. The result of this method is also a Gaussian process. We investigate the approximation of various target stationary processes with these Product of Experts and Sum of Experts models. Our results show that the preferred choice between the two models depends on the type of target process. We also show that for AR (1) and MA (2) target processes, an exact representation of these processes using only two component TSGPs can be found. Recently Hinton (1999...",3회,"Products and sums of tree-structured gaussian processes
CKI Williams, SN Felderhof - 2001
3회 인용 관련 학술자료",,,,,,,,
SDTs: Sparse dynamic trees,"Nicholas J Adams, Christopher KI Williams",1999/9/7,,2,,527-532,IET,"We introduce a class of image models which we call sparse dynamic trees (SDTs). These extend our previous work (1999) on dynamic trees by introducing a top-down generative prior for the tree structures, which leads to a sparse use of nodes in the network. We present results showing the properties of these networks in action on 1D patterns.",3회,"SDTs: Sparse dynamic trees
NJ Adams, CKI Williams - 1999 Ninth International Conference on Artificial …, 1999
3회 인용 관련 학술자료 전체 8개의 버전",1999 Ninth International Conference on Artificial Neural Networks ICANN 99.(Conf. Publ. No. 470),,,,,,,
Effect of a high volume of carbohydrate solution on rehydration during recovery from prolonged running and subsequent exercise capacity,"SH Wong, C Williams, N Adams",1996/8/1,JOURNAL OF SPORTS SCIENCES,14,4,351-352,TAYLOR & FRANCIS LTD,,3회,"Effect of a high volume of carbohydrate solution on rehydration during recovery from prolonged running and subsequent exercise capacity
SH Wong, C Williams, N Adams - JOURNAL OF SPORTS SCIENCES, 1996
3회 인용 관련 학술자료",,,,,,,,
THE USE OF MODIFIED BÉZIER TRIANGLES FOR THE,CJK Williams,1994,Structural Engineering Review,6,3-4,245-253,,"A method is described for the form finding and analysis of cable net structures using curvilinear triangular finite elements. Each triangle is described by a complete cubic function of the two element coordinates plus two singular functions to give C"" continuity. The coefficients of the functions are controlled by 12 Bézier points, 10 for the cubic plus two extra points for the singular functions. There are five coordinates at each Bézier point, the three Cartesian coordinates and the “cable number'for each of the two scts of cables making up the net.",3회,"THE USE OF MODIFIED BÉZIER TRIANGLES FOR THE
CJK Williams - Structural Engineering Review, 1994
3회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
On-stream ore liberation detection system,,1972/4/25,,,,,,"A method for determining the extent to which ores should be crushed and ground for optimum beneficiation in which dust is separated from the crushed ore and is then continuously sampled, and concentrated as to the desired mineral component and the concentrate continuously analyzed to determine the content of one of the mineral components thereof. The analysis is then used to determine the extent of grinding to control the composition of the final concentrate. Also the analysis may be used to proportion ore obtained from various sources to assist in controlling the composition of the final concentrate.",3회,"On-stream ore liberation detection system
CJ Williams - US Patent 3,658,260, 1972
3회 인용 관련 학술자료 전체 2개의 버전",,,,,Charles J Williams,US,,3658260
VAEs in the Presence of Missing Data,"Mark Collier, Alfredo Nazabal, Christopher KI Williams",2020/6/9,arXiv preprint arXiv:2006.05301,,,,,"Real world datasets often contain entries with missing elements eg in a medical dataset, a patient is unlikely to have taken all possible diagnostic tests. Variational Autoencoders (VAEs) are popular generative models often used for unsupervised learning. Despite their widespread use it is unclear how best to apply VAEs to datasets with missing data. We develop a novel latent variable model of a corruption process which generates missing data, and derive a corresponding tractable evidence lower bound (ELBO). Our model is straightforward to implement, can handle both missing completely at random (MCAR) and missing not at random (MNAR) data, scales to high dimensional inputs and gives both the VAE encoder and decoder principled access to indicator variables for whether a data element is missing or not. On the MNIST and SVHN datasets we demonstrate improved marginal log-likelihood of observed data and better missing data imputation, compared to existing approaches.",2회,"VAEs in the Presence of Missing Data
M Collier, A Nazabal, CKI Williams - arXiv preprint arXiv:2006.05301, 2020
2회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
The Extended Dawid-Skene Model,"Michael PJ Camilleri, Christopher KI Williams",2019/9/16,,,,121-136,"Springer, Cham","While label fusion from multiple noisy annotations is a well understood concept in data wrangling (tackled for example by the Dawid-Skene (DS) model), we consider the extended problem of carrying out learning when the labels themselves are not consistently annotated with the same schema. We show that even if annotators use disparate, albeit related, label-sets, we can still draw inferences for the underlying full label-set. We propose the Inter-Schema AdapteR (ISAR) to translate the fully-specified label-set to the one used by each annotator, enabling learning under such heterogeneous schemas, without the need to re-annotate the data. We apply our method to a mouse behavioural dataset, achieving significant gains (compared with DS) in out-of-sample log-likelihood (−3.40 to −2.39) and F1-score (0.785 to 0.864).",2회,"The Extended Dawid-Skene Model
MPJ Camilleri, CKI Williams - Joint European Conference on Machine Learning and …, 2019
2회 인용 관련 학술자료 전체 7개의 버전",Joint European Conference on Machine Learning and Knowledge Discovery in Databases,,,,,,,
Model Criticism in Latent Space,"Sohan Seth, Iain Murray, Christopher KI Williams",2019,Bayesian Analysis,14,3,703-725,International Society for Bayesian Analysis,"Model criticism is usually carried out by assessing if replicated data generated under the fitted model looks similar to the observed data, see eg Gelman, Carlin, Stern, and Rubin (2004, p. 165). This paper presents a method for latent variable models by pulling back the data into the space of latent variables, and carrying out model criticism in that space. Making use of a model's structure enables a more direct assessment of the assumptions made in the prior and likelihood. We demonstrate the method with examples of model criticism in latent space applied to factor analysis, linear dynamical systems and Gaussian processes.",2회,"Model Criticism in Latent Space
S Seth, I Murray, CKI Williams - Bayesian Analysis, 2019
2회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
Fast interaction functions for bond-based peridynamics,"H David Miranda, John Orr, Chris Williams",2018/5/4,European Journal of Computational Mechanics,27,3,247-276,Taylor & Francis,"Numerical implementations of bond-based peridynamics are computationally intensive. We propose a new class of fast interaction functions for constitutive modelling that reduce calculation time when compared to other formulations in the literature. This is achieved by substituting the stretch definition from the original interaction functions with a new stretch measure that we call modified stretch. The resultant interaction functions are proven to approximate the existing formulations, and proven to require equivalent stability and convergence conditions under explicit time integration. Gains of speed greater than 11% were obtained in numerical tests that compared the new functions with those in the literature. The new approach was verified against classical elastic theory using simple examples and shows good agreement. Examples describing three-dimensional quasi-brittle structures are also presented. The …",2회,"Fast interaction functions for bond-based peridynamics
HD Miranda, J Orr, C Williams - European Journal of Computational Mechanics, 2018
2회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Prestressed gridshell structures,"Mats Ander, Alexander Sehlström, Paul Shepherd, Chris JK Williams",2017/9/28,Proceedings of IASS Annual Symposia,2017,16,1-9,International Association for Shell and Spatial Structures (IASS),"This paper describes a method for the form finding of shell structures composed of both compression and tension members which may lie in one layer or two layers. The length of some of the members can be constrained to a fixed length yielding some control of the resulting form found shape. The form finding is accomplished by adjusting the nodal positions until an equilibrium state is reached using dynamic relaxation. If part of a structure is unstable due to compression forces, then a negative mass must be used in the dynamic relaxation. The length constraint is met by adjusting the force density during form finding, again using dynamic relaxation. Finally, case studies are presented where the applied load and the prestress is used to govern the form found shape.",2회,"Prestressed gridshell structures
M Ander, A Sehlström, P Shepherd, CJK Williams - Proceedings of IASS Annual Symposia, 2017
2회 인용 관련 학술자료 전체 16개의 버전",,,,,,,,
Particle–In–Cell numerical solver for free surface flows with fluid–solid interactions,"Qiang Chen, Jun Zang, DM Kelly, CJK Williams, Aggelos Dimakopoulos",2015,"30th International Workshop on Water Waves and Floating Bodies. Bristol, UK",,,,,"In the past few decades Computational Fluid Dynamics (CFD) techniques have been widely used for both academic research and commercial engineering applications. CFD techniques have become more and more popular as computational power has continued to increase. For the solution of the Navier–Stokes equations three principal approaches are typically employed these being: Eulerian methods, Lagrangian methods and hybrid Eulerian-Lagrangian methods. While grid based Eulerian methods perform well in terms of equation discretization, enforcing incompressibility and improving computational efficiency [3], they have drawbacks with regards to integration of the advection term and require more effort in handling the free surface boundary especially when its is subject to extensive deformation. From this point of view, purely Lagrangian techniques such as the SPH method and Moving Particle Semi Implicit (MPS) schemes seem to be more suitable for free surface fluid problems as they can handle large free surface deformation easily (eg [1]). In addition Lagrangian methods can integrate the advection term relatively trivially through advecting the discretized fluid elements. However, pure Lagrangian methods tend to be extremely demanding in terms of CPU time as millions of particles may be used for high accuracy (eg [1]). Our work is motivated by the idea of developing a hybrid Eulerian–Lagrangian approach based on the PIC framework which exhibits both the flexibility of the SPH method in terms of ability to simulate complex problems and the computational efficiency of Eulerian methods. The PIC method was originally devised for …",2회,"Particle–In–Cell numerical solver for free surface flows with fluid–solid interactions
Q Chen, J Zang, DM Kelly, CJK Williams… - 30th International Workshop on Water Waves and …, 2015
2회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
The Pascal Visual Object Classes Challenge: A Retrospective,"CKI Williams, J Winn, A Zisserman, L Van Gool, SMA Eslami, M Everingham",2014,Int. J. Comput. Vis.,111,1,98136,,"The Pascal Visual Object Classes Challenge: A Retrospective. CKI Williams, J Winn, A Zisserman, L Van Gool, SMA Eslami, M Everingham Int. J. Comput. Vis. 111:11, 98136, 2014.",2회,"The Pascal Visual Object Classes Challenge: A Retrospective
CKI Williams, J Winn, A Zisserman, L Van Gool… - Int. J. Comput. Vis., 2014
2회 인용 관련 학술자료",,,,,,,,
Christopher Williams: The Production Line of Happiness,"Christopher Williams, Mark Benjamin Godfrey, Roxana Marcoci, Matthew S Witkovsky",2014,,,,,Art Institute of Chicago,"Christopher Williams’ recent photographs reveal the unexpected beauty and cultural resonance of commercial, industrial and instructional photography, and also adopts their production methods. Often working in collaboration with set designers, models and technicians, the resulting technically precise photographs recall imagery from 1960s advertising, the Cold War era, as well as the histories of art, photography and cinema. However, closer inspection reveals that flaws and aberrations which would usually be removed in production or postproduction, such as a model's dirty feet or a bruise on a ripe apple, remain in the final images. Williams also sees the photographs themselves as part of a larger system of display which includes exhibition design, walls, books, posters, videos, vitrines, and signage, and uses these elements playfully within the exhibition.
The Production Line of Happiness brings together over 50 photographs from Williams’ 35-year career, and is on show from 29 April 2015. Five new works never seen before in the UK go on display including a pristine image of a broken Citroen car headlight, an image influenced by British and European Pop art. The photographs are displayed in an architectural installation specially conceived by the artist and inspired by histories of display. Temporary walls come from art institutions in the Rheinland region of Germany, where Williams currently lives and works and are both a reference to and a partial reprisal of a 2009 exhibition at the Bonner Kunstverein made in collaboration with Austrian artist Mathias Poledna.",2회,"Christopher Williams: The Production Line of Happiness
C Williams, MB Godfrey, R Marcoci, MS Witkovsky - 2014
2회 인용 관련 학술자료",,,,,,,,
In Memoriam: Mark Everingham,"Andrew Zisserman, John Winn, Andrew Fitzgibbon, Luc Van Gool, Josef Sivic, Chris Williams, David Hogg",2012/11/1,IEEE Computer Architecture Letters,34,11,2081-2082,IEEE Computer Society,"MARK EVERINGHAM was a brilliant colleague. You may have been aware of him at conferences where he asked penetrating questions that could crystallize a key aspect of a paper. In conversation with him you might have been stunned by a new connection he made between areas of research or to a crucial related work. These questions and observations were a reflection of his very broad knowledge and deep understanding of computer vision and machine learning. To us, they demonstrated his intellect and insight, but to him they were just a way of being helpful, a way of ensuring that the field made progress. Mark was incredibly generous with his time. Those of us that worked with him are aware of how much he contributed behind the scenes, without expecting any recognition. Nowhere is this more apparent than in the organization of the PASCAL Visual Object Classes (VOC) challenge to which he devoted colossal amounts of time and effort. There are also the more visible contributions to the community in area chair duties at both CVPR and ECCV, as a program cochair for BMVC, and as a member of the TPAMI editorial board. Everything he did: research, experimentation, software, paper writing, talks, was of the highest standard and a testament to his intellectual stamina. He was kind and demonstrated a gentle, dry wit that made time spent with Mark both stimulating and enjoyable. Mark was born in Bristol in 1973, winning a scholarship to Clifton College, and completing his A levels at Filton College in 1991. Directly after school he worked on a research project for the Bristol Eye Hospital, developing software for remote electrodiagnosis …",2회,"In Memoriam: Mark Everingham
A Zisserman, J Winn, A Fitzgibbon, L Van Gool, J Sivic… - IEEE Computer Architecture Letters, 2012
2회 인용 관련 학술자료 전체 12개의 버전",,,,,,,,
Numerical simulation of a floating body in multible degrees of freedom,"J Westphalen, DM Greaves, A Hunt-Raby, Christopher JK Williams, PK Stansby, T Stallard",2010/4,,,,81-88,The Royal Institution of Naval Architects,"Computational results for a floating body representing a single cylinder of the Manchester Bobber are compared with measured data from physical tank tests concerning the survivability of this wave energy converter in extreme waves. The float is connected to a counterweight via a pulley system, which is represented by additional forces and restricted degrees of motion in the computational approach. Two setups are discussed. In the first the float is restricted to move in vertical direction only. The second experiment also includes the horizontal displacement. The computations use a Navier-Stokes solver. The equations are discretised using a Finite Volume approach and solved for both water and air employing a Volume of Fluid method and a high resolution interface capturing scheme. For this challenging case, which also includes the inertia of the counterweight, rather than the motion of an independent floating body, the displacements of the float are presented and shown to be in reasonable agreement with the experiments.",2회,"Numerical simulation of a floating body in multible degrees of freedom
J Westphalen, DM Greaves, A Hunt-Raby… - Marine Renewable and Offshore Wind Energy, April 21 …, 2010
2회 인용 관련 학술자료","Marine Renewable and Offshore Wind Energy, April 21, 2010-April 23, 2010",,,,,,,
Advances in Neural Information Processing Systems 23: 24th Annual Conference on Neural Information Processing Systems 2010. Proceedings of a meeting held 6-9 December 2010 …,"JD Lafferty, CKI Williams, J Shawe-Taylor, RS Zemel, A Culotta",2010,,,,,"Curran Associates, Inc.",,2회,"Advances in Neural Information Processing Systems 23: 24th Annual Conference on Neural Information Processing Systems 2010. Proceedings of a meeting held 6-9 December 2010, Vancouver, British Columbia, Canada.
JD Lafferty, CKI Williams, J Shawe-Taylor, RS Zemel… - NIPS, 2010
2회 인용 관련 학술자료",NIPS,,,,,,,
Probabilistic Models for Image Understanding,"Bill Triggs, Chris Williams",2010,International journal of computer vision,88,2,,,"Aims and scope: Probabilistic models provide a compelling framework for describing image and video content at levels ranging from small image patches to overall scene and motion structure. We solicit papers describing the development, learning and use of principled probabilistic models for image understanding. Relevant topics include (but are not limited to):
• low level models (image patches, random fields),• object recognition/detection,• structural models/image parsing,• structured models of human motion,• probabilistic frameworks for image representation,• efficient algorithms for learning such models,• frameworks and datasets for evaluating such models.",2회,"Probabilistic Models for Image Understanding
B Triggs, C Williams - International journal of computer vision, 2010
2회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Terahertz waveguiding on metamaterials,Christopher Rhys Williams,2009/8,,,,,,"Terahertz time-domain spectroscopy (TTDS) is a powerful spectroscopic technique, combining pulsed broadband operation with high sensitivity coherent detection at room temperature. This thesis describes studies of terahertz surface plasmon polariton (SPP) guidance on a range of metamaterial structures using TTDS. Metamaterials are artificial media constructed from sub-wavelength dimension conducting elements which have an electromagnetic response that can be engineered by creating geometrical plasma-like resonances. In this work, highconfinement terahertz waveguiding is achieved by binding SPPs to cavity resonances which spoof the behaviour of intrinsic surface plasmon resonances found at much higher frequencies. The main aim of these studies is to investigate their properties with regard to potential applications in waveguiding and sensing. The first two chapters of this thesis describe the background to the subject. In chapter 3, the construction of a novel, flexible geometry, fibre-coupled TTDS system using hollow-core photonic crystal fibre (HC-PCF) is described. The extension of the system to include a near-field probe for evanescent field characterisation is also discussed. In chapter 4, we present the first direct observation of terahertz SPP propagation on plasmonic metamaterials consisting of copper sheets patterned with two-dimensional arrays of square copper-lined holes. Wavelength-scale field confinement is experimentally observed over an octave in frequency close to the band edge, representing a two order of magnitude increase in confinement compared to a flat metal sheet. In chapter 5, metamaterials consisting …",2회,"Terahertz waveguiding on metamaterials
CR Williams - 2009
2회 인용 관련 학술자료 전체 3개의 버전",,,,University of Bath,,,,
Numerical simulation of an oscillating cone at the water surface using computational fluid dynamics,"Jan Westphalen, Deborah Greaves, Chris Williams, Kevin Drake, Paul Taylor",2009/4,,,,,,In coastal and offshore engineering fluid-structure interaction is of great interest. Realistic estimation of hydrodynamic forces and motions is essential in the safe and cost efficient design of,2회,"Numerical simulation of an oscillating cone at the water surface using computational fluid dynamics
J Westphalen, D Greaves, C Williams, K Drake… - 2009
2회 인용 관련 학술자료",,,,,,,,
Unsupervised learning of multiple aspects of moving objects from video,"Michalis K Titsias, Christopher KI Williams",2005/11/11,,,,746-756,"Springer, Berlin, Heidelberg","A popular framework for the interpretation of image sequences is based on the layered model; see e.g. Wang and Adelson [8], Irani et al. [2]. Jojic and Frey [3] provide a generative probabilistic model framework for this task. However, this layered models do not explicitly account for variation due to changes in the pose and self occlusion. In this paper we show that if the motion of the object is large so that different aspects (or views) of the object are visible at different times in the sequence, we can learn appearance models of the different aspects using a mixture modelling approach.",2회,"Unsupervised learning of multiple aspects of moving objects from video
MK Titsias, CKI Williams - Panhellenic Conference on Informatics, 2005
2회 인용 관련 학술자료 전체 10개의 버전",Panhellenic Conference on Informatics,,,,,,,
new physical layer architecture for future nulti-mode mobile communication systems,"Y Li, S McLaughlin, D Cruickshank, C Williams",2004/11,,,,,,"New Physical Layer Architecture for Future Multi-Mode Mobile Communications Systems. Y Li, S McLaughlin, DGM Cruickhsank, C Williams Wireless World Research Forum Research Programme, 11/2004.",2회,"new physical layer architecture for future nulti-mode mobile communication systems
Y Li, S McLaughlin, D Cruickshank, C Williams - WWRF, 2004
2회 인용 관련 학술자료",,WWRF,,,,,,
Recovery from prolonged intermittent shuttle running following 9 days of ascorbic acid supplementation,"DM Bailey, C Williams, D Markovitch, A Dean, JMM Webb, JR Powell",2002/2/1,,539,,67P-67P,CAMBRIDGE UNIV PRESS,,2회,"Recovery from prolonged intermittent shuttle running following 9 days of ascorbic acid supplementation
DM Bailey, C Williams, D Markovitch, A Dean… - JOURNAL OF PHYSIOLOGY-LONDON, 2002
2회 인용 관련 학술자료",JOURNAL OF PHYSIOLOGY-LONDON,,,,,,,
Comparing Mean Field and Exact EM in Tree Structured Belief Networks,"Nicholas J Adams, Christopher KI Williams, Amos J Storkey",2001/6,Fourth International ICSC Symposium on Soft Computing and Intelligent Systems for Industry. ICSC-NAISO Adademic Press,,,,,"We make a thorough comparison between a variationally-based learning approach and exact EM using tractable fixed architecture tree-structured belief networks, and so gain valuable insights into learning with mean field methods. We then introduce disconnections into the model showing how they can be folded into a single structure by viewing them as degeneracies in the conditional probability tables, and investigate learning with them. The results suggest that mean field performs sufficiently well to be useful in learning in more complex models where standard approaches are intractable.",2회,"Comparing Mean Field and Exact EM in Tree Structured Belief Networks
NJ Adams, CKI Williams, AJ Storkey - Fourth International ICSC Symposium on Soft …, 2001
2회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Gaussian regression and optimal finite dimensional linear models,"Huaiyu Zhu Santa, Huaiyu Zhu, Christopher KI Williams, Richard Rohwer, Michal Morciniec",1997,,,,,,"The problem of regression under Gaussian assumptions is treated generally. The relationship between Bayesian prediction, regularization and smoothing is elucidated. The ideal regression is the posterior mean and its computation scales as O (n 3), where n is the sample size. We show that the optimal m-dimensional linear model under a given prior is spanned by the first m eigenfunctions of a covariance operator, which is a trace-class operator. This is an infinite dimensional analogue of principal component analysis. The importance of Hilbert space methods to practical statistics is also discussed. Keywords: regression, Gaussian measures, linear model, principal component, spline, regularization, eigenfunctions. Gaussian Regression and Optimal Finite Dimensional Linear Models 3 1 Introduction Many problems in computation and statistics can be generally described as fitting a"" curve"" from a discrete set of data. Here we allow a liberal interpretation of curve which could be any mappin...",2회,"Gaussian regression and optimal finite dimensional linear models
HZ Santa, H Zhu, CKI Williams, R Rohwer, M Morciniec - Neural Networks and Machine Learning, 1997
2회 인용 관련 학술자료",Neural Networks and Machine Learning,,,,,,,
The collaboration between architects and engineers in the design of unconventional structures,"M Voyatzaki, Christopher Williams",1996,,,,,,"Voyatzaki, M., & Williams, C. (1996). The collaboration between architects and engineers in the design of unconventional structures. 454-458. Paper presented at Institut fur Konstrukton und Entwurf II, Universitat Stuttgrart … The collaboration between architects and engineers in the design of unconventional structures. / Voyatzaki, M; Williams, Christopher … 1996. 454-458 Paper presented at Institut fur Konstrukton und Entwurf II, Universitat Stuttgrart … Voyatzaki, M & Williams, C 1996, 'The collaboration between architects and engineers in the design of unconventional structures', Paper presented at Institut fur Konstrukton und Entwurf II, Universitat Stuttgrart, 1/01/96 pp. 454-458 … Voyatzaki M, Williams C. The collaboration between architects and engineers in the design of unconventional structures. 1996. Paper presented at Institut fur Konstrukton und Entwurf II, Universitat Stuttgrart … Voyatzaki, M ; Williams …",2회,"The collaboration between architects and engineers in the design of unconventional structures
M Voyatzaki, C Williams - Institut fur Konstrukton und Entwurf II, 1996
2회 인용 관련 학술자료",Institut fur Konstrukton und Entwurf II,,,,,,,
ptype: probabilistic type inference,"Taha Ceritli, Christopher KI Williams, James Geddes",2020/3/16,Data Mining and Knowledge Discovery,,,1-35,Springer US,"Type inference refers to the task of inferring the data type of a given column of data. Current approaches often fail when data contains missing data and anomalies, which are found commonly in real-world data sets. In this paper, we propose ptype, a probabilistic robust type inference method that allows us to detect such entries, and infer data types. We further show that the proposed method outperforms existing methods.",1회,"ptype: probabilistic type inference
T Ceritli, CKI Williams, J Geddes - Data Mining and Knowledge Discovery, 2020
1회 인용 관련 학술자료 전체 8개의 버전",,,,,,,,
A building of unlimited height,"Mats Ander, Jens Olsson, Paul Shepherd, Robert Stuart-Smith, Christopher Williams",2019/10/7,Proceedings of IASS Annual Symposia,2019,4,1-8,International Association for Shell and Spatial Structures (IASS),"We consider the overall buckling under own weight of a thin-walled column of circular crosssection and a radius that is a hyperbolic sine function of distance from the top of the column. The maximum stress is limited to a given value, but there is no limit to the height of the column. The wall thickness is determined by consideration of local buckling. It can be made to represent a building by adjusting the own weight of the column to include the weight of the floors, finishes, cladding and imposed load.",1회,"A building of unlimited height
M Ander, J Olsson, P Shepherd, R Stuart-Smith… - Proceedings of IASS Annual Symposia, 2019
1회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Advanced critical care practitioners–Practical experience of implementing the Advanced Critical Care Practitioner Faculty of Intensive Care Medicine Curriculum in a London …,"Christopher Williams, Emma Bennett, Nia Bromage",2019/2,Journal of the Intensive Care Society,20,1,NP1-NP2,SAGE Publications,"Dear Editor, We read with interest the article by Lee et al. 1 and thought it would be useful to present the feedback from our survey after implementing an advanced critical care practitioner (ACCP) programme in a UK tertiary critical care centre. Our training programme appears to mirror that of Lee et al. 1 and began in 2012; currently there are two qualified FICM registered and one trainee ACCP. Many audits and evaluations of advanced practice roles concentrate on patient experience2 or specific procedures3, 4; little has been done locally or nationally to evaluate the impact of the ACCP role. The impact of ACCPs on our unit was evaluated through a questionnaire distributed to the MDT to gain their experiences and perceptions. In total, 50 responses were collected and we inadvertently obtained a realistic cross section of the MDT (20 doctors, 20 nurses, 9 physiotherapists and an HCSW) with a mixture of grades …",1회,"Advanced critical care practitioners–Practical experience of implementing the Advanced Critical Care Practitioner Faculty of Intensive Care Medicine Curriculum in a London Critical Care Unit: Response letter
C Williams, E Bennett, N Bromage - Journal of the Intensive Care Society, 2019
1회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
From a weightless bent wire coat hanger to shell structures via the Beltrami stress tensor,"Samar Malek, Allan McRobie, Paul Shepherd, Chris Williams",2017/3/1,Journal of the International Association for Shell and Spatial Structures,58,1,39-50,International Association for Shell and Spatial Structures (IASS),"A weightless wire coat hanger bent out of its plane is one of the simplest possible structures. All it does is transfer a force and moment around a closed space curve. Assembling a family of coat hangers enables us to build up trusses and frames and if we allow an infinite number of coat hangers which overlap we can assemble plates, shells and fully three dimensional structures. We can apply loads to these structures via a loading frame and wires, also made from coat hangers. A wire carrying an electric current produces a magnetic field in the space surrounding the wire. For the bent coat hanger we can imagine that there is a vector field surrounding the wire as a result of the force and moment in the wire. We can use this vector field to obtain expressions for the forces and moments in a shell in equilibrium with applied loads.",1회,"From a weightless bent wire coat hanger to shell structures via the Beltrami stress tensor
S Malek, A McRobie, P Shepherd, C Williams - Journal of the International Association for Shell and …, 2017
1회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Peridynamics for concrete structures–a new explicit analysis method,"Helder Miranda, Christopher Williams, John Orr",2016/7/4,,,,,University of Dundee,"Optimisation of performance and reduction of costs of structures are major issues in engineering. However, this optimisation requires very accurate numerical models to predict the behaviour of the structures that are currently not available for concrete structures after they start cracking.Since concrete may develop cracks, which contradict the classical solid mechanics assumption of a continuum, the results obtained are in general not satisfactory. The classical theory of solid mechanics is formulated in terms of differential equations relying on the basic assumption of material continuity that does not exist in the cracked material. The presented model is based on the existing peridynamics theory which describes the mechanics of materials by employing integral equations, which are valid during cracking. The discretization of the structure in a set of material particles, correspondent interactions and an explicit scheme of integration based on Verlet method are described. Cracks can form by the breaking of interparticle bonds. The capacity of the model to predict the development of discrete cracks in tensile zones was verified with simple numerical tests.This work can provide the basis for more accurate strategies of predicting concrete structures and similar materials behaviour. The main consequences would be the reduction environmental impacts, cost of construction and also the development of new architectonic concepts along with developments in other industries.",1회,"Peridynamics for concrete structures–a new explicit analysis method
H Miranda, C Williams, J Orr - 2016
1회 인용 관련 학술자료 전체 5개의 버전",,,,,,,,
An explicit method for simulation of quasi-brittle materials and structures based on peridynamic theory,"H David Miranda, Chris Williams, John Orr, North East Bath",2016,12th World Congress on Computational Mechanics,,,,,"This contribution describes a numerical method to solve the peridynamics equations using a simple explicit scheme based on the Euler method [2], where the spatial discretisation consists of a finite set of material particles and interparticle bonds. Cracks may develop by disruption of these interparticle bonds. The onset and evolution of discrete cracks in tensile zones is predicted in this paper using simple examples. The formulation of the method, comparison with the elastic theory and derivation of relations between model parameters and macroscopic elastic modulus are presented. Furthermore, an initial investigation of the model’s ability to reproduce damage through the spontaneous formation of cracks during loading is analysed. The obtained results may improve the models used to describe quasi-brittle materials vulnerable to cracking and concrete structures in particular. Those improved models may lead to …",1회,"An explicit method for simulation of quasi-brittle materials and structures based on peridynamic theory
HD Miranda, C Williams, J Orr, NE Bath - 12th World Congress on Computational Mechanics, 2016
1회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Adapting stroke pressure of a transmission control element,,2012/5/15,,,,,,"A method for controlling a transmission includes applying a reference stroke pressure to an oncoming control element while executing a downshift to a target gear, determining a stroke pressure adjustment in response to a turbine speed flare during the downshift, and re-executing the downshift while applying to the oncoming element an adapted stroke pressure that is a sum of the stroke pressure adjustment and the reference stroke pressure.",1회,"Adapting stroke pressure of a transmission control element
TG Feldpausch, KM Jungbluth, CM Williams… - US Patent 8,180,538, 2012
1회 인용 관련 학술자료 전체 4개의 버전",,,,,"Terry G Feldpausch, Karl M Jungbluth, Christopher M Williams, Todd J Newman, Henry A Rebandt",US,12277356,8180538
Aspirin and Other Antiplatelet Agents and Their Effects on Cardiovascular Disease in Type 2 Diabetes,"CD Williams, MS Kirkman",2012/2/1,,6,1,62-70,Current Science Inc.,"Reduction of cardiovascular disease (CVD) events in patients with type 2 diabetes remains an area of intense interest and research. Recent trials of lower systolic blood pressure goals and combination lipid therapy have failed to show a significant reduction in CVD events in patients with diabetes. Antiplatelet agents are an additional option for CVD risk reduction in patients both with and without diabetes. However, two recent trials have questioned the role of aspirin in the primary prevention of CVD events in patients with diabetes. Although sub-analyses of larger trials have suggested a potential benefit of thienopyridine therapy in patients with diabetes, direct comparative trials are lacking and aspirin remains the appropriate first-line agent. Recent guidelines issued by the American Diabetes Association, American Heart Association, and American College of Cardiology Foundation on the use of aspirin for …",1회,"Aspirin and Other Antiplatelet Agents and Their Effects on Cardiovascular Disease in Type 2 Diabetes
CD Williams, MS Kirkman - Current Cardiovascular Risk Reports, 2012
1회 인용 관련 학술자료 전체 4개의 버전",,,Current Cardiovascular Risk Reports,,,,,
51 Low-dose sodium nitrite relieves myocardial ischaemia in patients with coronary artery disease: a targeted no-donor effect,"TE Ingram, RA Bleasdale, C Templeton, C Williams, A Margulescu, AG Fraser, PE James",2011/6/1,Heart,97,Suppl 1,A34-A34,BMJ Publishing Group Ltd,"Introduction
Sodium nitrite (NaNO2) became a popular means of treating angina in the 19th century, as its stable chemical structure allowed for cheap preparation and easy storage. However, the effects were slow and unpredictable and so it fell out of favour as more potent and faster-acting agents became available, (eg, organic nitrates). Recent in vitro evidence shows that nitrite (NO2-) exhibits an enhanced vasodilator effect in hypoxia; an environmental modification which encourages its reduction to nitric oxide (NO). Therefore NaNO2 could potentially be an anti-ischaemic agent at much lower doses than those used historically, and be without the adverse side effects associated with organic nitrates (eg, systemic hypotension and tachyphylaxis).
Method
A double-blind, placebo-controlled, cross-over study was performed in 10 subjects with proven myocardial ischaemia documented by exercise tolerance testing …",1회,"51 Low-dose sodium nitrite relieves myocardial ischaemia in patients with coronary artery disease: a targeted no-donor effect
TE Ingram, RA Bleasdale, C Templeton, C Williams… - Heart, 2011
1회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Distributed intelligence or a simple coherent mental model?,"Chris JK Williams, Roly Hudson",2011/1/7,Distributed Intelligence in Design,,,27-35,Wiley‐Blackwell,"This chapter contains sections titled:
Models
Innovation
Theory
Calculations and safety
Physical models
Other worlds
Reference",1회,"Distributed intelligence or a simple coherent mental model?
CJK Williams, R Hudson - Distributed Intelligence in Design, 2011
1회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Christopher Williams,"Christopher Williams, Claudia Beck, John Miller",2011/1/7,,,,,DAP,"Auch, wenn ich zukünftig die Abteilung internationaler ausrichten und unterstützend ein reges Besucherprogramm einführen möchte, habe ich unter anderem angefangen, mit meinen Studenten die zeitgenössische Kunstgeschichte im Rheinland aufzuarbeiten–nicht nur die der Photographie, sondern auch die der Malerei, der Bildhauerei, der Musik und die des Films. Es ist sehr wichtig für die Studenten, die Geschichte der Photographie zu studieren, allerdings nur im größeren Kontext des Studiums der Kunstgeschichte im Allgemeinen.",1회,"Christopher Williams
C Williams, C Beck, J Miller - 2011
1회 인용 관련 학술자료 전체 11개의 버전",,,,,,,,
Low-dose sodium nitrite provides targetted relief of myocardial ischaemia in patients with coronary artery disease,"TE Ingram, RA Bleasdale, C Templeton, C Williams, AG Fraser, PE James",2010/9/1,,31,,57-57,OXFORD UNIV PRESS,,1회,"Low-dose sodium nitrite provides targetted relief of myocardial ischaemia in patients with coronary artery disease
TE Ingram, RA Bleasdale, C Templeton, C Williams… - EUROPEAN HEART JOURNAL, 2010
1회 인용 관련 학술자료",EUROPEAN HEART JOURNAL,,,,,,,
Correction Note on the Results of Multi-task Gaussian Process Prediction,"EdwinV Bonilla, KianMingA Chai, ChristopherK I Williams",2009/1/13,,,,,,This note rectifies the results presented in section 6 of the publication “Multi-task Gaussian Process Prediction”[1] regarding the compiler and school applications.,1회,"Correction Note on the Results of Multi-task Gaussian Process Prediction
EV Bonilla, KMA Chai, CKI Williams - 2009
1회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
On the extension of eigenvectors to new datapoints,Christopher KI Williams,2006/11/18,"Note, available at {http://homepages. inf. ed. ac. uk/ckiw/postscript/nyseig. pdf}",,,1-3,,"In this note we consider an× n kernel matrix Knn and the submatrix Kmm (for m< n) obtained by selecting m rows/columns of Knn. We show that the Nyström approximation (Williams and Seeger, 2001) of the top m eigenvectors of Knn is equivalent to that obtained from a variational argument based on Rayleigh’s principle.",1회,"On the extension of eigenvectors to new datapoints
CKI Williams - Note, available at {http://homepages. inf. ed. ac. uk/ckiw …, 2006
1회 인용 관련 학술자료 전체 4개의 버전",,,,,,,,
Analysis of doubly loaded end blocks in FRP-prestressed concrete,"L Gale, TJ Ibell, C Williams",2006/10,Magazine of Concrete Research,58,8,547-563,Thomas Telford Ltd,"Corrosion in conventional steel-reinforced and prestressed concrete bridges is a major durability concern. Fibre-reinforced polymer (FRP) materials have received widespread interest as an alternative material to steel. Owing to the low stiffness of these materials compared with steel, it could be argued that concrete bridges containing FRP should be prestressed. In doing so, this removes much of the strain capacity in the FRP, so that serviceability of the bridge is ensured and efficient use is made of all materials. Although relevant research into FRP-prestressed concrete is well established, the area of post-tensioned anchorage zones has received very little attention. The current paper concentrates on the analysis (and the design) of post-tensioned anchorage zones subject to multiple anchors, with the feasibility of adopting FRP bars as equilibrium reinforcement. Using an elasticity-based model, both the position …",1회,"Analysis of doubly loaded end blocks in FRP-prestressed concrete
L Gale, TJ Ibell, C Williams - Magazine of Concrete Research, 2006
1회 인용 관련 학술자료 전체 6개의 버전",,,,,,,,
Probabilistic in Silico Prediction of Protein-Peptide Interactions,"Wolfgang Lehrach, Dirk Husmeier, Christopher KI Williams",2005/12/2,,,,188-197,"Springer, Berlin, Heidelberg","Peptide recognition modules (PRMs) are specialised compact protein domains that mediate many important protein-protein interactions. They are responsible for the assembly of critical macromolecular complexes and biochemical pathways [Pawson and Scott, 1997], and they have been implicated in carcinogenesis and various other human diseases [Sudol and Hunter, 2000]. PRMs recognise and bind to peptide ligands that contain a specific structural motif. This paper introduces a novel discriminative model which models these PRMs and allows prediction of their behaviour, which we compare with a recently proposed generative model. We find that on a yeast two-hybrid dataset, the generative model performs better when background sequences are included, while our discriminative model performs better when the evaluation is focused on discriminating between the SH3 domains. Our model is also …",1회,"Probabilistic in silico prediction of protein-peptide interactions
W Lehrach, D Husmeier, CKI Williams - Systems Biology and Regulatory Genomics, 2005
1회 인용 관련 학술자료 전체 13개의 버전",,Systems Biology and Regulatory Genomics,,,,,,
Program: For Example: Dix-Huit Lecons Sur La Société Industrielle (Revision I) von Christopher Williams; Ausstellung vom 21.05.-24.07. 2005,"Christopher Williams, Helmut Draxler",2005,,,,,Lukas & Sternberg,Skip to content Toggle navigation IxTheo …,1회,"Program: For Example: Dix-Huit Lecons Sur La Société Industrielle (Revision I) von Christopher Williams; Ausstellung vom 21.05.-24.07. 2005
C Williams, H Draxler - 2005
1회 인용 관련 학술자료",,,,,,,,
Gaussian Markov Processes,"Carl Edward Rasmussen, Christopher KI Williams",2005,,,,207-219,MIT Press,"For IEEE to continue sending you helpful information on our products and services, please consent to our updated Privacy Policy … I have read and accepted the IEEE Privacy Policy … A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2020 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.",1회,"Gaussian Markov Processes
CE Rasmussen, CKI Williams - 2005
1회 인용",,,,,,,,
Relationships between GPs and other models,"Carl Edward Rasmussen, Christopher KI Williams",2005,,,,129-150,MIT Press,"This chapter contains sections titled: Reproducing Kernel Hilbert Spaces, Regularization, Spline Models, Support Vector Machines, Least-Squares Classification, Relevance Vector Machines, Exercises",1회,"Relationships between GPs and other models
CE Rasmussen, CKI Williams - 2005
1회 인용 관련 학술자료",,,,,,,,
Wind generated waves on fabric structures,"L Mabon, Christopher Williams",1999,,,,119-125,Oxford University Press,"Mabon, L., & Williams, C. (1999). Wind generated waves on fabric structures. In SG Sajjadi, NH Thomas, & JCR Hunt (Eds.), Wind-over-wave Couplings: Perspectives and Prospects (pp. 119-125). Oxford University Press … Wind generated waves on fabric structures. / Mabon, L; Williams, Christopher … Wind-over-wave Couplings: Perspectives and Prospects. ed. / SG Sajjadi; NH Thomas; JCR Hunt. Oxford University Press, 1999. p. 119-125 … Mabon, L & Williams, C 1999, Wind generated waves on fabric structures. in SG Sajjadi, NH Thomas & JCR Hunt (eds), Wind-over-wave Couplings: Perspectives and Prospects. Oxford University Press, pp. 119-125, In: Wind-over-Wave Couplings, Perspectives and Prospects, Oxford, 1999, pp.119-125, 1/01/99.",1회,"Wind generated waves on fabric structures
L Mabon, C Williams - In: Wind-over-Wave Couplings, Perspectives and …, 1999
1회 인용 관련 학술자료","In: Wind-over-Wave Couplings, Perspectives and Prospects, Oxford, 1999, pp. 119-125",,,,,,,
Robert LeRicolais-Visions and Paradox,"Emma Nsugbe, Christopher Williams",1999,AA Files,39,,55-60,,Skip to main navigation Skip to search Skip to main content …,1회,"Robert LeRicolais-Visions and Paradox
E Nsugbe, C Williams - AA Files, 1999
1회 인용 관련 학술자료",,,,,,,,
EFFECTS OF DIFFERENT AMOUNTS OF CARBOHYDRATE INGESTION ON SUBSEQUENT ENDURANCE CAPACITY AND REHYDRATION DURING RECOVERY,"SH Wong, C Williams, T Hazir",1998/5/1,Medicine & Science in Sports & Exercise,30,5,245,LWW,"The purpose of this study was to examine the effects of ingesting different amounts of carbohydrate (CHO) on subsequent endurance capacity and rehydration, during short-term recovery from prolonged submaximal running. Nine well-trained men performed a 90 min run at 70% VO 2 max on a level treadmill (T1) followed by 4 h rehydration-recovery (REC), and then an open-ended run to exhaustion at 70% VO 2 max (T2) as a measure of their endurance capacity, on two occasions, at least 7 days apart. During the REC, a fixed volume of fluid equivalent to 150% of the body mass lost (≈ 2.5% of pre-exercise body mass) during T1 was consumed. Subjects ingested 50 g of CHO from a 6.5% CHO-electrolyte solution 30 min after T1 on both occasions as their first prescribed fluid intake. Thereafter, subjects ingested either the same solution (CE) or a CHO-free sweetened placebo (PL) every 30 min up to the beginning …",1회,"EFFECTS OF DIFFERENT AMOUNTS OF CARBOHYDRATE INGESTION ON SUBSEQUENT ENDURANCE CAPACITY AND REHYDRATION DURING RECOVERY
SH Wong, C Williams, T Hazir - Medicine & Science in Sports & Exercise, 1998
1회 인용",,,,,,,,
Effect of FDA approval of thombolytic therapy on symptom onset intervals and assessment times in emergency department patients with stroke,"SR Williams, N Aziz, CM Williams, R Monzni, D Schreiber",1998,Journal of Stroke and Cerebrovascular Diseases,5,7,377,,,1회,"Effect of FDA approval of thombolytic therapy on symptom onset intervals and assessment times in emergency department patients with stroke
SR Williams, N Aziz, CM Williams, R Monzni… - Journal of Stroke and Cerebrovascular Diseases, 1998
1회 인용 관련 학술자료 전체 2개의 버전",,,,,,,,
Chadic historical syntax: Reconstructing word order in Proto-Chadic,Charles Kinston Williams,1989,,,,,,It has been argued recently that the comparative method is not a suitable tool for engaging in diachronic syntactic research. The results of this study demonstrate that the comparative method can indeed be used to make realistic generalizations about the syntax of a proto-language.,1회,"Chadic historical syntax: Reconstructing word order in Proto-Chadic
CK Williams - 1989
1회 인용 관련 학술자료",,,,Indiana University,,,,
Tenofovir effect on renal function factoring in both MDRD-calculated glomerular filtration rate (GFR) and spot urine protein-to-creatinine (UPC) ratio,"T Vanig, Q Liao, B Ha, C Williams, COL110154 Study Team",,Poster 96E presented at the Annual Meeting of the American College of Clinical Pharmacy,,,19-22,,"Methods
This analysis did not account for possible primary renal disease that may be present at the start of ART treatment nor the variable follow-up duration prior to analysis baseline, other nephrotoxic drugs, differences in patient demographics, and HIV disease characteristics.",1회,"Tenofovir effect on renal function factoring in both MDRD-calculated glomerular filtration rate (GFR) and spot urine protein-to-creatinine (UPC) ratio
T Vanig, Q Liao, B Ha, C Williams… - Poster 96E presented at the Annual Meeting of the …
1회 인용 관련 학술자료",,,,,,,,
A principled approach to non-maximum suppression for object detection,"Christopher KI Williams, Wojciech Wojcikiewicz",,,,,,,"Scanning window object detectors (eg [10],[3]) typically produce a number of positive responses close by to the correct detection, and this leads to the need to have a further non-maximum suppression (NMS) stage to thin out the multiple responses and to suppress spurious responses. This process is often carried out using heuristics which contain many arbitrary parameters/thresholds. In this paper we present a principled approach to NMS. This is based on modelling the detections of a single object with a particular distribution (which we call the scale-sensitive Gaussian, SSG), and then describing the set of all detections with mixture of SSGs. We present empirical results on the MIT+ CMU faces dataset showing that our approach is highly competitive with the OpenCV detector of Lienhart et al [6].
One very popular approach to object recognition and localization in images is to run a “scanning window” detector across the image at a dense grid of locations and scales. Examples include the Viola and Jones face detector [10] and the pedestrian detector of [3]. However, such methods typically produce a number of positive responses close by to the correct detection, and this leads to the need to have a further non-maximum suppression (NMS) stage to thin out the multiple responses, and to suppress spurious responses. For example, Figure 3 (a) shows all the bounding boxes output by the boosted cascade frontal face detector of Lienhart et al1 [6], which is available under OpenCV; this detector has a similar design to [10]. Figure 3 (b) shows the result of non-maximum suppression operating on these detections. The NMS stage involves grouping the …",1회,"A principled approach to non-maximum suppression for object detection
CKI Williams, W Wojcikiewicz
1회 인용 관련 학술자료 전체 3개의 버전",,,,,,,,
Automating Data Science: Prospects and Challenges,"Tijl De Bie, Luc De Raedt, José Hernández-Orallo, Holger H Hoos, Padhraic Smyth, Christopher KI Williams",2021/5/12,arXiv preprint arXiv:2105.05699,,,,,"Given the complexity of typical data science projects and the associated demand for human expertise, automation has the potential to transform the data science process. Key insights: * Automation in data science aims to facilitate and transform the work of data scientists, not to replace them. * Important parts of data science are already being automated, especially in the modeling stages, where techniques such as automated machine learning (AutoML) are gaining traction. * Other aspects are harder to automate, not only because of technological challenges, but because open-ended and context-dependent tasks require human interaction.",,"Automating Data Science: Prospects and Challenges
T De Bie, L De Raedt, J Hernández-Orallo, HH Hoos… - arXiv preprint arXiv:2105.05699, 2021
전체 3개의 버전",,,,,,,,
The Effect of Class Imbalance on Precision-Recall Curves,Christopher KI Williams,2021/4/1,Neural Computation,33,4,853-857,MIT Press,"In this note, I study how the precision of a binary classifier depends on the ratio of positive to negative cases in the test set, as well as the classifier's true and false-positive rates. This relationship allows prediction of how the precision-recall curve will change with , which seems not to be well known. It also allows prediction of how and the precision gain and recall gain measures of Flach and Kull vary with .",,"The Effect of Class Imbalance on Precision-Recall Curves
CKI Williams - Neural Computation, 2021
관련 학술자료 전체 4개의 버전",,,,,,,,
Inference for Generative Capsule Models,"Alfredo Nazabal, Christopher KI Williams",2021/3/11,arXiv preprint arXiv:2103.06676,,,,,"Capsule networks (see e.g. Hinton et al., 2018) aim to encode knowledge and reason about the relationship between an object and its parts. % In this paper we focus on a clean version of this problem, where data is generated from multiple geometric objects (e.g. triangles, squares) at arbitrary translations, rotations and scales, and the observed datapoints (parts) come from the corners of all objects, without any labelling of the objects. We specify a generative model for this data, and derive a variational algorithm for inferring the transformation of each object and the assignments of points to parts of the objects. Recent work by Kosiorek et al. [2019] has used amortized inference via stacked capsule autoencoders (SCA) to tackle this problem -- our results show that we significantly outperform them. We also investigate inference for this problem using a RANSAC-type algorithm.",,"Inference for Generative Capsule Models
A Nazabal, CKI Williams - arXiv preprint arXiv:2103.06676, 2021
전체 3개의 버전",,,,,,,,
Towards Stratified Space Learning: Linearly Embedded Graphs,"Yossi Bokor, Katharine Turner, Christopher Williams",2021/1,arXiv preprint arXiv:2101.04375,,,,,"In this paper, we consider the simplest class of stratified spaces--linearly embedded graphs. We present an algorithm that learns the abstract structure of an embedded graph and models the specific embedding from a point cloud sampled from it. We use tools and inspiration from computational geometry, algebraic topology, and topological data analysis and prove the correctness of the identified abstract structure under assumptions on the embedding. The algorithm is implemented in the Julia package this http URL, which we used for the numerical simulations in this paper.",,"Towards Stratified Space Learning: Linearly Embedded Graphs
Y Bokor, K Turner, C Williams - arXiv preprint arXiv:2101.04375, 2021
관련 학술자료 전체 2개의 버전",,,,,,,,
Form-Finding of Shells Containing Both Tension and Compression Using the {A} iry Stress Function,"Masaaki Miki, Emil Adiels, William Baker, Toby Mitchell, Alexander Sehlstrom, Christopher Williams",2020/12/14,Preprints,,,,MDPI AG,"Pure-compression shells have been the central topic in the form-finding of shells. This paper studies tension-compression mixed type shells by utilizing a NURBS-based isogeometric form-finding approach that analyzes Airy stress functions to expand the possible plan geometry. A complete set of smooth version graphic statics tools is provided to support the analyses. The method is validated using examples with known solutions, and a further example demonstrates the possible forms of shells that the proposed method permits. Additionally, a guideline to configure a proper set of boundary conditions is presented through the lens of asymptotic lines of the stress functions.",,"Form-Finding of Shells Containing Both Tension and Compression Using the {A} iry Stress Function
M Miki, E Adiels, W Baker, T Mitchell, A Sehlstrom… - Preprints, 2020
관련 학술자료 전체 3개의 버전",,,,,,,,
Upwind Summation By Parts Finite Difference Methods for Large Scale Elastic Wave Simulations In Complex Geometries,"Kenneth Duru, Frederick Fung, Christopher Williams",2020/11/5,arXiv preprint arXiv:2011.02600,,,,,High-order accurate summation-by-parts (SBP) finite difference (FD) methods constitute efficient numerical methods for simulating large-scale hyperbolic wave propagation problems.,,"Upwind Summation By Parts Finite Difference Methods for Large Scale Elastic Wave Simulations In Complex Geometries
K Duru, F Fung, C Williams - arXiv preprint arXiv:2011.02600, 2020
관련 학술자료 전체 3개의 버전",,,,,,,,
A tribute to Professor Edward Winter: Edward Winter 28 June 1950–18 July 2020,"AM Nevill, C Williams, RJ Copeland, SW Flint",2020/9/5,Journal of Sports Sciences,,,1-3,Routledge,"This tribute honours Professor Edward Winter who, during a distinguished career, made a substantial contribution to the discipline of Sport and Exercise Science. Edward authored more than 200 publications, was involved in the review of more than 2000 manuscripts and abstracts and had extensive experience of supervising and examining research candidates. Specifically here, Professor Winter made a major contribution to the Journal of Sport Sciences as section editor for Sport Performance for over a decade. The editorial Board wishes to formally acknowledge the contribution made by Edward to; the work of the Journal, the development of the British Association of Sport and Exercise Sciences and the science of sport and exercise. This editorial comprises contributions from colleagues across the sport and exercise community that are published elsewhere (Copeland et al., 2020).",,"A tribute to Professor Edward Winter: Edward Winter 28 June 1950–18 July 2020
AM Nevill, C Williams, RJ Copeland, SW Flint - Journal of Sports Sciences, 2020
관련 학술자료 전체 8개의 버전",,,,,,,,
Learning Direct Optimization for scene understanding,"Lukasz Romaszko, Christopher KI Williams, John Winn",2020/9/1,Pattern Recognition,105,,107369,Pergamon,"We develop a Learning Direct Optimization (LiDO) method for the refinement of a latent variable model that describes input image x. Our goal is to explain a single image x with an interpretable 3D computer graphics model having scene graph latent variables z (such as object appearance, camera position). Given a current estimate of z we can render a prediction of the image g(z), which can be compared to the image x. The standard way to proceed is then to measure the error E(x, g(z)) between the two, and use an optimizer to minimize the error. However, it is unknown which error measure E would be most effective for simultaneously addressing issues such as misaligned objects, occlusions, textures, etc. In contrast, the LiDO approach trains a Prediction Network to predict an update directly to correct z, rather than minimizing the error with respect to z. Experiments show that LiDO converges rapidly as it does not …",,"Learning Direct Optimization for scene understanding
L Romaszko, CKI Williams, J Winn - Pattern Recognition, 2020
관련 학술자료 전체 4개의 버전",,,,,,,,
Customizing Sequence Generation with Multi-Task Dynamical Systems,"Alex Bird, Christopher KI Williams",2019/10/11,arXiv preprint arXiv:1910.05026,,,,,"Dynamical system models (including RNNs) often lack the ability to adapt the sequence generation or prediction to a given context, limiting their real-world application. In this paper we show that hierarchical multi-task dynamical systems (MTDSs) provide direct user control over sequence generation, via use of a latent code that specifies the customization to the individual data sequence. This enables style transfer, interpolation and morphing within generated sequences. We show the MTDS can improve predictions via latent code interpolation, and avoid the long-term performance degradation of standard RNN approaches.",,"Customizing Sequence Generation with Multi-Task Dynamical Systems
A Bird, CKI Williams - arXiv preprint arXiv:1910.05026, 2019
관련 학술자료 전체 3개의 버전",,,,,,,,
Applications of Timber Gridshells for Humanitarian Assistance and Disaster Relief Efforts,"Thomas B Imhoff, Samar R Malek",2019/10/7,Proceedings of IASS Annual Symposia,2019,11,1-8,International Association for Shell and Spatial Structures (IASS),"From 1970 to 2000, 68 percent of United States naval operations were categorized as Humanitarian Assistance and Disaster Relief (HA/DR). These relief efforts identified a need for deployable, lightweight structures, capable of sheltering a large area. Large-span shelters are necessary in HA/DR because they provide space for community gathering, emergency services, educational facilities, and worship. Gridshells are a solution to this need because of their portability and efficiency. Formed from flat, linear members bent on-site into a curved surface, gridshells are relatively large structures that can be built without the use of heavy machinery. To broaden the use of gridshells, this paper quantifies the effects of asymmetric loading and bracing on their performance, as both are likely occurrences in HA/DR. The design requirements and constraints for the gridshell were established by fieldwork in Athens, Greece and …",,"Applications of Timber Gridshells for Humanitarian Assistance and Disaster Relief Efforts
TB Imhoff, SR Malek - Proceedings of IASS Annual Symposia, 2019
관련 학술자료 전체 3개의 버전",,,,,,,,
Multi-Task Time Series Analysis applied to Drug Response Modelling,"Alex Bird, Chris Williams, Christopher Hawthorne",2019/4/11,,,,2174-2183,PMLR,"Time series models such as dynamical systems are frequently fitted to a cohort of data, ignoring variation between individual entities such as patients. In this paper we show how these models can be personalised to an individual level while retaining statistical power, via use of multi-task learning (MTL). To our knowledge this is a novel development of MTL which applies to time series both with and without control inputs. The modelling framework is demonstrated on a physiological drug response problem which results in improved predictive accuracy and uncertainty estimation over existing state-of-the-art models.",,"Multi-Task Time Series Analysis applied to Drug Response Modelling
A Bird, C Williams, C Hawthorne - The 22nd International Conference on Artificial …, 2019
관련 학술자료 전체 7개의 버전",The 22nd International Conference on Artificial Intelligence and Statistics,,,,,,,
Endoscopic sensing of distal lung physiology,"Debaditya Choudhury, Michael G Tanner, Sarah McAughtrie, Fei Yu, Bethany Mills, Tushar R Choudhary, Sohan Seth, Thomas H Craven, James M Stone, Ioulia K Mati, Colin J Campbell, Mark Bradley, Christopher KI Williams, Kevin Dhaliwal, Timothy A Birks, Robert R Thomson",2019,Journal of Physics: Conference Series,1151,1,012009,IOP Publishing,"The alveolar space forms the distal end of the respiratory tract where chemoreceptor driven gas exchange processes occur. In healthy humans, the physiological state within the alveoli is tightly regulated by normal homeostatic mechanisms. However, pulmonary abnormalities such as chronic obstructive pulmonary disease may induce significant perturbation of the homeostatic baselines of physiology as well as cause host tissue damage. Therefore, physiological parameters (pH, glucose, oxygen tension) within the alveolar space provide a key biomarker of innate defence. Here, we discuss an endoscope-deployable fibre-optic optrode for sensing pH in the alveolar space. In order to circumvent the unwanted Raman signal generated within the fibre, the optrode consists of a custom asymmetric dual-core optical fibre designed for spatially separated optical pump delivery and SERS signal collection. pH sensing is …",,"Endoscopic sensing of distal lung physiology
D Choudhury, MG Tanner, S McAughtrie, F Yu, B Mills… - Journal of Physics: Conference Series, 2019
관련 학술자료 전체 6개의 버전",,,,,,,,
"The use of virtual work for the formfinding of fabric, shell and gridshell structures","Christopher Williams, Paul Shepherd, Emil Adiels, Mats Ander, Erica Hörteborn, Jens Olsson, Karl-Gunnar Olsson, Alexander Sehlström",2018/9/24,,,,,,"The use of the virtual work theorem enables one to derive the equations of static equilibrium of fabric, shell and gridshell structures from the compatibility equations linking the rate of deformation of a surface to variations in its velocity. If the structure is treated as a continuum",,"The use of virtual work for the formfinding of fabric, shell and gridshell structures
C Williams, P Shepherd, E Adiels, M Ander… - Advances in Architectural Geometry, 2018",Advances in Architectural Geometry,,,,,,,
Canecrete: a low-cost construction system for shell structures in Colombia,"E Cortes-Paez, J Orr, S Emmitt, T Ibell, C Williams",2018/7/16,Proceedings of IASS Annual Symposia,2018,20,1-8,International Association for Shell and Spatial Structures (IASS),"The correct flow of forces in thin shell structures arises from a correlation between form, material and construction. Conventional construction with rigid formworks for casting reinforced concrete thin shells has become expensive, inefficient, and negatively impacts the environment. Recent research addressing methods to limit, reuse, or integrate the formwork as part of a thin shell structure has explored the use of elastic synthetic materials such as structural fabrics, steel wires, and synthetic polymer composites. Although such methods have optimised the construction of thin shells, most are technically or financially inaccessible in developing countries. This paper focusses on a low-cost alternative using an elastic vegetable material known as wild cane. This giant reed grows around the world with a diameter of up to 40 mm. A common construction method using this material elastically deforms flat rods to form curved …",,"Canecrete: a low-cost construction system for shell structures in Colombia
E Cortes-Paez, J Orr, S Emmitt, T Ibell, C Williams - Proceedings of IASS Annual Symposia, 2018
관련 학술자료",,,,,,,,
Vehicle and method to control rolling engagements,,2017/4/25,,,,,,"When a vehicle driver selects reverse while a vehicle is moving forward, a transmission controller applies friction shift elements within the transmission to create a partial tie-up condition to decelerate the vehicle. Once the vehicle slows below a threshold speed, the controller engages a selectable one way brake and releases some of the friction shift elements to engage a reverse gear ratio.",,"Vehicle and method to control rolling engagements
KM Jungbluth, CM Williams, KH Nickerson - US Patent 9,631,723, 2017
관련 학술자료 전체 4개의 버전",,,,,"Karl M Jungbluth, Christopher Marcus Williams, Kurt Howard Nickerson",US,14605456,9631723
Endoscopic sensing of pH in the distal lung (Conference Presentation),"Debaditya Choudhury, Michael G Tanner, Sarah McAughtrie, Fei Yu, Bethany Mills, Tushar R Choudhary, Sohan Seth, Thomas Craven, James M Stone, Ioulia K Mati, Colin J Campbell, Mark Bradley, Christopher KI Williams, Kevin Dhaliwal, Timothy A Birks, Robert R Thomson",2017/4/19,,10041,,100410B,International Society for Optics and Photonics,"In healthy humans, the physiological state in the distal lung alveolar acinar units is tightly regulated by normal homeostatic mechanisms. Pulmonary abnormalities such as chronic obstructive pulmonary disease, that are characterized by recurrent cycles of inflammation and infection involving dense infiltration by myeloid derived peripheral blood cells, may result in significant perturbation of the homeostatic baselines of physiology in addition to host tissue damage. Therefore, the ability to quantify and monitor physiology (e.g. pH, glucose level, oxygen tension) within the alveolar acinar units would provide a key biomarker of distal lung innate defence. Although in vitro modeling of fundamental biological processes show remarkable sensitivity to physiological aberrations, little is known about the physiological state of the distal lung due to the inability to concurrently access the alveolar sacs and perform real-time …",,"Endoscopic sensing of pH in the distal lung (Conference Presentation)
D Choudhury, MG Tanner, S McAughtrie, F Yu, B Mills… - Optical Techniques in Pulmonary Medicine II, 2017
전체 4개의 버전",Optical Techniques in Pulmonary Medicine II,,,,,,,
The Concrete ‘Sound Object’and the Emergence of Acoustical Film and Radiophonic Art in the Modernist Avant-Garde,Christopher Williams,2017/2/1,Transcultural Studies,13,2,239-263,Brill,"Radiophonic art could not have emerged at the end of the 1920s without an intense period of experimentation across the creative fields of radio, new music, phonography, film, literature and theatre. The engagement with sound recording and broadcast technologies by artists radically expanded the scope of creative possibility within their respective practices, and more particularly, pointed to new forms of (inter-)artistic practice based in sound technologies including those of radio. This paper examines the convergence of industry, the development of technology, and creative practice that gave sound, previously understood as immaterial, a concrete objectification capable of responding to creative praxis, and so brought about the conditions that enabled a radiophonic art to materialize.",,"The Concrete ‘Sound Object’and the Emergence of Acoustical Film and Radiophonic Art in the Modernist Avant-Garde
C Williams - Transcultural Studies, 2017
관련 학술자료 전체 4개의 버전",,,,,,,,
Software and data for endoscopic sensing of alveolar pH,"Debaditya Choudhury, Michael G Tanner, Sarah McAughtrie, Fei Yu, Bethany Mills, Tushar R Choudhary, Sohan Seth, Thomas H Craven, James M Stone, Ioulia K Mati, Colin J Campbell, Mark Bradley, Christopher KI Williams, Kevin Dhaliwal, Timothy A Birks, Robert Roderick Thomson",2016/12/9,,,,,,"Previously unobtainable measurements of alveolar pH were obtained using an endoscope-deployable optrode. The pH sensing was achieved using functionalized gold nanoshell sensors and surface enhanced Raman spectroscopy (SERS). The optrode consisted of an asymmetric dual-core optical fiber designed for spatially separating the optical pump delivery and signal collection, in order to circumvent the unwanted Raman signal generated within the fiber. Using this approach, we demonstrate a ~100-fold increase in SERS signal-to-fiber background ratio, and demonstrate multiple site pH sensing with a measurement accuracy of ±0.07 pH units in the respiratory acini of an ex vivo ovine lung model. We also demonstrate that alveolar pH changes in response to ventilation.",,"Software and data for endoscopic sensing of alveolar pH
D Choudhury, MG Tanner, S McAughtrie, F Yu, B Mills… - 2016",,,,,,,,
Dataset for An Explicit Method for Simulation of Cracking Structures Based on Peridynamic Theory,"David Miranda, Christopher Williams, John Orr",2016/7/24,,,,,University of Bath,"Cite this dataset as: Miranda, D., Williams, C., Orr, J., 2016. Dataset for An Explicit Method for Simulation of Cracking Structures Based on Peridynamic Theory. Bath: University of Bath Research Data Archive. Available from: https://doi.org/10.15125/BATH-00194 … Please contact the Research Data Service in the first instance for all matters concerning this item.",,"Dataset for An Explicit Method for Simulation of Cracking Structures Based on Peridynamic Theory
D Miranda, C Williams, J Orr - 2016",,,,,,,,
An explicit method for simulation of reinforced concrete structures based on peridynamic theory,"Helder Miranda, Christopher Williams, John Orr",2016/7,,,,,,"Despite the massive use of concrete by the construction industry, its optimisation remains a scientific and engineering challenge, that has important implications for the global environ and economy. Difficulties predicting the material behaviour after cracking are part of the problem, since design relies on accurate models. As the cracks start to grow, the hypothesis of material continuity that is critical to the differential equations of the classical theory becomes obsolete. In fact, many issues are documented in the literature regarding the employment of the classical continuum solid mechanics and the finite element method in this context. In order to avoid these problems, the recent peridynamics theory [1] was formulated without differential equations or continuity requirement.",,"An explicit method for simulation of reinforced concrete structures based on peridynamic theory
H Miranda, C Williams, J Orr - The 12th World Congress on Computational …, 2016
전체 3개의 버전",,"The 12th World Congress on Computational Mechanics,(WCCM) XII, 2016",,,,,,
Process partial response channel,,2016/6/16,,,,,,Techniques for processing a partial response channel are disclosed. A segment of the signal is matched to one or more of a set of signal patterns. The set of the signal patterns is changed for a subsequent segment of the signal.,,"Process partial response channel
R Jibry, R Morling, P Walsh, C Williams - US Patent App. 14/908,535, 2016
관련 학술자료 전체 3개의 버전",,,,,"Rafel Jibry, Robert Morling, Peter Walsh, Christopher Williams",US,14908535,
Software to assess the utility of autofluorescence-based pulmonary optical endomicroscopy to predict the malignant potential of solitary pulmonary nodules in humans,"Sohan Seth, Christopher KI Williams, Kevin Dhaliwal, Mark Bradley",2015/10/2,,,,,University of Edinburgh,"Solitary pulmonary nodules are common, often incidental findings on chest CT scans. The investigation of pulmonary nodules is time-consuming and often leads to protracted follow-up with ongoing radiological surveillance, however, clinical calculators that assess the risk of the nodule being malignant exist to help in the stratification of patients. Furthermore recent advances in interventional pulmonology include the ability to both navigate to nodules and also to perform autofluorescence microendoscopy. In this study we assessed the efficacy of incorporating additional information from label-free fibre-based optical endomicroscopy of the nodule on assessing risk of malignancy. Using image analysis and machine learning approaches, we find that this information does not yield any gain in predictive performance in a cohort of patients.",,"Software to assess the utility of autofluorescence-based pulmonary optical endomicroscopy to predict the malignant potential of solitary pulmonary nodules in humans
S Seth, CKI Williams, K Dhaliwal, M Bradley - 2015",,,,,,,,
Modelling Scene Structure: Vision as Inverse Graphics,Christopher KI Williams,2015/8/1,,44,,359-360,SAGE PUBLICATIONS LTD,,,"Modelling Scene Structure: Vision as Inverse Graphics
CKI Williams - PERCEPTION, 2015",PERCEPTION,,,,,,,
29. Ongoing Trials Fluoxetine Or Control Under Supervision (FOCUS): ESOC-1608,"C Williams, K Innes, M Dennis, G Mead",2015/4,International Journal of Stroke,10,,428-429,,,,"29. Ongoing Trials Fluoxetine Or Control Under Supervision (FOCUS): ESOC-1608
C Williams, K Innes, M Dennis, G Mead - International Journal of Stroke, 2015",,,,,,,,
Poster 575 Rational Prescribing in an Acute Inpatient Rehabilitation Facility: A Progress Report of a Three Year Quality Improvement Project,"Christopher J Williams, Mikhail Zhukalin, Mike Reed, Dale C Strasser",2014/9,PM&R,6,,S386-S387,,,,"Poster 575 Rational Prescribing in an Acute Inpatient Rehabilitation Facility: A Progress Report of a Three Year Quality Improvement Project
CJ Williams, M Zhukalin, M Reed, DC Strasser - PM&R, 2014
전체 2개의 버전",,,,,,,,
French flowers blooming: the music for testimony: a discussion between Sandy Evans and Christopher Williams,"Sandy Evans, Christopher Williams",2013,,,,,"Middletown, Connecticut: Wesleyan University Press",Macquarie University ResearchOnline.,,"French flowers blooming: the music for testimony: a discussion between Sandy Evans and Christopher Williams
S Evans, C Williams - 2013
전체 2개의 버전",,,,,,,,
Course Information,"Christopher M Bishop, Carl Edward Rasmussen, Christopher KI Williams, Day Time Room",2013,,,,,,"Welcome to INSC 201 Introduction to Information Sciences! I hope this course will ignite your interests in the information sciences and also give you new ideas and ways to think about our information environment and your own information practices. Reading is important to me. This course requires a lot of reading, but know that faculty have carefully selected the foundational readings for you and there is no textbook. The readings will be from scanned textbook chapters, journal articles, newspaper and magazine articles, blog posts, videos, and so forth. All of the readings are in Canvas site. Writing is also important to me. For some of the weeks, you will be asked to submit a reading reflection. These reflections are due the evening before the second class meeting (Thursday) each week. We will discuss the readings or activities in class. Participation is another way to demonstrate and earn points in this course. Writing about what you read is a great way you internalize your understanding of these materials. Your reading journal is worth 20% of your INSC 201/Fall 2020/Course Syllabus grade, so it really is important! For some of you, maintaining a weekly reading and writing practice will require a great a deal of discipline, but you can do it! In weeks without a reading reflection, you will complete one short activity due the evening before the second class meeting (Thursday) each week. These activities serve as experiential learning to interact with the concepts in class. These activities are also important and",,"Course Information
CM Bishop, CE Rasmussen, CKI Williams, DT Room - 2013
관련 학술자료 전체 2개의 버전",,,,,,,,
RA-01. ADVANCED IMAGING STUDIES IN A PATIENT WITH TRANSITIONAL CELL CARCINOMA OF THE BLADDER WITH BRAIN METASTASES,"Yoon Choi, Patrik Gabikian, Fang Zhu, Daniel Appelbaum, Robert Wollmann, Rimas Lukas",2012/10,Neuro-oncology,14,suppl_6,,,OBJECTIVE: To report octreotide scan and magnetic resonance spectroscopy (MRS) characteristics in a patient with brain metastases from transitional cell carcinoma of the bladder. BACKGROUND: Metastatic brain tumors are the most common tumors of the central nervous system (CNS). The differential diag,,"RA-01. ADVANCED IMAGING STUDIES IN A PATIENT WITH TRANSITIONAL CELL CARCINOMA OF THE BLADDER WITH BRAIN METASTASES
Y Choi, P Gabikian, F Zhu, D Appelbaum, R Wollmann… - Neuro-oncology, 2012
전체 2개의 버전",,,,,,,,
RA-30. MR PARAMETERS ARE INDICATIVE OF MALIGNANT TRANSFORMATION IN INFILTRATING LOW-GRADE GLIOMAS,"Llewellyn Jalbert, Adam Elkhaled, Joanna Phillips, Christopher Williams, Soonmee Cha, Mitchel Berger, Susan Chang, Sarah Nelson",2012/10,Neuro-oncology,14,suppl_6,,,"Infiltrating gliomas are highly aggressive tumors of the central nervous system that include astrocytomas, oligodendrogliomas, and mixed oligoastrocytomas. The prognosis for patients diagnosed with these diseases can vary significantly, depending on the grade of malignancy and histological character",,"RA-30. MR PARAMETERS ARE INDICATIVE OF MALIGNANT TRANSFORMATION IN INFILTRATING LOW-GRADE GLIOMAS
L Jalbert, A Elkhaled, J Phillips, C Williams, S Cha… - Neuro-oncology, 2012
전체 2개의 버전",,,,,,,,
Trainees’ presentations,"J Horwood, C Williams, N Iqbal, R Adams, R Hargest, DC Bosanquet, L Ye, VM Saravolac, A Rangaraj, WG Jiang, KG Harding, I Alam, JW Stephens, KE Lewis, MJ Lewis, A Fielding, J Barry, JN Baxter, Thomas Baumer, A Goyal, B Baruah, I Monypenny, H Sweetland, S Goyal, R Mansel, JD Mason, J Morris, TD Reid, WG Lewis, M Evans, G Williams, J Stamatakis, A Radcliffe, J Hanson, M Davies",2012/4,The Annals of The Royal College of Surgeons of England,94,1,e49-e51,The Royal College of Surgeons of England,"Methods
A prospective database of all patients with squamous carcinoma of the anus, treated at a regional centre, was constructed. Patient demographics, tumour stage and grade, primary treatment modality, disease-free and overall survival data were recorded. In particular, tumour morphology as described at initial examination under anaesthetic was recorded. The database was examined using standard statistical techniques.
Results
Between 2003 and 2009, 92 patients with squamous cell carcinoma of the anus were recorded. Fifty-four per cent of patients had exophytic tumours; the remaining had ulcerating disease. Eighty-six per cent of those with exophytic disease were alive at follow-up (median 60 months) compared with 39% with ulcerating tumours. Patients with ulcerating tumours presented with significantly more advanced disease (p=< 0.05), more likely to be treated initially with palliative intent (21% vs …",,"Trainees’ presentations
J Horwood, C Williams, N Iqbal, R Adams, R Hargest… - The Annals of The Royal College of Surgeons of …, 2012",,,,,,,,
Supplementary Material: Multiple Texture Boltzmann Machines,"Jyri J Kivinen, Christopher KI Williams",2012/2/3,,,,,,"The models did not have any special boundary units, and therefore at the boundaries and especially at the corners due to diagonal offsets between the tiles there were sites which we less constrained than in the center of the image. This often caused boundary artifacts unless special care was taken. We tried various ways of dealing with these problems, for each of the models and textures. The results we report use a mixed way of dealing with them: For all models except TPoT, we clamped the borders of the negative particles to zero as in [10]. For the TPoT, we simply discarded the boundary data in computing the gradients for parameter updates, which seemed to work best for this model.",,"Supplementary Material: Multiple Texture Boltzmann Machines
JJ Kivinen, CKI Williams - 2012
전체 5개의 버전",,,,,,,,
"Anal tumour morphology significantly predicts treatment response, disease free and overall survival","Cardiff Wales, J Horwood, C Williams, N Iqbal, R Adams, R Hargest",2012,Ann R Coll Surg Engl,94,,e46-e54,,"Methods
A prospective database of all patients with squamous carcinoma of the anus, treated at a regional centre, was constructed. Patient demographics, tumour stage and grade, primary treatment modality, disease-free and overall survival data were recorded. In particular, tumour morphology as described at initial examination under anaesthetic was recorded. The database was examined using standard statistical techniques.
Results
Between 2003 and 2009, 92 patients with squamous cell carcinoma of the anus were recorded. Fifty-four per cent of patients had exophytic tumours; the remaining had ulcerating disease. Eighty-six per cent of those with exophytic disease were alive at follow-up (median 60 months) compared with 39% with ulcerating tumours. Patients with ulcerating tumours presented with significantly more advanced disease (p=< 0.05), more likely to be treated initially with palliative intent (21% vs …",,"Anal tumour morphology significantly predicts treatment response, disease free and overall survival
C Wales, J Horwood, C Williams, N Iqbal, R Adams… - Ann R Coll Surg Engl, 2012
전체 2개의 버전",,,,,,,,
"Special Issue on Probabilistic Models for Image Understanding, Part II","Bill Triggs, K Christopher, I Williams",2011/12/1,International Journal of Computer Vision,95,3,313,Springer Science & Business Media,"This is an addendum to the original editorial of our IJCV Special Issue on Probabilistic Models for Image Understanding (Triggs and Williams 2010), detailing three papers that were accepted after that editorial was published and giving full citations for all of the papers in the issue. Given the recent success and popularity of image understanding methods based on structured probabilistic models, we felt that the time was ripe for a special issue covering the full range of approaches in this area. Submissions closed in July 2008 and the first part of the issue containing the following eight papers (Li and Fei-Fei 2010; Kapoor et al. 2010; Vidal and Jedynak 2010; Ross et al. 2010; Larlus et al. 2010; Porway et al. 2010; Tuytelaars et al. 2010; Everingham et al. 2010; Guan et al. 2010; Shi et al. 2011; Zhu et al. 2011) was published in IJCV 88 (2) in June 2010. Themes covered included image classification, object detection …",,"Special Issue on Probabilistic Models for Image Understanding, Part II
B Triggs, K Christopher, I Williams - International Journal of Computer Vision, 2011
관련 학술자료 전체 7개의 버전",,,,,,,,
Abstract B110: Early radiographic and physiologic changes in patients with recurrent low-grade gliomas treated with everolimus under a phase II clinical trial.,"Michael Wahl, Christopher Kazu Williams, Janine M Lupo, Daphne Haas-Kogan, Sarah J Nelson",2011/11/12,,10,11 Supplement,B110-B110,American Association for Cancer Research,"Low-grade gliomas (LGG) are slow-growing, primary brain tumors that frequently recur after primary surgical treatment. Recent work has established the activation of the PI3K/mTOR pathway in most LGG, raising the possibility that mTOR inhibitors such as everolimus (RAD001) may benefit patients with LGG. Early imaging markers of treatment response and disease progression are needed to assess patients undergoing experimental therapy.
In this phase II clinical trial, 17 patients with recurrent low-grade gliomas were treated with everolimus. Serial multimodal magnetic resonance imaging was obtained every two months for up to 12 months while patients were undergoing treatment. At each time point, the volume of hyperintensity on T2-weighted imaging (T2ALL) and the contrast-enhancing lesion on T1-weighted imaging (CEL), if present, were manually defined. Maps of imaging parameters were generated …",,"Abstract B110: Early radiographic and physiologic changes in patients with recurrent low-grade gliomas treated with everolimus under a phase II clinical trial.
M Wahl, CK Williams, JM Lupo, D Haas-Kogan… - 2011",,,Molecular Cancer Therapeutics,,,,,
A2 The potential and pitfalls of anonymised data linkage for follow-up of patient outcomes in prehospital emergency care research,"A Sánchez, H Snooks, I Cheung, C Williams, K Jones",2011/11/1,Emergency Medicine Journal,28,11,e2-e2,BMJ Publishing Group Ltd and the British Association for Accident & Emergency Medicine,"Background
Due to the nature of collection, storage and retrieval of data in emergency prehospital care, following up patient outcomes can be challenging. Data are often of poor quality, data structures within which they are housed complex and difficult to interrogate, and outcome data can be owned by various providers of care. Issues of ethics, consent and research/information governance further complicate matters. The Secure Anonymised Information Linkage (SAIL) databank is currently pioneering a system that collects routine social and heath records from numerous providers and assembles them within one structure that allows patient data to be stored, linked, accessed and analysed for research purposes without the need for individual (identifiable) personal data.
Methods
This system was tested within a cluster Randomised Controlled Trial (RCT) in prehospital emergency care. The Support and Assessment …",,"A2 The potential and pitfalls of anonymised data linkage for follow-up of patient outcomes in prehospital emergency care research
A Sánchez, H Snooks, I Cheung, C Williams, K Jones - Emergency Medicine Journal, 2011
전체 4개의 버전",,,,,,,,
Supplementary Material Factored Shapes and Appearances for Parts-based Object Understanding,"SM Ali Eslami, Christopher KI Williams",2011/7/27,,,,,,"Consider a synthetic dataset of two bars of variable length such as the one shown in Fig. 1. Notice that in each image the two bars are synchronised (ie their lengths are equal), and that the red bar always occludes the blue bar. We train a global FSA model (L= 2, H= 1) on this dataset. The data is trivial to segment with appearance cues alone, but we focus on the way in which FSA learns to model the shapes of the two bars. First we plot the learned appearance model upon convergence of the learning algorithm in Fig. 2. In Fig. 3 we plot samples of the learned shape model. Notice how the bars vary in length, are always of the same size, and appear with the correct occlusion ordering. In Fig. 4 we show the way in which the image structure varies as v moves in 1D space. We also train a local FSA model (H= 1 per layer), and plot the samples it generates in Fig. 5. The generated bars now appear with different lengths …",,"Supplementary Material Factored Shapes and Appearances for Parts-based Object Understanding
SMA Eslami, CKI Williams - 2011
전체 15개의 버전",,,,,,,,
Sparse Canonical Correlation Analysis for Biomarker Discovery: A Case Study in Tuberculosis,"Juho Rousu, Daniel D Agranoff, John Shawe-Taylor, Delmiro Fernandez-Reyes",2011/7/20,Machine Learning in Systems Biology,,,73,,"Biomarker discovery from’omics data is a challenging task due to the high dimensionality of data and the relative scarcity of samples. Here we explore the potential of canonical correlation analysis, a family of methods that finds correlated components in two views. In particular we use the recently introduced technique of sparse canonical correlation analysis that finds a projection directions that are primally sparse in one of the views and dually sparse in the other view. Our experiments show that the method is able to discover meaningful feature combinations that may have use as biomarkers for tuberculosis.",,"Sparse Canonical Correlation Analysis for Biomarker Discovery: A Case Study in Tuberculosis
J Rousu, DD Agranoff, J Shawe-Taylor… - Machine Learning in Systems Biology, 2011
관련 학술자료 전체 5개의 버전",,,,,,,,
"Morgan, Godfrey Charles, Viscount Tredegar (1831-1913)",Christopher Williams,2011,,,,,Oxford University Press,,,"Morgan, Godfrey Charles, Viscount Tredegar (1831-1913)
C Williams - 2011",,,,,,,,
Data-Intensive Research Workshop (15-19 March 2010) Report,"Malcolm Atkinson, David De Roure, Jano van Hemert, Shantenu Jha, Ruth McNally, Robert Mann, Stratis Viglas, Christopher KI Williams",2010/5/1,,,,,University of Edinburgh,"We met at the National e-Science Institute in Edinburgh on 15-19 March 2010 to develop our understanding of DIR. Approximately 100 participants (see Appendix A) worked together to develop their own understanding, and we are offering this report as the first step in communicating that to a wider community. We present this in turns of our developing/emerging understanding of"" What is DIR?"" and"" Why it is important?'"". We then review the status of the field, report what the workshop achieved and what remains as open questions.",,"Data-Intensive Research Workshop (15-19 March 2010) Report
M Atkinson, D De Roure, J van Hemert, S Jha… - 2010",,,,,,,,
Localisation microscopy using quantum dots,"Ondrej Mandula, Christopher KI Williams, Rainer Heintzmann",2010,,,,,,Localisation microscopy (LM) techniques such as STORM/fPALM have proved to be viable techniques in biological research. These techniques provide super-resolution images of fluorescently labelled biological samples by localisation of,,"Localisation microscopy using quantum dots
O Mandula, CKI Williams, R Heintzmann - 40th Society for Neuroscience Annual Meeting, 2010",40th Society for Neuroscience Annual Meeting,,,,,,,
Mountains and history in the literature of Raymond Williams,Christopher Williams,2010,,,,581-592,Cambridge Scholars Publishing,,,"Mountains and history in the literature of Raymond Williams
C Williams - 2010",,,,,,,,
A Meta-information Based Rule Mining System for Vehicle Parking Decision Support,"Jian Su, Wenyong Weng, Zebing Wang",2009/5/19,,1,,325-328,IEEE,"Vehicle parking problem is a critical problem for most Chinese cities. In order to find out the rules hidden in the underlying data of vehicle parking, a rule mining system has been developed based on a meta-information mechanism. Meta-information is a simple data structure for describing a distributed information system or its subsystems of the rough set theory, and meta-information mechanism is a suitable basis to implement many rough set methods, such as rule extraction and attribute reduction. By the rule mining system, many meaningful rules will be extracted. The rule mining system is a typical application of meta-information mechanism, and will take advantages of the merits of meta-information mechanism.",,"A Meta-information Based Rule Mining System for Vehicle Parking Decision Support
J Su, W Weng, Z Wang - 2009 WRI Global Congress on Intelligent Systems, 2009
관련 학술자료 전체 4개의 버전
Component Analysis Workshop*
F De la Torre, A Leonardis, H Bischof, A Shashua…",2009 WRI Global Congress on Intelligent Systems,,,,,,,
Volume Contents Volume 176 (2009),"DS Greenberg, JND Kerr, CM Bäckman, Y Zhang, N Malik, L Shan, BJ Hoffer, H Westphal, AC Tomac, TE Cheng, KK Yoder, MD Normandin, SL Risacher, AK Converse, JA Hampel, MA Miller, ED Morris, M Neumann, Y Wang, S Kim, SM Hong, L Jeng, M Bilgen, J Liu, DJ MacGregor, CKI Williams, O Moldestad, P Karlsen, S Molden, JF Storm, T Gener, R Reig, MV Sanchez-Vives, JM Taylor, MB Delatycki, PJ Lockhart, M Melendez-Ferro, E Perez-Costas, RC Roberts, V Di Biase, BE Flucher, GJ Obermair, MS Jafri, R Tang, CM Tang, M Aspalter, A Vyas, J Feiner, J Griffin, T Brushart, R Redett, RM Kalwani, L Bloy, MA Elliott, JI Gold, S Techangamsuwan, R Kreutzer, M Kreutzer, I Imbschweiler, K Rohn, K Wewetzer, W Baumgärtner, RC Wyeth, RP Croll, AOD Willows, AN Spencer, NT Vandehey, PC Garell, D Murali, EM Smith, R Davidson, RJ Nickles, BT Christian, HA Johnson, DV Buonomano",2009,Journal of Neuroscience Methods,176,,319-320,,"Journal of Neuroscience Methods 176 (2009) 319–320 Issue 1 15 January 2009 Basic Neuroscience Automated correction of fast motion artifacts for two-photon imaging of awake animals DS Greenberg and JND Kerr (Germany) 1 Generalized tetracycline induced Cre recombinase expression through the ROSA26 locus of recombinant mice CM Bäckman, Y. Zhang, N. Malik, L. Shan, BJ Hoffer, H. Westphal and AC Tomac (USA) 16 A rat head holder for simultaneous scanning of two rats in small animal PET scanners: Design, construction, feasibility testing and kinetic validation TE Cheng, KK Yoder, MD Normandin, SL Risacher, AK Converse, JA Hampel, MA Miller and ED Morris (USA) 24 Assessing gait impairment following experimental traumatic brain injury in mice M. Neumann, Y. Wang, S. Kim, SM Hong, L. Jeng, M. Bilgen and J. Liu (USA, Germany, PR China) 34 Computational Neuroscience A new method of …",,"Volume Contents Volume 176 (2009)
DS Greenberg, JND Kerr, CM Bäckman, Y Zhang… - Journal of Neuroscience Methods, 2009",,,,,,,,
Modelling Multi-context Robot Inverse Dynamics with Gaussian Processes,"Kian Ming A Chai, Christopher KI Williams, Stefan Klanke, Sethu Vijayakumar",2008/9/1,,,,,,"In this chapter we are concerned with the problem of controlling a robot manipulator (ie a multijointed robot arm) to follow a given trajectory; this is known as the inverse dynamics problem. We consider a robot manipulator with ℓ revolute joints, and denote the joint angles as q1: ℓ. Similarly the joint velocities and accelerations are denoted by q1: ℓ, and q1: ℓ respectively. For brevity we set x=(q1: ℓ, q1: ℓ, q1: ℓ)′∈ R3ℓ. Our aim is to then learn (or estimate) the inverse dynamics of the robot from data; that is, to learn the ℓ torque functions τ1: ℓ (x), τ: R3ℓ↦→ Rℓ. It might be thought that estimating τ (x) would be unnecessary given knowledge of the physics of the robot. Indeed, for a simple and highly structured robot manipulator, it is often possible to find an analytical form for the input/output mapping that is needed to compute the torques, for example using inverse models based on rigid body dynamics derived from the Newton-Euler algorithm (Featherstone, 1987). These models are parameterized in terms of kinematic and dynamic parameters. The latter, which include the mass, centre of mass and moments of inertia of each link, are usually unknown even to the manufacturers of the robots (An et al., 1988). The calibration of these dynamic parameters is neither trivial nor robust, for example Armstrong et al.(1986) estimated them for a PUMA 560 arm by disassembling it and measuring the properties of the individual links using a set of rather elaborate procedures, and Corke and Armstrong-Hélouvry (1994) have noted 200% to 400% variation in the parameters of PUMA 560 robot reported in the literature. Some dynamic parameters, such as those for …",,"Modelling Multi-context Robot Inverse Dynamics with Gaussian Processes
KMA Chai, CKI Williams, S Klanke, S Vijayakumar - 2008
관련 학술자료 전체 4개의 버전",,,,,,,,
Signal masking in Gaussian channels,"John A Quinn, Christopher KI Williams",2008/3/31,,,,2989-2992,IEEE,"We consider the problem of modifying the noise properties of a channel in order to make the source as indecipherable as possible given the output. Applications include jamming communications, maintaining confidentiality near spoken conversations and masking noise pollution. We present results as to how this can be done efficiently, assuming that we have a Gaussian channel and a constraint on the power of the noise. We go on to consider the case in which there is a positive signal which we want to remain coherent, as well as a negative signal which we wish to confound. We also discuss the application of the theory to acoustic signals, where we consider aspects of the human auditory system.",,"Signal masking in Gaussian channels
JA Quinn, CKI Williams - 2008 IEEE International Conference on Acoustics …, 2008
관련 학술자료 전체 12개의 버전","2008 IEEE International Conference on Acoustics, Speech and Signal Processing",,,,,,,
Overcoming Depression and Low Mood: A Five Areas Approach,"Masud Awal, Christopher Williams",2008/3/1,Behavioural and Cognitive Psychotherapy,36,2,248,Cambridge University Press,"The book then includes sections and workbooks on important topics, which are entitled"" Understanding why I feel as I do"","" Practical problem-solving"","" Being assertive"","" Building relationships"","" Noticing and changing extreme and unhelpful thinking"","" Overcoming reduced activity and avoidance"","" Using exercise to boost how you feel"","" Helpful and unhelpful things we can do"","" Alcohol, drugs and you"","" Overcoming sleep problems"","" Understanding and using antidepressant medication"","" Planning for the future"", as well as a section on how to use and support self-help.",,"Overcoming Depression and Low Mood: A Five Areas Approach
M Awal, C Williams - Behavioural and Cognitive Psychotherapy, 2008
관련 학술자료 전체 3개의 버전",,,,,,,,
Christopher Williams in Conversation with Mark Godfrey,"Christopher Williams, Mark Godfrey",2007/10/1,"Afterall: A Journal of Art, Context and Enquiry",,16,62-70,Central Saint Martins College of Art & Design and California Institute of the Arts,"Christopher Williams: Dix-huit Le? onssur la soci? t? industrielle is a book by Raymond Aron published in 1963. It is a classic of sociology and economics about the Cold War period. It concerns Soviet Russia, the United States and China to some degree, and it's about oil and potatoes and corn. It's a very basic description of the economic structure of the Cold War. I picked up the book because I saw the cover represented in Jean-Luc Godard's Two or Three Things IKnow about Her (1966). I'd been told the film was somewhat based on the book, so I went out and bought it and decided that I'd use it as a starting place for my new project. The word'le? ons9 (lectures) was attractive to me because I've heard people call my work'didactic'and I wantedto tackle that criticism head-on. By placing it in my title I raise the question: What lesson am I putting forward? What have I taught you? What am I being didactic about …",,"Christopher Williams in Conversation with Mark Godfrey
C Williams, M Godfrey - Afterall: A Journal of Art, Context and Enquiry, 2007
관련 학술자료",,,,,,,,
Article Index,"Keith Topping, IJ Markov, JF Gabriel, T Langbecker, F Albermani, AJ Kappos, A Manafpour, P Huybers, EAO Nsugbe, CJK Williams, SML Adriaenssens, MR Barnes, SC Kerr, NWM Bishop, SSE Lam, GP Zou, QS Li, HI Epstein, G Torello Jr, HF Chen, D Shu",2007/3,Journal Information,2007,,,,"My main focus here will be upon peer tutoring, and within that upon peer tutoring within colleges and universities. However, there will be implications for peer tutoring in other settings and other kinds of tutoring.",,"Article Index
K Topping, IJ Markov, JF Gabriel, T Langbecker… - Journal Information, 2007
관련 학술자료 전체 2개의 버전",,,,,,,,
"Leonard de Vinci, Gustave Eiffel, Le Corbusier et l'hydrodynamique de particules lissees",CJK Williams,2007/3,L'architecture d'aujourd'hui,369,,88--95,,"Williams, CJK (2007). Leonard de Vinci, Gustave Eiffel, Le Corbusier et l'hydrodynamique de particules lissees. L'architecture d'aujourd'hui, 369, 88--95 … Leonard de Vinci, Gustave Eiffel, Le Corbusier et l'hydrodynamique de particules lissees. / Williams, CJK … In: L'architecture d'aujourd'hui, Vol. 369, 03.2007, p. 88--95 … Williams, CJK 2007, 'Leonard de Vinci, Gustave Eiffel, Le Corbusier et l'hydrodynamique de particules lissees', L'architecture d'aujourd'hui, vol. 369, pp. 88--95 … Williams CJK. Leonard de Vinci, Gustave Eiffel, Le Corbusier et l'hydrodynamique de particules lissees. L'architecture d'aujourd'hui. 2007 Mar;369:88--95 … Williams, CJK. / Leonard de Vinci, Gustave Eiffel, Le Corbusier et l'hydrodynamique de particules lissees. In: L'architecture d'aujourd'hui. 2007 ; Vol. 369. pp. 88--95.",,"Leonard de Vinci, Gustave Eiffel, Le Corbusier et l'hydrodynamique de particules lissees
CJK Williams - L'architecture d'aujourd'hui, 2007",,,,,,,,
ACCESS to Great Britain and the english-speaking world,"Vivien Williams, Christopher Williams",2007,,,,,Loffredo Editore,,,"ACCESS to Great Britain and the english-speaking world
V Williams, C Williams - 2007",,,,,,,,
Politics daily,J Williams,2007,,,,,,,,"Politics daily
J Williams - 2007",,,,,,,,
Nutrition discussion forum-Response,"C Williams, E Stevenson, M Nute",2006/4/1,BRITISH JOURNAL OF NUTRITION,95,4,846-846,CABI PUBLISHING,,,"Nutrition discussion forum-Response
C Williams, E Stevenson, M Nute - BRITISH JOURNAL OF NUTRITION, 2006",,,,,,,,
"Jeroen de Rijke & Willem de Rooij, Christopher Williams",Christopher Williams,2006,,,,,König,"Mit der gemeinsamen Ausstellung von Christopher Williams und de Rijke/de Rooij in allen drei Räumen der Secession setzen wir zwei Traditionen der letzten Jahre fort: einerseits Künstler, die bisher nicht miteinander gearbeitet haben, einzuladen, zusammen ein Projekt zu erarbeiten und andererseits Positionen vorzustellen, die konzeptuell stark den Einfluss der Moderne auf das Zeitgenössische reflektieren. Das Projekt von Christopher Williams und de Rijke/de Rooij zeigt, wo die Schnittstellen der beiden Werke liegen, wo Gemeinsamkeiten bestehen, aber auch, wo sich unterschiedliche Ansätze und Lösungen konstruktiv gegenüberstehen. Die Art, wie sie die begleitenden Publikationen und Drucksorten angelegt haben, erläutert die Natur dieses Ausstellungsprojektes: Der Katalog ist in zwei gleiche Teile aufgesplittet, Vanessa Joan Müller schreibt je einen Text für beide Positionen, zwei weitere Autoren (Christian Höller und Christian Kravagna) befassen sich nur mit einem der beiden Werkkomplexe. Mathias Poledna gestaltet beide Bände, die sich äußerlich nur in der Namensgebung unterscheiden. Auch die beiden Einladungskarten sind auf Bild-und Textseite identisch, außer dass auf der einen Textseite oben Christopher Williams, auf der anderen de Rijke/de Rooij steht-dies wird eventuell nur einem kleinen Teil der Empfängerinnen auffallen, der andere Teil mag denken, zwei gleiche Karten erhalten zu haben. Ohne die komplexen Gedankengebilde von Christopher Williams und de Rijke/de Rooij auf einen gemeinsamen Nenner verkleinern zu wollen, lässt sich feststellen, dass dem Nachdenken über die Konstruktion von Bild, von …",,"Jeroen de Rijke & Willem de Rooij, Christopher Williams
C Williams - 2006
관련 학술자료",,,,,,,,
Sports nutrition (handbook of sports medicine and science),C Williams,2005/5/1,,39,5,307-307,British Association of Sport and Excercise Medicine,"At first glance, this book could be mistaken as the abridged version of Nutrition in sport, which is the latest publication in the IOC Medical Commission’s Encyclopaedia in sports medicine and science series. Nutrition in sport is the definitive text on sports nutrition because all the relevant topics are covered by internationally recognised experts in the field. It is a delight for researchers and teachers because it provides authoritative, well written comprehensive reviews of the current literature on all the relevant topics in sports nutrition. So why bring out another text so quickly after the publication of Nutrition in sport? The answer is to help bridge the gap between principles and practice. This Handbook succeeds because it not only provides the reader with the essential background on the nutritional preparation for, the participation in, and the recovery from training and competition but also because it is written by two of the …",,"Sports nutrition (handbook of sports medicine and science)
C Williams - 2005
전체 7개의 버전",,,British Journal of Sports Medicine,,,,,
The 2005 PASCAL Visual Object Classes Challenge,"Jorma Laaksonen, Diane Larlus, Bernt Schiele, Mark Everingham, Andrew Zisserman, Christopher KI Williams, L van Gool, Moray Allan, Christopher M Bishop, Olivier Chapelle, Navneet Dalal, Thomas Deselaers, Gyuri Dorkó, Stefan Duffner, Jan Eichhorn, Mario Fritz, Christophe Garcia, Tom Griffiths, Frédéric Jurie, Thomas Keysers, Markus Koskela, Bastian Leibe, Hongying Meng, Hermann Ney, Cordelia Schmid, Edgar Seemann, John Shawe‐Taylor, Amos Storkey, Sandor Szedmak, Bill Triggs, Ilkay Ulusoy, Ville Viitaniemi, Z Jianguo",2005/4,,,,117-176,Springer,"The PASCAL Visual Object Classes Challenge ran from February to March 2005. The goal of the challenge was to recognize objects from a number of visual object classes in realistic scenes (ie not pre-segmented objects). Four object classes were selected: motorbikes, bicycles, cars and people. Twelve teams entered the challenge. In this chapter we provide details of the datasets, algorithms used by the teams, evaluation criteria, and results achieved.",,"The 2005 PASCAL Visual Object Classes Challenge
J Laaksonen, D Larlus, B Schiele, M Everingham… - First PASCAL Machine Learning Challenges Workshop …, 2005
전체 2개의 버전",First PASCAL Machine Learning Challenges Workshop (MLCW 2005),,,,,,,
Mathematical Background,"Carl Edward Rasmussen, Christopher KI Williams",2005,,,,199-206,MIT Press,"For IEEE to continue sending you helpful information on our products and services, please consent to our updated Privacy Policy … I have read and accepted the IEEE Privacy Policy … A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2020 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.",,"Mathematical Background
CE Rasmussen, CKI Williams - 2005",,,,,,,,
Theoretical Perspectives,"Carl Edward Rasmussen, Christopher KI Williams",2005,,,,151-170,MIT Press,"This chapter contains sections titled: The Equivalent Kernel, Asymptotic Analysis, Average-Case Learning Curves, PAC-Bayesian Analysis, Comparison with Other Supervised Learning Methods, Appendix: Learning Curve for the Ornstein-Uhlenbeck Process, Exercises",,"Theoretical Perspectives
CE Rasmussen, CKI Williams - 2005",,,,,,,,
Approximation Methods for Large Datasets,"Carl Edward Rasmussen, Christopher KI Williams",2005,,,,171-188,MIT Press,"This chapter contains sections titled: Reduced-rank Approximations of the Gram Matrix, Greedy Approximation, Approximations for GPR with Fixed Hyperparameters, Approximations for GPC with Fixed Hyperparameters, Approximating the Marginal Likelihood and its Derivatives, Appendix: Equivalence of SR and GPR using the Nyström Approximate Kernel, Exercises",,"Approximation Methods for Large Datasets
CE Rasmussen, CKI Williams - 2005",,,,,,,,
Further Issues and Conclusions,"Carl Edward Rasmussen, Christopher KI Williams",2005,,,,189-198,MIT Press,"This chapter contains sections titled: multiple Outputs, Noise Models with Dependencies, Non-Gaussian Likelihoods, Derivative Observations, Prediction with Uncertain Inputs, Mixtures of Gaussian Processes, Global Optimization, Evaluation of Integrals, Student's t Process, Invariances, Latent Variable Models, Conclusions and Future Directions",,"Further Issues and Conclusions
CE Rasmussen, CKI Williams - 2005",,,,,,,,
Datasets and Code,"Carl Edward Rasmussen, Christopher KI Williams",2005,,,,221-221,MIT Press,"For IEEE to continue sending you helpful information on our products and services, please consent to our updated Privacy Policy … I have read and accepted the IEEE Privacy Policy … A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity. © Copyright 2020 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.",,"Datasets and Code
CE Rasmussen, CKI Williams - 2005",,,,,,,,
"The origin of Guideline Daily Amounts and the Food Standards Agency's guidance on what counts as'a lot'and'a little'(vol 7, pg 549, 2004)","M Rayner, P Scarborough, C Williams",2004/8/1,PUBLIC HEALTH NUTRITION,7,5,693-693,CABI PUBLISHING,,,"The origin of Guideline Daily Amounts and the Food Standards Agency's guidance on what counts as'a lot'and'a little'(vol 7, pg 549, 2004)
M Rayner, P Scarborough, C Williams - PUBLIC HEALTH NUTRITION, 2004",,,,,,,,
CLEANING ASTRONOMICAL DATABASES USING HOUGH TRANSFORMS AND RENEWAL STRINGS,"CKI WILLIAMS, AJ STORKEY, NC HAMBLY, RG MANN",2004,,,,439-452,,In this paper we are concerned with detecting artefactual linear features such as satellite or aeroplane tracks and scratches in astronomical images. The standard approach to line detection is the Hough transform (HT). By combining the HT with renewal processes and hidden Markov models we obtain a probabilistic model (renewal strings) that is a highly effective method for removing these artefacts.,,"CLEANING ASTRONOMICAL DATABASES USING HOUGH TRANSFORMS AND RENEWAL STRINGS
CKI WILLIAMS, AJ STORKEY, NC HAMBLY, RG MANN - Advances In Scattering And Biomedical Engineering, 2004
관련 학술자료",,Advances In Scattering And Biomedical Engineering,,,,,,
SEQUENTIALLY FITTING GAUSSIAN MIXTURES USING AN OUTLIER COMPONENT,"MK TITSIAS, CKI WILLIAMS",2004,,,,386-393,,We describe a method for training mixture models by learning one model at a time and thus building the mixture model in a sequential manner. We do this by incorporating an auxiliary outlier component (a uniform density to any of the data points) into the mixture model which allows us to fit just one data cluster by “ignoring” the rest of the clusters. Once a model is fitted we remove from consideration in a probabilistic fashion all the data explained by this model and then repeat the operation. This process can be viewed as fitting a mixture model using a constrained EM algorithm. A natural stopping criterion is to stop adding components once the outlier component fits no data (or just real background clutter). We also apply the algorithm to train -component mixtures of Gaussians and show results real data.,,"SEQUENTIALLY FITTING GAUSSIAN MIXTURES USING AN OUTLIER COMPONENT
MK TITSIAS, CKI WILLIAMS - Advances In Scattering And Biomedical Engineering, 2004
관련 학술자료 전체 3개의 버전",,Advances In Scattering And Biomedical Engineering,,,,,,
"Vetterli, M., see Hasler, D., T-PAMI Mar 03 301-315 Victor, B., see Kyong Chang, T-PAMI Sep 03 1160-1165 Vitria, J., see Bressan, M., T-PAMI Oct 03 1312-1317","C Vogler, RF Wagner, Wai-Kin Kong, Wai Lam, JZ Wang, L Wang, S Wang, Y Wang, D Weinshall, Weng Juyang, J Weston, Wey-Shiuan Hwang, CKL Williams, LR Williams, R Wilson, RC Wilson, D Windridge, KYK Wong, M Wong, M Worring, YH Wu, Xiao Han, Xiao-Rong Hou, Xiao-Shan Gao, Xiaoyi Jiang, Xinge You, J You, You Xinge, Yuan Yan Tang, AL Yuille, A Zelinsky, J Zerubia, D Zhang, Zhang Yilu, Zheng Nan-Ning, Zheru Chi, Zhu Song Chun, Zhu Song-Chun, S Zilberstein, E Zink, A Zisserman, B Zitova, O Zoeter, A Zomet, SW Zucker, M Zuliani, J Zunic, ZuWhan Kim",2003/12,IEEE Transactions on Pattern Analysis and Machine Intelligence,25,12,,,"This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the coauthors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under he primary entry in the Author Index.",,"Vetterli, M., see Hasler, D., T-PAMI Mar 03 301-315 Victor, B., see Kyong Chang, T-PAMI Sep 03 1160-1165 Vitria, J., see Bressan, M., T-PAMI Oct 03 1312-1317
C Vogler, RF Wagner, WK Kong, W Lam, JZ Wang… - IEEE Transactions on Pattern Analysis and Machine …, 2003",,,,,,,,
A Brief Critique of Methods of Sampling and Reporting Pathogens in Populations of Fish,"CHRISTOPHER J Williams, CHRISTINE M Moffitt",2002,AMERICAN FISHERIES SOCIETY SYMPOSIUM,,,213-214,AMERICAN FISHERIES SOCIETY,"Studies of the disease status and distribution of pathogens in natural and captive populations of fish and of the implications of fish health in fisheries management have increased in recent years. With this new focus is a desire to use retrospective analyses from a variety of sources in order to examine trends on a larger geographic scale. To compare data and to model various outcomes with accuracy, estimates of the prevalence and of the confidence limits are needed. For years, pathologists have considered the implications of sample size on estimations of pathogen prevalence in fish populations, and sampling protocols used for screening have been developed and adapted from recommendations by Ossiander and Wedemeyer (1973) and Simon and Schill (1984). However, these methods addressed samples in which individual fish were examined for the agent of interest. Confounding the interpretation of the outcome of tests is the use of pooled samples from several fish, processed in a single assay, and low numbers of pooled samples. The American Fisheries Society Fish Health Bluebook (Thoesen 1994) recommends a pooling of samples for analysis of several specific pathogens, including most viral screenings, and for many analyses of parasites, such as Myxobolus cere-bralis (the causative agent of salmonid whirling disease), in which whole heads or half heads from like size fish are combined and digested with pepsintrypsin to free spores for quantification. Likelihood-based methods can be used to estimate apparent prevalence and to construct confidence intervals that can be used for samples with any combination of group sizes. This …",,"A Brief Critique of Methods of Sampling and Reporting Pathogens in Populations of Fish
CJ Williams, CM Moffitt - AMERICAN FISHERIES SOCIETY SYMPOSIUM, 2002
관련 학술자료",,,,,,,,
00T 0 3 2. Él SCIENCE LIBRARY,"Haga Attias, Chri Bishop, H Chipman, Tianjia Chu, Merli Clyde, Brendan J Frey, Dan Geiger, Edward I George, Yishay Mansour, Christopher Meek, Evangelos Milios, RJ Mislevy, Petri Myllymäki, Nikunj C Oza, Amos J Storkey, Michael E Tipping, Henry Tirri, Michel Verleysen, Haiqin Wang, Christopher KI Williams, Changwon Yoo, Nevin L Zhang",2001,"Artificial Intelligence and Statistics 2001: Proceedings of the Eighth International Workshop: January 4-7, 2001, Key West, Florida",,,310,Morgan Kaufmann Pub,"The Society for Artificial Intelligence and Statistics (SAAS) is dedicated to facilitating interactions between researchers in Al & Statistics. Many of the papers presented at this year's workshop were concerned with methods for combining simpler constituent models into more powerful aggregate models, such procedures have been exploited to great effect in both machine learning (eg, boosting and statistics (eg, Bayesian model averaging). Though in many respects the papers are very varied in their goals, approaches, and fields of application, they are unified in their use of probability as a framework for quantitative reasoning about uncertainty. A significant proportion of the papers make use of graphical models to represent complex patterns of dependence and independence. Several of these papers focus on methods and applications of these networks in dynamic contexts; others investigate methods for trying to infer the graphical structure from data, several papers present new computational methods for deriving consequences from a network; others investigate sensitivity of network models to specification of parameters and appropriate priors for these parameters. Several papers describe applications of Bayesian network techniques in such diverse fields as music, speech & language processing, and medicine. Finally, a welcome addition to the set of workshop topics is the inclusion of a number of papers which focus on the use of kernel methods in regression, discriminant analysis, and vector quantization.",,"00T 0 3 2. Él SCIENCE LIBRARY
H Attias, C Bishop, H Chipman, T Chu, M Clyde… - Artificial Intelligence and Statistics 2001: Proceedings …, 2001",,,,,,,,
"Kenton Bamford. Distorted Images: British National Identity and Film in the 1920s. (Cinema and Society Series.) London: I.B. Tauris; dist. by St. Martin's Press, New …",Christopher Williams,2000,Albion,32,2,364-365,Cambridge University Press,//static.cambridge.org/content/id/urn%3Acambridge.org%3Aid%3Aarticle%3AS0095139000055253/resource/name/firstPage-S0095139000055253a.jpg,,"Kenton Bamford. Distorted Images: British National Identity and Film in the 1920s.(Cinema and Society Series.) London: IB Tauris; dist. by St. Martin's Press, New York. 1999. Pp. xii, 227. $49.50. ISBN 1-86064-358-2.
C Williams - Albion, 2000
전체 2개의 버전",,,,,,,,
Occupational Exposure to Blood among Emergency Medicine Residents,"Carol H Lee, Wallace A Carter, William K Chiang, Cleopas M Williams, Andrew W Asimos, Jay S Kaufman, Lewis R Goldfrank",1999/5/1,Academic Emergency Medicine,6,5,387,SAEM,"Objectives:
To investigate the epidemiologic characteristics of potentially infectious occupational exposures to blood among emergency medicine (EM) residents.
Methods:
A SAEM sponsored multiple choice survey was administered anonymously to all EM residents participating in the 1998 American Board of Emergency Medicine in-service examination. Survey questions included resident demographics, use of universal precautions, frequency and types of exposures to blood, and exposure reporting. Residents who experienced at least one exposure were then asked to complete an additional set of questions referring only to their latest exposure. Mean values were calculated for each variable and differences between groups were compared by chi-square analysis.
Results:
3163 surveys were distributed to the resident participants and 2985 surveys (94.4%) were returned. 56.1% of participants reported at least …",,"Occupational Exposure to Blood among Emergency Medicine Residents
CH Lee, WA Carter, WK Chiang, CM Williams… - Academic Emergency Medicine, 1999",,,,,,,,
The Effect of FDA Approval of Thrombolytic Therapy on the Management of Acute Stroke in the Emergency Department,"N Aziz, S Williams, C Williams, R Monzni, D Schreiber",1998/9,Annals of Emergency Medicine,32,3,,,,,"The Effect of FDA Approval of Thrombolytic Therapy on the Management of Acute Stroke in the Emergency Department
N Aziz, S Williams, C Williams, R Monzni, D Schreiber - Annals of Emergency Medicine, 1998",,,,,,,,
Minor head injury,"Robin Ball, C WILLIAMS",1998/1,Archives of disease in childhood,78,1,95,BMJ Publishing Group,"EDITOR,—Varicella, caused by primary infection with varicella zoster virus (VZV), is a common and highly contagious disease of childhood, and accounts for about one million cases per year in Japan. In 1994, the Welfare Ministry of Japan approved the use of oral aciclovir to treat varicella infections in otherwise healthy children. In spite of the recommendation that the treatment should not be used routinely for varicella in otherwise healthy children, the number of children treated with oral aciclovir has been increasing gradually in Japan.
It has rarely been reported that immunocompromised children with chronic VZV infection became resistant to aciclovir. However, no evidence that oral aciclovir treatment in otherwise healthy children with varicella leads to the appearance of resistant virus has been shown. To know the potential of antiviral resistance, we measured the susceptibilities to aciclovir in the paired isolates …",,"Minor head injury
R Ball, C WILLIAMS - Archives of disease in childhood, 1998
관련 학술자료 전체 7개의 버전",,,,,,,,
The analogy of natural form in architecture and engineering,"E Nsugbe, Christopher Williams",1998,,,,,,"Nsugbe, E., & Williams, C. (1998). The analogy of natural form in architecture and engineering. 125-134. Paper presented at Engineering a New Architecture, Aarhus School of Architecture, Denmark … The analogy of natural form in architecture and engineering. / Nsugbe, E; Williams, Christopher … 1998. 125-134 Paper presented at Engineering a New Architecture, Aarhus School of Architecture, Denmark … Nsugbe, E & Williams, C 1998, 'The analogy of natural form in architecture and engineering', Paper presented at Engineering a New Architecture, Aarhus School of Architecture, Denmark, 1/01/98 pp. 125-134 … Nsugbe E, Williams C. The analogy of natural form in architecture and engineering. 1998. Paper presented at Engineering a New Architecture, Aarhus School of Architecture, Denmark … Nsugbe, E ; Williams, Christopher. / The analogy of natural form in architecture and engineering. Paper …",,"The analogy of natural form in architecture and engineering
E Nsugbe, C Williams - Engineering a New Architecture, 1998",Engineering a New Architecture,,,,,,,
"BNF for Children 2006, second annual edition","M Harries, C Williams, WD Stanish",1997,Sports Med,24,,347-58,,"This website requires cookies, and the limited processing of your personal data in order to function. By using the site you are agreeing to this as outlined in our privacy notice and cookie policy.",,"BNF for Children 2006, second annual edition
M Harries, C Williams, WD Stanish - Sports Med, 1997",,,,,,,,
Combining spatially distributed predictions from neural networks,Christopher KI Williams,1997,,,,,Aston University,"In this report we discuss the problem of combining spatially-distributed predictions from neural networks. An example of this problem is the prediction of a wind vector-field from remote-sensing data by combining bottom-up predictions (wind vector predictions on a pixel-by-pixel basis) with prior knowledge about wind-field configurations. This task can be achieved using the scaled-likelihood method, which has been used by Morgan and Bourlard (1995) and Smyth (1994), in the context of Hidden Markov modelling",,"Combining spatially distributed predictions from neural networks
CKI Williams - 1997
관련 학술자료 전체 5개의 버전",,,,,,,,
"The School of Civil & Structural Engineering, University of Plymouth",C Williams,1995,STRUCTURAL ENGINEER,73,,118-118,INSTITUTION OF STRUCTURAL ENGINEERS,,,"The School of Civil & Structural Engineering, University of Plymouth
C Williams - STRUCTURAL ENGINEER, 1995",,,,,,,,
Volume 28 June 1994,"C Chryssanthopoulos, CM Hennessy, C Williams, S Robbins, GJ Waked, J McClaran",1994/6,,,,,,"Editorial 75 )bituary 77 Lord Porritt troversy 79 Licit steroid use - hope for the future AP Miller Review 84 Magnetic resonance imaging in sports medicine - an overview T. Featherstone Iarticles 90 Sport and exercise headache: Part 1. Prevalence among university students S. J. Williams and H. Nukada 96 Sport and exercise headache: Part 2. Diagnosis and classification S. J. Williams and H. Nukada 101 Self-reported long-term effects of diving and decompression illness in recreational SCUBA divers D. McQueen, G.Kent and A. Murrison 105 The influence of pre-exercise glucose ingestion on endurance runningcapacity C. Chryssanthopoulos, L. C. M. Hennessy and C. Williams 110 Sport related injuries attending the accident and emergency department RS Jones and T. Taggart 112 An epidemiological survey on ankle sprain M. S. Yeung, K.-M. Chan, CH So and WY Yuan 117 Athletic footwear affects balance in men S. Robbins, E. Waked, GJ Gouw …",,"Volume 28 June 1994
C Chryssanthopoulos, CM Hennessy, C Williams… - 1994
전체 2개의 버전",,,,,,,,
Detecting and reconstructing vascular trees in retinal images [2167-82],"P Jasiobedzki, CK Williams, F Lu",1994,PROCEEDINGS-SPIE THE INTERNATIONAL SOCIETY FOR OPTICAL ENGINEERING,,,815-815,SPIE INTERNATIONAL SOCIETY FOR OPTICAL,,,"Detecting and reconstructing vascular trees in retinal images [2167-82]
P Jasiobedzki, CK Williams, F Lu - … -SPIE THE INTERNATIONAL SOCIETY FOR OPTICAL …, 1994",,,,,,,,
Developmental Aspects of Neoplasia,"Juan Arechaga, F Dixon, DE Swartzendruber, CF Graham, VE Papaioannou, I Damjanov, RL Gardner, L Sachs, A Rizzino, RE Scott, CY Tzen, MM Witte, S Blatti, H Wang, RE Parchment, PK Nakane, RL Brinster, DG Theis, PJ Koch, WW Franke, ED Adamson, EJ Purpus, PA McCue, LA Couture, JM Lehman, MW McBurney, AE Chung, N Skreb, F Bulic-Jakus, V Crnek, J Stepic, M Vlahovic, H Sobis, A Verstuyf, M Vandeputte, CL Mummery, AJ van den Eijnden-van Raaij, T Muramatsu, S Sell, FT Bosman, A de Bruïne, C Flohil, A van der Wurff, J ten Kate, WW Dinjens, RG McKinnell, JM Lust, W Sauerbier, LA Rollins-Smith, JW Williams, CS Williams, DL Carlson, LM Fink, JF Eidt, K Johnson, JM Cook, CD Cook, J Morser, R Marlar, CL Collins, R Schaefer, SS Xie, M Mareel, M Bracke, F Van Roy, L Vakaet, D Baban, Y Matsumura, S Kocialkowski, D Tarin",1993,Int. J. Dev. Biol,37,,117-124,,"5 year JCR Impact Factor Scimago Journal Rank. Int j Dev Biol Linking Development, Stem Cells and Cancer Research. ABOUT US; ARCHIVE: Search for Articles find a paper by title, author... All Issues all published issues; Special Issues all our prestigious special issues. SUBMIT: Instructions guidelines for authors; Advantages of submitting your paper to us; Submit Manuscript manuscript submission system. SUBSCRIBE; ADVERTISE; CONTACT. |. Purchase this issue. Vol. 37 No. 1 (1993) pp.1-243. Developmental Aspects of Neoplasia. Reminiscences and reflections; Special review; Contributions. Special issue dedicated to Professor G. Barry Pierce. Int. J. Dev. Biol. (1993) 37: 1-243 Reminiscences and reflections. On the boundary between development and neoplasia. An interview with Professor G. Barry Pierce. Juan Arechaga Int. J. Dev. Biol. (1993) 37: 5-16 Barry Pierce--why germ cells and germinal tumors? F Dixon …",,"Developmental Aspects of Neoplasia
J Arechaga, F Dixon, DE Swartzendruber, CF Graham… - Int. J. Dev. Biol, 1993",,,,,,,,
INFLUENCE OF CARBOHYDRATE SUPPLEMENTATION ON RUNNING PERFORMANCE,"C WILLIAMS, MG NUTE, MP WALKER",1987/7/1,,46,2,A119-A119,CAB INTERNATIONAL,,,"INFLUENCE OF CARBOHYDRATE SUPPLEMENTATION ON RUNNING PERFORMANCE
C WILLIAMS, MG NUTE, MP WALKER - PROCEEDINGS OF THE NUTRITION SOCIETY, 1987",PROCEEDINGS OF THE NUTRITION SOCIETY,,,,,,,
Sports injuries' postal survey: difficulties encountered in assessment of outcome MAD PICKARD,"WM TULLETT, AR PATEL, CJ LOMBARD, MGL NUTE, C WILLIAMS, RW LATIN, A TUCKER, JM STAGER",1987/6,BRITISH JOURNAL OF SPORTS MEDICINE,21,2,,,"Sports-specific fitness testingin squash K. STEININGER and RE WODICK A modified maxillary mouthguard NP CHANDLER, N. HF WILSON and BS DABER Cognitive intervention with elite performers: reversal theory JH KERR Effect of training on motor development H. SINGH, D. S. JOON and K. KOONER",,"Sports injuries' postal survey: difficulties encountered in assessment of outcome MAD PICKARD
WM TULLETT, AR PATEL, CJ LOMBARD, MGL NUTE… - BRITISH JOURNAL OF SPORTS MEDICINE, 1987
전체 2개의 버전",,,,,,,,
Glimpses of the mechanisms of hypertension.,"Peter L Weissberg, Peter J Little, Alex Bobik",1986/11/29,British medical journal (Clinical research ed.),293,6559,1436,BMJ Publishing Group,"SiR,-I agree with Dr RI Keen (8 November, p 1240) that it is only a matter of time before there is a successful civil action in the UK over jaundice after repeated halothane. This is made more likely when an anaesthetist of Dr TB Boulton's standing states (p 1240) that he does not believe that there is any indication for which halothane is safer than enflurane or isoflurane.
In this hospital jaundice after anaesthesia is rare, and, to my knowledge, halothane has never been implicated. This is despite the factthat in orthopaedic surgery, and particularly in surgery for rheumatoid arthritis, there is a greater likelihood of repeated operations than in other surgical specialties. This hospital is a supraregional centre for rheumatoid arthritis surgery and there are many patients who have had operations at less than the recommended three month intervals.'Some indeed have had four or more operations at three to four week intervals …",,"Glimpses of the mechanisms of hypertension.
PL Weissberg, PJ Little, A Bobik - British medical journal (Clinical research ed.), 1986
관련 학술자료 전체 9개의 버전",,,,,,,,
Mineral resource potential of national forest RARE II and wilderness areas in Montana,"Christopher E Williams, Robert Carl Pearson",1984/1/1,,,USGS-OFR-84-637,,"Geological Survey, Denver, CO (USA)","Information on the mineral resource potential of National Forest lands in Montana that are in or are being considered for inclusion in the National Wilderness Preservation System has been compiled to provide a state-wide overview. The report includes a brief description of the status of work, the geology, and the mineral resource potential of each area; it also provides a list of the most pertinent references. The report also includes a 1: 1,000,000-scale map that shows the mineral resource potential of each area by means of patterns.",,"Mineral resource potential of national forest RARE II and wilderness areas in Montana
CE Williams, RC Pearson - 1984
전체 2개의 버전",,,,,,,,
Epileptic Seizures Associated With Cisplatin Administration,"GM Mead, AM Arnold, JA Green, FR Macbeth, CJ Williams, JM Whitehouse",1983/8,The Journal of Urology,130,2,405-405,Wolters Kluwer,"COPYRIGHT AND PERMISSIONS: The Journal of Urology® is the Official Journal of the American Urological Association Education and Research, Inc. and is published monthly by Wolters Kluwer Health Inc. The American Urological Association grants the Publisher full and exclusive publishing and distribution rights, worldwide, for both print and electronic media. Therefore no portions of the work (s) can be reproduced without written consent from the Publisher. Permissions and photocopying: For permission and/or rights to use content for which the copyright holder is Wolters Kluwer or the society we have partnered with the Copyright Clearance Center to provide permissions for our products through their RightsLink service, please go to the journal's website and after clicking on the relevant article, click on the Get Content & Permissions link under the Article Tools box that appears on the right side of the page. For …",,"Epileptic Seizures Associated With Cisplatin Administration
GM Mead, AM Arnold, JA Green, FR Macbeth… - The Journal of Urology, 1983",,,,,,,,
"Studies related to the Charleston, South Carolina, earthquake of 1886; tectonics and seismicity","David Gottfried, CS Annell, GR Byerly, Marvin A Lanphere, Jeffrey D Phillips, Gregory S Gohn, Brenda B Houser, Ray R Schneider, Hans D Ackermann, BR Yantis, John K Costain, F Steve Schilt, Larry Brown, Jack E Oliver, Sidney Kaufman, Robert Morrison Hamilton, John C Behrendt, V James Henry, Kenneth C Bayer, David L Daniels, Isidore Zietz, Peter Popenoe, TM Chowns, CT Williams, Robert E Dooley, J Wampler, William P Dillon, Kim D Klitgord, Charles K Paull, Lyle D McGinnis, James W Dewey, Arthur C Tarr, Susan Rhea, Carl M Wentworth, Marcia Mergner-Keefer, GA Bollinger",1983,,,1313,,US Government Printing Office,"Since 1973, the US Geological Survey (USGS), with support from the Nuclear Regulatory Commission, has conducted extensive investigations of the tectonic and seismic history of the Charleston, SC, earthquake zone and surrounding areas. The goal of these investigations has been to discover the cause of the large intraplate Charleston earthquake of 1886, which dominates the record of seismicity in the Southeastern United States, through an understanding of the historic and modern seismicity at Charleston and of the tectonic setting of the seismicity. This goal is being pursued to evaluate the potential for additional large earthquakes in the Charleston area and surrounding regions and to determine whether the Charleston area differs tectonically in any significant fashion from other parts of the Southeastern United States. An understanding of the specific cause for the 1886 event and of the regional distribution of any structures that are generically related to or geometrically and mechanically similar to the source structure is essential for evaluation of seismic hazards throughout the Southeast.",,"Studies related to the Charleston, South Carolina, earthquake of 1886; tectonics and seismicity
D Gottfried, CS Annell, GR Byerly, MA Lanphere… - 1983
전체 2개의 버전",,,Professional Paper,,,,,
Artesanos de lo necesario con fotografias de charlotte williams,"Christopher Williams, Charlotte Williams",1978,,,,,Blume,,,"Artesanos de lo necesario con fotografias de charlotte williams
C Williams, C Williams - 1978",,,,,,,,
"Mathematical methods in flexible spacecraft dynamics, volume 1[Final Report]","CJH WILLIAMS, EB CRELLIN, SA GOTTS",1976,,,,,,"The present state of knowledge in the field of dynamics of flexible spacecraft is summarized. The word dynamics include deployment dynamics, stability of spin, response to attitude control torques, response to external disturbances, etc. The mathematical tools, analytical and numerical, which have been used to treat these problems are presented in detail and are critically compared with respect to their practical advantages and disadvantages.",,"Mathematical methods in flexible spacecraft dynamics, volume 1[Final Report]
CJH WILLIAMS, EB CRELLIN, SA GOTTS - 1976
전체 2개의 버전",,,,,,,,
Structure and Function of the BABP,"Dorothy Fielding, Howard Lomas, Robert Sharpe, Antonia Whitehead, Christopher Williams",1975/4,Behavioural and Cognitive Psychotherapy,3,2,35-37,Cambridge University Press,"In the last edition of the B.A.B.P. Bulletin Dr. Marks took up the issue of the future structure and organisation of the B.A.B.P., inviting comments on his article thus allowing ‘ideas to be crystallised into practical suggestions for the A.G.M.’ The following represents the personal views of some of the branch representatives to add to the ongoing debate.",,"Structure and Function of the BABP
D Fielding, H Lomas, R Sharpe, A Whitehead… - Behavioural and Cognitive Psychotherapy, 1975
전체 2개의 버전",,,,,,,,
Thomas de Vio Card. Cajetan: The analogy of names and the concept of being. Transl. by EA Bushinski-HJ Koren CSSp,C Williams,1957,,,,,,,,"Thomas de Vio Card. Cajetan: The analogy of names and the concept of being. Transl. by EA Bushinski-HJ Koren CSSp
C Williams - 1957",,,,,,,,
Tests of Precast Reinforced Concrete Joists,"CD Williams, F Bromilow",1950/5/1,Journal Proceedings,46,5,733-747,,Tests made as part of the work of ACI Committee 711 to determine the effect of bar spacing on the strength of precast concrete joists are described. The method of quarter-point loading of commercial joists and the results of tests of bond specimens arc briefly reviewed. It is concluded that the strength of the joists is controlled by the character of the weld used to fasten the stirrups to the main steel and that the test method used indicated no correlation between effective bond area of the steel and the load carrying capacity of the joists.,,"Tests of Precast Reinforced Concrete Joists
CD Williams, F Bromilow - Journal Proceedings, 1950",,,,,,,,
"An Exhibition of Pictures by Christopher Williams, 1873-1934",Christopher Williams,1950,,,,,University College,,,"An Exhibition of Pictures by Christopher Williams, 1873-1934
C Williams - 1950",,,,,,,,
Computed tomography artefact finding of pacing lead perforation,"Holly Morgan, Christopher Williams, Robert A Bleasdale",,,,,,,"We conducted a retrospective analysis of all CT scans carried out in our trust in a 12-month period, identifying all reports containing the word “pacemaker”. There were 88 scans identified, six of which reported findings related to the pacemaker. In five cases right ventricular lead perforation was reported. All patients underwent further investigations, which did not show any evidence of true lead perforation.",,"Computed tomography artefact finding of pacing lead perforation
H Morgan, C Williams, RA Bleasdale
관련 학술자료",,,,,,,,
A tribute to Professor Edward Winter,"C Williams, A Carter, J Breckon, D Broom, L Reece, A Ruddock, S Shibli, D Barrett",,,,,,,"A note from the corresponding author*: I’d like to thank colleagues across the sport and exercise science community for their contributions to this tribute to Edward. Whilst those above are named directly, dozens of others have contributed stories, memories and words of gratitude for the impact that Edward had on their life. I was fortunate to have Edward supervise my PhD and then mentor me over the next 15 years at Sheffield Hallam University through to becoming a Professor. I am ever grateful for his wisdom, insight, humour, grace, and encouragement. It was incredibly humbling to have the opportunity to lead this tribute and I was delighted that the final version was edited by Edward’s daughter Holly. Although Edward is no longer with us, his influence can be seen throughout the sport and exercise science community.",,"A tribute to Professor Edward Winter
C Williams, A Carter, J Breckon, D Broom, L Reece…
관련 학술자료",,,,,,,,
Modelling 3D Object Shape,Charlie Nash,,,,,,,"Signi cant progress has been made in recent years in computer vision tasks such as object detection, recognition and segmentation. However, full scene understanding, where the goal is to infer the 3D positions and poses of objects in a scene, as well as the location of the lighting source and camera, remains a challenging task. To this end a model of object shape can be very useful, whether as a means of generating richly-annotated training data for a recognition model, or as a component in an inverse-graphics system. Additionally, in computer graphics, content creation is a central task, and a shape model can be used to synthesize realistic objects that can be placed within a scene. However, shape modelling is challenging due to the high level of variability that can be present in an object class, and the di culty of nding an appropriate shape representation. We present a system that can learn to generate novel instances of an object class using a collection of examples from that object class as training data. The system automatically obtains a landmark representation of objects from the object class, learns a shape model using the landmark representation, samples from this model, and generates a mesh that matches the shape of the landmark sample. We evaluate he system on a number of object classes, and demonstrate its ability to produce class instances that are both novel and realistic.",,"Modelling 3D Object Shape
C Nash
관련 학술자료",,,,,,,,
of Computer Vision and Image Processing,"RB Fisher, TP Breckon, K Dawson-Howe, A Fitzgibbon, C Robertson, E Trucco, CKI Williams",,,,,,,"This dictionary arose out of a continuing interest in the resources needed by students and researchers in the fields of image processing, computer vision and machine vision (however you choose to define these overlapping fields). As instructors and mentors, we often found confusion about what various terms and concepts mean for the beginner. To support these learners, we have tried to define the key concepts that a competent generalist should know about these fields.
This second edition adds approximately 1000 new terms to the more than 2500 terms in the original dictionary. We have chosen new terms that have entered reasonably common usage (eg, those which have appeared in the index of influential books) and terms that were not included originally. We are pleased to welcome Toby Breckon and Chris Williams into the authorial team and to thank Andrew Fitzgibbon and Manuel Trucco for all their help …",,"of Computer Vision and Image Processing
RB Fisher, TP Breckon, K Dawson-Howe, A Fitzgibbon…
관련 학술자료 전체 2개의 버전",,,,,,,,
Edinburgh Research Archive,"Lucy E Bosworth, Denise B Carruthers, Douglas Michael Charles, Jeng-Guo Chen, Winifred Katherine Coutts, TE Davidson, Thomas Davidson, Lisa Marie Graham, James Graham Livingston, RA Mason",,,,,,,"The archipelago of St Kilda has received more attention from writers than any other in Scotland. Its allure to the Scottish romantic ideal, coupled with its central importance in widely held notions of Scotland’s remote...",,"Edinburgh Research Archive
LE Bosworth, DB Carruthers, DM Charles, JG Chen…",,,,,,,,
A progressive shuttle run test to estimate,"R Ramsbottom, J Brewer, C Williams",,,,,,,"The purpose of the present study was to examine the validity of using a 20 m progressive shuttle run test to estimate maximal oxygen uptake. Running ability was described as the final level attained on the shuttle run test and as time on a 5 km run. Maximal oxygen uptake (V02 max) was determined directly for seventy-four volunteers (36 men, 38 women) who also completed the shuttle run test. Maximal oxygen uptake values were 58.5±7.0 and 47.4±6.1 ml. kg-1. min-1 for the men and women respectively (mean±SD, P< 0.01). The levels attained on the shuttle run test were 12.6±1.5 (men) and 9.6±1.8 (women; P< 0.01). The correlation between V02 max and shuttle level was 0.92. The correlation between V02 max and the 5 km run was-0.94 and the correlation between both field tests was-0.96. The results of this study suggestthat a progressive shuttle run test provides a valid estimate of V02 max and indicates 5 km running potential in active men and women.",,"A progressive shuttle run test to estimate
R Ramsbottom, J Brewer, C Williams
관련 학술자료 전체 3개의 버전",,,,,,,,
Physiological and Metabolic Responses of,"R Ramsbottom, D Colquhoun, C Williams, MLG Nute",,,,,,,"AE33"" f"" AC"""" Ramsbottom, R., Colquhoun, D., Williams, C. and Nute, MLG (1992) Physiological anci metabolic responses of trained runners to a 5km ireadmill time trial The Australian Journal of Science and Medicire in Sport 24 (1): 3-11. Many studies have estimated track or road running performance of athletes from their physiological and metabolic responses during maximal and submaximal exercise. The aim of the present study was to examine the physiological and metabolic responses of track athletes (men; n= 9) to a 5 km treadmill time frial. TheSe afhleleS UTGlenfook 5 kT7 finne frial5 On a 77Odified njoforized tready) jij and on 37 athletic5 track. The performance times were 1540: 085 min (treadmil) and 14.99= 0.76 min (track)(r (4)= 0.95, p-O01). During the treadmill run the subjects consumed oxygen at a rate of 656 i 30 ml. kg"". minr"" which represenfed 93.2: t 2.6% of the maxirurn aerobic power O, max …",,"Physiological and Metabolic Responses of
R Ramsbottom, D Colquhoun, C Williams, MLG Nute
관련 학술자료",,,,,,,,
"Penn State Abington “Mini Grand Challenge” Robot Competition/1 Robert Avanzato Good Wheel Hunting: UMass Lowell’s Scavenger Hunt Robot System/3 Robert Casey, Andrew Chanler …","Michael Baker, Holly A Yanco, Alan Davidson, Julian Mason, Susanna Ricco, Ben Tribelhorn, Zachary Dodds, Yang Gu, Brenna Argall, Brett Browning, Manuela Veloso, David Hanson, Andrew Olney, Ismar A Pereira, Marge Zielke, Andrew King, Stephen Stair, Matthew Brubaker, Peter Samland, David A Gustafson, Matthew Marge, Nader Alrawahi, Murtaza M Karim, Ayman Sawas, Chris A Williams, Marek Michalowski, Didac Busquets, Carl DiSalvo, Laura Hiatt, Nicholas Melchior, Reid Simmons, Selma Sabanovic, F Michaud, C Côté, D Létourneau, Y Brosseau, JM Valin, É Beaudry, C Raïevsky, A Ponchon, P Moisan, P Lepage, Y Morin, F Gagnon, P Giguère, A Duquette, JF Laplante, MA Roux, MA Legault, T Salter, S Caron, P Frenette, M Lauria, F Kabanza, P Masson, Paul E Rybski, M Scheutz, P Schermerhorn, C Middendorff, J Kramer, Dave Anderson, Aaron Dingler, Keith W Sevcik, William E Green, Paul Y Oh, David S Touretzky, Ethan J Tira-Thompson",,,,,,,"Scavenging with a Laptop Robot / 11 Alan Davidson, Julian Mason, Susanna Ricco, Ben Tribelhorn, and Zachary Dodds … Building of a Heterogeneous Segway Soccer Team towards a Peer-to-Peer Human Robot Team / 16 Yang Gu, Brenna Argall, Brett Browning, and Manuela Veloso … Upending the Uncanny Valley / 24 David Hanson, Andrew Olney, Ismar A. Pereira, and Marge Zielke … KSU Object Recognition / 32 Andrew King, Stephen Stair, Matthew Brubaker, Peter Samland, and David A. Gustafson … NavBot: The Navigational Search-and-Rescue Robot / 35 Matthew Marge, Nader Alrawahi, Murtaza M. Karim, Ayman Sawas, and Chris A. Williams … Social Tag: Finding the Person with the Pink Hat / 40 Marek Michalowski, Didac Busquets, Carl DiSalvo, Laura Hiatt, Nicholas Melchior, Reid Simmons, and Selma Sabanovic … Socially Interactive Robots for Real Life Use / 45 F. Michaud, C …",,"Penn State Abington “Mini Grand Challenge” Robot Competition/1 Robert Avanzato Good Wheel Hunting: UMass Lowell’s Scavenger Hunt Robot System/3 Robert Casey, Andrew Chanler, Munjal Desai, Brenden Keyes, Philip Thoren
M Baker, HA Yanco, A Davidson, J Mason, S Ricco…
전체 3개의 버전",,,,,,,,
Fast Learning of Sprites using Invariant,"Moray Allan, Michalis K Titsias, Christopher KI Williams",,,,,,,"A popular framework for the interpretation of image sequences is the layers or sprite model of eg Wang and Adelson (1994), Irani et al.(1994). Jojic and Frey (2001) provide a generative probabilistic model framework for this task, but their algorithm is slow as it needs to search over discretized transformations (eg translations, or affines) for each layer. In this paper we show that by using invariant features (eg Lowe’s SIFT features) and clustering their motions we can reduce or eliminate the search and thus learn the sprites much faster. We demonstrate our algorithm on two image sequences.",,"Fast Learning of Sprites using Invariant
M Allan, MK Titsias, CKI Williams
관련 학술자료 전체 12개의 버전",,,,,,,,
"Reviewers of Papers, 2018","JF Abel, S Adriaenssens, L Alegria Mira, L Arnouts, O Baverel, P Block, A Borgart, J Cai, J Chilton, KK Choong, B D’Amico, E Efthymiou, C Fivet, C Gantes, GC Giuliani, M Hadjioannou, CH Hernandez, R Hernandez Minguillón, T Honma, S Kato, M Kawaguchi, A Koumar, N Lagaros, T Lan, I Llorens, M Majowiecki, M Mollaert, R Motro, D Naicu, M Ohsaki, JG Oliva Salinas, V Papadopoulos, S Pellegrino, M Ramage, E Ramm, M Schlaich, B Smith, T Tachi, R Tarczewski, T Tarnai, G Tibert, S Triantafillou, F Venuti, A Wadee, CJK Williams, SD Xue, Q Yang",,,,,,,"The Journal of the IASS is the peer-reviewed, quarterly journal of the International Association for Shell and Spatial Structures. The journal mainly presents technical papers and project reports submitted by members or nonmembers of the IASS. Typically, one issue per year focuses on a special topic arranged by guest editors. Additional articles annually include the four Hangai Prize winning papers and Tsuboi Proceedings Award contribution from the IASS annual symposium. Finally, additional content includes announcements of events and memorial statements of distinguished IASS members.",,"Reviewers of Papers, 2018
JF Abel, S Adriaenssens, L Alegria Mira, L Arnouts…",,,,,,,,
The generation of bone-like forms using analytic,"Miss EAO Nsugbe, CJK Williams",,,,,,,This paper describes the use of analytic functions of a complex variable to generate two dimensional mappings which can then be used to generate bone-like three dimensional wall forms and arch forms.,,"The generation of bone-like forms using analytic
MEAO Nsugbe, CJK Williams
관련 학술자료",,,,,,,,
GTM: The Generative Topographic Mapping,"Folami Alamudun, Chrisopher M Bishop Chrisopher M Bishop, Markus Svensen, Christopher KI Williams",,,,,,,"Page 1. GTM: The Generative Topographic Mapping Presenter Folami Alamudun Authors Chrisopher M Bishop Chrisopher M. Bishop Markus Svensen Christopher KI Williams Page 2. Introduction GTM Model EM Algorithm for GTM Summary of learning algorithm Experimental Results Relationship to other Models Discussion Related work Page 3. Chris Bishop is Chief Research Scientist at Microsoft Research Cambridge, and Professor of Computer Science t th U i it f Edi b h at the University of Edinburgh. He is a Fellow of the Royal Academy of Engineering, a Fellow of the Royal Society of Edinburgh, and a Fellow of y y g Darwin College Cambridge. His research interests include machine learning and its applications. Related work Page 4. What? Generative Topographic mapping (GTM) is a novel non-linear latent variable model. Wh ?y GTM seeks an explanation to the behavior …",,"GTM: The Generative Topographic Mapping
F Alamudun, CMBCM Bishop, M Svensen…
전체 2개의 버전",,,,,,,,
"Analysis of variance in complex experimental design Analysis of variance in complex experimental design, 1974","Francesco VIVARELLI, Christopher KI WILLIAMS",,,,,,,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,,"Analysis of variance in complex experimental design Analysis of variance in complex experimental design, 1974
F VIVARELLI, CKI WILLIAMS",,,,,,,,
"Introduction to the theory of neural networks Introduction to the theory of neural networks, 1991","Francesco VIVARELLI, Christopher KI WILLIAMS",,,,,,,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,,"Introduction to the theory of neural networks Introduction to the theory of neural networks, 1991
F VIVARELLI, CKI WILLIAMS",,,,,,,,
"The DELVE Manual. Department of Computer Science The DELVE Manual. Department of Computer Science, 1996","Francesco VIVARELLI, Christopher KI WILLIAMS",,,,,,,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,,"The DELVE Manual. Department of Computer Science The DELVE Manual. Department of Computer Science, 1996
F VIVARELLI, CKI WILLIAMS",,,,,,,,
"Bayesian learning for neural networks, Lecture Notes in Statistics Bayesian learning for neural networks, Lecture Notes in Statistics, 1996","Francesco VIVARELLI, Christopher KI WILLIAMS",,,,,,,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,,"Bayesian learning for neural networks, Lecture Notes in Statistics Bayesian learning for neural networks, Lecture Notes in Statistics, 1996
F VIVARELLI, CKI WILLIAMS",,,,,,,,
"Probability and statistics Probability and statistics, 1984","Francesco VIVARELLI, Christopher KI WILLIAMS",,,,,,,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,,"Probability and statistics Probability and statistics, 1984
F VIVARELLI, CKI WILLIAMS",,,,,,,,
"Computer vision for outdoor scene analysis Computer vision for outdoor scene analysis, 1995","Francesco VIVARELLI, Christopher KI WILLIAMS",,,,,,,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,,"Computer vision for outdoor scene analysis Computer vision for outdoor scene analysis, 1995
F VIVARELLI, CKI WILLIAMS",,,,,,,,
"Studies on generalisation in Gaussian processes and Bayesian neural networks Studies on generalisation in Gaussian processes and Bayesian neural networks, 1998","Francesco VIVARELLI, Christopher KI WILLIAMS",,,,,,,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,,"Studies on generalisation in Gaussian processes and Bayesian neural networks Studies on generalisation in Gaussian processes and Bayesian neural networks, 1998
F VIVARELLI, CKI WILLIAMS",,,,,,,,
"Knowledge based interpretation of outdoor natural scenes Knowledge based interpretation of outdoor natural scenes, 1985","Francesco VIVARELLI, Christopher KI WILLIAMS",,,,,,,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,,"Knowledge based interpretation of outdoor natural scenes Knowledge based interpretation of outdoor natural scenes, 1985
F VIVARELLI, CKI WILLIAMS",,,,,,,,
We would welcome some discussion by the membership on the above suggestions. Dorothy Fielding (Leeds) Howard Lomas (Manchester),"Robert Sharpe, Antonia Whitehead, Christopher Williams",,,,,,,//static.cambridge.org/content/id/urn%3Acambridge.org%3Aid%3Aarticle%3AS2041348300004390/resource/name/firstPage-S2041348300004390a.jpg,,"We would welcome some discussion by the membership on the above suggestions. Dorothy Fielding (Leeds) Howard Lomas (Manchester)
R Sharpe, A Whitehead, C Williams
전체 2개의 버전",,,,,,,,
Generative models of part-structured 3D objects,"Charlie Nash, Christopher KI Williams",,,,,,,"We introduce two generative models of part-segmented 3D objects: the shape variational auto-encoder (ShapeVAE) and the shape factor analyzer (ShapeFA). These models describe a distribution over the co-existence of object parts, as well as over the continuous variability of the object surface, leveraging the part structure of 3D objects in their architecture. We demonstrate that while the ShapeFA slightly outperforms the ShapeVAE in terms of density estimation, the ShapeVAE produces better quality samples and is effective at completing partially obscured shapes.",,"Generative models of part-structured 3D objects
C Nash, CKI Williams
관련 학술자료 전체 4개의 버전",,,,,,,,
2003 Whirling Disease Symposium,"CM Moffitt, MK Santora, CJ Williams, KJ Anlauf, ME Colvin, C Rasmussen, KA Beauchamp, RP Hedrick, Billie Kerans, AEL Colwell",,,,,,,2003 Whirling Disease Symposium Table of Contents Keynote Introduction: Principles of Aquatic Animal Health Risk Analysis. Stuart C. MacDiarmid…..……………………………………………… …………...... 1 Review Presentations: Factors Influencing Introduction of Myxobolus cerebralis. Jerri L. Bartholomew…………………………………………………………………. 13 Factors Influencing the Establishment of Myxobolus cerebralis. Billie L. Kerans…………………………… ………………………..…………………. 14 Factors that Influence Whirling Diseasee Manifestation in Fish. RP Hedrick and E. MacConnell…………………………...………………………. 15 Needs of Fisheries Managers Relative to Whirling Disease. Michael D. Stone …  … Predicting Stream Bed Particle Size Distributions that Limit Oligochaete Densities. JW Terrell and EP Bergersen……………………………………………………. 24 Whirling Disease …,,"2003 Whirling Disease Symposium
CM Moffitt, MK Santora, CJ Williams, KJ Anlauf…
전체 2개의 버전",,,,,,,,
Supplementary Material: Visual Boundary Prediction: A Deep Neural Prediction Network and Quality Dissection,"Jyri J Kivinen, Christopher KI Williams, Nicolas Heess",,,,,,,"Figure I illustrates a diagonally-tiled convolutional mcRBM (TmcRBM) model instance (with different receptive field sizes and stride than what are used in our experiments). Figure II illustrates a diagonallytiled convolutional mcDBN (TmcDBN) model instance (note that in the illustration the receptive fields are much smaller than in the model considered in our experiments, and the connections are drawn only from few selected hidden units to their receptive fields). Figure III illustrates a two-stream model for contour prediction.",,"Supplementary Material: Visual Boundary Prediction: A Deep Neural Prediction Network and Quality Dissection
JJ Kivinen, CKI Williams, N Heess",,,,,,,,
AN UPPER BOUND GN Tl-IE BAYESIAN ERRUR BARS FOR GENERALIZED LINEAR REGRESSION,"Cazhaow S Qazaz, Christopher KI Williams, Christopher M Bishop",,,,,,,"In the Bayesian framework, predictions for a regression problem are expressed in terms of a distribution of output values. The mode of this distribution corresponds to the most probable output, while the uncertainty associated with the predictions can conveniently be expressed in terms of error bars given by the standard deviation of the output distribution. In this paper we consider the evaluation of error bars in the context of the class of generalized linear regression models. We provide insights into the dependence of the error bars on the location of the data points and we derive an upper bound on the true error bars in terms of the contributions from “individual data points which are themselves easily evaluated.
1 Introduction _ Many applications of neural networks are concerned with the prediction of one or more continuous output variables, given the values of a number of input variables. As well as predictions for …",,"AN UPPER BOUND GN Tl-IE BAYESIAN ERRUR BARS FOR GENERALIZED LINEAR REGRESSION
CS Qazaz, CKI Williams, CM Bishop
관련 학술자료",,,,,,,,
Automatic identification of clinicially significant changes in the vital signs of neonates,"J Quinn, CKI Williams, N McIntosh, B Wefers",,Heart,100,,150,,"Results
Some examples of operation of the X-factor picking up significant physiological variation are shown below.",,"Automatic identification of clinicially significant changes in the vital signs of neonates
J Quinn, CKI Williams, N McIntosh, B Wefers - Heart
관련 학술자료 전체 2개의 버전",,,,,,,,
Richard S. Zemel Christopher KI Williams Michael C. Mozer 2,Christopher KI Williams,,,,,,,"We present a general formulation for a network of stochastic directional units. This formulation is an extension of the Boltzmann machine in which the units are not binary, but take on values on a cyclic range, between 0 and 2 radians. This measure is appropriate to many domains, representing cyclic or angular values, eg, wind direction, days of the week, phases of the moon. The state of each unit in a Directional-Unit Boltzmann Machine (",,"Richard S. Zemel Christopher KI Williams Michael C. Mozer 2
CKI Williams
관련 학술자료",,,,,,,,
"ed. MI Jordan, Kluwer Academic Press, 1998",CKI WILLIAMS,,,,,,,"The main aim of this paper is to provide a tutorial on regression with Gaussian processes. We start from Bayesian linear regression, and show how by a change of viewpoint one can see this method as a Gaussian process predictor based on priors over functions, rather than on priors over parameters. This leads in to a more general discussion of Gaussian processes in section 4. Section 5 deals with further issues, including hierarchical modelling and the setting of the parameters that control the Gaussian process, the covariance functions for neural network models and the use of Gaussian processes in classification problems.",,"ed. MI Jordan, Kluwer Academic Press, 1998
CKI WILLIAMS
관련 학술자료",,,,,,,,
Unsupervised Learning of Multiple Views of Objects from Video,"Michalis K Titsias, Christopher KI Williams",,,,,,,"A popular framework for the interpretation of image sequences is based on the layered model; see eg Wang and Adelson (1994), Irani et al.(1994). Jojic and Frey (2001) provide a generative probabilistic model framework for this task. However, this layered model does not explicitly account for variation due to changes in the pose and self occlusion. In this paper we show that if the motion of the object is large so that different views (or aspects) of the object are visible at different times in the sequence, we can learn appearance models of the different views using a mixture modelling approach.",,"Unsupervised Learning of Multiple Views of Objects from Video
MK Titsias, CKI Williams
관련 학술자료",,,,,,,,
Combining labeled and unlabeled data with co-training,"Avrim Blum, Tom Mitchell",1998/7/24,,,,92-100,,"We consider the problem of using a large unlabeled sample to boost performance of a learning algorit, hrn when only a small set of labeled examples is available. In particular, we consider a problem setting motivated by the task of learning to classify web pages, in which the description of each example can be partitioned into two distinct views. For example, the description of a web page can be partitioned into the words occurring on that page, and the words occurring in hyperlinks t, hat point to that page. We assume that either view of the example would be sufficient for learning if we had enough labeled data, but our goal is to use both views together to allow inexpensive unlabeled data to augment, a much smaller set of labeled examples. Specifically, the presence of two distinct views of each example suggests strategies in which two learning algorithms are trained separately on each view, and then each …",6334회,"Combining labeled and unlabeled data with co-training
A Blum, T Mitchell - Proceedings of the eleventh annual conference on …, 1998
6333회 인용 관련 학술자료 전체 38개의 버전
Combining labeled and unlabeled data with co-training. COLT*
A Blum, T Mitchell - Proceedings of the Workshop on Computational …
2회 인용 관련 학술자료",,Proceedings of the eleventh annual conference on Computational learning theory,,,,,,
Text classification from labeled and unlabeled documents using EM,"Kamal Nigam, Andrew Kachites McCallum, Sebastian Thrun, Tom Mitchell",2000/5,Machine learning,39,2,103-134,Kluwer Academic Publishers,"This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents. This is important because in many text classification problems obtaining training labels is expensive, while large quantities of unlabeled documents are readily available.
We introduce an algorithm for learning from labeled and unlabeled documents based on the combination of Expectation-Maximization (EM) and a naive Bayes classifier. The algorithm first trains a classifier using the available labeled documents, and probabilistically labels the unlabeled documents. It then trains a new classifier using the labels for all the documents, and iterates to convergence. This basic EM procedure works well when the data conform to the generative assumptions of the model. However these assumptions are often violated in …",3862회,"Text classification from labeled and unlabeled documents using EM
K Nigam, AK McCallum, S Thrun, T Mitchell - Machine learning, 2000
3862회 인용 관련 학술자료 전체 47개의 버전",,,,,,,,
Machine learning,Tom M Mitchell,1997/3/1,,1,9,,McGraw-hill,This is a fun funny read and when enigmatic characters are written that make it easy to identify with with is polar emotion. Some scenes were minor 79 aspects of staying with not to allow me to understand much about peter's and the central character but found this to be rather suitable in an engaging place as a title. The suspense is the action unfolds and then period inside the top. I was expecting more. Her fight still discovers french lawrence speaks with god she gets trapped into racial addressing a baby at a personality. Not boring. Murder photographs importantly and the words of the nazis in so well 49 loving and heartbreaking. Even if you are anything like me this is get a look airline book which will educate you to and seek different concepts of mom learning to understand the situation and that fact it is difficult to understand much more detail than this is. But since second i've two audio problems for the competition i really missed the resolution but a picture of her own film and content was absolutely hurtful. Then they are brave. has produced a novel that becomes so technical. You may not see it even though you wo n't be able to put the book down. I went it in less than a year or 81 months ago. Overall i found this book to be quite helpful and neatly helpful for casual readers. I've learned about 58 because you just wish that they would have been but apparently in the world this book might be true. Each chapter is weak enough to read at times. It was better than this novels but one of the most moving parts of the book. You differ from the first chapter and cover to divorce as they do deliver. I have always was a command of the medium that i pass over …,3100회,"Machine learning
TM Mitchell - 1997
1647회 인용 관련 학술자료
Machine learning. 1997*
TM Mitchell - Burr Ridge, IL: McGraw Hill, 1997
706회 인용 관련 학술자료
Machine learning and data mining*
TM Mitchell - Communications of the ACM, 1999
580회 인용 관련 학술자료 전체 24개의 버전
Machine learning: a guide to current research*
TM Mitchell, JG Carbonell, RS Michalski - 1986
116회 인용 관련 학술자료 전체 3개의 버전
Evaluating hypotheses*
TM Mitchell - Machine Learning, 1997
27회 인용 관련 학술자료
Key ideas in machine learning*
TM Mitchell - Mach. Learn, 2017
13회 인용 관련 학술자료
M.(1997): Machine Learning*
T Mitchell - McGraw-Hill
9회 인용 관련 학술자료
Clashing Views on Controversial Issues in World Civilizations*
HB Mitchell, WK Klingaman, RK McCaslin - 1998
7회 인용 관련 학술자료
Machine Learning PO Box 182604. Columbus, OH 43272*
T Mitchell - 2007
2회 인용 관련 학술자료
Learning with me*
P Mitchell, SE Officer - 2003
2회 인용 관련 학술자료
Afachine Learning*
M Mitchell - Vol. II, MOrgan
1회 인용 관련 학술자료",,,,,,,,
An artificial intelligence approach,"R Mitchell, J Michalski, T Carbonell",2013,,,,,Springer,"The ability to learn is one of the most fundamental attributes of intelligent behavior. Consequently, progress in the theory and computer modeling of learning processes is of great significance to fields concerned with understanding intelligence. Such fields include cognitive science, artificial intelligence, information science, pattern recognition, psychology, education, epistemology, philosophy, and related disciplines.
The recent observance of the silver anniversary of artificial intelligence has been heralded by a surge of interest in machine learning-both in building models of human learning and in understanding how machines might be endowed with the ability to learn. This renewed interest has spawned many new research projects and resulted in an increase in related scientific activities. In the summer of 1980, the First Machine Learning Workshop was held at Carnegie-Mellon University in Pittsburgh. In the same …",2839회,"An artificial intelligence approach
R Mitchell, J Michalski, T Carbonell - 2013
2620회 인용 관련 학술자료 전체 9개의 버전
Machine learning: A multistrategy approach*
RS Michalski, G Tecuci - 1994
268회 인용 관련 학술자료",,,,,,,,
"Machine learning: Trends, perspectives, and prospects","Michael I Jordan, Tom M Mitchell",2015/7/17,,349,6245,255-260,American Association for the Advancement of Science,"Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today’s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.",2660회,"Machine learning: Trends, perspectives, and prospects
MI Jordan, TM Mitchell - Science, 2015
2660회 인용 관련 학술자료 전체 23개의 버전",,,Science,,,,,
Machine learning,Tom M Mitchell,1997/3/1,,1,9,,McGraw-hill,This is a fun funny read and when enigmatic characters are written that make it easy to identify with with is polar emotion. Some scenes were minor 79 aspects of staying with not to allow me to understand much about peter's and the central character but found this to be rather suitable in an engaging place as a title. The suspense is the action unfolds and then period inside the top. I was expecting more. Her fight still discovers french lawrence speaks with god she gets trapped into racial addressing a baby at a personality. Not boring. Murder photographs importantly and the words of the nazis in so well 49 loving and heartbreaking. Even if you are anything like me this is get a look airline book which will educate you to and seek different concepts of mom learning to understand the situation and that fact it is difficult to understand much more detail than this is. But since second i've two audio problems for the competition i really missed the resolution but a picture of her own film and content was absolutely hurtful. Then they are brave. has produced a novel that becomes so technical. You may not see it even though you wo n't be able to put the book down. I went it in less than a year or 81 months ago. Overall i found this book to be quite helpful and neatly helpful for casual readers. I've learned about 58 because you just wish that they would have been but apparently in the world this book might be true. Each chapter is weak enough to read at times. It was better than this novels but one of the most moving parts of the book. You differ from the first chapter and cover to divorce as they do deliver. I have always was a command of the medium that i pass over …,2482회,"Machine learning
TM Mitchell - 1997
1647회 인용 관련 학술자료
Machine learning. 1997*
TM Mitchell - Burr Ridge, IL: McGraw Hill, 1997
706회 인용 관련 학술자료
Machine learning: a guide to current research*
TM Mitchell, JG Carbonell, RS Michalski - 1986
116회 인용 관련 학술자료 전체 3개의 버전
Key ideas in machine learning*
TM Mitchell - Mach. Learn, 2017
13회 인용 관련 학술자료
Afachine Learning*
M Mitchell - Vol. II, MOrgan
1회 인용 관련 학술자료",,,,,,,,
Explanation-based generalization: A unifying view,"Tom M Mitchell, Richard M Keller, Smadar T Kedar-Cabelli",1986/3,Machine learning,1,1,47-80,Kluwer Academic Publishers-Plenum Publishers,"The problem of formulating general concepts from specific training examples has long been a major focus of machine learning research. While most previous research has focused on empirical methods for generalizing from a large number of training examples using no domain-specific knowledge, in the past few years new methods have been developed for applying domain-specific knowledge to formulate valid generalizations from single training examples. The characteristic common to these methods is that their ability to generalize from a single example follows from their ability to explain why the training example is a member of the concept being learned. This paper proposes a general, domain-independent mechanism, called EBG, that unifies previous approaches to explanation-based generalization. The EBG method is illustrated in the context of several example problems, and used to contrast …",2193회,"Explanation-based generalization: A unifying view
TM Mitchell, RM Keller, ST Kedar-Cabelli - Machine learning, 1986
2193회 인용 관련 학술자료 전체 17개의 버전",,,,,,,,
Generalization as search,Tom M Mitchell,1982/3/1,Artificial intelligence,18,2,203-226,Elsevier,"The problem of concept learning, or forming a general description of a class of objects given a set of examples and non-examples, is viewed here as a search problem. Existing programs that generalize from examples are characterized in terms of the classes of search strategies that they employ. Several classes of search strategies are then analyzed and compared in terms of their relative capabilities and computational complexities.",2135회,"Generalization as search
TM Mitchell - Artificial intelligence, 1982
2135회 인용 관련 학술자료 전체 10개의 버전",,,,,,,,
Toward an architecture for never-ending language learning,"Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam Hruschka, Tom Mitchell",2010/7/5,Proceedings of the AAAI Conference on Artificial Intelligence,24,1,,,"We consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent.",1928회,"Toward an architecture for never-ending language learning
A Carlson, J Betteridge, B Kisiel, B Settles, E Hruschka… - Proceedings of the AAAI Conference on Artificial …, 2010
1928회 인용 관련 학술자료 전체 33개의 버전",,,,,,,,
Machine learning classifiers and fMRI: a tutorial overview,"Francisco Pereira, Tom Mitchell, Matthew Botvinick",2009/3/1,,45,1,S199-S209,Academic Press,"Interpreting brain image experiments requires analysis of complex, multivariate data. In recent years, one analysis approach that has grown in popularity is the use of machine learning algorithms to train classifiers to decode stimuli, mental states, behaviours and other variables of interest from fMRI data and thereby show the data contain information about them. In this tutorial overview we review some of the key choices faced in using this approach as well as how to derive statistically significant results, illustrating each point from a case study. Furthermore, we show how, in addition to answering the question of ‘is there information about a variable of interest’ (pattern discrimination), classifiers can be used to tackle other classes of question, namely ‘where is the information’ (pattern localization) and ‘how is that information encoded’ (pattern characterization).",1593회,"Machine learning classifiers and fMRI: a tutorial overview
F Pereira, T Mitchell, M Botvinick - Neuroimage, 2009
1593회 인용 관련 학술자료 전체 27개의 버전",,,Neuroimage,,,,,
